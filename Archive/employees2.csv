job_title,address,employment_type,seniority,min_experience,job_categories,salary_type,salary_range,job_description,job_skills
Data Engineer,1 DEPOT CLOSE 109841,Permanent,Professional,6 years exp,Information Technology,Monthly,"$7,000to$13,000","Hewlett Packard Enterprise is an industry leading Technology Company that enables customers to go further, faster. With the industry’s most comprehensive portfolio, spanning the cloud to the data center to workplace applications, our technology and services help customers around the world make IT more efficient, more productive and more secure.

We have an open position for Data Engineer to join the Global Digital Technology and Innovation team.  This team drives the adoption of new Big Data technologies and advanced analytics for a $26B worldwide business.  The team leads key initiatives across the world sponsored by senior leadership and is responsible for data analytics led innovations and business process improvement.

Key Responsibilities:

Understand business requirement to build reliable data infrastructure using big data technologies
Work with the data engineering team to develop & maintain data pipelines for batch & stream processing.
Build tools suitable to provide data 24x7 for a global team, thru acquiring, monitoring and root cause analysis of data issues
Identify, design, and implement internal process improvements and tools to automate data processing and ensure data integrity while meeting data security standards
Build tools for better discovery and consumption of data for various consumption models in the organization – DataMarts, Warehouses, APIs, Adhoc Data explorations
Architect and create data views from big data store to feed into analysis engines, visualization engines etc.
Work with data scientist and business analytics team to assist in data ingestion and data-related technical issues


Qualifications, Experience & Knowledge Required :

Bachelor’s degree in IT, Computer Science, Software Engineering, Business Analytics or equivalent
Advanced university degree would be additional advantage
Possess 6 years of experience in data warehousing / distributed system (e.g. Hadoop)
Experience with relational SQL and NoSQL DB
Expert in building and optimizing ‘big data’ data pipelines, architectures, and data sets
Experience in data ingestion, cleaning and processing tools.
Excellent experience in data processing using Scala/Python/Java
Proficient in Big data tools and ecosystem (e.g. HIVE, HBase, Kafka, Spark, ...)
Knowledge & practices of SDLC process and agile methodologies
Strong in user requirements gathering, maintenance, and support
Highly organized, self-motivated, pro-active, and able to plan
Experience managing users and vendors is a plus
","['Microsoft Technologies', 'Microsoft Office', 'Scala', 'Data Analysis', 'Innovation', 'Big Data', 'Hadoop', 'efficient', 'Information Technology', 'Data Centre', 'Spark', 'Project Management', 'Engineering', 'help customers', 'HBase', 'Linux', 'Data']"
Senior Data Analyst,"NANYANG TECHNOLOGICAL UNIVERSITY, 50 NANYANG AVENUE 639798","Contract, Full Time",Manager,5 years exp,Information Technology,Monthly,"$4,500to$8,000","Responsibilities:

leading the implementation of Student Data Governance (SDG) framework across Student Admin Departments, Colleges, and Schools; Secretariat support to the SDG Steering Committee Meetings
leading and conducting Data Quality (DQ) Assurance programme across different data areas and monitor DQ via developing DQ dashboard
developing and managing student data catalogue for management reporting and data analytics projects
driving the adoption of NTU Education Dashboards to support decision-making at different level of the University
leading, developing, and managing data analytics projects to provide enhanced insights from student data, such as student profiling, data analysis to support policy maker in relevant policies, predictive analysis of students at-risk, degree programme quality assurance analysis, student quantitative or qualitative feedback analysis using Natural Language Processing (NLP)
training staff in data-related framework, concepts, and competency in data analytics
supporting business data users in student data migration activities (including profiling, cleansing, mapping of data) during the Student Management System (SMS) project implementation

[The role is expected to lead and facilitate, in addition to execution.]
Requirements:

Bachelor / Master’s degree in data sciences / computer science / mathematics
More than 5 years’ working experiences in data analytics / data governance
Possesses technical expertise in data models, database design & development, data mining & machine learning; knowledge in Natural Language Processing (NLP) is an advantage
Good knowledge of and experience with data visualisation tools (e.g., Qlik Sense), and programming languages including Python/R and SQL
Experience in planning and developing data analytic projects to support business needs
Ability to communicate effectively with business users on data-related requirements and outcomes
","['Machine Learning', 'Dashboard', 'Data Analysis', 'Predictive Analysis', 'Natural Language Processing', 'Mathematics', 'Data Quality', 'Data Governance', 'Data Mining', 'SQL', 'Data Migration', 'Database Design', 'Data Analytics', 'Training Staff', 'Data Visualisation']"
Senior Data Engineer,201 JOO CHIAT ROAD 427472,Full Time,Professional,8 years exp,Engineering,Monthly,"$7,000to$10,000","Responsibilities

We have a fantastic opportunity for an experienced Data Engineer to join our global team. This role will play a major part in the delivery of our Group Data Strategy and Data Transformation Journey by delivering, enhancing, and maintaining our company Data Platform which will drive how our data is managed and used to deliver outcomes in a host of key areas to maximise business value and growth delivering improvements for internal and external stakeholders and clients.

This role will be responsible for expanding and optimizing our data and data pipeline architecture. The ideal candidate is an experienced data pipeline builder and data wrangler who will support our software developers, database architects, data analysts and data scientists on data initiatives to navigate and leverage our significant data assets to build the optimal production models. You will ensure optimal data delivery architecture is consistent throughout ongoing projects and you must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

Tasks (what does the role do on a day-to-day basis)

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Implement data flows to connect operational systems, data for analytics and business intelligence (BI) systems
document source-to-target mappings
re-engineer manual data flows to enable scaling and repeatable use
write ETL (extract, transform, load) scripts and code to ensure the ETL process performs optimally
develop business intelligence reports that can be reused

Key behaviours we expect to see

In addition to demonstrating our Group Values, the role holder will be expected to demonstrate the following:
Communicates Effectively, Adjusting communication style to fit the audience & message. 
Providing timely information to help others across the organisation. 
Encourages the open expression of diverse ideas and opinions
Action Orientated Readily taking action on challenges without unnecessary planning and identifies new opportunities, taking ownership of them
Interpersonal, Savvy, Relating comfortably with people across all levels, functions, cultures & geographies.
Builds rapport in an open, friendly & accepting way
An analytical mind, excellent problem-solving & diagnostic skills, attention to detail

Required Experience

Education / professional qualifications

Bachelor's degree in computer science or another related field
8+ years of experience in software engineering.
Background in Financial Industry preferred.

Background & Technical experience

Proficiency in Linux fundamentals and Bash scripting skills.
Programming expertise in one or more languages, mainly: Python, Go, Scala, C++, Kotlin
Expertise on Python libraries - Pandas, Numpy, PySpark, Dask.
In-Depth Knowledge of Algorithms and Data Structures
Deep understand of database systems e.g., PgSQL/MySQL and Microsoft SQL server
Experience with at least one cloud platforms e.g., AWS, Azure, GCP
Experience with one or more Datalakes/Datawarehouses - Snowflake / DataBricks / Redshift etc
Experience in Stream processing - Kafka, Kineses etc
Basic Experience with Node.js and JavaScript.
Experienced in the implementation of Data warehousing solutions
Experienced in the implementation of API solutions and tooling
","['PySpark', 'Business Intelligence', 'Pandas', 'Scalability', 'Scala', 'Azure', 'Big Data', 'Data Transformation', 'Software Engineering', 'Scripting', 'ETL', 'SQL', 'Python', 'GCP', 'Data Warehousing', 'Linux']"
delivery manager (data) – 14k,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616",Permanent,Manager,8 years exp,Information Technology,Monthly,"$8,000to$14,000","We’re looking for an experienced Delivery Manager who has experience in delivering enterprise-wide data programs / projects, and ability to manage stakeholders, business, and other IT delivery at different levels.

About the role

-Stakeholder Management & Communications
-Delivery and Resource Management
-Financial Management
-Contract Management
-Data Domain Expertise

Skills and experience required

Bachelor’s degree in Business Management, IT, Computer Science, Computer Engineering or equivalent
Minimum 10 years of experience in delivering large scale data programs in big data, data warehouse, BI & reporting and / or data management
Experience in delivering projects in agile delivery methodologies
Experience in working with cross functional teams comprises of IT, business, data product owners and vendors
Experience in procurement process – managing tenders and negotiating contracts
Experience in IT financial management, budgeting and project cost controlling
Experience in senior stakeholder management

To apply online please use the apply function, alternatively you may contact Chloe Chen at chloe.chen(@)randstad.com.sg. (EA: 94C3609 /R1768253)","['Big Data', 'Financial Management', 'Data Management', 'Contract Management', 'Agile', 'Procurement', 'Project Management', 'Banking', 'Budgeting', 'Customer Satisfaction', 'Resource Management', 'Stakeholder Management', 'Project Cost', 'Service Delivery']"
Data Manager,"INTERNATIONAL PLAZA, 10 ANSON ROAD 079903","Permanent, Full Time",Professional,3 years exp,Information Technology,Monthly,"$4,500to$7,000","
Working Location: Buona Vista
Monday to Friday


Job Description:

To provide services for management information delivery via the global data warehouse.
Design and develop enterprise Data Warehouse components including Architecture, Database, ETL processes for the daily data loading from SAP and other application systems and the OBIEE related modelling
Implementation of new requirements in close cooperation with team in Munich
Design source to target mapping and ETL test cases
Develop code to load data mart tables and develop Oracle DB objects including tables, indexes, constraints, and views
Perform tuning of the data load procedures to reduce data load time
Develop Oracle PL/SQL packages, SQL & UNIX scripts, ETL and job scheduling systems, OBIEE (backend) components in the Data Warehouse environment
Provide analysis and resolution of data discrepancy issues


Job Requirements:

Degree in Information Management or Industrial Engineering with minimum 3 years of experience in Oracle data warehouse environments, good understanding of data warehouse concepts in a manufacturing environment will be an added advantage

HOW TO APPLY:
Interested applicants, please click on “Apply Now” or email to submit your resume.
We regret only shortlisted candidates will be notified.
Stafflink Services Pte Ltd
EA Licence No.: 04C4294
EA Personnel: Astrid Tan
EA Personnel Reg. No.: R22107644","['OBIEE', 'Oracle', 'Information Management', 'Data Management', 'Industrial Engineering', 'ETL', 'Unix', 'Data Quality', 'Test Cases', 'Data Governance', 'Tuning', 'SQL', 'SAP', 'Scheduling', 'Manufacturing']"
Data Engineer,111  Somerset Rd 238164,Full Time,Senior Executive,3 years exp,Engineering,Monthly,"$8,300to$12,000","About the role
As Data Engineer you'll join one of our mission oriented squads or platform teams.
Data is key in all of our products, and your contributions will have a big impact.
You can be located anywhere in the world, as our work is 100% online. The position is full-time.
Responsibilities

Design, develop and support data pipelines, warehouses and reporting systems to solve business operations, users and product problems
Work closely with product engineers to create, test and maintain data models
Collaborate and influence stakeholders and support engineers to ensure our data infrastructure meets constantly evolving requirements
Work closely with analysts to create data analytics and research platform
Contribute to engineering efforts from planning and organization to execution and delivery to solving complex engineering problems
Take initiative and be responsible for technical solutions to data quality and workflow challenges
Write and review technical documents, including design, development, and revision documents.‍

Are you the right person for this role?
The ideal candidate for us has:

3+ years work experience as a Data Engineer or similar role
Experience with building data pipelines using Python and SQL
Experience designing data models and data warehouses
Experience in computer science, data structures, algorithms and software design
Experience with the following: BigQuery, Postgres, Airflow, Kubernetes, dbt

The following are nice-to-haves:

Experience with Data Visualization tools
Experience with Ethereum and the crypto markets (either professionally or as a hobby)
","['Postgres', 'Kubernetes', 'Big Data', 'Pipelines', 'Data Structures', 'Hadoop', 'ETL', 'Data Quality', 'Computer Science', 'Data Engineering', 'DBT', 'SQL', 'Python', 'Software Design', 'Java', 'Data Analytics', 'Databases', 'Algorithms', 'Data Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Engineer,"MAPLETREE BUSINESS CITY, 20 PASIR PANJANG ROAD 117439",Contract,Executive,3 years exp,Information Technology,Monthly,"$5,000to$8,000","About Us
Green Link Digital Bank is Singapore's inaugural wholesale digital bank focusing on supply chain finance, mainly serving MSMEs and aiming to help MSMEs grow and improve digitization.

We are looking for a Data Engineer joining our Data Management Office (DMO). The DMO provides comprehensive data services to all business units, and manages data governance policies and procedures. We apply best practices in managing our data assets and making it our competitive advantages to serve our customers better. We are embarking on a greenfield project to build our big data platform with the latest technologies. We invite the best talent to join us on this exciting journey.

Responsibilities

Design, develop and test a custom distributed big data platform using the latest technologies
Design, create and maintain physical data models optimised for performance, security, privacy, and maintenance
Design and develop real-time and batch ETL/ELT processes that ingest and transform a variety of data sources into data warehouse and data lake
Design and build data reconciliation processes to ensure data completeness and accuracy
Diagnose and remediate production issues
Provide training to users and other team members on technical aspects of data flow, procedures, and use of tools to consume the data effectively
Create and maintain documentations of technical solutions such as solution design, system architecture, technical specifications, and user manuals


Requirements

In-depth knowledge of concepts and practices building big data platforms, including data warehouse, data mart, and data lake
Practical experience in big data technologies, such as Hive, Spark, Kafka, Sqoop, Greenplum and any other RDBMS
Proficient with SQL, Stored Procedures, Shell, Python, and Java
Familiar with Elasticsearch or other NoSQL databases
Experiences in CI/CD and containerization are added advantages
Passionate for technical excellence and eager to learn new technologies
Committed to rigorous quality standards
","['Big Data', 'Greenplum', 'Creating technical specifications', 'ETL', 'NoSQL', 'Data Engineering', 'Spark', 'SQL', 'ElasticSearch', 'Python', 'RDBMS', 'Data Marts', 'Data Warehouse Architecture', 'Hive', 'Java', 'System Architecture', 'Sqoop', 'Technical Solution Design']"
Data Engineer Senior Manager,"RAFFLES CITY TOWER, 250 NORTH BRIDGE ROAD 179101",Permanent,Senior Management,12 years exp,Information Technology,Monthly,"$15,000to$22,000","About Accenture
Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services and Accenture Song — all powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. Our 721,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities.

Data Engineer Lead – Senior Manager
Key Responsibilities

Developing, testing and implementing business systems of the highest complexity
Ensures cross team integration and proper hand-offs of      code/tasks to meet schedules
Designs reusable software components and incorporates      reusable assets into the application design
Research and evaluate Data Engineering tools and frameworks
Participate on POCs and assist in client presentations
Assist engineering leadership in hiring and interviewing top talent
Mentor junior staff conduct design/code/test reviews
Assist in developing centre of excellence, best practices, documentation, re-usable assets
Proficient in distributed architecture, understanding of required infrastructure setup
Mentor junior team members

Qualifications

15+ years of experience with significant experience in the Data Engineering space
Experience in designing and building robust and highly scalable data platform and data pipelines
Experience with leading a team of experienced Data Engineers
Prior experience working in the consulting space will be highly advantageous
Strong programming proficiency using 1 or 2 of the following languages: Scala, Python, Java
Extensive experience with data modelling and designing/supporting both streaming and batch ETL pipelines
Clear understanding of distributed computing, especially in databases
Hands-on in SQL and NOSQL with a deep understanding of query optimization
Experience with open-source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)
Experience working on any of the Cloud platforms (GCP, AWS, Azure)
Good to have: Certification for Data Engineers or Solution Architect in 1 or more Cloud Technologies (AWS, GCP, Azure)
Strong communications skills and presentation skills to C levels
Ability to manage numerous requests concurrently and be able to prioritize and deliver

You will also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.","['Leadership', 'Classroom', 'Scala', 'Azure', 'Pipelines', 'Architect', 'ETL', 'Cassandra', 'NoSQL', 'Data Engineering', 'Spark', 'SQL', 'Python', 'Apache Kafka', 'Hive', 'GCP', 'Java', 'Design Research', 'Databases']"
 , , , , , , , , , 
Senior Data Engineer,"PARKVIEW SQUARE, 600 NORTH BRIDGE ROAD 188778",Full Time,Middle Management,6 years exp,"Consulting, Engineering, Information Technology",Monthly,"$10,000to$14,500","
Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 6 years, 10 locations and 500+ employees later we still believe that today. We connect the dots within our customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our customers, we are looking for senior level Data Engineers with a proven track record to join the Quantexa family. We also have positions open for mid-level candidates looking for an opportunity to learn new skills and progress their careers in a dynamic and exciting start-up environment.   🚀

What does a Data Engineer role at Quantexa look like?
In order to be a successful Data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders. You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.

Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our clients expectations and delivering a first-class service. 🥇

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion, Entity Resolution and Elasticsearch, with our platform being hosted on both private and public virtual clouds, such as Google cloud, Microsoft Azure and Amazon. Our primary language is written in Scala, but don’t worry If that’s not currently your strongest language, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Typical responsibilities include:

Write defensive, fault tolerant and efficient code for data processing.
Automate data processing to enable on-going alerts on high-risk activity.
Participate in customer workshops and refinement sessions, presenting project results to clients both face to face and virtually.
Work very closely with data scientists to ensure efficient and effective delivery of solutions.
Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients, including on their sites.
Work with our expert software development team to produce reusable applications.
Use emerging and open-source technologies such as Spark, Hadoop, and Scala.
Collaborate on scalability issues involving access to massive amounts of data and information.
Take on ad-hoc tasks as required for the running of a small, yet rapidly expanding business.


What do I need to have?

Proven big data experience, either from an implementation or a data science prospective.
Several years of hands-on experience working as part of an engineering development team, ideally in SCRUM.
Arrive with experience at working with a variety of modern development tooling (e.g. Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g. Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting).
Excellent technical skills including hands-on knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
Experience with MVC frameworks such as AngularJS
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines.
Strong coding experience in the likes of Scala, Java, or Python.
Enthusiasm to learn and develop emerging technologies and techniques.
Exhibit strong technical communication skills with demonstrable experience of working in rapidly changing client environments.
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies.
Strong academic qualifications and come from a software engineering background or other scientific degree incorporating IT modules (e.g. Maths/Physics).
","['Git', 'Microsoft Azure', 'Scalability', 'Scala', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'Scripting', 'ETL', 'Open Source', 'Python', 'Docker', 'Data Science', 'Java', 'Software Development']"
Senior Data Engineer,"FUNAN, 109 NORTH BRIDGE ROAD 179097",Full Time,Manager,6 years exp,Information Technology,Monthly,"$8,000to$9,500","SUMMARY STATEMENT 
We’re looking for a curious, intelligent, and proactive cloud focused Senior Data Engineer
to help us tackle complex data analytics projects end-to-end in Microsoft Azure. You will work with various teams based in multiple locations globally to deliver solutions on the Azure Cloud using core Azure cloud tools and languages. In addition, you will participate in improving recent implementations. You’re committed to delivering high quality interactions and you’re excited about making a big impact on a small team.


You love building the best data storage, processing, and visualization solutions; apart from being functional and insightful you really want it all to look beautiful, from initial design to naming conventions, code & visualization. 
We won’t have to tell you much about data architectures, data processing and integration technologies and methodologies or business intelligence ecosystems; your expert knowledge is up to date or you can research and learn. You have deep understanding of all things data including ingestion, transformation, and consumption. 
You enjoy working in a diverse business with multiple cultures and stakeholders. 
You thrive in a fast-pace project environment where excellent collaboration and communication skills are key to success. 
When it comes to the crunch, you love the pressure of an occasional healthy deadline. 
You proactively identify opportunities for work optimisation including opportunities for automation. 
You’re fluent in English. 

This position is not an infrastructure position. 

KEY RESPONSIBILITIES
Data Architecture

Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.
Reverse engineer existing database data models, manage and maintain existing and new logical and physical data models.

Data Engineering (Development)

Collaborate with functional group leaders and engineering team(s) to gather and analyse business and technical data requirement needs and understand how data is collected, analysed & utilised to design and implement the management, monitoring, security, and privacy of data using the full stack of Azure data services. 
SQL server development and coding complex functions, stored procedures, triggers, indexes, queries or ad-hoc analyses, and views (using T-SQL). 
Design and develop Azure Data Factory ETL, ELT or ingestion processes that will transform a variety of on-prem and cloud (structured and unstructured) data sources into SQL databases or data warehouses or integration solutions, including REST APIs, Event Drive or Queue based integrations. 
Design and build Microsoft Azure functions to optimize data extractions and ensure data validation, cleansing and merging forms a critical part of data processing solutions. 
Ensure that data services securely and seamlessly integrate with other data platform technologies or application services such as Azure Cognitive Services, Azure Search, or even bots. 
Enhance existing or build new SQL Server Analysis Services solutions, tabular models or OLAP cubes used in the business intelligence ecosystem and develop Multi-Dimensional Expression (MDX) queries to extract data from OLAP cubes for reporting and analytical purposes. 
Enhance existing or build new enterprise or departmental business intelligence solutions, inclusive of Power BI. 
Adhere to or recommend best practice cloud services, database or data engineering, and identity standards and perform team and 3rd party code reviews in accordance with such standards. 
Build prototypes or pilots using new technologies. 
Present solutions and recommendations to stakeholders.

Testing

Perform unit, integration, or system testing (automated or otherwise) on all developed code and / or system components through stringent routines and procedures to ensure accuracy and solution integrity and that solutions run smoothly with optimum operational efficiency, ensuring all solutions will meet SLAs & performance criteria.
Provide feedback on solutions’ usability, features, and design based on results of testing.
High focus on performing your own data reconciliations during testing phases to ensure that your development work has been completed successfully prior to deployments for user acceptance testing.

Production Support and Maintenance

Provide exceptional support by applying critical thinking skills to troubleshoot, determine the cause of failure, and quickly restore failed components or processes when they occur; Diagnose and remediate resource contention issues and failures in application logs.
Participate in an on-call rotation with the team when necessary, specifically related to customer-facing digital cloud solutions.
Report and escalate issues to 3rd party vendors if necessary.
Conduct monthly reviews of incidents and service requests, analyse, and recommend improvement in quality and work with the internal team on identifying pain points in existing Azure deployments and configuration and ways to alleviate them.
Working experience in hardening cloud production environments for error handling, fault tolerance, self-healing, monitoring and incident alerting and recovery beneficial.
Monitor connections and locks and performance of SQL instances to track historical peak load on servers and proactively working on performance tuning and writing queries for front-end applications.
Manage, monitor, and ensure the security and privacy of data to satisfy business needs.

Other Critical Deliverables:

Legacy Migrations: Migrating on-prem SQL instances and legacy SAS datasets to Azure SQL in development, test, or production environments.
Training and Mentorship: Provide technical training and mentoring to other teams and team members and organize and execute training sessions for the user base of in-house developments for new workflows, procedure recommendations, the availability of data in operational data stores as well as the data warehouse and how to consume the data effectively in business intelligence and analytics tools withing the organization.
Documentation: Originate and maintain documentation for new and existing solutions throughout the solutioning life cycle, covering all applicable functional areas, such as bugs, change requests, operational policies and procedures, solution designs, integration and API specifications, technical specifications, test plans and test results, production control (and / or job scheduling), security administration, TSQL code and logical as well as physical data models where applicable.
Our values: Living the NMG values of Collaboration, Curiosity, Go for It, and Make it Count in all that you do.

YOUR EXPERIENCE & CAPABILITIES
The successful candidate for this role will be able to demonstrate:

Strong organisational abilities and high attention to detail.
The ability to thrive within a small team whilst also working independently.
Agility in approach, reacting positively to change and shifting priorities.
Effective communication skills and the ability to collaborate cross-group or cross-geo.
Working well under pressure with excellent time management skills.
A passion for technical excellence and a flair for user experience and design.
Excellent analytical, process design and problem-solving skills.
Resourcefulness and troubleshooting aptitude.
Ability to communicate technical needs and solutions with non-technical staff and comfortable performing component demonstration for key business stakeholders and project managers.

Technical Capabilities must encompass the following:

Experience in multiple or all Azure components, including: API Management, Event Hubs, Data Factory, Functions, Resource Manager Templates, Storage Accounts, Notifications Hub, Key Vault, DevOps, Data Lake Stores, Data Lake Analytics, Synapse Analytics, Databricks, HD Insight, SSAS, SQL Database or similar cloud infrastructure (5+ years’ experience and deep expertise in data engineering as applied to Azure preferred), including Visual Studio as applied to SSAS development.
In-depth knowledge of standard concepts, practices and procedures related to database modelling (logical and physical) and management, concepts of data lakes, data warehousing and data marts as well as legacy migrations to cloud services.
Infrastructure automation for continuous integration and continuous deployment of technical solutions leveraging Azure Services and Features.
Hands-on experience in scripting languages such as Python, R, etc.
Modern version control Git, SVN, TFS, etc.

Experience that will make you stand out:

Advanced Business Intelligence experience, understanding of BI areas and reporting using SQL, SSAS, Tabular Models and Power BI, including proactive identification of issues and coordination of resolutions.
Applicable Azure certifications including for example Implementing an Azure Data Solution, Designing an Azure Data Solution, Designing and Implementing Microsoft DevOps Solutions.
Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing, and curation as well as metadata management: data governance, data quality, master data management, lineage, data cataloguing, etc.
Being able to conceptualize the full project life cycle.
QA testing.

If you are interested in this role and meet the criteria, kindly apply directly at https://nmgconsulting.peoplehr.net/Pages/JobBoard/Opening.aspx?v=ad882e44-6723-48eb-8975-266f874eb075","['Git', 'Business Intelligence and Data Analytics', 'project life cycle', 'Azure', 'Data Management', 'Scripting', 'SQL Azure (Cloud SQL Server)', 'ETL', 'Data Governance', 'Data Engineering', 'SQL', 'Python', 'Data Architecture', 'Continuous Integration', 'Performance Tuning', 'Visualization', 'Data Analytics', 'Data Warehousing', 'Liaising with Stakeholders', 'high level of accuracy']"
Data Engineer,21 TAI SENG DRIVE 535223,"Permanent, Full Time",Executive,2 years exp,Information Technology,Monthly,"$4,500to$6,000","Our Team
Mighty Jaxx is the leading integrated future culture platform in Southeast Asia today. With a mission to supercharge future culture phygitally, Mighty Jaxx’s integrated platform will empower future pop culture brands with an end-to-end supply chain of digital and phygital collectibles, including artist development and incubation, proprietary IP operation and providing global consumers access to new D2C experiences.
Mighty Jaxx partners with the greatest creative talents in the world, as well as top global brands such as Netflix, Formula 1, Hasbro, Toei Animation, Cartoon Network, Nickelodeon, Warner Brothers, Adidas and many more to ship millions of phygital collectibles to over 90 countries worldwide.
We are proud to be an equal opportunity employer with a diverse, inclusive work environment and encourage our employees to bring their authentic, fun-loving, and high-energy selves to the workplace.
The Job
We are looking for a Data Engineer interested in building a data platform within Mighty Jaxx to discover, analyse and report on operational insights to internal stakeholders.  As our Data Engineer, you will be working with various business and technology teams to design, develop and maintain our data platform for reporting, analytics and other data related services
Responsibilities

Design, develop and maintain data ETL processes, ensure the processes are fulfilling business needs and SLAs
Facilitate technical planning and optimize the data infrastructure, models and pipelines to improve data platform stability
Design and develop Data Products to drive business outcomes
Collaborate with business stakeholders to understand their data needs and develop robust and scalable data models
Develop processes to answer recurring business questions and identify opportunities for improvement
Ensure Data Quality through continuous improvement and monitoring

Requirements

At least 2 years prior experience in the following technologies and languages:
    
SQL/NoSQL and BI visualization (e.g. Tableau, Power BI, AWS Quicksight)
Python or other related programming languages
Developing and maintaining ELT/ETL scripts and pipelines
Experience with data warehousing (e.g. AWS Redshift, Google BigQuery and Microsoft Azure SQL Data Warehouse)


Able to work closely with various internal teams and stakeholders to deliver tasks when required
Data-driven, highly organized
Able to work independently; self-organize, prioritize and execute tasks assigned
Deadline-oriented and self-motivated with the ability to think outside the box.
Have exposure to Agile and weekly sprint and release working models
Strong command of English, both written and spoken
Excellent communication skills - very good at inter and intra-team communication
Is a team player who endorses collaborative work style

To apply, please send an updated copy of your resume to HR@mightyjaxx.com.
While we value all submissions, we regret that only shortlisted candidates will be contacted by our HR team.","['Tableau', 'Excellent Communication Skills', 'Microsoft Azure', 'Artist Development', 'Pipelines', 'Hadoop', 'Agile', 'ETL', 'Data Quality', 'SQL', 'IP', 'Python', 'Visualization', 'Animation', 'Power BI', 'Data Warehousing']"
Senior Data Engineer,"SHENTON HOUSE, 3 SHENTON WAY 068805",Permanent,Professional,5 years exp,Information Technology,Monthly,"$7,000to$14,000","What you’re going to do

Design, construct, install, test, and maintain data management systems
Build high-performance algorithms, predictive models, and prototypes
Ensure that all systems meet the business/company requirements as well as industry practices
Integrate up-and-coming data management and software engineering technologies into existing data structures
Develop set processes for data mining, data modeling, and data production
Create custom software components and analytics applications
Research new uses for existing data
Employ an array of technological languages and tools to connect systems together
Install/update disaster recovery procedures
Recommend different ways to constantly improve data reliability and quality


What we’re looking for

Bachelor’s degree in computer science or similar
Min. 5 years’ proven experience as a Data Engineer or similar
Proficient in Data Modelling, Data Architecture , ETL, Data warehousing, Data Lake.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Proficient in one or more scripting language (e.g Python, R)
Experience in Apache Hadoop based analytics coving data processing, access, storage, governance, security, and operations.
Experience in Cloud based Big Data technologies.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Prior data streaming experience with Spark/Python,...
Knowledge in deploying microservices
Creative thinking backed by strong analytical and problem-solving skills


Sharp minds, good vibes

We are the sharp-minded IT experts who tackle the trickiest software and security challenges. With more than 630 employees in our locations in Zurich (HQ), Bern, Lausanne, Budapest, Lisbon, Singapore, and Ho Chi Minh City, we make the digital business of our clients work.
As a great team, we empower each other to share, grow and succeed. The unique Adnovum spirit across locations stands for helping each other at any time, having an open door and contributing to an appreciating and trustful atmosphere. We always enjoy having a laugh, a coffee or a drink together!
Apart from our unique «one Adnovum» spirit, we offer a solution-oriented engineering culture with flat hierarchies, which gives you the opportunity to contribute with your opinions and ideas. We embrace flexible working, like the possibility to work part-time and a hybrid work model. Your continuous education and development are key to us. Therefore, we actively encourage and support individual training opportunities.
For data privacy reasons, we only accept applications submitted via our online portal. Applications received by e-mail cannot be processed. Thank you for your understanding.

Adnovum accepts only direct applications. Any applications submitted by recruitment agencies without contractual agreement will be treated as direct applications.","['RDS', 'Big Data', 'Data Modeling', 'Data Structures', 'Data Management', 'Shell Scripting', 'Software Engineering', 'Scripting', 'ETL', 'Reliability', 'EMR', 'Apache Hadoop', 'Data Mining', 'Python', 'Data Architecture', 'Data Warehousing']"
Senior Data Analyst,383 SIN MING DRIVE 575717,Full Time,Senior Executive,5 years exp,"Engineering, Professional Services",Monthly,"$6,000to$8,800","Responsibilities:

Manage data on AWS/Azure      platform
Write efficient SQL query to      extract and aggregate data from cloud data lake / data warehouse
Write Python script to      extract open source data for analysis
Perform Data analytics and      Data visualization on large data set using Tableau/Power BI
Create dashboard for      monitoring and alert user of anomalous event

Requirements:

Degree in Data Science,      Computer Science/ Engineering or equivalent
Minimum 5 years of      experience in data analyst function
Experience in managing data      in AWS/Azure platform
Experience in writing SQL      query to aggregate large data set
Good in Data Visualization      using Tableau / Power BI
Experience in writing      programming languages such as Python so as to create micro-service and      handle large data
Good knowledge in statistics
Good problem-solving and      data investigation skills
","['Tableau', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Mathematics', 'Investigation', 'Open Source', 'SQL', 'Python', 'Writing', 'Statistics', 'Data Science', 'Visualization', 'Data Analytics', 'Power BI', 'Data Visualization']"
Data Engineer,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979",Permanent,Executive,4 years exp,Information Technology,Monthly,"$6,500to$8,000","Role:Data Engineer

Job Description:
Support data management operations activities in research and investment data applications of Data Strategy 
Job Requirements:

Experience in data analysis.
Experience in managing data reconciliation/quality checks (gather requirements, implementation, monitoring and troubleshooting).
Proficient in Oracle PL/SQL.
Experience in working with enterprise databases using database technologies (MS SQL, Snowflake, Redshift and PostgreSQL) and data integration products (e.g. Informatica).
Experience in performing UAT.
Able to manage SLA and queries from end users.
Familiar with providing documentation support, e.g. in technical/functional specifications.
Possess finance domain knowledge.
Problem solving and logical thinking.
","['UAT', 'Troubleshooting', 'Oracle', 'Data Analysis', 'PostgreSQL', 'Big Data', 'Pipelines', 'Hadoop', 'Informatica', 'Data Management', 'ETL', 'Data Integration', 'Data Engineering', 'SQL', 'Databases', 'Data Strategy']"
Data Engineer,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979",Permanent,Executive,3 years exp,Information Technology,Monthly,"$6,500to$8,000","Role: Data Engineer


Job Description:

Support PEG projects
Support new Allegro data migration from GEMS to Master Data Management (MDM) for PEG.

Job Requirements:
Must have

Bachelor Degree in Computer Science, Computer Engineering or equivalent.
At least 5 years' experience of working as a data engineer via organization legacy systems.
Solid working knowledge of implementing ETL pipelines using Informatica BDM (DEI) on data warehouses and big data platforms, such as RDBMS, Informatica etc.
Familiar with application integration with RDBMS such as Oracle, MS-SQL or MySQL. Working knowledge of Oracle and MS-SQL will be a plus.
Hands-on experience of using Linux (or Unix-like OS) as the development environment and familiar with shell scripts and command line tools in Linux/Unix environment.
Possess experience in Systems Development Life Cycle implementation methodology (SDLC) and/or Agile methodologies like Scrum and Kanban.
Able to understand and apply the good industry practice of code versioning, testing, CICD workflow and code documentation.
Good team player, with strong analytical skills and enjoy complex problem solving with innovative ideas.
Strong communication/people skills are required to interact with data analysts, business end-users and vendors to design and develop solutions.
Good at working with details and meticulous for operations.

Nice to have

Big Data Platforms - Informatica, Snowflake, Kafka
Programming and Scripting - Python, .NET, Java
SQL Databases - Oracle, MS-SQL
","['Oracle', '.NET', 'Big Data', 'Pipelines', 'Allegro', 'Informatica', 'MySQL', 'Scripting', 'ETL', 'SQL', 'Python', 'Java', 'Databases', 'Linux']"
 , , , , , , , , , 
Senior Data Manager,"ONE GEORGE STREET, 1 GEORGE STREET 049145",Permanent,Manager,5 years exp,"Banking and Finance, Others",Monthly,"$8,000to$16,000","EDHEC is looking to recruit a Senior Data Manager to be based in Singapore, in order to support its research activities and the development of its newest FinTech ventures.
About ERCII:
EDHEC-Risk Climate Impact Institute aims to become the leading academic reference point helping long-term investors manage the asset-pricing implications of climate change as well as adaptation and mitigation efforts.
About EDHEC Infra:
EDHEC Infra is a provider of market indices, benchmarks and valuation analytics for investors in unlisted infrastructure equity and private debt. Asset owners, asset managers, consultants and asset valuation professionals use our datasets, which tracks thousands of investments in 25 countries over the past 20 years. Our data is available on a quarterly basis for hundreds of analytics and on a monthly basis for 25 key market benchmarks.
About Scientific Portfolio:
Scientific Portfolio aims to become a reference platform for Asset Owners to analyse and manage their financial and ESG risks.
Mission
The Senior Data Manager’s missions will include:
- Setting up a data management function to address the needs of ERCII, EDHEC  Infra, Scientific Portfolio’s quant and ESG research teams.
- Ensuring the quality and availability of data as per their functional requirements.
- Harmonising and optimising the purchase of financial and extra-financial data.
- Maintaining up-to-date information about the availability of data across the organization.
- In time, being capable to cover the acquisition and renewal of ESG and climate change data.
- Providing help on the analysis of contracts with data providers, in particular with respect to the allowed usages both for research and business purposes.
- Providing help on further contractual issues encountered by the concerned entities.
- Providing help on tracking compliance questions, notably with prospects.
Profile
The ideal candidate:
- Has a minimum of 5Y of experience including a proven experience in a data management role within the financial industry
- Has knowledge and exposure to legal and contractual matters
- Has knowledge of the regulatory environment for institutional investors and asset manager
- Has strong organizational and project management skills
- Shows flexibility and team spirit
- Can demonstrate strong written and verbal English communication skills.
Singapore citizenship or Permanent resident status is mandatory, please send applications to recruitment@edhec-dbd.com ","['Management Skills', 'Missions', 'Oracle', 'Clinical Research', 'Financial Management', 'Valuation', 'Data Center', 'Data Management', 'Investments', 'Clinical Data Management', 'Team Spirit', 'Climate Change', 'Data Entry', 'Climate', 'Accounting', 'Compliance', 'Databases', 'Able To Work Independently', 'Adaptation']"
Data Analyst(Tableau / SQL),"THE OCTAGON, 105 CECIL STREET 069534","Contract, Full Time",Junior Executive,2 years exp,Information Technology,Monthly,"$4,000to$5,500","Responsibilities

End to end Tableau visualisation. must be good in analytics. Create strong blending data capabilities within team so that we can come up with useful client information from data very quickly. Engage with business stakeholders across countries and gather requirement and liaise with ETL team to get the required data preparation. Promote analytics driven decision making processes across multiple segments/product portfolios. Engage and execute the dashboards on Tableau or similar visualization tools. Explore statistical and automation tools like R, SAS, Python for predictive and prescriptive analytics. Engage relevant technology teams to embed advanced statistical tools. Prepare and/or contribute to regular updates for various committees and governance forums. Provide insights to senior management and the network based on MIS and analytics. Highlight any perceived risks and early alerts to the management based on data analytics. Perform data validation and dashboard performance optimization.

Top 3 Must have skills (in terms of skills, qualifications, interpersonal, certification soft skills)
· Tableau
· SQL
· 1-2 years’ experience in analytics

Nice to have – Alteryx/Python/R/SAS

Please mail your CV at the earliest to meera.abhilash@tangspac.com","['Tableau', 'Dashboard', 'Automation Tools', 'ETL', 'Soft Skills', 'SQL', 'Python', 'Visualization', 'Decision Making', 'Data Analytics', 'MIS']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data - Data Analyst_Beginner,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979",Contract,Executive,1 year exp,Information Technology,Monthly,"$3,500to$4,500","Role:Data -   Data Analyst_Beginner
Location:MBFC

JD:
For fresh degree graduates – person should have some college   project exp. in Basic sql , r programming , some qlikview knowledge on any BI   tool

   .
   Responsibilities
    1) Gather and analyse requirements from business
    2) Perform data discovery and analysis from the bank’s data platform to   ensure requirements are feasible
    3) Conceptualise dashboard design through wireframes and prototypes
    4) Build complex visualizations in QlikView and other BI visualisation   tools, that will help derive insights for               user
    5) Apply best practices on user interface/user experience (UI/UX)
    6) Support the publication of the dashboard in production
    7) Conduct trainings and roadshows to promote awareness and usage from   target users
    8) Assist other data discovery tasks (non-dashboard related) that the team   is working on

  Qualifications and Requirements
    1) Bachelor’s degree in Business Analytics, Computer Science or   equivalent
    2) Knowledge in Business Intelligence (BI) tools, Visualization tools, and   scripting
    3) Knowledge in using SQL
    4) Ability to convert data into meaningful information
    5) Ability to problem-solve and propose fit for purpose solutions
    6) Strong interpersonal, communication and presentation skills
    7) Effective time and stakeholder management skills
    Shortlisted candidate to share a data project with storytelling","['Tableau', 'Wireframes', 'Management Skills', 'Business Intelligence', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Scripting', 'SQL', 'Business Analytics', 'Presentation Skills', 'Statistics', 'Visualization', 'Storytelling', 'Stakeholder Management', 'Data Analytics']"
Senior Data Engineer,6 SERANGOON NORTH AVENUE 5 554910,Permanent,Manager,7 years exp,Information Technology,Monthly,"$8,000to$12,000","We are expanding our strong data science team and are looking for talented AI practitioner with applied experience in the fields of Machine Learning and Deep learning to join us. This role is best suited for candidate that is interested in developing new AI application that has a direct and immense, real-world healthcare impact.
You need to have a deep passion for analyzing and resolving healthcare problems. You display an intellectual curiosity about the business needs as well as the capability to engage with stakeholders to understand business issues.
Critical Work Functions and Key Tasks:
Analyze data

Scope out problem definition and hypothesis for analysis for image related use case
Responsible for image analysis, synthesis and other aspects of algorithm development, including visual recognition, object detection, segmentation and medical image processing, etc.
Responsible for the exploration of cutting-edge technology in image related algorithms and ensure the technologies get successfully applied.
Design experiments to test data assumptions
Evaluate experiment outcomes to draw actionable conclusions
Deploy data models across different channels and customer platforms

Collaborative work

Partner with stakeholders to translate business problems into data science projects
Develop strategies to identify, acquire and use appropriate data sets to develop practical solutions and support decision making
Maintain an advanced knowledge of trends affecting the industry

Present insights

Synthesize findings into actionable insights
Apply data analysis, datamining and data processing to present data clearly
Provide rationale, business cases and ROI models to support investment

Requirements / Qualifications

PhD or Masters in a quantitative field such as Mathematics, Statistics, Information Technology, Physics, Engineering, Finance or equivalent
Solid research and engineering background and experience in computer vision, machine learning, and image processing/analysis algorithms.
Good experience with Python or R is prerequisite
Good experience with Deep learning framework e.g. Tensorflow, keras, Pytorch is prerequisite
Hands on experience in the development of image classification, object detection, segmentation or related is preferred.
Good experience with SQL and/or NoSQL is preferred
Preferably 5 - 7 years of relevant working experience.
Proven communication skill to explain insights from technical work to non-technical audience through presentation or other means
","['Machine Learning', 'Image Processing', 'Data Analysis', 'Pipelines', 'Mathematics', 'Information Technology', 'Computer Vision', 'Keras', 'PyTorch', 'SQL', 'Algorithm Development', 'Python', 'Statistics', 'Data Science', 'Decision Making', 'Image Analysis']"
Data Engineer (Senior Manager),6 SERANGOON NORTH AVENUE 5 554910,Permanent,Middle Management,10 years exp,Information Technology,Monthly,"$9,000to$13,000","We are expanding our strong data science team and are looking for talented AI practitioner with applied experience in the fields of Machine Learning and Deep learning to join us. This role is best suited for candidate that is interested in developing new AI application that has a direct and immense, real-world healthcare impact.
You need to have a deep passion for analyzing and resolving healthcare problems. You display an intellectual curiosity about the business needs as well as the capability to engage with stakeholders to understand business issues.
Critical Work Functions and Key Tasks:
Analyze data

Scope out problem definition and hypothesis for analysis for image related use case
Responsible for image analysis, synthesis and other aspects of algorithm development, including visual recognition, object detection, segmentation and medical image processing, etc.
Responsible for the exploration of cutting-edge technology in image related algorithms and ensure the technologies get successfully applied.
Design experiments to test data assumptions
Evaluate experiment outcomes to draw actionable conclusions
Deploy data models across different channels and customer platforms

Collaborative work

Partner with stakeholders to translate business problems into data science projects
Develop strategies to identify, acquire and use appropriate data sets to develop practical solutions and support decision making
Maintain an advanced knowledge of trends affecting the industry

Present insights

Synthesize findings into actionable insights
Apply data analysis, datamining and data processing to present data clearly
Provide rationale, business cases and ROI models to support investment

Requirements / Qualifications

PhD or Masters in a quantitative field such as Mathematics, Statistics, Information Technology, Physics, Engineering, Finance or equivalent
Solid research and engineering background and experience in computer vision, machine learning, and image processing/analysis algorithms.
Good experience with Python or R is prerequisite
Good experience with Deep learning framework e.g. Tensorflow, keras, Pytorch is prerequisite
Hands on experience in the development of image classification, object detection, segmentation or related is preferred.
Good experience with SQL and/or NoSQL is preferred
Preferably 5 - 7 years of relevant working experience.
Proven communication skill to explain insights from technical work to non-technical audience through presentation or other means
","['Machine Learning', 'MASSIVE', 'Data Analysis', 'Pipelines', 'Open Source Software', 'Mathematics', 'Information Technology', 'Computer Vision', 'PyTorch', 'SQL', 'Algorithm Development', 'Python', 'Statistics', 'Data Science', 'Decision Making', 'Image Analysis']"
Senior Data Engineer,"21 COLLYER QUAY, 21 COLLYER QUAY 049320",Permanent,Professional,10 years exp,Others,Monthly,"$8,000to$16,000","Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/en-US/amplifyhealthexternal/job/Senior-Data-Engineer_JR-35657
What you will do?
The role entails building a reusable sustainable framework to ensure collection, processing and availability of high-quality health care data to enable us to achieve the core purpose. The Data Engineer will work collaboratively with the Program Managers, Data Scientists, Systems Architects to define data sources and to build a custom data framework that facilitates Machine Learning, AI and productionising AI models based on the principles of ETL/ELT. Together these teams will enable data driven actionable insights.
The role is based in Singapore.
Core responsibilities include:

Develop and implement a reusable architecture of data pipelines to make data available for various purposes including Machine Learning (ML), Analytics and Reporting
Work collaboratively as part of team engaging with system architects, data scientists and business in a healthcare context
Work comfortably with structured and unstructured data in a variety of different programming languages such as SQL, R, python, Java etc
Understanding of distributing programming and advising data scientists on how to optimally structure program code for maximum efficiency
Build data solutions that leverage controls to ensure privacy, security, compliance and data quality
Understand meta-data management systems
Orchestration architecture in the designing of ML/AI pipelines
Deep understanding of cutting-edge cloud technology and frameworks to enable Data Science
System integration skills between Business Intelligence and source transactional
Improving overall production landscape as required
Write unit tests and participate in code reviews
Define strategies with Data Scientists to monitor models postproduction

What skills do you need?
Behavioural skills

A passion for programming and working with data
Self-starter
Experience of leading a team to deliver solutions
Willingness to learn and grow exponentially
A restless curiosity in learning new technology
Ability to work cohesively in a team environment and balance multiple priorities
A team player who can work alone when required and without supervision
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude
Ethical and able to maintain confidentiality and manage boundaries

Technical understanding
Essential:

Advanced database knowledge in SQL
Advanced MS Azure tools such as


Azure Data Factory
Synapse Analytics
Azure Data Lake Gen2
Azure Databricks


Modern Azure datawarehouse skills
Experience working on large and complex datasets

Advantageous:

Programming languages such as


R
Python
Scala
Java


Unix/Linux admin experience including shell script development
Exposure to AI or model development
Knowledge of:


Azure stream analytics
PowerBI
Azure ML Services
ML Flow


Understanding and application of Big Data and distributed computing principles (Hadoop and MapReduce)
ML model optimization skills in a production environment
Production environment machine learning and AI
DevOps/DataOps and CI/CD experience
Kubernetes and container setup and configuration
Feature store design and development
Master data management

Qualifications
The following requirements are preferred:

Honours or Master’s degree in BSc Computer Science
Honours or Master’s degree in Engineering or Software Engineering with solid experience in data mining and machine learning
Other qualifications will also be considered if accompanied by the relevant experience
10 to 15 years of experience is preferred
","['Machine Learning', 'Business Intelligence', 'Scala', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'Data Quality', 'MapReduce', 'Data Mining', 'SQL', 'Python', 'Data Science', 'Metadata', 'Java', 'Power BI']"
Data Engineer,"SAMSUNG HUB, 3 CHURCH STREET 049483","Permanent, Full Time",Professional,3 years exp,Information Technology,Monthly,"$6,000to$9,000","What We Value: Our Culture
Creating a culture that inspires change and momentum requires the right team. We know what it takes to lead an industry, and are looking for leaders who seek constant growth, want to excel, and continuously improve upon themselves and the industry. The culture at Revantage is built on our shared core values and commitment to be:

Achievers – We expect high standards for      ourselves and enable the success of our teams.
Enthusiasts - We face challenges with      optimism and believe anything is possible.
Leaders - We commit to continuously      improve our performance.
Learners – We learn from our challenges,      successes and the diversity of our people.
Partners - We deliver value and positive      impact to our partners.

Why This Role Is Valuable
The primary responsibility of the Data Engineer is to design, develop, implement and support the core data platform and supporting processes that enable data centric functionality for data integration, data analytics and reporting within Revantage Asia and the Portfolio Companies that it supports.

How You Add Value
(including but are not limited to)
•Be comfortable to work within a startup mindset/environment and be capable and willing to bring order and maturity to the environment.
•Take ownership of data engineering efforts that builds data pipelines to transform and automate data flows and ensure constancy and quality of enterprise data.
•Be comfortable to leverage existing frameworks, methodology and tools (eg. Sparx Enterprise Architect) to deliver initiatives according to agreed code and design practices.
•Develop high quality and reusable code to support core data platform initiatives including data integration, data warehousing, and data transformation pipelines.
•Translate data models, mappings and specification into engineered solution
for consumption by downstream systems, data analysts and data scientists
•Ensure code, configuration and other technology artifacts are delivered within agreed time schedules and any potential delays are escalated in advance
•Work closely with all the squad and product owners and participate in SCRUM team ensure team productivity and improved quality
•Support enterprise data quality capabilities by developing technology solutions that enable continuous improvement of data quality
•Ensure engineering products and codes are documented and maintained in the source code repositories and collaboration spaces (e.g. Confluence, SharePoint)

What You Bring To The Role
•3-5 years professional experience as a data engineer, software engineer, data analyst, data scientist, or related role
•Experience with Microsoft Azure Data Integration Stack (Azure Data Lake Gen2, Azure Data Factory, Delta Lake, SSIS, SQL Server, Azure Data Warehouse)
•Have experience developing solution using the Microsoft Power Platform including design, solution architecture, issue identification/resolution, and support.
•Good knowledge of Power platform and Microsoft 365 suites (SharePoint, Power Apps, Power Automate, Power BI, Teams, Power Fx, Dataverse, GraphAPI, Power Query etc.)
•Expertise building ETL and data pipelines on Databricks using data engineering languages Python and SQL on Azure
•Proven experience with all aspects of the Data Pipeline (Data Sourcing, Transformations, Data Quality, Etc
•Experience with Azure DevOps including test and build automation tools and processes
•Experience with relational and dimensional database modelling (Relational, Kimball, Data Vault)
•Excellent technical documentation and writing skills, and have published API documentation or similar
•Experience with visual modelling tools including UML","['Factory', 'Azure', 'Pipelines', 'Data Transformation', 'ETL', 'Data Integration', 'Data Quality', 'Data Engineering', 'SQL', 'SQL Server', 'Python', 'API', 'Data Analytics', 'Power BI', 'Data Warehousing']"
Senior Data Engineer,78 AMOY STREET 069897,"Permanent, Full Time",Senior Executive,5 years exp,"Banking and Finance, Consulting",Monthly,"$7,000to$14,000","Responsibilities

Develop processes of the ingestion of data using various programming languages, techniques and tools from systems implemented using Oracle, Teradata, SAP, and Hadoop technology stack
Evaluate and make decisions around dataset implementations designed and proposed by peer engineers.
Build large consumer database models for financial planning & analytics including Balance Sheet, PnL, Cost Analytics and Related Ratios
Develop ETL, real time and batch data processes feeding into in-memory data infrastructure.
Perform and document data analysis, data validation, and data mapping/design
Conduct unit tests and develop database queries to analyse the effects and troubleshoot any issues

Prefered Skills/Experience

Experience with Quantexa
Quantexa Certification preferred.

Good to have knowledge/experience

Data Platform - Data Lake, Data Warehouse, Data Management, BI Analytics & Data Science Platform
Data Engineering Workloads - Sourcing, Ingesting, Distributed Layered Storage, History, Warehousing, Data Mart
Data Sourcing Approach - Batch, Real-time Streams, Change Data Capture, Bulk REST API
Data Storage approach covering Interim, Base, History, Archive, Formats, Schema registry, Schema Evolution
Designing Interactive, intuitive & fast User Consumption & Semantic layers using Data Hub & BI concepts
Data Platform Management concepts - Scalability, HA, Failover, DR, monitoring, Tuning, Workload, performance, troubleshooting, release
","['Warehousing', 'Teradata', 'Scalability', 'Oracle', 'Data Analysis', 'Big Data', 'Pipelines', 'Financial Planning', 'REST', 'Hadoop', 'Data Management', 'ETL', 'Tuning', 'Data Engineering', 'Data Science', 'API']"
Data Governance Director,"BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908","Permanent, Full Time",Manager,10 years exp,"Banking and Finance, Information Technology",Monthly,"$15,000to$20,000","Our client is a financial services firm with a strong presence within the APAC region. They are looking to hire for a Data Governance Director to join the team.
RESPONSIBILITIES:

Develop and implement a data governance framework that includes policies, standards, and procedures for data management, data quality, data privacy, and data security.
Define and maintain data-related roles and responsibilities, including data owners, stewards, and custodians, and ensure that these roles are understood and supported across the organization.
Establish data quality and data accuracy standards and oversee data quality monitoring and reporting.
Work with business units to identify and document critical data elements and define data lineage and data dictionaries to ensure consistency across the organization.
Develop and manage data governance-related training programs to ensure employees are educated on data governance principles and practices.
Collaborate with IT and security teams to ensure that data security and privacy policies and practices are in place and enforced.
Define and implement data-related risk management and compliance procedures and oversee their implementation.

REQUIREMENTS:

Bachelor's degree in computer science or equivalent with at least 10 years of leadership experience in data governance or data management
In-depth knowledge of data governance principles, policies, and procedures, as well as industry best practices and regulatory requirements related to data management, privacy, and security.
Strong project management skills and experience leading cross-functional teams to implement data governance programs.
Excellent communication and collaboration skills with the ability to work across departments and at all levels of the organization.
Experience in banking, insurance or financial services industry will be highly recommended

Please contact Xavier Yap at XavierY@charterhouse.com.sg for a confidential discussion
EA License no: 16S8066 | Reg no.: R1980978
Only successful candidates will be notified.","['Management Skills', 'Leadership', 'Data Management', 'Private Banking', 'VBA', 'Risk Management', 'Data Quality', 'Data Governance', 'Data Mining', 'Compliance', 'Project Management', 'Banking', 'Tax Reporting', 'Regulatory Requirements', 'Financial Services']"
Data Engineer,383 SIN MING DRIVE 575717,Full Time,Executive,2 years exp,Engineering,Monthly,"$3,500to$6,800","Responsibilities:

Expanding data collection as      well as optimizing data pipelines for cross-functional teams
Work closely with data      analysts and business end-users to implement and support data platforms
Tuning, troubleshooting and      scaling identified big data technologies.
Analyse, tackle and resolve      day-to-day operational incidents related to data provision
Build suitable tools to      provide data through acquiring, monitoring and analyzing root cause of      data issues
Identify, design, and      implement process improvements and tools to automate data processing with      data integrity
Work with data scientist and      business analytics to assist in data ingestion and data-related technical      issues
Design, build and maintain      the batch or real time data pipeline in production using big data      technology
Design, build and manage data      warehouse such as designing data model
Create data views from big      data platform to feed into analysis engines or visualization engines

Requirements:

Bachelor degree in Computer      Science, Computer Engineering, Software Engineering or equivalent
At least 2 years of relevant      working experience in ETL/data integration and data modelling
Experience with Data      Engineering and Data Quality
Cloud experience, ideally      with Azure and AWS
Understanding of Big data      technologies like HDFS, Hive, Spark
Experience of relational or      NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL)
Experience in data      warehousing / distributed system
Experience in data      ingestion, cleaning and processing tools
Experience in data      acquiring, data processing using Scala/Python/Java
Highly organized,      self-motivated, pro-active, and desire to learn new technology
Excellent communication and      collaborative skills
","['Data modelling', 'Oracle', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'ETL', 'Data Integration', 'Data Quality', 'Data Engineering', 'SQL', 'Business Analytics', 'Visualization', 'Data Warehousing', 'Databases']"
SN9180682 - Senior Data Engineer,"REPUBLIC PLAZA, 9 RAFFLES PLACE 048619","Permanent, Full Time",Senior Executive,7 years exp,Information Technology,Monthly,"$10,000to$12,000","The Company

Our client is an innovative, international digital insurance consultancy that is growing massively in the region and is looking to hire a Senior Data Engineer. This person will be a key contributor in facilitating projects that involves data engineering expertise to meet their regional business needs. You will collaborate with stakeholders such as senior leaders, developers, data scientists, to architect and develop solutions using a multitude of advanced technologies, tools, and cloud services.

The Role

You will develop efficient data pipelines across multiples endpoints that support a variety of data types and formats while following established development and security best practices. You will review existing data architecture and identify issues or opportunities for improvement. You will propose data architecture for new projects. You will work with Event data, unstructured data, and related technology such as NoSQL and document database and establish and maintain platforms, tools, and best practices to improve the overall framework. You will utilize cloud services to improve end-to-end data pipeline performance, availability, and security. You will communicate and work directly with internal stakeholders to develop critical data solutions, make data-driven decisions, and achieve key business goals and partner with the project team to develop reliable, cost-effective, and high-quality solutions and provide timely communications around project progress and issue resolutions. You will also offer mentorship and train peers on standards around data engineering best practices, including documentation.

Your Profile

You must possess a Bachelor’s degree in Computer Engineering with over 8 years of data engineering experience and at least 2 years of data architecture experience. Solid understanding of SQL and relational databases and data warehouses with good understanding of NoSQL database types and implementations (i.e.. document, key-value, column, graph) are required. Solid experience with modern ELT/ETL tools and frameworks and working with various data types and formats, both structured and unstructured (e.g. JSON, XML, text, Excel, csv, parquet, etc.) are highly desirable. The capability to design, lead, implement, and support data engineering projects, developing and demonstrating proof-of-concept, proficient in at least one cloud technology stack with a focus on services that relate to data engineering, such as Azure (e.g. SQL/PostgreSQL Database, CosmosDB, Blob/Data Lake Storage, DMS, Data Factory, Synapse, Functions, VMs, Container Apps), AWS (e.g. RDS, Aurora, S3, EMR, DynamoDB, DMS, Glue, Athena, Redshift, Lambda, EC2, ECS Fargate are required. Knowledge of managing sensitive data (e.g. PII) and deploying solutions to maintain data privacy and security, experience in Big Data/distributed data processing (e.g. Spark, Hadoop, Flink) and understanding of version control (e.g. GitLab, GitHub, BitBucket) and expertise in at least one programming language (Python preferred, Golang, Scala, Java, etc.) are advantageous.

Apply Today

Please send your resume, in WORD format only and quote reference number SN9180682, by clicking the apply button. Please note that only short-listed candidates will be contacted.

EA Licence No: 07C5595 | EA Registration No: R1109288","['RDS', 'Factory', 'Scala', 'Azure', 'Pipelines', 'Architect', 'Hadoop', 'DynamoDB', 'Data Engineering', 'EMR', 'SQL', 'Python', 'Data Architecture', 'Java', 'S3', 'Databases']"
SN12578386 - Senior Data Engineer,"REPUBLIC PLAZA, 9 RAFFLES PLACE 048619","Permanent, Full Time",Senior Executive,7 years exp,Information Technology,Monthly,"$10,000to$13,000","The Company

Our client is an innovative, international digital insurance consultancy that is growing massively in the region and is looking to hire a Senior Data Engineer with a prior DevOps or CloudOps experience. This is an excited newly created role which will equip you with the autonomy to handle end-to-end data engineering scope. You will be a key contributor in facilitating projects that involves data engineering expertise to meet their regional business needs. You will collaborate with stakeholders such as senior leaders, developers, data scientists, to architect and develop solutions using a multitude of advanced technologies, tools, and cloud services.

The Role

You will develop efficient data pipelines across multiples endpoints that support a variety of data types and formats while following established development and security best practices. You will review existing data architecture and identify issues or opportunities for improvement. You will propose data architecture for new projects. You will work with Event data, unstructured data, and related technology such as NoSQL and document database and establish and maintain platforms, tools, and best practices to improve the overall framework. You will utilize cloud services to improve end-to-end data pipeline performance, availability, and security. You will communicate and work directly with internal stakeholders to develop critical data solutions, make data-driven decisions, and achieve key business goals and partner with the project team to develop reliable, cost-effective, and high-quality solutions and provide timely communications around project progress and issue resolutions. You will also offer mentorship and train peers on standards around data engineering best practices, including documentation.

Your Profile

You must possess a Bachelor’s degree in Computer Engineering with over 7 years of data engineering experience and at least 2 years of data architecture experience. Solid understanding of SQL and modern ELT/ETL tools and frameworks and working with various data types and formats, both structured and unstructured are highly desirable. The capability to design, lead, implement, and support data engineering projects, developing and demonstrating proof-of-concept, proficient in at least one cloud technology stack with a focus on services that relate to data engineering, such as Azure and or AWS are required. Knowledge of managing sensitive data (e.g. PII) and deploying solutions to maintain data privacy and security, experience in Big Data/distributed data processing (e.g. Spark, Hadoop, Flink) and understanding of version control (e.g. GitLab, GitHub, BitBucket) and expertise in at least one programming language (Python preferred, Golang, Scala, Java, etc.) are advantageous. Prior DevOps and/or CloudOps experience with the ability to design and develop CI/CD pipelines and establish deployment best practices with a good understanding of application development such as Python is highly preferred.

Apply Today

Please send your resume, in WORD format only and quote reference number SN12578386, by clicking the apply button. Please note that only short-listed candidates will be contacted.

EA Licence No: 07C5595 | EA Registration No: R1109288","['Version Control', 'Scala', 'Autonomy', 'Azure', 'Pipelines', 'Architect', 'Hadoop', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Data Architecture', 'Java']"
BL9091524 - Senior Data Engineer,"REPUBLIC PLAZA, 9 RAFFLES PLACE 048619","Permanent, Full Time",Senior Executive,7 years exp,Information Technology,Monthly,"$11,000to$13,000","The Company

Our client is a leading consulting firm with a global presence, and they are currently looking for a Senior Data Engineer as part of their expansion plans and this is an exciting opportunity to be part of a growing organization.

The Role

As a Senior Data Engineer, you will be responsible for building efficient data pipelines across multiple endpoints that support a variety of data types and formats, assess existing data architecture, and identify issues for improvement and recommend data architecture for new projects. You will define, oversee, and maintain platforms, tools, and best practices, utilize cloud services to improve data pipeline performance. You will work with internal stakeholders to develop critical data solutions and make data-driven decisions to achieve business goals.

Your Profile

You should possess a Degree, with at least 7 years of experience in data engineering, with 2 years of exposure in data architecture. You should have some experience with software engineering, be proficient in at last one cloud technology stack such as Azure or AWS. Solid SQL experience and expertise in at least one programming language such as Python, Golang, Java or Scala is required for the role. Extensive experience with ETL tools and frameworks will be needed.

Apply Today

Please send your resume, in WORD format only and quote reference number BL9091524 by clicking the apply button. Please note that only short-listed candidates will be contacted.

EA Licence No: 07C5595 | EA Registration No: R1217739","['Scala', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Data Architecture', 'Data Science', 'Consulting', 'Java', 'Databases']"
Senior Data Engineer,"NORTH BRIDGE CENTRE, 420 NORTH BRIDGE ROAD 188727",Full Time,Professional,5 years exp,Information Technology,Monthly,"$10,000to$15,000","We are seeking for an enthusiastic and inquisitive team to join our growing organization. In this position you will be given many opportunities to pick up and learn about location data, get your hands dirty from working with big data technologies, creating robust data pipelines and big data engineering solutions. You will also get chance to perform analysis on location data. The more curious you are, the more you will learn with us.
You’ll be working closely with all facets of the team and learning about the overall data economy.
Requirements and Qualifications

2-5 years of experience in data engineering, analytics or data science background.
Strong programming skills in Java/Python, excellent SQL skills
Experience with relational SQL and NoSQL databases.
Expertise in AWS services EMR, RDS, Athena, S3,Data Pipeline, Redshift
Experience with big data tools: Hadoop, Spark, Kafka
Experience with data streaming systems like spark-streaming, storm.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with shell scripting
Ability to quickly understand and appreciate underlying business context, problems and objectives of analytical projects
Clear communication skills to run well defined analysis and produce reports
Excellent time management skills

Duties and Responsibilities

Create and maintain optimal data pipeline architecture
Identify, design, and implement internal process improvements: automating manual processes, optimising data delivery, re-designing infrastructure for greater scalability
Build analytics tools that utilises the data pipeline to provide actionable insights into customer delivered data, operational efficiency and other key business performance metrics.
Optimise and improve our existing data products.

Benefits

Direct interaction and learning from an experienced team
Learning Big Data stack, data monetisation and business model of a data marketplace
Flexible working hours, work from home
","['RDS', 'Scalability', 'Big Data', 'Pipelines', 'Hadoop', 'Shell Scripting', 'ETL', 'Workflow Management', 'Data Engineering', 'EMR', 'SQL', 'Data Science', 'S3', 'Databases']"
Senior Data Engineer,"CROSS STREET EXCHANGE, 18 CROSS STREET 048423",Full Time,Professional,5 years exp,"Consulting, Information Technology",Monthly,"$7,000to$12,000","Are you at your most vibrant when you’ve successfully distilled data into its simplest, most meaningful form?
Thoughtworks is a global software consultancy with an aim to create a positive impact on the world through technology. Our community of technologists thinks disruptively to deliver pragmatic solutions for our clients' most complex challenges. We are curious minds who come together as collaborative and inclusive teams to push boundaries, free to be ourselves and make our mark in tech.
Our developers have been contributing code to major organizations and open source projects for over 25 years. They’ve also been writing books, speaking at conferences and helping push software development forward, changing companies and even industries along the way. We passionately believe that software quality is driven by open communication, review and collaboration. That’s why we’re such vehement supporters of open source and have made significant contributions to open source tools for testing, continuous delivery (GoCD), continuous integration (CruiseControl), machine learning and healthcare.
As consultants, we work with our clients to ensure we’re evolving their technology and empowering adaptive mindsets to meet their business goals. You could influence the digital strategy of a retail giant, build a bold new mobile application for a bank or redesign platforms using event sourcing and intelligent data pipelines. You will learn to use the latest Lean and Agile thinking, create pragmatic solutions to solve mission-critical problems and challenge yourself every day.
Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.
You’ll spend time on the following:

You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems
You will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy, support and operate data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product
Seamlessly incorporate data quality into your day-to-day work as well as into the delivery process

Here’s what we’re looking for:

You are equally happy coding and leading a team to implement a solution
You have a track record of innovation and expertise in Data Engineering
You’re passionate about craftsmanship and have applied your expertise across a range of industries and organizations
You have a deep understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
You’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments
Working with data excites you: you have created Big data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systems
Advocate your data engineering expertise to the broader tech community outside of Thoughtworks, speaking at conferences and acting as a mentor for more junior-level data engineers
Assure effective collaboration between Thoughtworks’ and the client’s teams, encouraging open communication and advocating for shared outcomes
","['Machine Learning', 'Modeling', 'Azure', 'Big Data', 'Cloud Computing', 'Pipelines', 'Hadoop', 'Data Quality', 'Data Engineering', 'EMR', 'Security Strategy', 'Digital Strategy', 'Architecture Design', 'Data Architecture', 'Continuous Integration', 'software development tools', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
DATA ENGINEER,"SPRINGLEAF TOWER, 3 ANSON ROAD 079909","Permanent, Full Time",Executive,1 year exp,Engineering,Monthly,"$5,500to$9,500","ABOUT US

Bright Point Capital Pte Ltd is a fund management company regulated by the Monetary Authority of Singapore (MAS). We are currently seeking talents to assist in managing one of our funds, Theme International VCC - Theme International Trading.

Theme International Trading's investment objective is to make liquid investments targeting high risk-adjusted returns. The fund uses quantitative trading models to capture arbitrage opportunities and improve market efficiency by providing liquidity and price discovery on the derivative markets.

We would like to expand our trading team and have motivated individuals with strong integrity to join us.

ROLE: DATA ENGINEER
If you are great at coding and data analysis, we would encourage you to apply!

Responsibilities:

Build ETL pipelines and processes to ingest data from variety of data sources
Manage large volumes of structured and unstructured data and transforming it into useable form for analytics purposes
Maintain and optimize the performance of our data analytics infrastructure to ensure accurate, reliable and timely delivery of key insights for decision making
Maintain and improve the quality of datasets
Automate data collection and processing for analytical modelling input
Perform simple machine learning tasks such as feature engineering, descriptive statistics etc


Requirements:

Diploma/Bachelor Degree in Computer Science or equivalent
Good command of database structures and query languages.
2+ years of Python development experience, preferably familiar with popular libraries such as Pandas, Scrapy.
Experience working with cloud infrastructure such as Azure, AWS, or GCP
Knowledge in Big Data, Sparks, Hadoop HDFS will be added advantage
Knowledge in NLP, Machine Learning and frameworks like sklearn and Tensorflow/Keras/PyTorch would be a plus.


ATTRACTIVE BENEFITS

Daily lunch provided in office
Employee group medical insurance
In-house gym & shower
Fully-stocked employee pantry


APPLICATION PROCEDURE:
Interested candidates please submit your CV and cover letter to:recruit@themeinternationaltrading.com","['Machine Learning', 'Pandas', 'Data Analysis', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'ETL', 'Targeting', 'Python', 'Statistics', 'Capital', 'Arbitrage', 'GCP', 'Analytical Modelling', 'Data Analytics']"
 , , , , , , , , , 
 , , , , , , , , , 
Business & Data Analyst,"GOLDBELL TOWERS, 47 SCOTTS ROAD 228233",Full Time,Executive,2 years exp,"Information Technology, Others",Monthly,"$3,000to$4,500","What do we do?
Join the ride at SWAT Mobility - If you're up for a challenge with one of the most exciting startups in the field of Smart Mobility, Transit and Logistics Technology!

SWAT is a high-tech mobility company that focuses on dynamic, on-demand, ride-sharing technology. With our world-class routing platform, we have deployed our solutions for governments in Singapore, Japan and Australia. Having deployed in 8 countries, we also look at solving multiple mobility challenges including optimizing employee transport for large corporations, reimagining public transport, creating data driven intelligent transport planning and introducing high tech logistics solutions to bring higher convenience, better visibility and reduced cost to our customers.

We are on a mission to empower the world to move more with less.
SWAT is looking for a Business & Data Analyst to join the Analytics Team. The ideal candidate is someone who is able to think critically, is a self-starter, and comfortable with open ended problem solving. We value effective communicators with a positive work attitude that are motivated by the desire to learn, achieve and contribute.

Responsibilities

Partner with sales and operations teams in developing pre-sales solutions, analyzing client data and validating solutions with our in-house simulation engine.
Support analytics services delivering large-scale analytics consulting projects.
Design and implement operational dashboards and queries for internal/external stakeholders to assist in pattern, trend and business insights identification.
Write scripts to automate reports workflows and processing of large datasets.

Desired Skills

Advanced Python knowledge
Basic to intermediate SQL knowledge
Ability to work with large amounts of data to discover patterns and trends and form conclusions based on findings. Must be extremely detail oriented.
Ability to create beautiful, structured presentation decks
Excellent analytical, communication and problem-solving skills
Exposure to one or more dashboarding platforms (Tableau/PowerBI/Metabase)
Knowledge of Geographical Information Systems (GIS) tools would be a bonus
Experience in the transportation sector would be a bonus

Qualifications

Minimum of 2 years experience in a Data Analytics role.
Bachelor’s Degree or higher from a recognised university, preferably in a quantitative subject.
If you are not from a quantitative subject you are still more than welcome to apply, so long as you are able to meet the technical skill requirements specified above.
","['SWAT', 'Tableau', 'Microsoft Excel', 'Data Analysis', 'Trend', 'Problem Solving', 'Routing', 'Public Transport', 'SQL', 'Transportation', 'Python', 'Consulting', 'Data Analytics', 'Power BI']"
Senior Fraud Data Analyst,"PRUDENTIAL TOWER, 30 CECIL STREET 049712",Full Time,Senior Executive,2 years exp,Engineering,Monthly,"$8,333to$16,666","This role will work on building out Airwallex’s risk product domain with a focus on delivering a financial crime detection and prevention solution across all product domains. Airwallex is building a centralised risk platform that will harness advanced analytics and machine learning techniques to enable real-time decisioning across a diverse range of product lines and platforms. The risk product domain is responsible for building the platforms, engines & case management whilst also delivering the risk models so you will be involved in crafting the full end-to-end risk capability.
As a fraud data analyst, the principal responsibility of this role will be to conceive, design, and monitor fraud risk management strategies to manage fraud losses and improve business profitability for our acquiring, payout and FX products. You will be responsible for developing risk detection framework and fraud solutions to ensure optimal balance between user experience, business enablement, operational expense and loss exposure.

Responsibilities:

Craft and refine risk strategies which include defining risk controls, the customer experience and operational workflows with emphasis on minimizing the impact on customers, our brand and organizational critical metrics.
Use data driven insights to size opportunity, measure performance and to determine what is working and what is not working; Monitor performance of existing & new solutions and optimize to ensure desired results
Communicate concise and actionable business strategies and present new strategy recommendations to senior management for approval
Collaborate with partner in Platform, Operations and other internal teams, as well as external partners like data vendors to formulate and execute fraud risk solutions

Qualifications:

Msc/BS degree in Mathematics, Statistics, Operations Research, Finance, Economics or related quantitative discipline.
2-5 years proven fraud or credit risk experience or equivalent, including analytics, modeling implementation, and stakeholder management.
Must be an intuitive, organized analytical thinker, with the ability to perform detailed analysis. Knowledge of analytical tools and use of data to validate strategies or hypotheses.
Demonstrates excellent consensus building written, verbal and presentation skills with senior leaders of the organization.
Experience working with cross-functional, geographically distributed teams, managing by influence is a plus.
Proficiency in SQL and in at least one statistical analysis tool: Python / R / SAS
","['Machine Learning', 'Customer Experience', 'Mathematics', 'Operations Research', 'Economics', 'SQL', 'Python', 'Fraud', 'Presentation Skills', 'Statistics', 'Prevention', 'Case Management', 'Stakeholder Management', 'Fraud Risk Management', 'Credit Risk']"
Data Engineer,4 KAKI BUKIT AVENUE 1 417939,"Permanent, Full Time",Professional,5 years exp,"Engineering, Sciences / Laboratory / R&D",Monthly,"$5,000to$10,000","We are seeking a strong candidate with AI & analytics experience to work with an exciting robotics intelligence project in Delta Research Centre. The role will be responsible for executing analysis that deliver valuable insights, providing predictive analytic solutions with high quality and making sure the deployment with sound business sense. Candidate will participate and execute project through contribution of analytics research and deliver impactful research and business outcomes.

Job Description

Contribute to the development of on-going or new research and development effort in perception, navigation, material handling for robotics intelligence
Design, implement and evaluate robotic perception, cognitive computing and decision making framework for intelligent mobile robot
Develop solutions and insights based on image/signal processing, modelling, machine learning and data fusion methods
Perform on-site or off-site data collection, data organization and processing
Perform algorithm modification, training, testing and validation under different conditions

Job Requirements

Programming skills: Python, C/C++
Must be result-orientated, independent and a self-driven team player
Strong in written and verbal communication
","['Tableau', 'Machine Learning', 'Verbal Communication', 'Big Data', 'Hadoop', 'Mathematics', 'Research and Development', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Data Science', 'Robotics', 'Team Player', 'Decision Making', 'Data Analytics']"
Data Engineer,"PARK AVENUE CHANGI, 2 CHANGI BUSINESS PARK AVENUE 1 486015",Permanent,Professional,5 years exp,Information Technology,Monthly,"$7,000to$11,000","· 5-10 years of application development experience in Spark, Spark SQL, Scala with Java/python/.Net is a must.
· Strong understanding and hands on experience of Big Data technologies like CDH, Hadoop/HDFS, S3, Colibra, Claudera Workbench, etc
· Technical proficiency on data mining techniques and performance optimization
· Adequate knowledge of database systems (RDBMS, MariaDB, SQL, NOSQL)
· Handling of reporting packages (Tableau, QlikView) is nice to have
· AWS experience is nice to have
· Degree in Computer Science or Engineering is a must
· Good problem diagnosis and creative problem-solving skills
· Passion to learn and master diverse new technologies in the open-source community
· Accuracy and attention to detail
· Team-working, Verbal and Written communication skills","['Tableau', 'Scala', 'Big Data', 'Pipelines', 'Hadoop', 'Application Development', 'ETL', 'MariaDB', 'Data Engineering', 'Data Mining', 'SQL', 'Java', 'Databases']"
 , , , , , , , , , 
Data Engineer,"WOODLANDS EAST INDUSTRIAL ESTATE, 57 SENOKO DRIVE 758236","Permanent, Full Time",Executive,2 years exp,Engineering,Monthly,"$3,500to$5,800","Job Scope

To provide the technical drive on the company’s i4.0 digitalization and automation plans.
To understand departmental digitalization requirements and use programming or software to reduce digital waste.
Help to drive digitization / digitalization efforts for data analysis on key operational metrics; to increase operational capacity, efficiency, productivity and manpower utilisation.
To design and build data solutions that support company’s data and analytics strategy in driving business insights.
To work closely with ERP, MES and other technology vendors to implement and support the company’s implementations.

Requirements

Respectful
Good communication skills
Growth mindset
Willing to accept new challenges and learn
Technical requirements: Industrial control and automation, Power and PLC systems
Academic qualifications in computer science or related fields
Min programming skills: Python, SQL database
Understanding of data governance, data security and data analytics
","['MES', 'Data Analysis', 'Big Data', 'Pipelines', 'ERP', 'Hadoop', 'ETL', 'PLC', 'Data Governance', 'SQL', 'Good Communication Skills', 'Python', 'Digitization', 'Data Analytics', 'Databases']"
Manager - Data Science,"ONE MARINA BOULEVARD, 1 MARINA BOULEVARD 018989","Permanent, Full Time",Manager,2 years exp,Information Technology,Monthly,"$10,000to$13,000","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities, and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.
Functional Description
Decision Science colleagues will serve as a key member of the Credit and Fraud Risk organization. We seek a thought-leader and a problem-solver who can blend business, technical, and industry best practices when it comes to developing the analyses, models, and algorithms that power our customers’ digital experiences.
This critical team is responsible for managing enterprise risks throughout the customer lifecycle, across our consumer and commercial businesses, and across all our global products. We develop industry-first data capabilities, build profitable decision-making frameworks, create machine learning-powered predictive models, and improve customer servicing strategies.
Our Decision Science teams use industry leading modeling and AI practices to predict customer behavior. We develop, deploy and validate predictive models and support the use of models in economic logic to enable profitable decisions across credit, fraud, marketing and servicing optimization engines.
Responsibilities:

Work with massive amounts of digital data (Web, App, API) and sophisticated tools in an industry leading Big Data environment.
Build everything from basic reports to advanced machine learning models and algos to drive improvements to our customer’s online and mobile app experiences.
Work with product owners to revolutionize the product and content design with a data-driven approach
Collaborate with tech partners to test, implement and deploy modeling solutions to production system.
Develop insights into customer behavior and introduce new approaches to transform complex behavioral data into actionable information
Leverage the power of closed loop through Amex network to make decisions more intelligent and relevant
Innovate with a focus on developing newer and better approaches using big data & machine learning solutions

Qualifications:

PhDs in a quantitative field (Computer Science, Statistics, Mathematics, Physics, Operation Research and etc.) with hands-on experience leveraging sophisticated analytical and machine learning techniques. PhD degree with practical experiences NLP is a significant plus.
Expertise in an analytical language (Python, R or the equivalent), and experience with databases (Hive, SQL, or the equivalent). Knowledge of SAS is a plus but not required.
Deep understanding of machine learning/statistical algorithms such as deep learning and boosting. Experience with data visualization is a plus
Demonstrated ability to frame business problems into mathematical programming problems, leverage external thinking and tools (from academia and/or other industries) to engineer a solution and deliver business insights.
Ability to work effectively in a team environment
Independent thinker who’s organized, has great attention to detail, and can multi-task
Strong communication skills
Ability to learn quickly and work independently with sophisticated, unstructured initiatives
Ability to integrate with cross-functional business partners worldwide
Proficient in presentation tools, including Excel and PowerPoint
","['Machine Learning', 'MASSIVE', 'Modeling', 'Big Data', 'Customer Experience', 'Physics', 'Mathematics', 'SQL', 'Attention to Detail', 'Python', 'Fraud', 'Statistics', 'Databases', 'Data Visualization']"
 , , , , , , , , , 
Data Analyst,5 LOYANG WAY 508720,Permanent,Junior Executive,1 year exp,Information Technology,Monthly,"$3,800to$4,500","Job Requirements


Collecting the data from multiple heterogeneous data sources (SAP, K2, Salesforce CRM)
Check the actual nature of the data by conducting preliminary data analysis
Conduct the thorough analysis of data to check for meaningful data
Perform data mining with using different querying techniques of SQL
Check for different data configurations and patterns
Create different kind of reports with using different Business Intelligence tools like Jet Report or Power BI
Master data quality (guidelines and analysis) and collaboration with various departments
SAP & Salesforce optional (On job training provided)


Job Requirements


Min a degree holder
Experience in BI tools
Understand and gather business requirement
Act as business partner between business and IT
Willing to work at Loyang
","['Tableau', 'Machine Learning', 'Microsoft Excel', 'Data Analysis', 'Mathematics', 'Data Mining', 'SQL', 'SAP', 'Python', 'Business Intelligence Tools', 'Statistics', 'Visualization', 'Data Analytics', 'Power BI', 'Databases', 'Data Visualization']"
Data Engineer,"OXLEY BIZHUB 2, 62 UBI ROAD 1 408734",Full Time,Junior Executive,3 years exp,Information Technology,Monthly,"$4,500to$4,950","This role is under: the Tech Team

PropertyLimBrothers is looking for a data engineer with strong data engineering skills and is responsible for building and managing platforms that will enable the business to thrive in the technology space.
You are required to have a deep appreciation of the complexity of the data engineering process, such as the challenges of data ingestion involving large or near-real-time datasets, the maintenance of high data quality, and the importance of automation for increasing ETL pipeline robustness and reducing the need for human intervention.

What will I be doing?

- Maintain and improve systems architecture for data engineering services and their ecosystem, spanning distributed cloud databases and databanks (AWS, Redshift, Google).
- Develop highly automated self-service data platforms with automated data pipelines for business users and data team to leverage on building visualisations. Ensure data-quality is of highest standards and accuracy.
- Champion the introduction of next-generation technologies in the data-ingestion workflow. Explore and evaluate possibilities of expanding the scope of data that can be ingested to future-proof and achieve our roadmap.
- Support the research and development of statistical machine learning and deep learning algorithms to meet complex product requirements. The scope includes defining hypotheses, executing necessary tests and experiments; evaluating, tuning and optimising algorithms and methods; and having an eye towards cloud implementation ease, scalability, and robustness in a live customer-facing production environment.

JOB REQUIREMENT

What is required of me?

- Minimum 3 years experience as a Data Engineer with hands-on experience in building data pipelines and web scrapping.
- Proficient in Python, SQL and JavaScript.
- Front-end Reporting & Dashboard and Data Exploration tools – Tableau.
- Strong analytical and technical skills in building data pipelines and API.
- Degree in Computer Science, Computer Engineering or equivalent.
- Experience in setting up AWS databases.
- Self-starter who is able to work independently in a fast-paced environment.","['Tableau', 'Machine Learning', 'Dashboard', 'Scalability', 'Pipelines', 'Customerfacing', 'JavaScript', 'ETL', 'Data Quality', 'Research and Development', 'Tuning', 'Data Engineering', 'SQL', 'Python', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Engineer,"SGX CENTRE II, 4 SHENTON WAY 068807","Contract, Full Time",Executive,2 years exp,Information Technology,Monthly,"$4,000to$6,000","Job Description:


Involve in project ideation / initiation phase and contribute to do preliminary business study
Analyze, assess and clarify functional specifications
Write specifications and ensure, validation and adherence to project's stakeholders needs
Enhancing data collection procedures to include information that are relevant
Processing, cleansing and verifying the integrity of data used for analysis
Implement and test components from functional specifications

Job Requirement:


Working knowledge of common data management toolkits such as SQL, R, Python, etc. and data visualization tools like Power BI, Tableau, Excel, etc
Data reporting and visualization experience with the ability to tell a story and drive analytics solutions is a plus.
Practical know-how with data integration and business intelligence tools such as ETL, Data warehousing, OLAP Cubes or semantic layers as well as data visualization tools and methods.


EA Number: 11C4879","['Tableau', 'Big Data', 'Pipelines', 'T-SQL', 'Hadoop', 'Data Management', 'ETL', 'Data Integration', 'SQL', 'Python', 'Business Intelligence Tools', 'Excel', 'OLAP', 'Visualization', 'SSIS', 'Power BI', 'Data Warehousing', 'Data Visualization', 'SSRS']"
Data Engineer,"MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Senior Executive,4 years exp,Information Technology,Monthly,"$6,100to$9,200","
Work with Industry 4.0 data program team which includes project implementation vendor resources, data experts from manufacturing engineering team, data analysts & business stakeholders.
Support end to end set up of data platform which is scalable and future proof for Maxeon based on the functional/non-functional & technical requirements.
Integrate data platform with Maxeon Applications and 3rd party system as required from both On-Premise and Multi Cloud.
Expand and optimize our data and data pipeline architecture, as well as optimize data flow systems in a secured and scalable manner.
Assemble large, complex data sets that meet functional / non-functional business requirements, transforming data into formats that are easy to consume and analyze.
Translate complex business requirements into scalable technical solutions meeting data warehousing design standards.
Solid understanding of analytics needs and proactiveness to build generic solutions to improve overall efficiency.
Data Profiling & Cleansing of data by applying data quality checks before ingesting the data.
Ingest, transform, process and store data efficiently into a database, data lake or Datawarehouse platform hosted on premise or cloud based environment.
Design & Build database, Enterprise Datawarehouse design and data modelling. To be able to organize data at both macro and micro level and provide logical data models for the consumers.
Build data foundation to provide an enterprise view of data across the organization which can be seamlessly accessed by Business users through Self-Service reporting.
Build a centralized data repository (Sand Box environment) with a robust data foundation to enable data discovery, data mining for advanced analytics usecases.
Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Able to communicate effectively, both written and verbal, with technical and non-technical multi-functional team

Knowledge and Technical Skills:

Bachelors degree in Science or Information Technology
Certified in Data & Analytics Cloud based solution
Proven track record in designing and implementing large-scale data solutions, performing architectural assessments, optimizing data models, establish and enforce engineering guidelines and standards on Cloud based environments
4+ years of experience in technical architecture, design & build of Data & Analytics projects in a multinational organization on On-Premise & Cloud based solutions.
In-depth experience in working with a data warehouse and knowledgeable on data warehouse modelling techniques
Highly knowledgeable in ETL/ELT processes, both design and implementation using various leading tools like for example Informatica, Ab-Initio, Talend etc
Experienced in implementing data pipelines for stream and batch ingestion/processing using Open-Source tools (Kafka, Apache Spark) as well as Cloud Native solutions.
Good experience in building data pipelines that ingests various types of data sources (structured, semi-structured and unstructured) into a database or data lake and populating a structured warehouse or data mart
Experienced in building data lake (distributed storage, Object store), databases & Datawarehouse in cloud (AWS, Azure, GCP), moving data applications to the cloud, and developing cloud native data applications.
Experienced in implementing SQL, NoSQL databases & MPP databases
Experience in Data archiving & Life Cycle Management.
Data Warehouse design, BI reporting and Dashboard development.
Prior experience in leading a team of technical developers will be a plus
Advanced SQL and Python skills are mandatory
Prior data modeling (dimensional, relational) and data engineering experience is mandatory
Prior experience in leading a team of technical developers will be mandatory
Strong understanding of development processes and agile methodologies is necessary

Complexity:

Works on problems and projects of diverse complexity.
Engages in analyses requiring evaluation of identifiable factors.
Exercises independent judgment within generally defined boundaries.
Networks with senior individuals, internally and externally, within own area of expertise.
","['Apache Spark', 'Azure', 'Data Modeling', 'Pipelines', 'Advanced SQL', 'Informatica', 'Data Quality', 'Data Engineering', 'Data Mining', 'SQL', 'Python', 'Abinitio', 'Data Warehousing', 'Databases', 'Business Requirements']"
Senior Data Analyst,"61 ROBINSON, 61 ROBINSON ROAD 068893",Contract,Professional,4 years exp,Information Technology,Monthly,"$9,000to$12,000","SALT Talent is hiring Senior Data Scientist for a global technology company for 12-months & renewable contract position. You will use data to shape product development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people.
Responsibilities:

Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.
Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses.
Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends.
Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations.
Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.
Preferred 4 to 6 years of relevant work experience.
Analytics : You will guide teams using data and insights. You will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them.
Communication and influence: You won’t simply present data but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity and be a trusted strategic partner.
Good SQL, Data Visualization, Python Data Analysis preferred

If you find this role interesting, kindly reach out to me Jaya jvenkataraman@welovesalt.com alternatively you may apply via the system!
CEI No: R1659595 / EA No: 07C3147","['Tableau', 'Forecasting', 'Microsoft Excel', 'Data Analysis', 'Experimentation', 'Mathematics', 'Quantitative Analysis', 'Product Engineering', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Visualization', 'Product Development', 'Data Analytics', 'Data Visualization']"
 , , , , , , , , , 
Data Engineer,"PAYA LEBAR SQUARE, 60 PAYA LEBAR ROAD 409051","Contract, Full Time",Middle Management,3 years exp,Information Technology,Monthly,"$8,000to$11,000","• Must have development experience in Big Data, Hadoop, Python, PySpark technologies. 

• Proficient in Oracle & PL/SQL with at least experience with the ability to fine tune performance of queries. 

• Ability to write complex analytical queries / Stored Procedures / Packages. 

• Good exposure to Unix/ Linux OS basic commands and hands on in Shell scripting. 

• Experience in L3 Production Support and Analysing & troubleshooting the production issues by engaging other relevant support teams. 

• Multi-tasking abilities and should be able to work under stringent deadlines.","['Machine Learning', 'PySpark', 'Troubleshooting', 'Oracle', 'Big Data', 'Pipelines', 'Hadoop', 'Shell Scripting', 'ETL', 'Unix', 'Data Engineering', 'SQL', 'Python', 'Java', 'Databases', 'Linux']"
Data Engineer,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979","Contract, Full Time",Senior Executive,3 years exp,Information Technology,Monthly,"$6,000to$10,000","Data Engineer (Azure Data Factory, Databricks, DevOps)

As a Data Engineer, you will support the implementation of projects focused on collecting, aggregating, storing, reconciling, and making data accessible from disparate sources to enable analysis and decision making. This role will also play a critical part in the data supply chain, by ensuring stakeholders can access and manipulate data for routine and ad hoc analysis. Additionally, you will support the full lifecycle of data from ingesting through analytics to action.

Key Role Responsibilities:
Day-to-day you will:

Translate business requirements to technical solutions leveraging strong business acumen 
Analyze current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services
Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
Deliver of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
Design and Build Modern Data Pipelines and Data Streams.
Design and Build Data Service APIs.
Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience
Implement effective metrics and monitoring processes.


Skill &amp; Capability Requirements:

Around 3 years of working experience as a Data Engineer 
Demonstrated experience in turning business use cases and requirements into technical solutions 
Experience in business processing mapping of data and analytics solutions. 
Ability to conduct data profiling, cataloging and mapping for technical design and construction of technical data flows
The ability to apply such methods to solve business problems using one or more Azure Data and
Analytics services in combination with building data pipelines, data streams, and system integration.
Ability to leverage a variety of programming languages &amp; data crawling/processing tools to ensure data reliability, quality &amp; efficiency
Experienced in Cloud Data Transformation using ETL/ELT tools such as Azure Data Factory, Databricks
Experienced in building modern cloud-based data architectures, building Lakehouse architecture using Databricks, and technologies such as Data Lake, Delta Lake, and Data Lakehouse e.g., Azure Data Lake Gen 2, Azure Delta Lake
Experienced in building data pipelines using pyspark and distributed computing, Python scripting using data engineering and machine learning libraries, PowerShell, bash, DAX, M-language, Big data files formats e.g. Parquet, Avro, ORC and Big data technologies such as Hadoop, Hive, Map-Reduce, Partition design, performance tuning in Spark
Experienced in Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals.
Experienced in Data Governance tools like Unity Catalog / Purview, Master Data Management (MDM) and Data Quality tools and processes
Knowledge of business intelligence tools such as Power BI, Tableau, Qlik, Cognos TM1
Knowledge of Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.
Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB &amp; Azure Stream Analytics are a plus.
Knowledge in data modeling and database management, such as performance tuning of the
Enterprise Data Warehouse, Data Mart, and Business Intelligence Reporting environments, and support the integration of those systems with other applications 
Experience preparing data for use in Azure Machine Learning / Azure Databricks
Experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc). 
Designing and building Data Pipelines using streams of IoT data. 
Knowledge of Lambda and Kappa architecture patterns.
Strong team collaboration and experience working with remote teams.  
Working experience in Visual Studio, PowerShell Scripting, and ARM templates.
Azure certifications (AZ-900, AZ-200, and 201), Databricks certification, DevOps certifications
","['Tableau', 'Machine Learning', 'Azure', 'Big Data', 'Data Modeling', 'DevOps', 'Pipelines', 'Hadoop', 'Data Transformation', 'Scripting', 'Data Quality', 'Data Governance', 'Data Engineering', 'SQL', 'Python', 'Power BI', 'Databases']"
Staff / Senior Risk Data Scientist,"PRUDENTIAL TOWER, 30 CECIL STREET 049712",Full Time,Senior Executive,7 years exp,Engineering,Monthly,"$11,666to$20,000","The Role:
This is a diverse role working within Airwallex’s risk product & analytics domain with a focus on delivering data insights to drive product & analytics optimisations and enhancements. Airwallex is building a centralised risk platform that will harness advanced analytics and machine learning techniques to enable real-time decisioning across a diverse range of product lines and platforms. The risk product & analytics domain is responsible for building the platforms, engines & case management whilst also delivering the risk models so you will be involved in crafting the full end-to-end risk capability.

Responsibilities：

Work with risk stakeholders throughout the company to identify opportunities for leveraging company data to drive risk solutions.
Mine and analyze data from the company database to drive optimization and improvement of risk strategies.
Assess the effectiveness and accuracy of new risk data sources and data gathering techniques.
Develop customized data models and algorithms to risk data sets and communicate the insights of the models to related stakeholders.
Develop A/B testing framework and test model quality for risk product.
Coordinate with multiple functional teams to implement models and monitor performance.
Develop processes and tools to monitor and analyze model performance and data accuracy.

Qualifications：

Bachelor's degree or higher in Computer Science, Math & Statistics, Finance & Economics, Engineering or related data disciplines.
At least 7 years of experience as a data analyst, data scientist or data engineer.
Strong problem-solving skills with an emphasis on risk-related product development.
Hands-on and solid experiences in using statistical computer languages (Python, R, SQL, etc.) to manipulate data and draw insights from large data sets.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, simulation, properties of distributions, statistical tests, etc.) and experience with applications.
A drive to learn and master new technologies and techniques.
Excellent written and verbal communication skills in English for coordinating across teams.
Experience working on data-driven financial risk models (e.g., money-laundering risk, credit risk, fraud risk) is preferred.
Experience running data analytics under cloud environments and using web applications is preferred.
","['Zumba', 'Machine Learning', 'Courts', 'XGBoost', 'Economics', 'Table Tennis', 'Yoga', 'SQL', 'Python', 'Foreign Languages', 'Fraud', 'Statistics', 'Ab Testing', 'Financial Risk', 'Data Analytics', 'Credit Risk']"
 , , , , , , , , , 
Data Management Officer,"OXLEY BIZHUB, 67 UBI ROAD 1 408730",Full Time,Junior Executive,1 year exp,"Admin / Secretarial, Customer Service, Professional Services",Monthly,"$2,000to$2,700","Job Description
CNCData seeks a Data Management Officer with a strong background in administration and data to join our team. The successful candidate will get excellent career advancement opportunity to grow to a leader role.

Responsibilities

To maintain and update records in CRM systems accurately
Manage the day-to-day communication and reporting with the designated client contact and ensure requests and queries are dealt with quickly and effectively
Perform logical check and data hygiene check constantly on data files and in systems.
Standardize, format and code data according to our internal standards
Performs and documents procedures for data collection, updating, cleaning and standardization
Involve in merging and consolidation of multiple data files from various data sources
Assist in other ad-hoc assignment

Requirements:

Candidate must possess at least a diploma in Administration, Data or Information-related fields with 1-2 years of relevant experience
Candidates with prior working experience with CRM systems are preferred
Preferably an advanced user of MS Excel. Must know how to use MS Word & MS Excel
Able to liaise effectively with client, internal team and contract staffs
Strong commitment, responsibilities, organized and independent
Highly self-motivated, problems solving skill and is a good team player
Be able to work with tight schedules
Good written and oral communication skills in English is required
Able to work dynamic, under pressure and results oriented
","['Microsoft Office', 'Microsoft Excel', 'Data Management', 'Team Spirit', 'Administration', 'Data Quality', 'Adaptability', 'Attention to Detail', 'Communication Skills', 'Administrative Support', 'Service Excellence']"
Data Engineer,12 Marina Boulevard  018982,Contract,Executive,5 years exp,"Banking and Finance, Information Technology",Monthly,"$9,000to$18,000","Responsibilities:

Design and build resilient and efficient data pipelines for both batch and real-time        streaming data
Architect and design data infrastructure on cloud using industry standard tools
Execute projects with an Agile mindset
Build software frameworks to solve data problems at scale
Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools
Ensure data integrity and scalability through enforcement of data standards. Improve data        validation and monitoring processes to proactively prevent issues and quickly identify issues. Drive resolution on the issues.
Define, understand, and test external/internal opportunities to improve our products and        services.

Requirements:

Bachelor’s Degree in Computer Science or have equivalent professional experience
Solid Experience with data processing tools such as Spark, Flink
Solid Experience implementing batch and streaming data pipelines
Solid experiences in Python/Go/Scala/Java.
In-depth knowledge of both SQL and NoSQL databases, including performance tuning and        troubleshooting
Familiar with DevOps tools such as Git, Docker, k8s
Experience with the cloud (e.g. AWS, Ali Cloud, GCP, Azure)
Be proficient in SQL, familiar with advanced SQL features such as window functions, aggregate        functions and creating scalar functions/user-defined functions.
Proven successful and trackable experience in full end-to-end data solutions involving data        ingestion, data persistence, data extraction and data analysis.
Self-driven, innovative, collaborative, with good communication and presentation skills

Preferred Qualifications:

Experience in FinTech, eCommerce, SaaS, AdTech, or Digital Wallet business industries.
Experience in working with teams across offices and timezones is a plus.
Experience in big data tools such as Amplitude/Tableau/QlikView, Ali Cloud DataWorks,        MaxCompute, Hadoop, Hive, Spark and HBase is a big plus.

Interested applicants, please email your resume to Celine Tan Si Ling
Email: celinetan@recruitexpress.com.sg
CEI Reg No: R1104662
EA Licence No: 99C4599","['Tableau', 'Git', 'digital wallets', 'Apache Spark', 'Scala', 'Big Data', 'Hadoop', 'Agile', 'Computer Science', 'QlikView', 'SQL', 'Python', 'SaaS', 'Hive', 'Docker', 'Java', 'HBase']"
Data Engineer,2 YISHUN AVENUE 7 768924,"Permanent, Full Time",Junior Executive,2 years exp,"Engineering, Information Technology",Monthly,"$3,800to$5,500","ASM Data Engineer
As ASMPT is rapidly growing, we embark to become a data-driven organization and are expanding our data platform. We seek an individual with strong passion in Data Engineering who will be comfortable to work in both on-premise and Cloud environments to build the data platform to support structured & unstructured datasets. You will be able to use different tools or create customized tools to transform and load data, administrate databases such as SQL and Hadoop, as well as implementing machine learning models for AIoT (Artificial Intelligence of Things).

Your Responsibilities

Manage and support on-premise and Cloud-based data lake and warehouse systems
Design, build, support and optimize new and existing data structure and ETL processes
Build scalable and efficient data pipelines & services to help analytics teams to process the data
Design useful dashboards and visualisation tools to display data insights and prediction/forecasting results
Liaise with third party tool providers to understand and improve data workflow
Work closely with data scientists and data analysts to deliver analytical solutions with robust underlying data platforms
Work with business team and data analysts to understand business requirements and build efficient and scalable data solutions


Minimum Qualification

Bachelor Degree in Computer Science, Software Engineering, Information Technology or any related disciplines
At least 2 years’ experience in data engineering, automation and integration is preferred
Strong programming and scripting skills in Python and other modern programming languages
Strong data management, schema design and SQL development skills
Deep understanding of databases and best engineering practices – which include logging, scaling up computation, continuous integration and continuous development (CI/CD)
Self-motivated and proactive, willing to learn new things
Good communication skills and strong team player


What our preferred candidates have?

Passionate in dealing with data, learning new data technologies, and discovering innovative and interesting solutions
Understand and experienced with Cloud platform, eg. Microsoft Azure, AWS, GCP
Business intelligence and reporting tools, eg. Power BI, Tableau, Qlik, etc
Experienced in development using Big Data platform (Hadoop/Hive/Hbase/Spark, etc.)
REST/Web API development and management
Knowledge in Statistical software is an advantage
Experience In building machine learning models is a plus


","['Tableau', 'Machine Learning', 'Big Data', 'Pipelines', 'Hadoop', 'Data Management', 'Artificial Intelligence', 'Software Engineering', 'Scripting', 'ETL', 'Data Engineering', 'SQL', 'Python', 'GCP', 'Databases', 'Business Requirements']"
Data engineer,"DELTA AVENUE ESTATE, 5 DELTA AVENUE 160005",Full Time,Executive,2 years exp,Sciences / Laboratory / R&D,Monthly,"$7,000to$14,000","Responsibilities

Manage event tracking, collaborate with the business team to build data metrics.
Data analysis and follow-up of operation activities.
In-depth understanding of business scenarios and pain points, provide data-driven solutions for various business lines.

Qualifications

Bachelor's degree or above in Computer Science or related majors, with 2-8 years experience in data development.
Good knowledge of data structure and algorithm foundation.
At least 2 years of experience in the data warehouse.
At least 2 years of experience in custom ETL design, implementation, and maintenance.
At least 2 years of experience with SQL statements, schema design, and dimensional data modeling.
At least 2 years of experience working with big data technologies such as Hadoop, Hive, Spark, Kafka，Hbase, etc.
Proficient in at least one object-oriented programming language such as Java, Scala, Python, etc.
Good communication skills, including the ability to identify and communicate data-driven insights.
","['Machine Learning', 'Scala', 'Data Analysis', 'Big Data', 'Data Modeling', 'Pipelines', 'Hadoop', 'ETL', 'Data Engineering', 'SQL', 'Good Communication Skills', 'Python', 'Data Science', 'Java', 'Data Analytics', 'Databases']"
Data Engineer,"PARKVIEW SQUARE, 600 NORTH BRIDGE ROAD 188778",Full Time,Non-executive,1 year exp,"Consulting, Engineering, Information Technology",Monthly,"$9,000to$11,000","Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 6 years, 10 locations and 600+ employees later we still believe that today. We connect the dots within our customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our customers, we are looking for Data Engineers with a proven track record and who are looking for an opportunity to learn new skills and progress their careers in a dynamic and exciting start-up environment.   🚀

What does a Data Engineer role at Quantexa look like?
In order to be a successful Data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders. You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.

Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our clients expectations and delivering a first-class service. 🥇

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion, Entity Resolution and Elasticsearch, with our platform being hosted on both private and public virtual clouds, such as Google cloud, Microsoft Azure and Amazon. Our primary language is written in Scala, but don’t worry If that’s not currently your strongest language, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Typical responsibilities include:
· Write defensive, fault tolerant and efficient code for data processing.
· Automate data processing to enable on-going alerts on high-risk activity.
· Participate in customer workshops and refinement sessions, presenting project results to clients both face to face and virtually.
· Work very closely with data scientists to ensure efficient and effective delivery of solutions.
· Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients, including on their sites.
· Work with our expert software development team to produce reusable applications.
· Use emerging and open-source technologies such as Spark, Hadoop, and Scala.
· Collaborate on scalability issues involving access to massive amounts of data and information.
· Take on ad-hoc tasks as required for the running of a small, yet rapidly expanding business.
What do I need to have?
· Proven big data experience, either from an implementation or a data science prospective.
· Several years of hands-on experience working as part of an engineering development team, ideally in SCRUM.
· Arrive with experience at working with a variety of modern development tooling (e.g. Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g. Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting).
· Excellent technical skills including hands-on knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
· Experience with MVC frameworks such as AngularJS
· Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines.
· Strong coding experience in the likes of Scala, Java, or Python.
· Enthusiasm to learn and develop emerging technologies and techniques.
· Exhibit strong technical communication skills with demonstrable experience of working in rapidly changing client environments.
· Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies.
· Strong academic qualifications and come from a software engineering background or other scientific degree incorporating IT modules (e.g. Maths/Physics).","['Git', 'Microsoft Azure', 'Scalability', 'Scala', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'Scripting', 'ETL', 'Open Source', 'Python', 'Docker', 'Data Science', 'Java', 'Software Development']"
Data Engineer,71 ROBINSON ROAD 068895,Full Time,Executive,3 years exp,Engineering,Monthly,"$7,500to$10,000","
Own different data pipelines and ensure data is flowing consistently and efficiently
Work closely with the Product Manager and other business stakeholders to understand 
their challenges from both a product and technical perspective
Participate in the evolution of the platform (infrastructure and services) to address any 
challenges identified or implement new features
Follow the highest software design standards and Kpler’s best practices
","['Machine Learning', 'Scala', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'Scripting', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Engineering', 'Software Design', 'Data Science', 'Java', 'Data Analytics', 'Databases']"
 , , , , , , , , , 
Data Analyst (Contract),"CONNECTION ONE, 167 JALAN BUKIT MERAH 150167","Contract, Full Time",Executive,1 year exp,"Healthcare / Pharmaceutical, Sciences / Laboratory / R&D",Monthly,"$4,000to$5,500","He/She will be part of the Research Department to help undertake research and analysis on issues that are relevant to the institution using data science techniques. He/She will help to interpret and manage data and solve complex problems using expertise in a variety of data niches. He/She will also work with multidisciplinary teams/stakeholders (e.g. clinicians, pharmacists, managers) to determine how to use business data for valuable healthcare solutions.
He/She will also be involved in developing relevant visualizations dashboards for monitoring purposes as well as creating custom-made data models and algorithms and leverage on them to improve patient experiences, revenue generation and monitor results of interventions.
He/She will also conduct literature review on specific research projects, be involved in scientific writing and/or generate technical reports. This will keep him/her abreast with the latest innovations in data science.

Requirements:

Foundation in computer science, modeling, statistics, analytics & mathematics, coupled with a strong business sense
Knowledge of machine learning techniques, including decision tree learning, clustering, artificial neural networks; experience with statistical programming languages (e.g. Python, R, SQL) to process data and gain insights from it
Multilingual coding knowledge/experience Java, JavaScript, C, C++ (preferred)
Experience/knowledge in data-mining techniques (e.g. social network analysis, natural language processing, time series analysis)
Candidate also need to be a team player and have a problem-solving aptitude
Ability to write reports, grant proposals and scientific papers. Track record of scientific publications is advantageous
Coordinate with research partners during project implementation


Interested applicants may apply at https://careers.singhealth.com.sg/job-invite/1438/","['Statistical Programming', 'Machine Learning', 'Time Series Analysis', 'Natural Language Processing', 'Mathematics', 'JavaScript', 'Artificial Neural Networks', 'Scientific Writing', 'Multilingual', 'Python', 'Interventions', 'Statistics', 'Data Science', 'Java', 'C++']"
Data Analyst (Contract),"CONNECTION ONE, 167 JALAN BUKIT MERAH 150167","Contract, Full Time",Executive,1 year exp,"Healthcare / Pharmaceutical, Sciences / Laboratory / R&D",Monthly,"$4,000to$5,500","He/She will be part of the Research Department to help undertake research and analysis on issues that are relevant to the institution using data science techniques. He/She will help to interpret and manage data and solve complex problems using expertise in a variety of data niches. He/She will also work with multidisciplinary teams/stakeholders (e.g. clinicians, pharmacists, managers) to determine how to use business data for valuable healthcare solutions.
He/She will also be involved in developing relevant visualizations dashboards for monitoring purposes as well as creating custom-made data models and algorithms and leverage on them to improve patient experiences, revenue generation and monitor results of interventions.
He/She will also conduct literature review on specific research projects, be involved in scientific writing and/or generate technical reports. This will keep him/her abreast with the latest innovations in data science.

Requirements:

Foundation in computer science, modeling, statistics, analytics & mathematics, coupled with a strong business sense
Knowledge of machine learning techniques, including decision tree learning, clustering, artificial neural networks; experience with statistical programming languages (e.g. Python, R, SQL) to process data and gain insights from it
Multilingual coding knowledge/experience Java, JavaScript, C, C++ (preferred)
Experience/knowledge in data-mining techniques (e.g. social network analysis, natural language processing, time series analysis)
Candidate also need to be a team player and have a problem-solving aptitude
Ability to write reports, grant proposals and scientific papers. Track record of scientific publications is advantageous
Coordinate with research partners during project implementation


Interested applicants may apply at https://careers.singhealth.com.sg/job-invite/1438/","['Statistical Programming', 'Machine Learning', 'Time Series Analysis', 'Natural Language Processing', 'Mathematics', 'JavaScript', 'Artificial Neural Networks', 'Scientific Writing', 'Multilingual', 'Python', 'Interventions', 'Statistics', 'Data Science', 'Java', 'C++']"
Data Analyst (Contract),"CONNECTION ONE, 167 JALAN BUKIT MERAH 150167","Contract, Full Time",Executive,1 year exp,"Healthcare / Pharmaceutical, Sciences / Laboratory / R&D",Monthly,"$4,000to$5,500","He/She will be part of the Research Department to help undertake research and analysis on issues that are relevant to the institution using data science techniques. He/She will help to interpret and manage data and solve complex problems using expertise in a variety of data niches. He/She will also work with multidisciplinary teams/stakeholders (e.g. clinicians, pharmacists, managers) to determine how to use business data for valuable healthcare solutions.
He/She will also be involved in developing relevant visualizations dashboards for monitoring purposes as well as creating custom-made data models and algorithms and leverage on them to improve patient experiences, revenue generation and monitor results of interventions.
He/She will also conduct literature review on specific research projects, be involved in scientific writing and/or generate technical reports. This will keep him/her abreast with the latest innovations in data science.

Requirements:

Foundation in computer science, modeling, statistics, analytics & mathematics, coupled with a strong business sense
Knowledge of machine learning techniques, including decision tree learning, clustering, artificial neural networks; experience with statistical programming languages (e.g. Python, R, SQL) to process data and gain insights from it
Multilingual coding knowledge/experience Java, JavaScript, C, C++ (preferred)
Experience/knowledge in data-mining techniques (e.g. social network analysis, natural language processing, time series analysis)
Candidate also need to be a team player and have a problem-solving aptitude
Ability to write reports, grant proposals and scientific papers. Track record of scientific publications is advantageous
Coordinate with research partners during project implementation


Interested applicants may apply at https://careers.singhealth.com.sg/job-invite/1438/","['Statistical Programming', 'Machine Learning', 'Time Series Analysis', 'Natural Language Processing', 'Mathematics', 'JavaScript', 'Artificial Neural Networks', 'Scientific Writing', 'Multilingual', 'Python', 'Interventions', 'Statistics', 'Data Science', 'Java', 'C++']"
Data Engineer,"SHAW CENTRE, 1 SCOTTS ROAD 228208","Contract, Permanent, Full Time",Executive,4 years exp,Information Technology,Monthly,"$3,500to$6,000","Job Requirements

- Leverage your understanding of complex data analysis and modeling to ensure Avanade project teams and clients can successfully extract value from their data. 

- Support hypothesis generation and testing, exploratory analysis, data preparation for statistical modelling/machine learning/deep learning, building machine learning or deep learning models and model interpretations.

Saghana Sithara | Registration Number: R1550224","['Machine Learning', 'Scala', 'Data Analysis', 'Modeling', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Data Science', 'Java', 'Data Analytics', 'Databases']"
 , , , , , , , , , 
Data Engineer  /  Associate Data Engineer,"TOURISM COURT, 1 ORCHARD SPRING LANE 247729","Permanent, Full Time",Senior Executive,3 years exp,"Information Technology, Travel / Tourism",Monthly,"$4,000to$8,000","What the role is:
Support the Data Science team in:

Helping to project manage, coordinate and implement Data Science & Analytics's (DS&A) data ingestion and data processing pipelines across different platforms
Ensuring that all data systems meet our business requirements and enable scalability of business processes


Main Responsibilities:

Project manage and deliver on data related implementations ensuring that deliverables are met within agreed scope and timelines
Work closely with vendors and internal stakeholders to project manage and coordinate DS&A’s data ingestion and data processing pipelines across platforms which can include mobile apps, SaaS platforms, on-premise databases and partner systems
Help architect DS&A’s data integrations and data processing flows between external / 3rd party data sources, AWS cloud datawarehouses (e.g. Redshift) and internal on-premise database instances for workloads at scale
Help to gather and translate business requirements into relevant database schemas, data integrations and data processing flows to meet business objectives
Develop data integrations (through API, SFTP etc) between AWS S3, Redshift instances and on-premise database instances (e.g. HANA)
Assemble large, complex datasets that meet functional and non-functional business requirements
Analyse and assess the effectiveness and accuracy of new data sources (e.g. datasets received from stakeholders) and annotation/ labelling of new training inputs.
Identify, design and implement internal process improvements: automating manual processes, data validation tools, optimising data delivery, re-designing infrastructure for greater scalability, etc.
Recommend different ways to constantly improve data reliability and quality, including helping review and enhance the existing data collection procedures to include data for building analytics models relevant for industry transformation
Develop monitoring toolkits to ensure that integration is executed successfully and alerts where integrations have failed
Provide guidance to internal teams on best practices for cloud to on-premise data integrations
Develop set processes for data mining, data modelling and data production
Support the integration and deployment of developed algorithms, machine learning and analytical models into current analytics system/production
Help setup, configure, deploy and validate machine learning models and analytics scripts on Amazon Sagemaker
Help in the implementation of CI/CD and deployment of ML models in production


Job requirements:

At least 2-3 years of Software Project Management experience successfully managing both internal stakeholders and external vendors.
Successfully delivered at least 2 medium to large scale software systems in either a Project Management role, Data Architect role or Data Integration role
Ability to understand the different business domains and to make connections between the data and the business needs.
Good and strong communication skills and able to explain the issues, design tradeoffs between performance, maintenance and business requirements.
Able to clearly articulate and justify the design decisions taken
Good attention to details with regards to data workflow, data quality, data integrity and how the data will be stored and accessed.
Strong analytics skills related to working with structured and unstructured datasets.
Experience in performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience in designing database schemas to support OLTP and OLAP systems
Experience with data pipeline tools (e.g. Talend, SSIS, BODS, Airflow, Kafka)
Experience in using Qliksense will be advantageous.
Experience with big data tools: Hadoop, Spark, Hive, Sqoop, etc.
Experience with stream-processing systems: Storm, Spark-Streaming, Kalfka etc.
Experience in software development and developing enterprise applications with integrations to SQL / no-SQL databases
Experience with object-oriented / object function scripting languages: Python, R, Java, etc.
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong working knowledge of SQL
Strong project management, stakeholder management and organisational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
At least 3 years of working experience in a related field with real-world skills and testimonials from formal employers.
Working experience with structured and unstructured datasets is essential

Preferred certifications:

Certified Scrum Master/ Agile Developer
Certified AWS Cloud Architect


Application Status: Shortlisted candidates will be contacted within 2 weeks from the closing date of this job posting. We regret to inform that only shortlisted candidates will be notified.","['Machine Learning', 'Scalability', 'Big Data', 'Pipelines', 'Hadoop', 'Scripting', 'Data Integration', 'Data Quality', 'Data Mining', 'SQL', 'Python', 'Data Science', 'Java', 'API', 'Databases', 'Business Requirements']"
Data Analyst,6 BATTERY ROAD 049909,Contract,Executive,5 years exp,Information Technology,Monthly,"$3,000to$6,000","An exciting Data Analyst (12 months renewable contract) job opportunity has just opened up at a global financial services company in Singapore. About the Data Analyst (12 months renewable contract). 
Role: In this role, you will responsible for automating queries, report preparation and supporting global teams.


Key Responsibilities:

Be an internal visualization analytics consultant in developing useful analytics products across use cases, segments, and product portfolios
Build compelling analytics products using industry leading analytics tools such as Tableau, Alteryx, driving use cases across data monetization, risk mitigation, productivity improvement, progress tracking and management reporting
Translate key challenges, requirements and needs from the business into impactful, actionable metric, KPIs and solutions, to solve everyday business problems
Act as a conduit between technical and business stakeholders by translating business/ functional requirements from Product Owners / delegates into technical requirements for processing by the technology teams
Assess key market trends, gaps, and opportunities to onboard new innovative technologies
Partner with stakeholders and senior management to build awareness and expand the analytics/automation offering of the team, aligning with business needs for today and the future
Build trust and strong working relationships with business and technology stakeholders
Extract and/or consolidate required data from core platforms e.g. Client Central and downstream systems e.g. order placement, product softwares to facilitate data analysis and reporting


To succeed in this Data Analyst (12 months renewable contract) role, you must have experience in Alteryx/Dataiku technologies.

Key Requirements:

3+ years’ experience in Financial Services Industry
Relevant analytics work experience and demonstrated career progression/increase in responsibilities
Strong academic record: Degree in Finance, Statistics, Computer Science or related field
Strong Knowledge of Tableau or similar visualization tools
At least one year of experience with any of the data processing tools Alteryx, Dataiku, or Tableau is required.
Proficient in SQL
Proficient in Microsoft Office, particularly Microsoft Excel & PowerPoint.
Strong understanding of Hadoop Database
Understanding in emerging cloud and smart technologies such as Azure, AWS, Cognitive Automation will be an added plus
Experience in data commercialization – facilitating partnerships and driving buy-in/adoption from stakeholders of varying levels
Understanding of the ETL process
Good presentation, time management, negotiation and influencing skills
Strong analytical and problem solving skills
Experience in project management from business requirement definition, solution validation, user testing, technical documentation and production roll out, especially on a global scale
Ability to manage multiple work streams with strong problem solving and analytical skills
Strong communication and presentation skills to varying levels of management
Highly driven and motivated with an eager-to-learn attitude and actively seek out ways to improve processes, people, and products Good presentation, time management, negotiation and influencing skills
Ability to influence without authority
Has experience with Agile / Scrum and/or Kanban certified


This is an excellent opportunity to be part of a company with a strong footprint within the region.

If you are driven, determined, and want to take the next step in your career, this is the role for you. Excellent career progression opportunities await the right person in this exciting Data Analyst (12 months renewable contract) role.

Apply today or email me to dipti.makawana@robertwalters.com.sg to discuss this new opportunity.

Do note that we will only be in touch if your application is shortlisted.

Robert Walters (Singapore) Pte Ltd
ROC No.: 199706961E | EA Licence No.: 03C5451
EA Registration No.: Dipti Makawana","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Analytical Skills', 'Azure', 'Hadoop', 'Translating', 'ETL', 'Productivity Improvement', 'SQL', 'Presentation Skills', 'Statistics', 'Monetization', 'Visualization']"
Senior Data Analyst,"UIC Building, 5  Shentonway 068808",Full Time,Professional,5 years exp,"Advertising / Media, Others",Monthly,"$7,000to$9,500","Responsiblities

· Become a travel industry expert and develop a wealth of material that will provide clients with up-to-date knowledge about current travel trends and the planning behavior of their customers.

· Mine through billions of data points with SQL and model with Python or R in order to generate actionable insights.

· Visualize key insights into Tableau, Google DataStudio, MS Excel, or MS PowerPoint.

· Work closely with business stakeholders to understand and translate their needs into data insights that drive client relationships.

· Contribute to the ideation, design, prototyping, and productization of scalable travel insights that will guide our clients through their media planning efforts.  Close partnership with Product and Engineering teams is expected.

Requirement

· 4+ years of hands-on experience in data analytics within a Big Data environment.

· Data engineering experience a plus.

· Technical skills:  Proficiency in both SQL and Tableau/DataStudio (or similar BI tool).  Experience in Python or R preferred.

· Strong business acumen required.

· Strong understanding of statistics and probability required.

· Excellent oral and written communication skills; comfortable presenting to clients and to all levels of organization.

· Experience in one of the following industries a plus:  Travel, eCommerce, Digital Advertising, AdTech

· BS in Computer Science, Mathematics, Statistics, Economics, Business Analytics, Data Science, or related field; MBA a plus.","['Tableau', 'Big Data', 'Mathematics', 'Business Acumen', 'Wealth', 'Economics', 'Data Engineering', 'SQL', 'Python', 'Business Analytics', 'Ms Powerpoint', 'Statistics', 'Data Science', 'Media Planning', 'Data Analytics']"
 , , , , , , , , , 
Data Engineer,461 CLEMENTI ROAD 599491,Full Time,Executive,2 years exp,"Consulting, Information Technology",Monthly,"$3,800to$7,000","Candidate for the role is expected to be passionate about working with huge datasets and have the experience working with businesses to build data products and services to turn data into insights using advanced analytics. Candidate should have experience with curation of data for analytics/AI, and a strategic/long term view on architecting data eco systems. Candidate is experienced in building efficient and scalable data services and has the ability to integrate data systems with relevant tools and services to support a variety of customer use cases/applications.

The candidate will work closely with business units, data analytic team and technical team (network, source system IT support) to achieve the following:

Responsibilities

Translate business requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.
Implement and adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation.
Analyse and organize raw data – structured and unstructured data. Designing, implementing, and operating large-scale, high-volume, high-performance data structures for analytics and data science
Build/Develop data systems and pipelines.
Data sources - Liaise with Source system teams to identify and validate data to ensure that data are complete, reliable and clean for data ingestion.
Ingestion components - Implementing data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes by leveraging on relevant technologies and big data tools
Transformation functions (e.g. filtering and aggregation)
Destinations (a data warehouse or data lake)
Design, develop, test and deploy frontend visualization (dashboards and reports) in collaboration with business end users. Helping continually to improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for users.
Implement solutions to facilitate more effective data discovery by data users

Supporting Activities

Working internally with business units and Data Analytic teams to:Identify opportunities for enhancements in data management capabilities, and work with relevant stakeholders to address operational or data issues in the data pipeline
Ensure data management processes comply with established framework & policies
Develop a good understanding of existing solutions and be able to support and enhance them
Maintain good documentation of the solutions and effectively communicate stakeholders about the value-add
Preparing data for prescriptive and predictive modelling
With the implementation of the data lake, candidate will be part of the team to build up, pilot and gain knowledge and proficiency in the AWS cloud hosted infrastructure and data analytic tools, as well as managing and developing data insights from the new data sources.

Requirements

Degree with minimum 2 years of relevant work experience as a Big Data Engineer with demonstrated strength in ETL/ELT (SSIS, AWS Glue), data modelling, data warehouse technical architecture and reporting/analytic tools.
Hands-on experience in AWS cloud services. E.g. S3, redshift, Lambda
Related working experience, specifically in the areas of data management and quality
Possess strong python, pyspark, SQL, Tableau skills, APIs
Ability to deal with ambiguity and prioritise/manage multiple tasks, with good problem-solving skills to ensure smooth data-to-insights conversion
Willing to listen to multiple stakeholders and forge consensus on win-win solutions to meet sound data governance and management principles
Exhibit values and principles of an Agile mindset
Highly motivated and able to work under tight timelines with minimal supervision
","['Tableau', 'PySpark', 'Big Data', 'Data Modeling', 'Pipelines', 'Data Structures', 'Data Management', 'Data Governance', 'SQL', 'Python', 'Data Architecture', 'Data Science', 'Visualization', 'SSIS', 'S3', 'Business Requirements']"
Data Engineer,383 SIN MING DRIVE 575717,Full Time,Executive,2 years exp,Engineering,Monthly,"$3,500to$6,800","Responsibilities:

Expanding data collection as      well as optimizing data pipelines for cross-functional teams
Work closely with data      analysts and business end-users to implement and support data platforms
Tuning, troubleshooting and      scaling identified big data technologies.
Analyse, tackle and resolve      day-to-day operational incidents related to data provision
Build suitable tools to      provide data through acquiring, monitoring and analyzing root cause of      data issues
Identify, design, and      implement process improvements and tools to automate data processing with      data integrity
Work with data scientist and      business analytics to assist in data ingestion and data-related technical      issues
Design, build and maintain      the batch or real time data pipeline in production using big data      technology
Design, build and manage data      warehouse such as designing data model
Create data views from big      data platform to feed into analysis engines or visualization engines

Requirements:

Bachelor degree in Computer      Science, Computer Engineering, Software Engineering or equivalent
At least 2 years of relevant      working experience in ETL/data integration and data modelling
Experience with Data      Engineering and Data Quality
Cloud experience, ideally      with Azure and AWS
Understanding of Big data      technologies like HDFS, Hive, Spark
Experience of relational or      NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL)
Experience in data      warehousing / distributed system
Experience in data      ingestion, cleaning and processing tools
Experience in data      acquiring, data processing using Scala/Python/Java
Highly organized,      self-motivated, pro-active, and desire to learn new technology
Excellent communication and      collaborative skills
","['Data modelling', 'Oracle', 'Azure', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'ETL', 'Data Integration', 'Data Quality', 'Data Engineering', 'SQL', 'Business Analytics', 'Visualization', 'Data Warehousing', 'Databases']"
Data Analyst,"AFRO-ASIA, 63 ROBINSON ROAD 068894","Permanent, Full Time",Senior Executive,1 year exp,Others,Monthly,"$3,500to$3,600","Do you love food and convenience put together? Then you just might love foodpanda.
foodpanda is the leading, on-demand food delivery company in Singapore, bringing thousands of your best loved restaurants online into your home or office. We continue to expand and grow in our core food delivery business, as well as in new verticals like grocery deliveries, with a strong tech infrastructure at our core. We’re all about bringing on the smartest folks as we continue to grow with an “all hands-on deck” environment and hire those who can thrive in a start-up culture.
We’re looking for a highly-driven and motivated Data Analyst for our team in Singapore. In this role you will be working with big data, testing, analysing, and building models to provide strategic insights to the business as well as comprehensive solutions. If you are looking for a dynamic environment where you will be exposed to projects covering operations, marketing, commercial and finance, then this may be the place for you!
This role will be based in Singapore and will report to the BI & Pricing Manager.
Responsibilities:

Build strong relationships with internal stakeholders to understand business challenges and opportunities. Recommend solutions across the complex range of products, business contexts, and processes
Manage end-to-end data projects; identify issues, gather information from various sources, analyze data, interpret patterns and trends, build prediction models, give recommendations, and create insightful automated reports.
Innovate, lead, and analyze pricing tests and other projects.
Review day-to-day operation processes, identify areas of improvement and make actionable recommendations based on underlying analysis
Be a steward of good data practices - robust documentation, versioning, playbooking, processes, and knowledge sharing
Automate and validate newly created reports and develop corrective actions to improve data integrity and quality
Support ad-hoc data requests

Requirements:

At least a Bachelor degree in Statistics, Mathematics, Computer Science or another analytical field
Minimum 1 years of relevant working experience
Analytical mind and business acumen with ability to work with large amounts of data to discover patterns and trends and to form conclusions based on findings. Must be extremely detail oriented.
Interest and/or experience in growth marketing would be a plus
Excellent analytical skills, independent thinking, data oriented, and knowledge of analytics tools required (SQL, Excel, Tableau, Python, or R)
Good communication and presentation skills
Quick learner and proven ability to handle multiple projects concurrently
High integrity and work ethic
Team player with an ability to function effectively in a dynamic, fast-paced environment

What we offer:

Challenging and fulfilling steep learning curve
Vibrant, dynamic & international workplace
Periodic fun & engaging company events & team activities
Tasty Thursdays
Birthday Leave
Work Anniversar(ies) Leave
Opportunity to be a value-adding contributor to this fast-growing global company

Please apply directly via the link here: https://grnh.se/d0d49b321us","['Tableau', 'Grocery', 'Data Analysis', 'Analytical Skills', 'Restaurants', 'Big Data', 'Mathematics', 'Business Acumen', 'SQL', 'Python', 'Presentation Skills', 'Statistics', 'Team Player', 'Data Analytics', 'Pricing']"
 , , , , , , , , , 
Data Engineer,"PAYA LEBAR SQUARE, 60 PAYA LEBAR ROAD 409051",Full Time,Middle Management,5 years exp,Information Technology,Monthly,"$8,000to$11,000","• Must have development experience in Big Data, Hadoop, Python, PySpark technologies. 
• Proficient in Oracle & PL/SQL with at least experience with the ability to fine tune performance of queries. 
• Ability to write complex analytical queries / Stored Procedures / Packages. 
• Good exposure to Unix/ Linux OS basic commands and hands on in Shell scripting. 
• Experience in L3 Production Support and Analysing & troubleshooting the production issues by engaging other relevant support teams. 
• Excellent written and oral communication skills. 
• Self-started with quick learning ability. 
• Multi-tasking abilities and should be able to work under stringent deadlines.","['PySpark', 'Troubleshooting', 'Oracle', 'Big Data', 'Hadoop', 'Shell Scripting', 'Oracle PL/SQL', 'Unix', 'Data Engineering', 'Production Support', 'SQL', 'Big Data Analysis', 'Python', 'Performance Tuning', 'Databases', 'Linux', 'Software Development']"
Data Analyst (Contract),"MAPLETREE BUSINESS CITY, 20 PASIR PANJANG ROAD 117439",Contract,Senior Executive,5 years exp,Information Technology,Monthly,"$5,000to$8,500","About Us
Green Link Digital Bank is Singapore's inaugural wholesale digital bank focusing on supply chain finance, mainly serving MSMEs and aiming to help MSMEs grow and improve digitization.
We are looking for a Data Analyst to join our Data Management Office (DMO) team. The DMO provides comprehensive data services to all business units and manages data governance policies and procedures. We apply the best practice in managing our data assets and make it our competitive advantage to serve our customers better. We are a young and growing team striving for excellence in data solutions.

Responsibilities

Create and maintain data catalog that includes all data assets
Understand the meaning of data and advise effective usage of it
Understand business requirements and ensure proper documentation
Perform data modelling and data mapping for data integration efforts
Perform data testing and data quality checks
Investigate data issues and liaise with relevant stakeholders to resolve it
Assist in data governance initiatives from policy implementation to administrative matters


Requirements

Curious and meticulous in defining and handling data
Excellent verbal and written communication skills
Proficient in data modelling
Familiar with databases, SQL, and BI tools
Familiar with banking products and processes
Working experiences in banking data projects preferred
Experiences in Java programming is an added advantage
","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Data Management', 'Data Integration', 'Data Quality', 'Data Governance', 'SQL', 'Digitization', 'Banking', 'Java', 'Data Analytics', 'Power BI', 'Databases', 'Business Requirements']"
 , , , , , , , , , 
Data Engineer,"MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981","Permanent, Full Time",Executive,2 years exp,Information Technology,Monthly,"$4,300to$7,500","Sephora is a global leader in omnichannel beauty retailing, and a division of LVMH – Moët Hennessy Louis Vuitton. At Sephora, we stand together, and we stand for something more. For the empowerment, exploration, and opportunity to impact people’s lives through the unlimited power of beauty. Every day we reimagine beauty, discover new brands, and influence positive change. Data plays a significant role in that.
We successfully operate more than three thousand points of sale across the Americas, Europe, the Middle East, and Asia. Together, we aim to animate the most loved beauty community in the world. Here in Asia, our teams run omnichannel businesses in 11 markets across the region (9 different markets in Southeast Asia), in addition to cross-border e-commerce to several more. Our success is built on innovation, a unique product portfolio, market-leading digital capability, and our unique customer experience. With ambitious growth plans, we always look for talented people who aspire to build businesses and develop themselves. Sparked by energy and excitement, our passion is contagious. We are united by a common goal – to reimagine the future of beauty.
We’re a data-driven omnichannel business with a special focus on e-commerce (our platform is built in-house!). The data team builds and maintains data management and Machine Learning capabilities to power both customer-facing services and internal data products. We manage a large-scale data platform in Google Cloud, relying heavily on BigQuery, Kubernetes, and Terraform.
The data team is looking to hire a proactive, commercially savvy Data Engineer to ensure all our data users - analysts, end users, or AI-driven systems, have access to the right data at the right time, and ensure its accuracy. You will get a chance to work on our core data pipelines (batch and streaming), machine learning platform, and cloud infrastructure, depending on your interests and previous experience. We believe in enabling our engineers to work across the stack to solve interesting problems and keep work exciting and enable this through weekly and monthly sharing sessions, pair coding, and architecture design sessions.
To be successful in this role
● You will need to be well-versed in building scalable, reliable, test-driven data pipelines to integrate data from various systems and platforms into the data warehouse on Google BigQuery.
● You will need to design the data warehouse schema, ensure extensibility, and clarity as new data sources are continuously integrated. You will oversee data reliability to build overall company trust in data to be more data-driven and continuously identify improvements to existing data architecture and data flows.
● You will need to promote and ensure technical excellence within the team. You are passionate about the culture and quality of engineering, and strive to continuously improve the quality and delivery of the team.
● You will need to enjoy working together in a team, planning and executing sprint tasks following Agile processes.
● You will need to be able to communicate clearly with our internal stakeholders, technical or non-technical, deeply understand business priorities and formalize them into challenges that can be tackled with engineering effort.
What we expect from you
● 2+ years of experience building software as a team following Agile methodologies.
● Strong production-level Python and SQL programming knowledge. Big bonus if you have also worked with BigQuery or are familiar with Golang or Javascript.
● Experience building and scaling batch ETL/ELT data pipelines, especially in Apache Airflow, Kubernetes, and DBT. Understanding of size and performance constraints.
● Experience building and scaling streaming data pipelines, especially in Apache Kafka, Spark, or Beam.
● Experience architecting and building data products with Cloud Services and Data Warehousing services in GCP or AWS (GCP is preferred).
● Knowledge of columnar databases, infrastructure automation tools like Terraform, data modeling techniques, data warehouse design patterns and google analytics is advantageous.
If these are aspects you value, please apply! Your attitude, experience and passion to excel are more important than specific experience.","['Machine Learning', 'Kubernetes', 'Data Modeling', 'Pipelines', 'Data Management', 'Reliability', 'SQL', 'Python', 'Data Architecture', 'Apache Kafka', 'GCP', 'Apache', 'Data Warehousing', 'Databases']"
 , , , , , , , , , 
Senior Data Analyst,"SUNTEC TOWER ONE, 7 TEMASEK BOULEVARD 038987",Permanent,Senior Executive,3 years exp,Information Technology,Monthly,"$7,000to$10,000","Senior Data / Business Analyst
Job Responsibilities:

Data normalization (standardize data embedding, provide standardized data query process, etc.)
Build a business indicator system (new user acquisition, user activity, user revenue, user retention, user promotion, etc.)
Explore User Characteristics (Motivator Analysis, A/B Test)
Support the data requirements put forward by various departments (abnormal index analysis, data query)

Skill requirements:

Bachelor degree or above, major in mathematics, statistics, computer related,
At least 3 years of work experience in data analysis
Proficient in statistical analysis and relevant knowledge of statistical learning methods;
Possess professional data processing and analysis capabilities;
Possess the ability to proficiently write SQL to fetch numbers, and be proficient in EXCEL. Familiar with BigQuery is preferred;
Ability to think independently, analyze problems, have strong sensitivity to data, and be able to withstand certain work pressure;
Have good expression, communication and coordination skills;
Experience in Internet advertising industry data is preferred, experience in data products is preferred
","['Tableau', 'Microsoft Excel', 'Advertising', 'Data Analysis', 'Big Data', 'Mathematics', 'SQL', 'Pressure', 'Python', 'Excel', 'Statistics', 'Visualization', 'Business Analyst', 'Data Analytics', 'Power BI', 'Data Visualization']"
 , , , , , , , , , 
Data Analyst,"ST ENGINEERING HUB, 1 ANG MO KIO ELECTRONICS PARK ROAD 567710",Permanent,Senior Executive,3 years exp,Engineering,Monthly,"$4,000to$7,000","The Smart Enterprise Platform Strategic Engineering Centre (SEP SEC) is one of five SECs within the Group Engineering Centre (GEC) in ST Engineering. Its mission is to deepen Data Analytics (DA) capabilities, proliferate DA usage group-wide, and to develop common/reusable DA products and tools for both internal and external use by all lines of businesses. The Advisory team in SEP SEC provides analytics consulting services to our internal customers and also assists them in projects with external customers. We are looking to hire an experienced data analyst with keen data analysis skills and ability to build rapport with customers. The analyst will primarily be involved in fundamental data warehousing and Business Intelligence projects and will also be working with our data scientists on predictive and prescriptive analytics projects. Key Responsibilities • Provide analytics consulting services internally and assist delivery team to implement resulting models into production • Support business unit project teams and external customers to develop, evaluate, refine, and deploy analytics models for production. You may be deployed temporarily to business units for the duration of some external projects • Work closely with data engineers, product managers, project managers, and platform developers in the implementation and deployment of the data analytics platform product • Mentor junior data analysts and review quality of work output Job Requirements • A Bachelors or Masters Degree in quantitative disciplines e.g. Science, Engineering, or Mathematics • 5 years or more of working experience in data analytics • In-depth technical knowledge and experience in any of the following will be a major plus o Operations Research o Econometrics o Social & Cognitive Computing ▪ Social Psychology ▪ User Experience Design, Human Computer Interface o Geospatial Analytics o Video/Image Processing o Analytics for Finance or Healthcare • Good understanding of end-to-end analytics process – ideation/value elicitation, requirements definition, data profiling, data preparation, analytical modelling, testing, validation, visualization, and deployment • Strong problem solving skills, curiosity, and passion for data science • Experienced in SQL (any flavour), Python, Spark, Java, or C • Familiar with ETL pipeline creation, BI reporting software, visualization tools • Excellent coordination and time management skills to handle complex projects • Willing and enthusiastic about continuous learning of new technologies and data science techniques/breakthroughs • Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills","['Management Skills', 'Healthcare', 'Mathematics', 'ETL', 'Written Communication', 'SQL', 'Project Management', 'Python', 'Analytical Problem Solving', 'Data Science', 'Consulting', 'Visualization', 'Java', 'Data Analytics', 'Data Warehousing']"
Data Analyst,"SHENTON HOUSE, 3 SHENTON WAY 068805",Permanent,Executive,3 years exp,Others,Monthly,"$4,000to$5,500","Roles And Responsibilities
· Perform business analysis using various techniques such as statistical analysis, explanatory and predictive modelling, data mining.
· Determine the best analytical model and approaches to present and explain solutions and options to business users.
· Provide support for a range of data cleansing and data modelling activities, as required by the business, using internal and external data sources. Sense-check large lists of data
· Work directly with internal and external clients to identify analytical requirements.
· Produce ad-hoc data queries and reports to support and guide business decisions.
· Assist in the evaluation, implementation and developmental of systems to capture business operation information and documentation of the system once delivered. Provide end-user training and vendor management for related systems, as necessary.
· Provide backup support for Reporting and Data Warehouse solution, OBIEE, or other reporting systems.

Requirements
· Bachelor’s Degree in Maths, Statistic and computer related
· 3 years’ related experience in IT data or business process in Gaming Industry preferred.
· Languages: R, Python, HTML, Javascript, C/C++, SQL, Matlab, SAS
· Experience with Database/Data Systems preferred: MS SQL, OBIEE, Oracle, ODI, MS Access, MS Power BI NO SQL, Data Lakes.
· Machine Learning, Statistical Analysis, AI Tools, CRM system experience preferred
· Strong math background
· Strong Excel skills with the ability to manipulate large data spreadsheets
Ability to effectively prioritize and execute tasks in a high-pressure environment","['CRM', 'Machine Learning', 'OBIEE', 'Oracle', 'HTML', 'Business Analysis', 'JavaScript', 'Data Mining', 'SQL', 'Vendor Management', 'Python', 'Spreadsheets', 'Business Process', 'Power BI']"
Business Data Analyst,"SUNTEC TOWER FOUR, 6 TEMASEK BOULEVARD 038986",Full Time,Professional,5 years exp,Information Technology,Monthly,"$7,000to$9,500","Job Description:
Kerry Interim is currently hiring for a Data Business Analyst for an investment firm having a global presence, they specialize in innovative investment and asset solutions. As a Business Analyst, you will bridge the gaps between the business requirement to technical requirements.

Responsibilities:

Gathering of project requirements from management or stakeholder.
Liaise with the technical team on translating business requirements into technical requirements.
Working with the Finance team and communicating with third-party IT vendors to define the scope of data extraction in the system.
Perform Data Analysis to cleanse and standardization of data with quality and consistent work.
Work and coordinate with External System integrator on bugs and issues for data-related matters.

Experience and Qualifications:

Degree in computer science, information technology, or any other relevant certification in data analytics with at least 3 full lifecycles of hands-on experience in preparing for ADFdi, FBDI, and HDL templates for migration into Oracle Cloud financials.
Good communication skills as you will be dealing with finance end-user and vendors to interpret any technical error in layman terms.
Proficient with data wrangling, analytics, and the use of transformation tools such as SQL, and Excel.

Added skills and experience:

Working knowledge of Oracle Cloud.
Experience in coding or reviewing codes in python.

To apply
Should you be interested to learn more about the above opportunity, please kindly share your CV (Word doc preferably) with Charles at Charles@kerryinterim.com We regret that only shortlisted candidates will be notified. 

Lic: 22C0942 Reg: R21103356","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Financials', 'Translating', 'Information Technology', 'SQL', 'Good Communication Skills', 'Python', 'Business Analyst', 'Bridge', 'Data Analytics', 'Power BI', 'Business Requirements']"
Data Analyst,"SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623","Contract, Full Time",Executive,3 years exp,Information Technology,Monthly,"$5,000to$7,000","Data Analyst - 12 months contract role

Key Required Skills:

Experience in business and/or financial analysis is a must
Knowledge in Business Intelligence software such as Power BI is a plus
Data processing, analysis, and automation experience
Meticulous with strong analytical and problem-solving skills
Working knowledge of statistical principles such as linear regression, logistic regression, univariate and multivariate analysis, and experimental design is a plus

Job Responsibilities:

Be a business partner to the operations units, performing analysis and providing operational reports highlighting key insights, trends, and actionable recommendations. 
Collecting and interpreting data & ETL of data sets
Analysing results
Reporting the results back to the relevant members of the business
Identifying patterns and trends in data sets
Defining new data collection and analysis processes
Participate in projects as part of the project delivery team; assist in achieving execution efficiencies and articulation of business requirements
Maintain and improve financial and data models for future use and eventual automation with respect to various enterprise applications
Perform other analysis and prepare other reports as requested

To apply online please use the apply function, alternatively you may contact Dalpreet Kaur at dalpreet.kaur@randstad.com.sg (EA: 94C3609 /R23111951)
","['Tableau', 'Business Intelligence', 'Microsoft Excel', 'Data Analysis', 'Logistic Regression', 'ETL', 'Interpreting', 'Data Collection and Analysis', 'Experimental Design', 'Financial Analysis', 'Articulation', 'Statistics', 'Data Analytics', 'Project Delivery', 'Power BI', 'Business Requirements']"
Data Analyst (Marketing),"JACKSON SQUARE, 11 LORONG 3 TOA PAYOH 319579","Permanent, Full Time",Senior Executive,2 years exp,"Information Technology, Marketing / Public Relations",Monthly,"$4,000to$6,000","Job Overview:
We are seeking an experienced Data Analyst to join our growing team in the real estate industry. In this role, you will play a critical part in using data to drive informed business decisions and provide valuable insights to our clients. The ideal candidate will have a strong understanding of data analysis, statistics, and data visualization.
Key Responsibilities:

Collect, process, and analyze large and complex data sets from multiple sources, including market trends, property transactions, and economic indicators.
Design and execute data-driven experiments to validate business hypotheses and provide actionable recommendations.
Develop and maintain dashboards and reports that visually communicate key insights and trends.
Collaborate with stakeholders across departments to understand their data needs and provide them with relevant insights and analysis.
Keep up-to-date with emerging trends and best practices in the real estate industry, and leverage this knowledge to improve our data analysis capabilities.
Develop and maintain data governance and data quality protocols to ensure that all data is accurate, complete, and consistent.

Requirements:

Possesses a Diploma, Bachelor’s or Master’s degree in a relevant field such as mathematics, statistics, computer science, or engineering.
2+ years of experience in data analysis, preferably in the real estate industry.
Strong knowledge of SQL, Python, R, or similar programming languages would be a plus
Experience with data visualization tools such as Tableau, Power BI, or QlikView would be a plus
Excellent communication and interpersonal skills, with the ability to present complex data analysis in a clear and concise manner.
Proven ability to work independently, prioritize tasks, and meet tight deadlines.

If you are a data-driven individual with a passion for real estate and a desire to make a meaningful impact, we encourage you to apply for this exciting opportunity.


About us:

Here's an opportunity to join South East Asia's top property technology company allowing homeowners and home buyers a better and smoother property transaction journey through the use of tech. Started in 2016 in Singapore, Ohmyhome quickly became the No #1 HDB Property App in Singapore in a matter of months. Since then Ohmyhome expanded into Malaysia and The Philippines in 2019 and 2021 respectively.","['Tableau', 'Data Analysis', 'Data Quality', 'Data Governance', 'QlikView', 'SQL', 'Python', 'Real Estate Marketing', 'R programming language', 'Power BI', 'Data Visualization']"
"Manager, Data Analytics & Operations, APAC","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Manager,10 years exp,Information Technology,Monthly,"$12,000to$16,000","Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance
At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions.

Purpose statement
Reporting to the Senior Data Science Manager, APAC, you will play a key role in the data team and be responsible for leading analytics domain and data operations. Your role includes but not limited to leading the development of analytics enablement domain to drive improved capabilities and strategic insights across departments, as well as leading data operations to build and manage data services and daily operations.

Roles & responsibilities

Data Analytics Enablement:

Design, develop, manage, and support enterprise level self-service analytics framework and enable capability in business with strong technical expertise.
Optimize overall technical landscape to maximize data utilization/usage and minimize data processing flow duplication.
Perform and lead the analysis and tracking of data product usage, and strategic partnering to share insights and ensure understanding.


Data Operation Management:

Design, implement and manage data operation framework and processes across data platform services, including data intake delivery process, data security control, governance model, data product lifecycle management, and platform cost control, etc.
Design, deploy and operate enterprise level data product management frameworks and processes, including data catalog, data lineage, governance, product adoption and performance, etc.
Design and manage data product lifecycle review and optimization.
Drive end-to-end projects for data product from design stage all the way to delivery and execution
Drive and support departments and divisions for modern data platform adoption.
Lead continuous improvement initiatives on data operations to improve service level, performance, management and control, and cost-efficiency.
Liaise with key stakeholders including senior management.


Requirements

Bachelor’s degree in relevant field or it’s equivalent, coupled with at least 10 years of experience in related scope of work
Solid hands-on expertise with minimum 2-3 years’ experience in design, development and managing cloud self-service analytics platform, e.g., Tableau or Power BI, including data flow control, modeling/schema, data packaging and sharing control, security, optimization, and performance tuning, etc. Experience in SQL coding.
Strong design, build and daily operational experience on enterprise level data platform and self-service analytics eco system.
Experience in enterprise data product management with successful high user adoption, including data catalog, lineage, governance & security, product performance, etc.
Working experience and knowledge of project management and stakeholder engagement in a regional capacity, with different cultures and across different time zones
A self-starter that works under consultative direction towards predetermined long-range goals and objectives and keen in continuous learning
Team management experience preferred


About us
As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen.

So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you!","['Tableau', 'Machine Learning', 'Data Analysis', 'Big Data', 'Data Management', 'Product Lifecycle Management', 'Stakeholder Engagement', 'Product Management', 'Data Mining', 'SQL', 'Project Management', 'Team Management', 'Performance Tuning', 'Data Science', 'Data Analytics', 'Power BI', 'Databases']"
 , , , , , , , , , 
Data Engineer,79 LOYANG WAY 508766,Full Time,Executive,2 years exp,Information Technology,Monthly,"$3,000to$4,500","Job Description

Recommend and build require infrastructure for optimal extraction, transformation and loading of data from various sources such as ERP. MES and other systems using SQL technologies.
Create, manage and maintain optimal data pipeline architecture. API and integration for ERP, MES and other systems used in the company.
Monitor and manage database and related systems to ensure optimized performance.
Assemble large, complex data sets that meet functional and non-functional business requirements.
Working with stakeholders such as sales, finance, operations, design, and executive teams to support their data infrastructure needs while assisting with data-related technical issues.
Build business intelligence and analytical tools using Power BI to utilize the data pipeline, and provide actionable insight into key business performance metrics.
Participate in external and internal audit to ensure company data and related system is effective and validated.
Create and maintain documentations and compliance for data and systems with reference to industry best practices.
Perform other tasks as assigned by the supervisor.

Requirements 

Bachelor’s degree (or equivalent) in Computer Science, Information and Communications Technology, or related discipline
3 or more years with RDBMS and NoSQL databases
3 or more years  of experience with Python, SQL, data visualization and exploration tools 
Working experience in MedTech / Manufacturing Industry
Experienced in building and maintaining ETL processes.
Experienced with Microsoft-based stack (M365, Power Platform, Azure, Dataverse,Microsoft SQL Server)
Knowledge of best practices in ICT operations and data management
Excellent  problem solving and troubleshooting skills.
Process  orientated with great documentation practices.
Communication   skills, especially for translating technical concepts to non-technical  business leaders.
Ability to  work on a dynamic, action-focused team that has concurrent projects
","['MES', 'Business Intelligence', 'ICT', 'Azure', 'Data Management', 'Translating', 'ETL', 'Microsoft SQL Server', 'SQL', 'Python', 'Internal Audit', 'API', 'Power BI', 'Databases', 'Data Visualization', 'Business Requirements']"
Data Engineer,540 AIRPORT ROAD 539938,Permanent,Senior Executive,5 years exp,"Engineering, Information Technology",Monthly,"$4,500to$8,500","Job Description

Engage in and improve lifecycle of infrastructure services from inception and design through development, deployment and refinement.
Develop web applications using ASP.Net MVC, C# and ASP.Net Web API, following the development standards and technical design provided
Understanding of best practices in software development process (SDLC) including coding standards, code reviews, design patterns, source control and object-oriented programming.
Tap knowledge from domain experts and write SQL scripts to manage & query databases to extract & generate required data for analysis.
Ability to develop web-based dashboards to show the results for internal & external customers is preferred.
Supports and develops software engineers by providing advice, coaching, and educational opportunities.
Develop software solutions by studying information needs conferring with users studying systems flow, data usage and work processes
Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code
Design and architect new software product for data analytics
2nd level user support for application interface issues across systems
Analyse issues and work with other team members to identify root cause to prevent future occurrences

Requirements and Skills

5 to 7 years of relevant experience in core software development using Microsoft technologies.
Working knowledge of C#, ASP.Net, MS SQL, JavaScript
ASP.NET Web API and Windows Services, SOAP, JSON
Experience with WPF framework will be an added advantage
Working knowledge in MSDN, TFS and SVN.
Degree in Engineering or Computer Science or IT
Hands on experience in technical design patterns, development and documentation.
Strong in SQL server complex SQL query and Stored procedure development (4+ years)
Experience in Software product development
","['Microsoft Technologies', 'MVC', 'ASPNet', 'Aspnet Web Api', 'WPF', 'Architect', 'SOAP', 'SQL', 'SQL Server', 'Windows Services', 'TFS', 'C#', 'API', 'Data Analytics', 'Databases', 'Aspnet MVC']"
 , , , , , , , , , 
Data Engineer,48 Changi South Street 1 486130,"Permanent, Full Time",Senior Executive,2 years exp,"Information Technology, Others",Monthly,"$5,000to$9,000","We are looking for talented Data Engineers, who will join our Data Science Team and help us build the state-of-the-art data analytics capabilities powering the future of our platform.

Roles and Responsibilities

Collaborate with DevOps and Business Intelligence teams to establish a common data processing and analytics platform and best practices.
Work closely with data scientists and software engineers to support the analysis of data, and the development and validation of models.
Design and implement data storage solutions to ensure data quality, availability, and scalability.
Monitor the performance of the data infrastructure and implement optimizations to improve efficiency and reduce costs.
Participate in technical discussions across the team through code reviews, RFC, or architecture review sessions.

Requirements

At least 2 years of experience working as a data engineer or similar.
Good understanding of Agile and DevOps practices: version control, CI/CD, Infrastructure-as-Code, containerization, observability/monitoring.
Experience building data infrastructure to address the needs of business and data teams. Strong knowledge of data architecture, data modeling, and data warehousing.
Deep familiarity with data processing systems such as Airflow, Dagster, Flyte, Spark, DBT, or similar and data cataloging tools such as Atlas, Amundsen, DataHub, or similar.
Deep familiarity with SQL (PostgreSQL preferred) and NoSQL databases (Redis, Elasticsearch preferred).
We use AWS, so familiarity with its data analytics services and databases, e.g., Redshift, Athena, Glue, EMR, etc. Also, familiarity with data platforms such as Sagemaker, Dataiku, Databricks, Datarobot, or similar.
Experience with data visualization and reporting tools like Metabase, Tableau, PowerBI, or Looker.

Preferred Qualifications

Hands-on experience supporting high-traffic consumer apps.
Experience with real-time data processing using Kafka, Flink, or similar tools.
Data science, MLOps, or related education or work experience.



","['Version Control', 'Business Intelligence', 'PostgreSQL', 'Big Data', 'Pipelines', 'SageMaker', 'Hadoop', 'Agile', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Data Science', 'Data Analytics', 'Data Warehousing', 'Databases']"
Data Analyst,"SOLARIS, 1 FUSIONOPOLIS WALK 138628","Permanent, Full Time",Executive,1 year exp,Information Technology,Monthly,"$3,000to$6,000","Job Responsibilities

Manage end-to-end data projects; identify issues, gather information from various sources, analyze data, interpret patterns and trends, build prediction models, give recommendations, and create insightful automated reports.
Define data sources and requirements, design and implement processes and models for complex, large-scale datasets used for predictive modelling, data mining, and research purposes.
Automate and validate newly created reports and develop corrective actions to improve data integrity and quality
Review day-to-day operation processes, identify areas of improvement and make actionable recommendations based on underlying analysis
Provide critical thinking to look at numbers, trends, and data and come to correct conclusions based on the findings.
Develop and support predictive analytics models using R and/or Python
Present key findings to senior management and/or other stakeholders with actionable recommendations.


Job Requirements

Min. 1 year experience as data analyst
Experienced with gathering analytics requirements from products, business stakeholders and translating them to technical requirements for the Engineer team to implement
Familar with Data Modelling, Data Engineering
Advanced skills in data analytics/ visualization programming languages/ tools –Tableau
Strong written and verbal communication skills
","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Critical Thinking', 'Translating', 'Predictive Analytics', 'Data Engineering', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Visualization', 'Data Analytics']"
Senior Data Analyst,"MIDVIEW CITY, 22 SIN MING LANE 573969","Permanent, Full Time",Senior Executive,5 years exp,Engineering,Monthly,"$5,000to$7,000","Our Team

Based in Singapore, Lumens Group is a family of brands offering an ecosystem of services around cars. Our story began as a private hire car leasing company to address the needs of the new sharing economy led by Uber and Grab. Our core business has been leasing to ride hailing drivers and we grew our car fleet to one of the largest in Singapore in under 8 years. During this time, we have expanded our services to personal & corporate vehicle leasing, vehicle purchasing and financing.

Emerging strong from the Covid-19 period, Lumens is building for an exciting new era that brings in a wide range of merchants and individual consumers to our ecosystem. By owning a critical mass of vehicles and driver relationships, we are able to innovate on vehicle setup, driver upskilling & deployment, as well as technology and data capabilities to build mobility platform services that impact our everyday lives.

The Job

Lumens is hiring for a Senior Data Analyst who has strong experience in data analytical insights and will drive data business initiatives within Lumens’ ecosystem.

Responsibilities

Proactively build and improve the organization’s business intelligence platform: organize dashboards, queries, permissions, data model
Build reporting pipelines for finance, operations, compliance and other departments
Analyze large data sets using a variety of database query and visualization tools
Work closely with Data Architects, Data Scientists, Data Engineers and SRE to deliver data products with quick time-to-market and optimal resources
Act as data evangelist for business stakeholders
Drive development of self-service BI platform
Manage and review product requirements within the team and provide feedback to product management and other stakeholders

Requirements

Minimum of 3 years of relevant experience data engineering preferred
Strong analytical skills
Advanced knowledge in data analysis & SQL
Understanding in data modelling for business use cases & self-service
Experience with Python
Experience on data warehouse, data lake, ETL frameworks, Apache Spark
Domain knowledge of digital wallet / p2p finance & payments

Benefits:

Competitive remuneration package (Monthly salary + Performance based bonus)
Medical and dental coverage
Reputably branded staff cafe
In-house gym and fitness corner
Exclusive staff petrol discount
","['Tableau', 'Business Intelligence', 'Apache Spark', 'Data Analysis', 'Analytical Skills', 'Pipelines', 'Architects', 'ETL', 'Data Engineering', 'Product Management', 'SQL', 'Python', 'Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Engineer,"100 PASIR PANJANG, 100 PASIR PANJANG ROAD 118518",Full Time,Executive,2 years exp,"Engineering, Healthcare / Pharmaceutical, Information Technology",Monthly,"$5,000to$10,000","Overview of the role
The role provides a tremendous opportunity for a candidate to work in a fast-growing startup with a million users (and growing) by deriving value from the massive volume of data we capture.
This is your chance to deploy Algorithms & Pipelines at SCALE. Over the coming years, those will be progressively supporting some, if not all, of the following: user classification from multimodal data, simple NLP supporting data capture & classification, providing AI Diagnosis, Prediction of treatment opportunities, inference of Health events from time series, Context inference from Geo-data & weather, etc. (i.e., prior knowledge of medical etc. is not expected).
As the Data Engineer+Scientist, you are responsible for designing and implementing data-driven services and solutions (Ie: Pipelines & Algorithms). You must be comfortable deploying your solutions (algorithms) to the cloud, ready to scale, and have a proven track record of designing pipelines for batch as well as streaming needs.
Roles & Responsibilities

Develop data pipelines that ingest data from a variety data sources to enable better data-informed decision-making within the business
Design and implement data science solutions / algorithms that provide smart features to our users
Contribute to an ongoing effort to improve data reliability, efficiency and quality

Skills/Experience should include some of those (by order of importance):

Experience in Python, REST APIs, and SQL
Familiarity with data warehousing concepts and data-modeling
Experience in using AWS cloud infrastructure and solutions such as Kinesis, Glue, S3, Redshift, ECS
Experience with ELT processing and workflow orchestration using Airflow and dbt
Experience with development systems such as Bitbucket & Docker

We want someone who is:

Able to deliver your work in a planned and timely manner
Able to work across cross-functional teams to gather requirements and come up with solutions

Qualities:

Rigor: 5/10 *
Self-Learning: 7/10
Initiative/Enthusiasm: 6/10
Team-Work: 6/10 **

*You will have the opportunity to learn good practices and methods to nurture Rigor. Rigor is critical to scale models & data collection.
** Team-Work is also critical for scalability, but keep in mind that here this is teamwork across functional teams, not within a silo. It will be about passing the ball to the person working on the UX showing the output from your algorithm, receiving the ball from the product manager, and even about understanding how the algorithm is impacted by the feelings of the user doing input.
Other info

Work Location: Singapore
COVID-19 Vaccination Requirement: Fully Vaccinated

If you are passionate and motivated to join our efforts in improving patient’s quality of life, please send your CV and brief description of your successful growth campaigns (if available) to careers@healint.com","['MASSIVE', 'Weather', 'Scalability', 'Pipelines', 'ETL', 'Reliability', 'SQL', 'Python', 'Docker', 'Data Science', 'Orchestration', 'S3', 'Data Warehousing']"
Data Analyst,"HSBC BUILDING, 21 COLLYER QUAY 049320","Permanent, Full Time",Fresh/entry level,1 year exp,Healthcare / Pharmaceutical,Monthly,"$4,000to$8,000","Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/amplifyhealthexternal/job/Singapore-SG-Amplify-Health/Data-Analyst_JR-32748

Where you would add value
The role will primarily work with cross functional teams across data analytics, actuarial analytics, data science, clinical (coders and doctors), and data engineers in an international team. The objective of the role is to ensure timeous, robust and accurate delivery of relevant data profiling and manipulation methods including responsibility of understanding and owning business logic to create meaningful and useful data assets. Effective communication between a range of stakeholders is vital to ensure delivery.
The ideal person has a passion for data and understand the life journey of data.

How you would make a difference
Core responsibilities include:

Understanding internal lineage of data sets through close collaborations with technology and business intelligence teams
Mining large structured and unstructured datasets for a multitude of companies with different data structures
Ownership of data structures and relevant business logic by setting standards and vision for normalised data sets
Creation and methods for development of scalable and re-usable data marts while understanding key business usage. This includes relevant testing structures to ensure high quality
Support the design of data systems to ensure data analytics takes place in an efficient, scalable, and reproducible way
Usage of data to find new insights to inform healthcare strategies and develop product – there will be a broad range of products to understand from clinical, operations, financial, fraud, digital, sales and marketing, wellness, etc.
Performing basic data analytics ad hoc to extract core data insights
Specification of data reports to derive business insights that will meaningfully change the environment
Present data and model findings in a way that provides actionable insights
Connecting with a multitude of local and international stakeholders to understand the data, systems, and analytical processes in a healthcare context
Improve processes and data outcomes where opportunities arise

What you need to be successful
Behavioural skills

Communication skills across a wide range of stakeholders
Ability to work cohesively in a team environment with key focus on the data
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude focused on continuous improvement
Ability to take and provide feedback to drive improved delivery
Rigorous ability to problem-solve and optimise environment

Technical understanding
A working understanding of the data used in healthcare is optimal as data forms the basis of products, as such the following core understandings are required:

Proficient in SQL, python, and advanced excel
Proficient experience of the data lifecycle in at least 2 out of the following areas of expertise from clinical, operations, financial, fraud, digital, sales and marketing, wellness, or any relevant dataset in healthcare
Proficient experience in generation of Datamart’s for healthcare
Working experience in health outcome indices and metrics and measures
Knowledge of databases and structures, governance and meta data standards including data architecture principals, ETL/ELT, etc.
Knowledge of patient health management, provider profiling, healthcare reporting, and other key healthcare technologies etc. is advantageous
Knowledge of clinical tools including coders, groupers, and classifications is advantageous
Knowledge of data science in the healthcare space is advantageous
Knowledge of healthcare benefit pricing, product pricing and other actuarial calculations (reserving, risk rating, etc.) is advantageous
Experience in Microsoft Azure preferred (Databricks, Synapse, Data Factory, etc.)

Qualifications

A bachelor's degree in statistics, healthcare related, or similar
A master's degree in a related field preferred
Experience in healthcare analytics.
Fresh graduates are welcome to apply
","['Microsoft Azure', 'Business Intelligence', 'Actuarial', 'Data Structures', 'Advanced Excel', 'Clinical Operations', 'SQL', 'Attention to Detail', 'Python', 'Fraud', 'Data Architecture', 'Statistics', 'Data Science', 'Data Analytics', 'Databases', 'Mining']"
Data Analyst,"HSBC BUILDING, 21 COLLYER QUAY 049320","Permanent, Full Time",Professional,8 years exp,Healthcare / Pharmaceutical,Monthly,"$8,000to$16,000","Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/amplifyhealthexternal/job/Singapore-SG-Amplify-Health/Data-Analyst_JR-32748

Where you would add value
The role will primarily work with cross functional teams across data analytics, actuarial analytics, data science, clinical (coders and doctors), and data engineers in an international team. The objective of the role is to ensure timeous, robust and accurate delivery of relevant data profiling and manipulation methods including responsibility of understanding and owning business logic to create meaningful and useful data assets. Effective communication between a range of stakeholders is vital to ensure delivery.
The ideal person has a passion for data and understand the life journey of data.

How you would make a difference
Core responsibilities include:

Understanding internal lineage of data sets through close collaborations with technology and business intelligence teams
Mining large structured and unstructured datasets for a multitude of companies with different data structures
Ownership of data structures and relevant business logic by setting standards and vision for normalised data sets
Creation and methods for development of scalable and re-usable data marts while understanding key business usage. This includes relevant testing structures to ensure high quality
Support the design of data systems to ensure data analytics takes place in an efficient, scalable, and reproducible way
Usage of data to find new insights to inform healthcare strategies and develop product – there will be a broad range of products to understand from clinical, operations, financial, fraud, digital, sales and marketing, wellness, etc.
Performing basic data analytics ad hoc to extract core data insights
Specification of data reports to derive business insights that will meaningfully change the environment
Present data and model findings in a way that provides actionable insights
Connecting with a multitude of local and international stakeholders to understand the data, systems, and analytical processes in a healthcare context
Improve processes and data outcomes where opportunities arise

What you need to be successful
Behavioural skills

Communication skills across a wide range of stakeholders
Ability to work cohesively in a team environment with key focus on the data
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude focused on continuous improvement
Ability to take and provide feedback to drive improved delivery
Rigorous ability to problem-solve and optimise environment

Technical understanding
A working understanding of the data used in healthcare is optimal as data forms the basis of products, as such the following core understandings are required:

Proficient in SQL, python, and advanced excel
Proficient experience of the data lifecycle in at least 2 out of the following areas of expertise from clinical, operations, financial, fraud, digital, sales and marketing, wellness, or any relevant dataset in healthcare
Proficient experience in generation of Datamart’s for healthcare
Working experience in health outcome indices and metrics and measures
Knowledge of databases and structures, governance and meta data standards including data architecture principals, ETL/ELT, etc.
Knowledge of patient health management, provider profiling, healthcare reporting, and other key healthcare technologies etc. is advantageous
Knowledge of clinical tools including coders, groupers, and classifications is advantageous
Knowledge of data science in the healthcare space is advantageous
Knowledge of healthcare benefit pricing, product pricing and other actuarial calculations (reserving, risk rating, etc.) is advantageous
Experience in Microsoft Azure preferred (Databricks, Synapse, Data Factory, etc.)

Qualifications

A bachelor's degree in statistics, healthcare related, or similar
A master's degree in a related field preferred
Experience in healthcare analytics.
","['Microsoft Azure', 'Business Intelligence', 'Actuarial', 'Data Structures', 'Advanced Excel', 'Clinical Operations', 'SQL', 'Attention to Detail', 'Python', 'Fraud', 'Data Architecture', 'Statistics', 'Data Science', 'Data Analytics', 'Databases', 'Mining']"
 , , , , , , , , , 
Data Analyst,"ORCHARD BUILDING, 1 GRANGE ROAD 239693",Full Time,Professional,1 year exp,Information Technology,Monthly,"$3,500to$6,000","Job Highlights

Be a key member of a high growth start up
Abundant opportunity to perform & shape the future
Dynamic, innovative & collaborative work culture

Job Description
We are looking for a result-driven individual who is well-versed in analyzing data and displays general business acumen, with a drive for growing businesses.
Key Responsibilities:

Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Ensure data integrity
Work with management to prioritize business and information needs.

Relevant Experience & Qualifications

BS in Mathematics, Economics, Computer Science, Information Management or Statistics
Experience in data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skill with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Knowledge of micro mobility trends and indicators
","['Tableau', 'Segmentation', 'Information Management', 'Mathematics', 'JavaScript', 'ETL', 'SPSS', 'Economics', 'Data Mining', 'Business Objects', 'Attention to Detail', 'Database Design', 'Statistics', 'Data Analytics', 'Databases']"
Data Analyst,"ESR BIZPARK @ CHANGI, 8 CHANGI BUSINESS PARK AVENUE 1 486018",Permanent,Fresh/entry level,1 year exp,Information Technology,Monthly,"$4,000to$5,000","
Salary Range: $4000 - $5000 + AWS + VB
Working location at Changi Business Park (near to Expo MRT station)
This is a permanent position



A. Overall Purpose Of The Job
As a member of the Data Operations team, the Data Analyst is responsible for maintenance and quality of all data loads and transformation for our global client base.


Responsibilities include:

- maintenance and improvement of existing configuration of all travel data ETL (extract, transform, load) processes
- technical support provided internally and externally in a timely fashion and maintained throughout the data lifecycle
- liaise with the travel agencies and data vendors on a global scale to collect and process data
- focus on continual improvement of data capture and data quality, troubleshooting and resolution of any ETL issues
- setup and configuration of data loads when required
This role is also responsible for liaising with external data providers, vendors and internal Clients and participating in cross functional teams and projects as required to support our customer base, including but not limited to working with the other Data Services teams, DTRM technology teams, Service Delivery Managers, OnlineHELP, and vendors to support ELT processes, new releases, enhancements, bug fixes and internal self-provisioning tools.


B. Key Responsibilities

Perform required modifications and maintenance of data loads, data transformation rules and configurations to reflect any changes and improvements for data processing and transfers;
Monitor successful execution of these transfers; investigate, resolve or escalate issues to apply a proper solution;
Perform data mining, research and correction for transaction lifecycle; liaise with Vendors for improvements;
Using SQL, analyse and validate data to ensure accuracy, quality, and integrity; create and analyse ad-hoc reports per client requests.
Collaborate with internal clients and Vendors to solve reported data and setup problems;
Manage quality control process of data feeds through reporting; identify data issues and follow-up with appropriate parties to bring to resolution;
Reconcile and action on quality control reports for data feeds. Assist in the implementation of new internal processes and technology enhancements. Provide training for new hires on existing ETL processes, reporting and system maintenance tasks.



Required Skills and Knowledge:

· Ability to analyse data and apply / recommend advanced solutions and issue handling processes
· Understand ETL processes and data flow
· Establishes good relationships with Vendors, customers and colleagues; Relate well to people at all levels; ability to manage positive attitude and rational thinking
· Detail oriented professional with a zeal for identifying, implementing and managing best practices for data quality
· Problem solver with a lean-in approach to troubleshooting and task management
· Ability to perform backend setup and configurations; monitor overall system performance and take actions to escalate potential issues and track resolutions
· Demonstrate an ability to actively participate in a process of improvement existing systems; escalate issues and suggest resolutions
· Focuses on customer needs and satisfaction; Sets high standards for quality and quantity; Monitors and maintains quality and productivity; Works in a systematic, methodical and orderly way
· Collaborate with other members of the cross functional team on the development of solutions and resolving existing issues for data loads, manipulation and tackling

Ability to use a methodology and process for requirements gathering and development
Solid analytical and troubleshooting skills required
Analytical thinking & problem solving skills
Results driven and self-motivator
Task management and ability to effectively manage multiple high priority projects
Strong written & oral communication skills
Travel Industry Experience with Global Distribution preferred



Required Work Experience

4+ years of SQL, MS Server preferred
4+ years of experience working with ETL processes
4+ years of experience working with data quality and records management
Experience with Aurora, DynamoDB a plus
Experience developing ad-hoc queries for operational support and analysis purposes
Strong experience with providing help desk experience in a customer facing role; ability to establish and maintain relationships with Vendors, Clients and team members
Travel data experience preferred



Required Qualifications

BA or higher
Degree in computer science or related discipline preferred

·","['Tableau', 'Requirements Gathering', 'Oral Communication Skills', 'Microsoft Excel', 'Quality Control', 'Oracle', 'Data Transformation', 'MySQL', 'ETL', 'DynamoDB', 'Data Quality', 'Task Management', 'Data Mining', 'SQL', 'Database Administration', 'Data Analytics', 'Databases', 'Service Delivery']"
Data Analyst,"THE CRESCENT @ KALLANG, 47 KALLANG PUDDING ROAD 349318","Permanent, Full Time",Executive,2 years exp,Logistics / Supply Chain,Monthly,"$2,500to$4,000","Our client is a company dealing in trading of FMCG products. They have a requirement for a Data Analyst who can handle the jobscope as given below

- require a strong grounding in mathematics
- Able to collect data from relevant sources and organizing that data then analyzing it and interpreting n simplifying accurately to inform Directors to make decisions.
- report the findings to Directors by translating simple graphics .
- Need comprehensive understanding of statistics, it means being able to parse extensive data sets for high-level insights.
- Need knowledge in common statistical concepts to know include probability distributions, statistical features, inventory control.
- will be responsible for the maintain, update and monitor inventory n sales report and based on historical sales numbers you will need to generate and prepare forecasted sales numbers.
- Martian n update on inventories report as well as the interpretation and presentation of statistical outcomes to support the operations and key business procurement strategies.

The right candidate must have flair for numbers and good at reporting. Candidates with minimum 2 years experience will be considered

Job location : Pasir Panjang
Work week : Mon-Fri
Salary : Upto 4k pm (open to discuss)

Interested candidates may please send their resume in MSWord format to jobs@saitech.com.sg

Job posted by
Bhanu Rajan
EA Regn : R1106079
Saitech Intl","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Inventory', 'Mathematics', 'FMCG', 'Translating', 'Inventory Control', 'Interpreting', 'Procurement', 'SQL', 'Python', 'Statistics', 'Graphics', 'Data Analytics', 'Data Visualization']"
Data Analyst,"CAPITAGREEN, 138 MARKET STREET 048946",Permanent,Professional,2 years exp,"Engineering, Information Technology, Insurance",Monthly,"$4,500to$8,300","Responsibilities:

Collaborate with IT, Business Owners, and Analytic teams to promote, design, and build effective Data structure
Explore ways to enhance data quality, reliability, and automation
Work with business stakeholders and develop/sign off on requirements , continuously re-prioritize backlog, define release scope, support creation of UAT test plans, and support testing and production releases
Responsible for developing/modifying various reports and dashboards using available tools like Qlik Sense and PowerBI
Manage user expectations via timely delivery of accurate information in the form of reports and dashboards
Collaborate with business teams by providing technical input to Data Governance policies, standards and processes related to data, access, and security (privacy & protection) of sensitive data
Work on API/Data feeding
Performance price UAT and review results

Requirements:

Candidates with strong analytical mindset, to be able to understand data flows and processes, dig into details, identify root causes, have SQL skills and be able to work with IT and business teams
Bachelor's degree or higher in a quantitative field of study and a minimum of 3 year analytical work experience
Experience in Python / Databricks / Apache Spark / Qlik / Scala / SQL
Understanding of enterprise data governance technologies and protocols
","['Tableau', 'UAT', 'Microsoft Excel', 'Apache Spark', 'Scala', 'Data Analysis', 'Data Quality', 'Data Governance', 'Reliability', 'PowerBI', 'SQL', 'Python', 'Statistics', 'Data Analytics', 'Databases', 'Data Visualization']"
Data Analyst,"SUNTEC TOWER FOUR, 6 TEMASEK BOULEVARD 038986",Full Time,Professional,3 years exp,Information Technology,Monthly,"$7,000to$8,500","Job Description:
Kerry Interim is currently hiring for Data Analyst work in a specific domain, an asset-management enterprise company in Singapore. This role is responsible for the transformation of AI and data projects from end to end.

Responsibilities:
Strong understanding of data and AI architecture solution design, the ability to think outside the box and understand how it can contribute to the success of the company.
You will be one of the core members of the Data & AI team, collaborating with various domain experts in the team such as data engineers, data developers, and data analysts.
A strong technical background is required to deliver data and AI projects from start to finish.
Ideally, you will need to have a strong communication skill set as you will be dealing with stakeholders and end users.

Experience and Qualifications:
· Minimum Diploma or Bachelor’s Degree in computer science, information systems, or any other relevant certification with at least 3 years of experience in data AI projects
· Understanding data management frameworks, and data architecture experienced in data wrangling, analytics, and transformation of data using tools such as Python, SQL, Power Query, etc.
· A strong understanding of Power BI and domain knowledge in asset management is preferable.

To Apply:
Should you be interested in learning more about the above opportunity, please kindly share your CV (quoting job title), with Charles Chow at charles@kerryinterim.com. We regret that only shortlisted candidates will be notified.

Lic: 22C0942 Reg: R21103356","['Tableau', 'Asset Management', 'Microsoft Excel', 'Data Analysis', 'Mathematics', 'Data Management', 'SQL', 'Finish', 'Python', 'Data Architecture', 'Statistics', 'Data Analytics', 'Power BI', 'Databases', 'Data Visualization']"
Data Engineer,"THE COMMERZE@IRVING, 1 IRVING PLACE 369546",Permanent,Professional,2 years exp,"Consulting, Information Technology",Monthly,"$5,000to$8,000","Develop and deliver data analytics and visualization projects working within a team by understanding the customers' business needs and their data workflows and then designing ETL pipelines ingesting into data warehouses to deliver impactful dashboards and reports. It also includes using the data to perform predictive analysis leveraging AI and ML technologies.

2 to 6 years of proven track record of analytics work experience. Fresh Graduates with relevant internship experience or good academic results are encouraged to apply
Work with the Data Team in data management project implementations
Develop Data Management pipelines using ETL tools and Data Warehouse platforms - both on Cloud and on-premises
Analyze Client Users' data and translate business queries into analytics using products like Tableau, PowerBI, etc.
Keeping abreast of developments and trends in data, analytics, and technology in the identified business areas and exploring new possibilities to optimize the use of existing data and technology in improving/transforming business processes
Explore and develop prototypes to gather feedback and validate proposed solutions for Clients
Provide training and support to empower Client Business Users to leverage data
Possess a good degree in Engineering, Statistics, Computer Science, Data Science, or related fields of study. Additional qualifications in Business Related domains and experience with DSAI / data modeling would be preferred
A good appreciation of data workflows, with at least 2 years of relevant work experience within the Data Management industry would be advantageous
Having experience in Scrum and/or agile implementation experience would be a plus.
Strong interpersonal and communication skills, with the ability to conceptualize complex issues and concepts and succinctly present them into possible avenues for review
Possess learning agility and enjoy challenging status quo
Technically savvy, i.e. proficiency in SQL, ETL Tools, and Cloud. Big Data, AWS/Azure, and BI/Data software programs like Tableau, Dataiku, Python, Talend, Pentaho, Microsoft, and Oracle products are an advantage
","['Tableau', 'Data Modeling', 'AWS', 'Data Management', 'ETL', 'SQL', 'Python', 'Data Science', 'Visualization', 'Data Analytics']"
Data Engineer,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,5 years exp,Information Technology,Monthly,"$6,000to$9,500","Responsibilities:

Collaborate with data scientists, coders, programmers and other stakeholders
Creating and managing the AI development process and general infrastructure of a product
Doing statistical analysis and interpreting findings
Automating critical tasks and procedures for a data science team
Creating data transformation infrastructure
Developing AI models communicating the utility of the AI models they generate to a diverse range of employees inside the organisation, including product managers and management executives
Converting machine learning models into APIs with which other apps may interact

Qualifications:

Master / Bachelor’s degree in computer science, computer engineering, or relevant field.
A minimum of 5 - 7 years’ experience in a similar role.
Strong knowledge of Datawarehouse / database / Cloud systems and data mining.
Excellent organizational and analytical abilities.
Outstanding problem solver.
","['Machine Learning', 'Hadoop', 'Data Transformation', 'ETL', 'Interpreting', 'Data Mining', 'SQL', 'Python', 'Data Analytics', 'Databases']"
"Engineer, Regional Data","MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983","Permanent, Full Time",Senior Executive,1 year exp,Information Technology,Monthly,"$4,500to$7,500","About the role
CGS-CIMB Securities International Pte. Ltd is one of the leading integrated financial service   providers in Asia. With a global presence in over 20 countries, and backed with an award-winning research team, the Company is well-positioned as Asia’s leading financial gateway, providing well researched and in-depth analysis of financial products.

Data Warehouses and Data Analytics are integral part of the enterprise strategic that can help   businesses steer business decision and insights for targeted marketing.

The successful candidate can help our enterprise better manage and leverage its data, by working with a   team or partner to provide a more powerful, scalable, and robustly architected environment to handle the growth in variety, volume, integrity and velocity of data.

Job Responsibilities
The incumbent will be responsible for:

Data Warehouse Design and Implementation
Data ETL pipelines and Data integrations.
To escalate when incidents/issues are discovered
Design and participate in data solution and ETL jobs that support collection, ingestion and transformation of back-office data especially client related data.
Design and build the data model to support high-performance data query, efficient data storage and analysis.
Understand the essential data application scenario of a financial institute, design and build a data warehouse that meets the requirement of business units like reporting, CRM, etc.
Lead end-to-end development/enhancement that encompass ETL jobs and building API end-points.
Performing code reviews and providing critical suggestions for fixes and improvements.
Implementing best practices and tune for optimization.
Supporting issue analysis during test phases, as well as production issue resolution.
Summarize and accumulate the methodology of data warehouse construction, and work with business units to support applications data requirement
Any other responsibilities/tasks as assigned by the Management from time to time.

Job Requirements
To thrive and be successful in this role, you must have / be:

Diploma/ Bachelor’s degree in computer science or a related field
Relevant experience in database administration, information technology, database architecture, or a related field
Advanced knowledge of database security, backup and recovery, and performance monitoring standards and tuning.
Understanding of relational and dimensional data modelling.
","['CRM', 'Management Skills', 'Leadership', 'Construction', 'Pipelines', 'ETL', 'Securities', 'Information Technology', 'Marketing', 'Data Design', 'Strategy', 'Tuning', 'Database Administration', 'Business Development', 'API', 'Data Analytics']"
 , , , , , , , , , 
 , , , , , , , , , 
DATA ANALYST,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979","Contract, Full Time",Executive,3 years exp,Information Technology,Monthly,"$1,800to$2,000","JOB DESCRIPTION:

• Extract and clean the data from various data sources to generate daily, weekly and monthly reports

• Set up the automation of reports from data extracted and stored by AWS

• Provide data analysis and insights to identify and recommend areas of improvement

• Fulfil ad-hoc data request from client and management

• Have some experience in ETL processes and mapping different sources of data with key identifiers

• Writing SQL queries to retrieve information quickly

• Management and Identification of key data points, trends that can be used in tandem with operations to increase KPI's

REQUIREMENTS:

• Minimum Bachelors in Business, Computer Science, Mathematics or any related field

• At least 3 year of experience in contact centre/service industry including data/trend prediction & analysis, self-help migration

• Experience in building reports using Excel, Tableau, SQL, Power BI, Python, or other business intelligence and data analytics tools Strong communication and presentation skills

• Proactive and able to work independently with minimum supervision

• Excellent time management with strong critical thinking and ability to handle pressure

*SQL","['Tableau', 'Business Intelligence', 'Microsoft Excel', 'Data Analysis', 'Critical Thinking', 'Mathematics', 'ETL', 'SQL', 'Pressure', 'Python', 'Presentation Skills', 'Data Analytics', 'Power BI', 'Able To Work Independently']"
Data Analyst,"KEPPEL BAY TOWER, 1 HARBOURFRONT AVENUE 098632","Permanent, Full Time",Senior Executive,3 years exp,Others,Monthly,"$3,000to$6,000","Job Description 

Design and develop monitoring systems and implement instrumentation of equipment and data acquisition. 
Development of applications on IIOT platform, design, setup and deployment. 
Implementing algorithms that can deliver data-exploration, decision support, recommendation systems, machine learning, etc. 
Analysis of data and deriving actionable outcomes. 

Requirements 

PhD/ Master/ Bachelor degree in computer science, computer engineering, information systems, industrial automation or a related discipline. 
Expertise in monitoring systems, computer networks, data structure, system deployment, and software engineering etc. 
Experiences in programming languages and/or development environment are advantages.
","['Tableau', 'Machine Learning', 'Microsoft Excel', 'Data Analysis', 'Mathematics', 'Software Engineering', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Instrumentation', 'System Deployment', 'Data Analytics', 'Power BI', 'Databases', 'Data Visualization']"
Data Analyst,"61 ROBINSON, 61 ROBINSON ROAD 068893",Contract,Senior Executive,2 years exp,Information Technology,Monthly,"$5,500to$7,500","We are looking for a Data Analyst for a social media client on a 12-month & renewable contract role. The Analyst will support APAC team to gather data from various sources, inspect, clean, and model the data to discover useful information that the business needs, including structuring their findings into easy-to-read reports, presentations and dashboards.

Job Responsibilities

Gather data from various sources, review and curate into meaningful metrics, insights and create visualizations for analysis, presentations, reports and dashboards.
Identify, track down and resolve data quality and code issues to ensure that databases and dashboards remain error-free and organized.
Prepare data model, regular management reports, analysis and quarterly performance metrics.
Maintain trustworthy and reliable forward-looking forecast data, strong commitment to accuracy and thoroughness in all aspects of data collection and curation.
Define, develop & document business processes and procedures to improve administrative efficiency.
Support Planners on other ad hoc requirements such as forecasting and supply planning.

Qualifications

2 - 5 years working knowledge and experience with data, databases and reporting.
Advanced spreadsheet skill and familiarity with management reporting.
Good SQL skill and familiarity with data modelling
Strong analytical, troubleshooting and data / information organizational skills.
Prior corporate real estate experience is a plus

If this sounds like your ideal job move, please reach out jvenkataraman@welovesalt.com alternatively please you may apply via the system!
CEI No: R1659595 / EA No: 07C3147","['Tableau', 'Machine Learning', 'Forecasting', 'Troubleshooting', 'Microsoft Excel', 'Data modelling', 'Data Analysis', 'Data Modeling', 'Social Media', 'Mathematics', 'Data Quality', 'SQL', 'Data model', 'Python', 'Statistics', 'Data Analytics', 'Databases', 'Corporate Real Estate', 'Data Visualization']"
Data Analyst,"SYMBIOSIS, 3 FUSIONOPOLIS WAY 138633",Permanent,Senior Executive,2 years exp,Information Technology,Monthly,"$5,000to$6,000","Overview:

We are looking for a hands-on research scientist with a good track record of experience in applying Data Science towards solving real-world problems in Operations Research (Linear and NonLinear Programming and Goal Programming) and Optimization Problems and preferably (Un)supervised Learning to name a few. You will be joining an excellent, multidisciplinary team and will be participating in cutting-edge work in operations research and artificial intelligence. You will be providing quality answers to large-scale problems with broad impact.

Responsibilities:

Do applied research on a wide array of Operations research and machine learning projects.
Conceptualize, Design, build and develop prototypes which demonstrate the required functionality rapidly
Develop transformative AI solutions to address our clients’ business requirements and challenges
Understand the latest industrial and academic developments in AI/ML, and apply it to create prototypes for demonstration.
Work with development teams to mature these algorithms into production quality programs

Desired candidate profile:

Degree in relevant field or considerable hands-on experience in AI research or application development
Hands-on research scientist with a proven track record of experience in applying machine learning methods towards solving real-world problems
Advanced understanding of AMPL, Gurobi is preferable. Pyomo and any other optimization software is a bonus
Basic understanding of Machine learning/Deep learning in python, Image Processing, NLP methodology is a plus

Basic Qualifications:

Good knowledge in designing AI systems and architecture.
Experience in development of end-to-end AI based products
Basic understanding of system architecture, components and requirements.
Very good python programming skills. Java programming skills a bonus
Detailed oriented and penchant for data quality control
Experience in deploying state-of-the-art, data-driven learning algorithms to solve business problems
Is a Self-Driven individual contributor who prefers working in an agile manner.
Ability to work independently and have ownership mentality
Familiarity/experience working with distributed computing tools or cloud environments such as AWS is a plus
Innovation minded, highly capable to think systematically, capable of redefining the solutions to overcome the competitors and solving problems.
Curious and willing to challenge existing solutions with innovative technology concepts
","['Tableau', 'Machine Learning', 'AMPL', 'Quality Control', 'Image Processing', 'Applied Research', 'Ability To Work Independently', 'Artificial Intelligence', 'Operations Research', 'Data Quality', 'Python', 'Data Science', 'Java', 'Python Programming', 'System Architecture', 'Business Requirements']"
Data & Analytics Project Manager,"OCEAN FINANCIAL CENTRE, 10 COLLYER QUAY 049315",Permanent,Professional,5 years exp,Information Technology,Monthly,"$7,000to$10,000","Based on the business demands, the Data & Analytics Project Manager plans, organizes, manages, and follows up internal/external resources to deliver a project/ program within the defined standards, budget, deadlines, and quality requirements
Role and Responsibility:

Acts as a proactive business partner, develops business relationships acting as the SPOC (Single Point of Contact) on a project/ program
Participates in the definition of the business case, cost model and overall objectives for the project/ program
Defines and monitors the project/ program plan, budget, KPIs and metrics, activities, methodologies, resources, and responsibilities' allocation (internal/ external)
Defines and reviews SLAs and oversees performance
Coordinates and integrates the different contents and deliverables to ensure the overall consistency and coherence of the designed solution
Prepares the project/program delivery and the knowledge transfer for RUN (Business as Usual services) in close collaboration with the operating/ service delivery teams
training, user support and communication
Defines and organizes project/ program steering activities, advises and reviews overall plan and status of the project/ program routinely
Tracks project/ program risks and decides on corrective measures and/ or any trade-offs needed to achieve objectives and minimize delays and costs
Manages the allocated internal/ external resources including third parties’ activities (incl. vendor partners)
Ensures the development of expertise and know how in his/ her field of responsibility

Requirement

Strong knowledge of project management methodologies with at least 5 years of experience practicing Agile methodologies
Prior experience in consumer (1st party) data is highly preferred
Able to quickly understand the data analytics requirements and KPIs used for consumer analysis
Experience in managing end to end Machine Learning Projects
Understands revenue growth management requirements and familiar with required datasets and its implementation
Working knowledge of data, BI & Analytics technologies (data warehouses, marts, big data, reporting and visualizations) is required
Working knowledge of DevOps and related tools. System design experience is required.
Strong communication skills in English, both verbal and written
Strong interpersonal skills, with an ability to thrive in a multi-cultural team
Strong in stakeholder engagement, scope and budget management, risks, and issue management
Skilled in influencing for positive outcomes
Proven experience in managing vendor partner relationships and delivery of projects in an offshore delivery/ services model
Self-initiated with high tolerance for ambiguity and ability to create structure. Ability to work in a team in an agile setting will be a plus
Ability to demonstrate leadership, even while handling crisis situations
Ability to adapt, and think ‘out of the box’
Google Cloud Platform/ Scrum/ PMI certifications will be a big plus
Prior experience in a similar regional position / role will be a plus
","['Machine Learning', 'Budget Management', 'Tolerance', 'Big Data', 'Interpersonal Skills', 'Scrum', 'Google Cloud Platform', 'Agile Methodologies', 'Agile', 'Stakeholder Engagement', 'System Design', 'Project Management', 'Data Analytics', 'Service Delivery']"
 , , , , , , , , , 
Data Analyst,"PRUDENTIAL TOWER, 30 CECIL STREET 049712","Permanent, Full Time",Executive,2 years exp,Information Technology,Monthly,"$4,000to$7,000","The Data Analyst will work with our the Savills SG and Regional team on real estate data project using Azure and mix of big data EDW solutions. Candidates must have strong numerical skills. They must possess excellent excel and data analysis skills, and a high level of aptitude with PowerPoint and PowerBI modelling skills.

Key Responsibilities:

Responsible for the structuring and execution of the company’s in-house data construction and management
Responsible for integration and analysis on ETL and varieties of data sources
Responsible for conducting data analysis of the real estate data.
Responsible for performing data analysis and aggregating property market data from most major Asian cities;
To assist the IT team with the collection and analysis of the in-house and external real estate data;
To assist in supporting the development and delivery of a data visualisation platform;
Participate in ETL implementation and enhancement
Working with Business Analysts to understand business requirements
Working with data integration technologies such as SSIS, Azure Data Factory, Function APP.
Working with data storage tools such as Azure Blob, Azure SQL, MongoDB.

Requirements:

Bachelor’s degree in Computer Science, Information Engineering or any relevant disciplines
2-3 years of experience in real estate data
2-3 years of experience in relevant domain (CRM, Big Data, Business Intelligence, Analytics Reporting)
Experience with ETL, data management, transformation, and modelling
Experience with Cloud Technologies
Required knowledge in SQL, C#.
Knowledge and experience in end-to-end project delivery, hybrid / agile delivery methodologies
Competent data analysis and numerical skills
Ability to coordinate and communicate with a network of regional officers
Independent, organized, conscientious efficient
Excellent attention to detail
Proficiency in MS Excel, Word, PowerPoint and preferably statistical software;
Professional acumen and demonstrated interest in commercial real estate
Knowledge of the Singapore property market is a plus
Knowledge in PowerBI is a plus
","['Factory', 'MongoDB', 'Business Intelligence', 'Data Analysis', 'Commercial Real Estate', 'Azure', 'Big Data', 'Data Management', 'ETL', 'Data Integration', 'PowerBI', 'SQL', 'Attention to Detail', 'SSIS', 'Business Requirements', 'Data Visualisation']"
Data Analyst,1 RAFFLES QUAY 048583,"Permanent, Full Time",Senior Executive,5 years exp,"Advertising / Media, Consulting",Monthly,"$6,000to$12,000","- Drive clarity and solve ambiguous, challenging business problems using data-driven approaches. Propose and own data analysis (including modeling, coding, analytics, and experimentation) to drive business insight and facilitate decisions.
- Dig into complex data sets and make sense out of them.
- Translate functional and technical requirements into architecture and design.
- Participate in code and design reviews to maintain high development standards.
- Measure business performance, develop core metrics and create dashboards to track and understand them.
- Identify data, metrics and analyses needs for business partners.
- Initiate, develop and maintain data pipelines and data models that power dashboards and data products with outstanding craftsmanship.
- Perform deep analyses and build models to understand customer behavior, and extract key insights that impact product decisions.
- Work across multiple subject matter specialists to drive new data initiatives, automation of reports, establish best practices and mentor junior members in the team.
- Lead analytics projects to completion.
- Work with the broader Data Science team to discover ways to scale our insights through better systems and automation.


Qualifications
Basic: 
- PhD, MS or Bachelors degree in Statistics, Economics, Computer Science or another quantitative field.
- Knowledge of Hadoop related technologies such as HDFS.
- Experience building high-quality end-to-end data solutions in an agile environment from requirements to production.
- Be able to proactively handle prioritization of work and deliver work of great quality and to influence the broader team.
- Experience with Looker, Tableau, Power BI, or other business intelligence platforms.

Preferred:
- Experience in technically mentoring junior team members.
- Previous experience working with social media data (unstructured and structured) is a plus.
- Strong communication skills, for example demonstrated through documentation and presentations. Able to present findings to senior management to inform business decisions.","['Tableau', 'Mentoring', 'Business Intelligence', 'Microsoft Excel', 'Data Analysis', 'Modeling', 'Pipelines', 'Experimentation', 'Hadoop', 'Agile', 'Economics', 'Statistics', 'Data Science', 'Data Analytics', 'Power BI']"
Data Analyst ,6 SERANGOON NORTH AVENUE 5 554910,"Part Time, Permanent",Professional,5 years exp,Information Technology,Monthly,"$5,000to$9,000","The is a new Business Analyst role to perform business analyst work for C3 - Healthcare Command, Control and Communication (C3) System's extension. He / She will be working with the C3 vendors to gather the requirements, perform data analysis, conduct UAT and support the project Go-Live.
Role and Responsibilities

Obtain and confirm the Budgetary Quotations from the source systems and vendors
Review and critique vendors’ quotations
Write funding / requirement approval papers
Review the data designs, ETL design, table designs and perform data analysis
To ensure the interface specifications meet the IHiS data governance, guidelines and policies
Monitor the data deliverables and ensure timely availability of data for development, UAT and production
Plan and coordinate end-user training for any system implementations / enhancements / Change Requests (CRs)
Manage vendors to achieve Key Performance Indicators / Service Level Agreements and reviews of contractual Terms & Conditions (when necessary)
Assist manager in formulating application implementation strategies / best practices
Identify data and business gaps within organization’s information systems by analyzing existing systems and workflows.
Recommend effective and cost saving solutions
Support positive project-vendor relationships and resolve conflicts
Support the team in defining project requirements, tracking and documentation
Manage and track project risk and issues

For each project, support the following tasks:

Develop an application Project Charter / variation charter for source system's integration and Module Schedule
Develop risk assessment and mitigation plans
Work closely with other source systems to assess the impact and dependencies
Review project progress and ensure that the project meet the project milestones on time
Review plan, conduct and co-ordinate the data UAT by working with the end-users
Assist the managers and users to sign-off the deliverables
Ensure audit conformance throughout the project life cycle
Prepare post implementation review

Requirements / Qualifications

At least 6 years’ experience in IT Projects
Solid working experience of Business Analyst’s roles and responsibilities
Has involved in at least 2 medium to large scale projects as Business Analyst
At least 2 years’ experience in vendor managed projects
Experience in all phases of project lifecycle
Experience in budgeting (costing, cost evaluation analysis etc.)
Experience in various procurement methodology e.g. RFQ, RFP etc.
Experience in writing approval papers
Must have the knowledge and experience to perform root cause analysis
","['Charter', 'Project Risk', 'Data Analysis', 'Predictive Analysis', 'Assurance', 'Root Cause Analysis', 'Systems Integration', 'ETL', 'Data Governance', 'Operating Systems', 'Fraud', 'Business Intelligence Tools', 'Internal Audit', 'Microsoft Power BI', 'Business Analyst', 'Audit']"
Analyst Data Operation,"TWENTY ANSON, 20 ANSON ROAD 079912",Full Time,Professional,3 years exp,Banking and Finance,Monthly,"$6,250to$7,500","Team Overview:
Data & AI-Data Operations (DO) is entrusted with maintaining all data integral to the investment decision process, for BlackRock the Investment Manager and its BlackRock Solutions (BRS) business In our proprietary Aladdin® end-to-end investment platform. DO closely partners with other teams such as Portfolio Management, Global Capital Markets, Relationship Management, Portfolio Compliance, Risk Analytics, Regulatory Reporting, and others, to ensure their business data needs are met accurately, timely, and efficiently.
The Data & AI philosophy is anchored on BlackRock’s cornerstone principles: Innovation, Fiduciary focus, Passion for Performance, and the unified purpose of One BlackRock. Through that lens, we strive to build value for our clients by understanding their needs, the markets, and using technology to create best in class solutions. As distributed team, Data & AI has presence across 8 countries servicing more than $17 trillion in AUM on Aladdin for BlackRock and BRS clients.
Responsibilities:

Deliver Premium Client Experience - understand the Investment management process and how Aladdin clients use Green Package data for their daily processes! Candidate should use the knowledge to engage with BlackRock’s clients to handle expectations for data quality and align the team’s support with the clients’ investment process
Project Management - engage with multi-functional teams to think creatively and deliver innovative solutions to Aladdin clients. Ability to contribute towards strategic projects for the business, data & technology projects targeting inefficiencies & automation
Teamwork -Collaborate with groups within the function, Engineering teams to perform project specific quality checks. Redesigning quality check process to identify impact worthy events and provide critical user input for modification of scripts to generate quality analytics
Technical Expertise -Use technical skills to ensure the accuracy of large analytical data sets, automate processes with scripts and efficiently query information from a vast database.
Subject Matter Expert- Develop deep grasp of the green package production! Work with people across on initiatives for Data Operations. Partner with the groups across the firm to understand, test, and implement modelling changes across the platform.
Innovate- Initiate and drive platform and process innovations to support new business needs, minimize risk, enhance quality, and navigate the changing markets.

Qualifications:

BTech + MBA/PGDBA from reputed institute with good knowledge of analytical concepts. BTech + CFA (level 2) will be a preferred candidature.
3 - 6 years of experience in FI modeling, valuation and analytics
Excellent problem-solving, critical-thinking skills and an ability to identify problems, design provide solutions to implement change.
Knowledge of financial products in Fixed Income, Equities and Derivatives, and familiarity with Risk analytics such as Durations, Spread, Beta and VaR would be an advantage.
Be a ‘Student of the Markets and Technology’ by following the global markets to understand how macro-economic factors can affect the analytics and harness the technology to seek critical problems.
","['Bloomberg', 'Microsoft Excel', 'Derivatives', 'Modeling', 'Valuation', 'Data Management', 'Relationship Management', 'Corporate Actions', 'Data Quality', 'Investment Management', 'Capital Markets', 'Portfolio Management', 'Fixed Income', 'Equities']"
Financial Data Analyst,11 IRVING PLACE 369551,Full Time,Junior Executive,1 year exp,Banking and Finance,Monthly,"$3,000to$3,500","Data Analyst
Canopy (https://canopy.cloud/) is a ""make sense of your data"" financial technology startup. We provide aggregation, visualization, analytics, and reporting services to financial institutions, wealth managers, and high net-worth individuals.
We are currently recruiting a Graduate Trainee who will be working in the Financial Data Transformation and Analysis joining a team of +10 Data Analysts tasked with unlocking the insights contained within their investment data - which we receive via PDF and bank datafeeds, working in the Financial Data Transformation and Analysis team. Working with External Asset Managers, High Networth Individuals and world renowned private banks such as Credit Suisse, Bank of Singapore and UBS.
We have developed an automated data extraction, standardization, enrichment, and aggregation tool (called “Canopy Engine”) which requires a human to help resolve exceptions, conduct sense checks, and tease out insights. The data and our insights will then be used by banks, wealth managers, and high-net-worth individuals. Our goal is to help our clients better understand their investment portfolio and thus make better investment decisions.
Data aggregation and analytics:

Process financial data (from pdf/excel/datafeed) using various internal systems
Reconcile, and interrogate the aggregated investment portfolio for inconsistencies and errors
Design client presentations and enhance customised reporting experience

Product and process development:

Actively contribute to the enhancement of our internal systems to make our process more efficient, accurate and timely

Client interactions:

Partner closely with Analytics & sales team to resolve client's data related questions
Open to fresh graduates with less than 1 year of work experience, with Bachelor's degree in Finance, Data Analytics is preferable.
Strong analytical skills with experience in handling large amount of data from pdf/excel
Proficiency in Microsoft Excel is a must
Demonstrable understanding of financial instruments (derivatives, funds, etc) is a significant advantage
Meticulous attention to detail
Ability to work under pressure
Team player with good interpersonal skills
Proactive at seeking improvements to workflows
Experience with Tableau is highly preferred
Experience with Trifacta or any Data Wrangling tools (ETL) is highly preferred
Singapore Citizen and PR perferred
","['Tableau', 'Microsoft Excel', 'Derivatives', 'Analytical Skills', 'Interpersonal Skills', 'Recruiting', 'Data Transformation', 'Wealth', 'Accounting', 'Attention to Detail', 'Financial Statements', 'Visualization', 'Team Player', 'Data Analytics', 'Financial Reporting']"
Data Analyst (Finance),"VISION EXCHANGE, 2 VENTURE DRIVE 608526","Permanent, Full Time",Executive,2 years exp,"Healthcare / Pharmaceutical, Information Technology",Monthly,"$3,600to$5,000","This is a regional position within the Finance department and you will be responsible for organizing data related to sales numbers and financials reporting activities of various legal entities. In this role, you will work closely with various stakeholders to prepare internal reports for executive leadership to support their decision making. You need to be self-driven and be confident enough to propose the most appropriate approach to fulfill the business and accounting requirements. Additionally, you need to constantly reassess the existing way of doing things and to come up with suggestions to further improve the business processes.
Job Responsibilities

Using automated tools to extract data from primary and secondary sources for business analytical requirements
Developing and maintaining databases, data systems – reorganizing data in a readable format
Using statistical tools to identify, analyze, and interpret patterns and trends in complex data sets that could be helpful for the diagnosis and prediction
Preparing and analyze reports for the management stating trends, patterns, and predictions using relevant data
Build solutions utilizing technologies including PowerBI, with a variety of data sources on-premise such as Infor Syteline, SQL Server, COGNOS and SalesForce

Job Requirements

Degree holder in Business Analytics, Information Technology, Data Science or Computer Science with Accounting knowledge
2 years of working knowledge of data mining principles: mapping, collecting data from multiple data systems on premises and cloud-based data sources
2 years of work experience developing and managing data products from ingestion to operations
2 years of experience supporting data analytics solutions
Self-driven, highly motivated and open-minded to change
Possesses strong analytical and problem-solving skill
Able to work under high pressure and prioritize with a heavy workload and multiple deadlines
In-depth understanding of and experience in designing structured and unstructured, SQL and No SQL data repositories
Strong knowledge about data modeling

We regret that only shortlisted applicants will be notified.","['Data Modeling', 'Financials', 'Cognos', 'Information Technology', 'PowerBI', 'Data Mining', 'SQL', 'Accounting', 'SQL Server', 'Business Analytics', 'Data Science', 'Decision Making', 'Data Analytics', 'Databases']"
 , , , , , , , , , 
UAT Data Analyst,"THE SIGNATURE, 51 CHANGI BUSINESS PARK CENTRAL 2 486066","Contract, Full Time",Junior Executive,1 year exp,Banking and Finance,Monthly,"$3,000to$4,000","Job Summary
We are looking for a self-motivated and independent UAT data Analyst within the banking domain.

Mandatory Skill-set:


Degree in Finance, Accounting, Business Administration, Computer Science or equivalent;
1-3 years of experience in Financial Reporting, Management Account and Regulatory Reporting;
Proficient in SQL scripting, PowerBI, Qlik,MS Excel functions including Pivot table;
Experience in conducting testing or User Acceptance Testing (UAT), logging errors and documenting test scripts, results and findings;
Maintain strong analytical, problem-solving, and communicating skills;
Good interpersonal skills and a strong team player.

Desired Skill-set:

Familiarity with Qliksense and HUE will be a plus;

Responsibilities:

Analyse and plan change requests and projects related to Financial Reporting, Management Accounting and Regulatory Reporting projects;
Perform regulatory requirements and data analyses, functional solution review and UAT;
Preparation of test scripts and writing SQLs based on mapping specifications;
Understand the process of change management, regulatory changes and reporting cycles;
Supervise change management by tracking, managing and escalating issues.

Should you be interested in this career opportunity, please send in your updated resume to apply@sciente.com at the earliest.
When you apply, you voluntarily consent to the disclosure, collection and use of your personal data for employment/recruitment and related purposes in accordance with the SCIENTE Group Privacy Policy, a copy of which is published at SCIENTE’s website (https://www.sciente.com/privacy-policy).
Confidentiality is assured, and only shortlisted candidates will be notified for interviews.
EA Licence No. 07C5639
","['QlikSense', 'UAT', 'Predictive Analysis', 'Interpersonal Skills', 'Scripting', 'Logging', 'PowerBI', 'SQL', 'Accounting', 'Management Accounting', 'Operating Systems', 'Fraud', 'Business Intelligence Tools', 'User Acceptance Testing', 'Internal Audit']"
 , , , , , , , , , 
Data Centre Associate,"BHARAT BUILDING, 3 RAFFLES PLACE 048617",Permanent,Executive,3 years exp,Information Technology,Monthly,"$4,000to$7,000","Responsibilities

Support in overseeing Data Center Operation team daily activites
Ensuring the safety and protection of customer's data is adhere to
Managing the storage of media to offsite storage
Backing up data onto media, be it on tape or tapeless
Presenting new tools that could be used to improve efficiency or cutting costs
Ensuring a safe and secured facility to protect the systems and power configuration
Providing support for technical support teams
Ensuring precautions are set in place whenever power outages or malicious attacks occurred
Ensuring the operations are in compliance with the regulations and laws
Assisting in updating the procedures and policies pertaining to Data Center operations

Requirements

Diploma in Information Technology or equivalent
At least 3 years of data center management
Qualification
Bachelor's Degree, Post Graduate Diploma, Professional Degree
","['Switches', 'Product Knowledge', 'Tape', 'Hardware', 'Housekeeping', 'Data Center', 'FMCG', 'Information Technology', 'Reliability', 'Direct Sales', 'Routers', 'ITIL', 'Cabling', 'Shipping', 'Technical Support']"
Data Analyst,"ESR BIZPARK @ CHANGI, 6 CHANGI BUSINESS PARK AVENUE 1 486017","Permanent, Full Time",Junior Executive,2 years exp,Information Technology,Monthly,"$3,000to$4,000","We are looking for a Business Intelligence Analyst with strong problem-solving skills and prior experience in building and managing BI assets. You should possess the ability to thrive in a fast-paced environment, working with passionate data-driven enthusiasts, and building the team's capabilities to solve data challenges for the organization. You will also help to enable the data driven culture within the organization and provide action driven insights.

Cultivate in-depth understanding of existing products and provide business solutions to new and existing clients across all verticals
Create, maintain and track relationships with prospects to better identify and address their needs
Collaborate with Data Engineers, Data Analyst & Data Science folks on the design, development and maintenance of analysis and reporting functions.
Presenting finds to stakeholders through various storytelling methods.
Providing deep dive analysis to improve business performance using datamining and statistical analysis.
Collaborate with team members to ensure we are building the right data marts, introduce flexible, smart metric frameworks that help us scale analysis quicker and identify areas of improvement in our BI processes.
Collaborate with cross-functional teams to understand their business problems and help to solve them using data.
Ensuring data quality for all BI assets built.
Focusing on continuous improvement on data processing efficiency and resource utilization.
Be the champion leading the data democratization efforts for the organization.
Consistently socialise and evangelise what's in our BI ecosystem so business users can tap into existing reports.
Adaptive to change and advancement in the BI world.
Maintaining the data bible/dictionary/glossary for all reports and dashboards.

Requirements

At least 1-3 years of experience working in a BI or analytics function preferably.
Good working knowledge on SQL and R/Python to perform data querying, building BI models and conducting data analysis.
Experience in data analysis and deep-dive analysis
Strong data visualisation skills using Tableau, Qlik, PowerBI, Microstrategy or other relevant visualisation tools. Qlik is must.
Good understanding of ETL/ELT concepts and their relevant use cases
Experience in gathering BI requirements and structuring specifications to produce business-relevant datasets and ensure data quality of the dataset.
Passion for democratizing data effectively to the wider organization for self-serve.
Keenness to innovate and improve the BI process beyond basic reporting, seeking ways to add value so that the organisation can consume data more effectively.
Strong communication skills, able to collaborate effectively with both sides of the business and technical divide.
A self-starter mindset who takes ownership and excels in a lean and fast-paced organisation.
Knowledge of Statistics & Machine Learning is a plus.
Team Player with the ability to work across a matrix environment in a fast-paced environment and constantly evolving environment
","['Tableau', 'Machine Learning', 'Business Intelligence', 'Microsoft Excel', 'Data Analysis', 'Data Quality', 'PowerBI', 'SQL', 'Python', 'Statistics', 'Data Science', 'Team Player', 'Storytelling', 'Data Analytics', 'Data Visualisation']"
 , , , , , , , , , 
Data Analyst Executive,"CITY HOUSE, 36 ROBINSON ROAD 068877",Contract,Executive,1 year exp,Others,Monthly,"$4,000to$4,500","Career exposure into government organization!
Yearly renewable contract possible for conversions with good performance!
Good start for your career advancement!
Monday - Friday, Central Location

Job responsibilities:

Ensure that data is collected in a timely and reliable manner
Implement strategies and initiatives to improve survey response rates
Advise the operations team on good data quality practices
Use data analytical tools to conduct validation checks to ensure data accuracy
Analyse macro trends to detect outliers and anomalies
Flag out and rectify any data errors and inconsistencies

Requirements

Strong analytical and quantitative skills
Excellent communication and interpersonal skills
Comfortable with working with diverse groups of people
Self-starter who is able to thrive in a fast-paced environment
Knowledge of Python, R or Tableau is an advantage

Thank you for your application but we regret only shortlisted applicants will be notified.

PERSOLKELLY Singapore
Pte Ltd | EA License No. 01C4394 • RCB No. 200007268E
EA Registration No.
R1766716 (Ng Yi Ling)

By sending us your
personal data and curriculum vitae (CV), you are deemed to consent to
PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose
your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with
the Privacy Policy.","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Predictive Analysis', 'Interpersonal Skills', 'Assurance', 'Risk Management', 'Data Quality', 'SQL', 'Python', 'Operating Systems', 'Fraud', 'Business Intelligence Tools', 'Internal Audit', 'Data Analytics', 'Data Visualization']"
Lead Data Analyst - HSBC Life,"MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983",Full Time,Professional,5 years exp,Banking and Finance,Monthly,"$9,000to$18,000","Principal Responsibilities

Leads and mentors a team of data analysts to be innovative, collaborative, and customer focus
Spots and improves data inefficiencies within the organisation
Facilitates workshops with technical and non-technical audiences
Has good business judgment and balances long-term strategic investment with near-term business goals
Has the ability to think strategically but also the ability to dive into tactical details
Engages with and influences executive-level and cross functional stakeholders
Defines end-to-end complex and/or greenfield data projects, from requirement gathering, execution, to delivery insights and recommendations
Delivers BI and reporting solutions by using tools such as QlikView, Tableau, PowerBI, and Looker

Requirements

Degree in Computer Science, Data Science, Mathematics, Statistics or another quantitative field
Experience in data analysis, data mining, data processing, and data visualization
Excellent communication skills and data driven problem solving
Experience leading teams
Customer centric mind-set

To be considered for this role, the relevant rights to work in Singapore is required.","['Tableau', 'Excellent Communication Skills', 'Business Intelligence', 'Data Analysis', 'PostgreSQL', 'Pipelines', 'Mathematics', 'PowerBI', 'Data Mining', 'SQL', 'Statistics', 'Data Science', 'Customer Focus', 'Databases', 'Data Visualization']"
Data Analytics Platform Engineer,"APERIA TOWER 1, 8 KALLANG AVENUE 339509",Contract,Professional,5 years exp,Information Technology,Monthly,"$5,000to$10,000","Responsibilities

Design and install software solutions for Data Management, Data Visualisation, Data Warehouses or Big Data platforms.
Collaborate closely with hardware and infrastructure stakeholders to deploy solutions in enterprise environments such as data centres or cloud providersApply security and network design best practices for data analytics solutions to minimise the risk of data exposure
Integrate data analytics platforms to peripheral applications for monitoring, authentication, alert management and log management etc
Work closely with project manager and technical leads to provide regular status reporting and support them to refine issues/problem statements and propose/evaluate relevant analytics solutions
Bring your experience and ideas to effective and innovative engineering, such as automation of routine monitoring and maintenance tasks
Work in interdisciplinary teams that combine technical, business and data science competencies that deliver work in waterfall or agile software development lifecycle methodologies
The range of accountability, responsibility and autonomy will depend on your experience and seniority, including:


Contributing to our internal networks and special interest groups
Mentoring to upskill peers and juniors


Possess good communications skills to understand our customers' core business objectives and build end-to-end data centric solutions to address them
Good critical thinking and problem-solving abilities

Requirements
Must-have:

Prior experience deploying large scale enterprise data analytics platforms from vendors such as SAS, Informatica, Talend, Microsoft, IBM, Tableau, Qlik, Oracle etc
Technical expertise in hardware, network and integration of platform software such as user authentication stores, enterprise application/system monitoring tools, mail servers etc
Service-delivery mindset to propose automation and preventive maintenance solutions
Undergraduate or graduate degree in Computer science or equivalent

Nice to have:

Experience with other aspects of data centre operations such as high availability and disaster recovery designs for resiliency and business continuity planning
Large scale data loading experience moving enterprise or operational data from source systems to new applications or data analytics solutions
Experience in leveraging on loud-based data analytics platform such as:


AWS serverless architecture in Lambda on AWS DynamoDB, EMR Redshift
Azure Data Factory or SQL Data Warehouse
GCP BigQuery/BigTable, Cloud Dataprep/Dataflow/Dataproc
","['Tableau', 'Azure', 'Big Data', 'Hardware', 'Critical Thinking', 'High Availability', 'Data Management', 'DynamoDB', 'EMR', 'SQL', 'GCP', 'Data Science', 'Business Continuity Planning', 'Data Analytics', 'Disaster Recovery', 'Data Visualisation']"
PM (Data Migration),"GB BUILDING, 143 CECIL STREET 069542","Contract, Full Time",Professional,6 years exp,Information Technology,Monthly,"$6,000to$7,800","• Proven management of data migration projects
• Experience with ETL tools (such as Talend)
• Experience of working in a complex, multi-priority organization, preferably experience on Hortonworks Data Platform, Cloudera and MariaDB
• Experience of working within delivery teams from multiple teams (including vendor product teams)
Key responsibilities of the Data Migration Project Manager will include:
• To be responsible for overall project management in ensuring the quality, cost, risk and compliance and project scheduling requirements are met
• To develop project plan based on business case or agreed scope for approval by Project Sponsor / Project Steering Committee (PSC), supported by establishment of the overall success criteria for the project
• To maintain effective project governance, processes and systems to be utilised throughout project
• To actively manage project risk in mitigating all identified risks and change control process
• Identifying the data migration impact of all proposed changes
• Reviewing gaps and proposing a solution for data migration during the solution design phase
• Devise and get approval for the data migration strategy for the implementation
• Oversee and ensure the production of a mapping matrix for all data
• Oversee and ensure a gap analysis for any missing or archive data
• Reviewing as is data quality and putting in place plans to address any required data quality improvements
• Oversee and ensure the building of intermediate database creation scripts
• Oversee and ensure the building of data validation scripts
• Ensure the accurate filling of intermediate data tables during data load","['Project Risk', 'ETL', 'Data Quality', 'MariaDB', 'Strategy', 'Data Migration', 'Compliance', 'Project Management', 'Change Control', 'Scheduling']"
Support Analyst (Data – Datawarehouse),"CT HUB, 2 KALLANG AVENUE 339407","Contract, Full Time",Middle Management,4 years exp,Banking and Finance,Monthly,"$8,000to$13,000","Support Analyst (Data – Datawarehouse)

Degree in computer science/engineering or related disciplines.
Min  4 years of experience in application development and support environment in ETL, Data warehouse, and business intelligence.
Experience in ETL, Data warehouse and various business intelligence tools on      Unix/Windows platforms.
Technical skills : Informatica, Oracle, MS BI, Unix/Linux, AS400, Control-M, Shell      scripting.
Knowledge of ITIL of similar framework will be advantage .
Experiences in Teradata, Big Data using Cloudera (CDH 5.8 or above), Hive, Impala, HDFS, YARN, Sqoop, Oozie, Hbase, kafka, Map Reduce/Spark are good advantageous.
","['Tableau', 'Version Control', 'PySpark', 'Business Intelligence', 'Teradata', 'Oracle', 'As400', 'Big Data', 'Informatica', 'Shell Scripting', 'Application Development', 'ETL', 'Business Intelligence Tools', 'ITIL', 'Power BI']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Analyst (Risk),"GUTHRIE HOUSE, 1 FIFTH AVENUE 268802","Permanent, Full Time",Executive,3 years exp,Information Technology,Monthly,"$5,500to$11,000","As a Data Analyst (Risk), you will be involved in supporting the risk operations by conducting data analysis of risk cases to discover risk trends and behavior patterns from big data sets, thereafter being involved in designing long-term solutions to fight fraud. The insights you provide will be optimizing risk strategies to create business value and enable trust for our clients.

Analysis of rich user and transaction data to uncover device, user, transaction, etc. trends that help alert SHIELD's risk systems and contribute to fraud prevention mechanisms
Optimize fraud detection by rapidly identifying emerging fraud trends through data-driven analysis and developing strategic fraud rules to address them
Perform data/statistical analysis to keep processes at the forefront of fraud detection by identifying areas of potential fraud risk and/or potential opportunities to improve current fraud mechanisms
Develop and communicate insights and recommended actions to stakeholders to manage risk by contributing toward machine learning models, and risk management principles to help clients trust their users by staying ahead of new and unknown fraud
Build and maintain dashboards for all stakeholders to provide visibility of key metrics, fraud patterns, and detection efficiency



3-5 years of experience as a hands-on analyst in a high-tech company
Minimum Bachelor Degree in Computer Science, Data Sciences, Statistics, Math, or other related fields
Strong experience in handling large-scale unstructured data
Experience in SQL or other data handling tools, as well as the ability to learn more advanced data
Business intelligence experience using tools such as Tableau, Qlik Sense, and Excel
Working experience with any of the data analysis tools such as R, Python, SPSS, SAS, etc.
Experience with the application of experimentation and statistical techniques (i.e. hypothesis testing, probability distributions, regression, decision trees, etc.)
Ability to take initiative in a fast-moving and dynamic environment, and take timely actions to prevent risk of fraud
","['Tableau', 'Machine Learning', 'Business Intelligence', 'Microsoft Excel', 'Data Analysis', 'Big Data', 'Experimentation', 'Risk Management', 'SPSS', 'SQL', 'Python', 'Fraud', 'Statistics', 'Prevention', 'Data Analytics', 'Ability To Learn']"
 , , , , , , , , , 
 , , , , , , , , , 
Head of Data (Transportation),205 BRADDELL ROAD 579701,Permanent,Manager,1 year exp,"Engineering, Information Technology, Others",Monthly,"$8,000to$16,000","Job Description
As Head of Data, you are responsible for leading the strategy, prioritization, development, and delivery of business objectives that leverages on data. You will apply industry best-practices and approaches, and further customize the practices to deliver innovative data-centered advantages that allow ComfortDelgro Private Mobility Group (PMG) to outpace competitors.

As Head of Data you will

Apply your expertise in data science, statistical analysis, data mining and the visualization of data to derive insights that value-add to business decision making (e.g. hypothesis testing, development of MVPs, prototyping etc)
Work with stakeholders from different functions of PMG to architect and design analytics solution to meet business objectives
Develop an enterprise data science strategy to achieve scale, synergies and sustainability of model deployment across data team
Conduct analysis and cultivate on continuous improvement programmes to improve on quality, productivity and delivery
Undertake rigorous analyses of business problems on structured and unstructured data with advanced quantitative techniques
Building and developing data models, data automation systems, performance metrics, and reporting systems
Develop and train predictive / ML models using a diversity of machine learning tools and frameworks
Overseeing the delivery of insights and reports used for analyzing business functions and performance metrics
Provide strategic leadership and technical knowledge to data team


Requirements:

Master Degree and/or Degree in Computer Science, Data Analytics, Statistics or equivalent
10 years’ experience in quantitative analysis and data science (machine learning / predictive modelling) with at least 3 years of leadership / people management experience
Deep expertise in a range of ML concepts, frameworks and techniques such as logistic regression, clustering, dimensionality reduction, recommendation systems, neural nets etc.
Strong understanding of data infrastructure technologies (e.g. Spark, TensorFlow etc)
Familiar with data engineering methodologies, including SQL, ETL and experience in manipulating data sets with structured and unstructured data using Hadoop, AWS or other big data platforms
Proficient in data visualization and the use of dashboarding tools (e.g. Tableau, Power BI)
Experience with development or delivery of products and solutions with a focus on data driven systems
Experience with development of Data Models
Strong analytical and problem-solving skills
High energy and motivated team player
Able to effectively work across functions and teams to drive projects and key initiatives to completion
","['Tableau', 'TensorFlow', 'Machine Learning', 'Sustainability', 'Data Analysis', 'Logistic Regression', 'Big Data', 'Architect', 'Hadoop', 'Data Management', 'Data Engineering', 'SQL', 'Data Architecture', 'Statistics', 'Data Science', 'Decision Making', 'Data Analytics', 'People Management Experience', 'Data Visualization']"
Financial Data Associate,71  Robinson Road 068895,Full Time,Non-executive,1 year exp,"Accounting / Auditing / Taxation, Banking and Finance",Monthly,"$4,000to$7,000","The Role / Responsibilities:

Support new deal set-up, data capture (e.g., amendments), lifecycle data maintenance, data quality assurance and tracking support to the rating analysts within the designated Line of Business (LOB)
Performs administrative tasks including but not limited: to data updates, prepares rating action, bulk rating actions, publishing ratings, research and press release templates and disclosures consistent with regulatory requirements, internal policies and guidelines for designated LOB support; participates in projects
Monitors designated mailboxes to ensure timely and effective handling of internal and external client requests. Organizes work to meet deadlines and time sensitive requests/projects.
Facilitates resolution to technical issues and/or more complex external inquiries with supervision by Senior Financial Data Associate/Specialist/Team Leader
Builds positive relationships with clients to ensure customer satisfaction
Demonstrates the ability to deal professionally with clients. Delivers high level of service across high volume of transactions.
Promptly and efficiently escalates conflicts/problems/database/data inconsistency
Able to identify and research issues and/or discrepancies with data and/or requests for follow up with the analyst.
Resolves basic client inquiries (both internal and external clients)
Demonstrates increasing awareness of procedures, guidelines and regulatory requirements as it pertains to their job function by asking relevant questions.
Liaison with Rating Teams and other Moody’s departments (Commercial, Information Technology, etc.) as required
Provide back-up coverage for designated associate in the event of absence and holidays to ensure seamless service to GMO clients
Willing to accept new challenges
Demonstrates flexibility with last minute changes in commitments and deadlines
Contributes positively to the team even under pressure or when performing routine and/or administrative tasks
Places interest of the team above individual self-interest
Continue to develop broad based knowledge of financial instruments, terminology, and related business practices


Qualifications:

Strong English language proficiency required. Strong Japanese language preferred.
Excellent attention to detail and ability to complete repetitive process with no error
Clear written and verbal communication skills with an ability to communicate complex business concepts to a senior audience.
Highly organized and efficient
Competency in Microsoft Office (Outlook, Excel, Word and Powerpoint.)
A strong client focused orientation with the drive and enthusiasm required to achieve results and assume customer satisfaction.
Strong interpersonal and teamwork skills
Works using own initiative and without close supervision
Strong administrative skills
Entry level position. Minimum of 1 year of corporate experience and/or relevant internship experience preferred.
Undergraduate/first-level degree (E.g. Bachelor’s degree) required
","['Outlook', 'Microsoft Office', 'Data Analysis', 'Quality Assurance', 'Literacy', 'Data Management', 'Assurance', 'Data Quality', 'Attention to Detail', 'Publishing', 'Customer Satisfaction', 'Regulatory Requirements', 'Teamwork Skills', 'Terminology', 'Retirement']"
 , , , , , , , , , 
Data Business Analyst (IFRS17),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557","Permanent, Full Time",Senior Executive,3 years exp,"Banking and Finance, Information Technology, Insurance",Monthly,"$4,600to$9,000","We are looking to build a team of Data Business Analysts who can act as a bridge between technology and business to work on data solutions. If you are a self-starter who looks at data as both science and art and enjoys partnering with business to drive tangible business outcomes, we welcome you to apply for the role!

Job Description

Work with Business Stakeholders, Project Managers and Technology teams to assist in the implementation of data projects.
Support data initiatives across Income, including requirement analysis, data mapping (ETL mapping), data documentation and data validation.
Work with business stakeholders to understand business requirements and facilitate identification of data requirements to meet business expectations.
Collaborate with Technology team to provide advisory support to develop data models for implementation of data repositories.
Run workshops with Business & Technology teams to source data from internal/external systems, document source to target data mapping, transformation logic and data validation rules.
Work with business stakeholders to establish data definition, data lineage and data quality rules
Support project managers in planning and scheduling of data activities.
Support Business Stakeholders during data validation and UAT phases of the project.


Experience / Skills

Good communication skills and experience in collaborating with different team members from business and technology.
Good understanding of enterprise applications, business processes and business requirement analysis.
Analytical, detail-oriented, ability to manage timelines and adapt to project needs.
Work experience in regulatory reporting projects such as IFRS 4, IFRS 17, BCBS 239 etc. is added advantage.
Advanced proficiency in SQL, or any other data querying language.
Advanced proficiency in Microsoft Excel and PowerPoint.
Proficient knowledge of Tableau, Power BI, or other business intelligence tools.
Insurance domain knowledge is an added advantage.


Qualifications

Degree in Maths / Statistics / Analytics/ Technology/ Business or a relevant discipline
3 years of experience and above in a business analyst or data analyst role working with business stakeholders
Working experience in at least one project related to business intelligence, reporting or data warehousing.
Experience in IFRS17 project would be an added advantage

Having 1 or more of the following experiences.

Working knowledge in database and system design
Working knowledge about querying data, data visualization and data analysis
Performed in the role of a business analyst in analytics or reporting capacity
","['Tableau', 'IFRS', 'UAT', 'Business Intelligence', 'Microsoft Excel', 'Data Analysis', 'Data Quality', 'SQL', 'Good Communication Skills', 'Statistics', 'Business Analyst', 'Data Analytics', 'Power BI', 'Data Visualization', 'Business Requirements']"
Data Project Manager (IFRS17),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557","Permanent, Full Time",Manager,10 years exp,"Banking and Finance, Insurance",Monthly,"$9,000to$17,000","As the company embarks on key data projects, we are seeking for an Experienced Data Project Manager to lead, manage and drive the successful delivery of IFRS data initiatives within budget, scope and timeline.

Job Scope

Collaborate and work with multiple stakeholders (IT and business) within Program team and across departments.
Responsible for planning, organizing, and directing the completion of the project while ensuring the project is on time, on budget, and within scope.
Plan, monitor and track progress of data related project tasks and activities based on overall project plan
Coordinate activities between various accountable stakeholders and ensure completion of activities in line with the project plan.
Effectively communicate on the progress
Adept in using MS Project to plan, monitor and track project.
Anticipate risks that may affect project delivery and to mitigate the risks with the stakeholder.


Requirements:

Degree holder in Information Technology, Information Systems, Computer Science o requivalent.
Analytical and structured.
Good verbal and written communication skills.
Stakeholder management.
At least 10 years’ experience in large scale project management.
A proven track record of successfully leading and delivering at least 3 major applications / systems implementation projects end-to-end (>$1m, 20 – 30 pax in project team)
Ability to step into the details (e.g. data mapping, data validation) when needed to resolve impediments while retaining full visibility of end to end view of project.
Strong project management, budget management, vendor management, change management and facilitation skills.
Highly organised, adaptable, meticulous with a strong sense of responsibility and ability to follow-through.
Sharp analytical and hands-on problem-solving skills including the ability to analyse and interpret complex information from numerous sources, prepare and present analysis and reports, deal with challenges creatively and achieve business focused solutions.
Excellent organisational skills and experience working in a fast-paced environment with a capacity to prioritise, multi-task, achieve business goals, perform and always work with a customer focused approach.
Excellent interpersonal, influencing and negotiation skills with demonstrated experience engaging and influencing key stakeholders and vendors to influence and achieve optimal business outcomes.
Experienced in project management & delivery in financial institutions, especially insurance sectors will be an advantage
","['IFRS', 'Budget Management', 'Change Management', 'Information Technology', 'Adaptable', 'Vendor Management', 'Stakeholder Management', 'Facilitation', 'Data Analytics', 'Project Delivery', 'IFRS project']"
"Librarian, Research Data Specialist","NANYANG TECHNOLOGICAL UNIVERSITY, 50 NANYANG AVENUE 639798","Contract, Full Time",Manager,3 years exp,"Education and Training, General Management",Monthly,"$3,700to$6,800","We invite applications for the position of Research Data Specialist in our Institutional Repositories Team, Office of Information, Knowledge and Library Services (OIKLS), Nanyang Technological University (Singapore). We are looking for an individual with exposure to institutional repository services or research data management, and keen to learn more on research data curation and archival in an academic setting.
The successful candidate will work closely with the Team, to provide services that include repository application management and advocacy for researchers on data curation, data sharing, and metadata standards. This position will report to the Team Lead of Institutional Repositories in OIKLS.
Responsibilities

Administer curation of datasets and maintain metadata standards for the institutional repository.
Engage and advise depositors in enhancement of metadata and appropriateness of data sharing.
Assess and report on research data archiving with stakeholders.
Provide advocacy for researchers to fulfil the research data archival obligations.
Conduct workshops for researchers on institutional repositories related topics.
Organize institutional repositories and open access related roadshow talks, workshops, seminars, and other events.
Participate in library-related projects.

Requirements

Master’s degree (MLIS or equivalent) is preferred.
3-5 years professional experience in research data management, research data archiving or related area.
Experience in conducting training and providing outreach services.
Exposure to institutional repository services.
Knowledge of repository metadata as well as understanding of metadata fields configuration is an advantage.
Understanding of Data Management Plan (DMP) in the context of research lifecycle
Awareness of emerging trends in scholarly communications and research support
Be comfortable to work within an academic library environment with a diverse population of colleagues, faculty, staff, and students.
Take ownership of tasks and good time management.
Self-motivated with independent learning skills and desire for continual life-long learning.
Proactive, flexible and comfortable with complexity and ambiguity.
Excellent communication and writing skills.

Interested applicants are invited to apply directly at our NTU Career Portal","['Archives', 'Data Sharing', 'Troubleshooting', 'Lifelong Learning', 'Data Analysis', 'Data Management', 'Data Quality', 'Tuning', 'Library Management', 'Advocacy', 'Python', 'Application Management', 'System Administration', 'Web Applications', 'Metadata', 'Writing Skills']"
Regional Senior Data Analytics Engineer,3 KAY SIANG ROAD 248923,Full Time,Professional,3 years exp,Logistics / Supply Chain,Monthly,"$7,000to$10,000","Responsibilities

Collaborate with business users and data analysts to understand user requirements
Design data models to meet critical product and business requirements, including reporting, data analysis, data science and other production applications
Develop and automate large scale, high-performance data warehouse pipelines
Monitor the usage of the data warehouse and optimize performance and cost through data modeling best practices
Maintain data warehouse documentation (data catalog) in collaboration with data analysts and data engineers
Implement data quality monitoring tools
Contribute to data warehousing processes and standards to improve the productivity and quality of output for the data team
Provide effective user administration, documentation, training materials and end user support
Maintain up-to-date knowledge of latest tools and technologies
Evaluate new tools and technologies for BI users

Requirements

Bachelors' Degree in: Computer Science, Engineering, Mathematics or Statistics
3 - 5 years experience of experience in data analytics
Experience in the following software: Data modeling, SQL, Python, Spark, Presto, Hive, bash, Linux, Git, GCP, Airflow, REST API
Experience in programming is a plus
Competency in Analytics and Computational Modelling, Business Needs Analysis, Data Visualization and Stakeholder Management
","['Tableau', 'Engineering Mathematics', 'user requirements', 'Big Data', 'Data Modeling', 'Administration', 'Access Control', 'Data Engineering', 'SQL', 'Python', 'Business Intelligence Tools', 'Statistics', 'Visualization', 'Data Analytics', 'Data Warehousing', 'Data Visualization']"
GIS Data Processor,"PRUDENTIAL TOWER, 30 CECIL STREET 049712","Permanent, Full Time",Professional,3 years exp,"Engineering, Information Technology",Monthly,"$3,000to$6,000","Greehill is digitizing urban trees in Singapore, and we are looking for professionals  with good spatial (3D) orientation skills to process and quality control the acquired field data.

Who we are

As the global pioneer in nature-based smart-city solutions, we help cities around the world to become more sustainable and more resilient against climate change. We are leading in applying smart city technologies such as the latest remote sensing and machine learning to green urban assets. With our cloud-based platform cities improve the well-being of their citizens through a greener, healthier, safer and more resilient urban environment while reducing operational costs. We currently operate offices in Budapest, Berlin, Singapore, San Francisco and Paris.

Your contribution will be

Ensure quality control of acquired field data
Mobile Laser Scanning trajectory processing
Terrestrial and mobile laser scanning data post-processing (post-processing, point cloud and photogrammetry)
Alignment and adjustment of different measurements
Ensure quality control of post-processed data
Solve GIS related tasks of processing
Manage camera adjustment
Provide data export and data management


We need you to have

Advanced computer skills (PC, Windows OS) with at least 3 years of experience
Fluent English communication
Have good spatial (3D) orientation ability
Interest in state-of-the-art technologies
Ability and interest to quickly understand and apply new software


We give preference to

GIS experience
Earlier experience with laser scanning (point cloud) field data capture and office data processing
Knowledge of RIEGL processing software (RiscanPro, RiProcess)
Knowledge of photogrammetry, camera calibration
GNSS knowledge about RTK quality, raw GNSS data post-processing (differential processing, network adjustment)


Please note when applying that we can only offer this position to Singaporean Citizens or Permanent Residents.","['Quality Control', 'Data Management', 'Remote Sensing', 'Climate Change', 'GIS', '3D', 'ArcGIS', 'Attention to Detail', 'Data Analytics', 'Calibration']"
Contract Data Analyst (11-month),"TOURISM COURT, 1 ORCHARD SPRING LANE 247729","Contract, Full Time",Manager,5 years exp,Information Technology,Monthly,"$4,000to$7,000","What the role is:
As part of the Analytics and Insights team, you will design, manage and collect data, use data analytics to produce insights that can empower STB and tourism industry to make data driven decisions, that will drive growth of Singapore tourism.
This is an 11-month contract position.

Main responsibilities:

Compile, analyse and report key tourism statistics to management, other government agencies and the public. This includes estimating Tourism Receipts contribution of strategic initiatives and associated projection for forward planning.
Use data analytics to answer key business questions. This involves understanding the Board's priorities and applying statistical analysis / data mining techniques to synthesise multiple data sources of varying nature (e.g. structured, unstructured).
Distil and present coherent insights using business intelligence tools (e.g. QlikSense) and carry out data storytelling to answer business questions. This may require building new dashboards from scratch based on user input and setting up the associated ETL workstreams.
Manage research projects by pre-empting and overseeing end-to-end survey processes, such as data collection, data processing, ensuring data quality, internal aligning of code frames vs other key datasets etc. Responsible for various aspects of vendor and contract management.
Contribute as data custodian and subject matter expert by identifying and managing data issues (e.g. anomalies, data gaps) using analytical tools such as R, so that data quality is good to be used for analytics.
Support test planning and test execution of enhancements to existing data visualisation.


Competency requirements:

Achieving results with others
Analytical thinking
Project management
Stakeholder management & relationship building
Personal development
Data analytics – perform analysis on data using data analysis tools (e.g. R, SQL) and statistical techniques to obtain insights, patterns or relationships
Data visualisation – Ability to set up new QlikSense dashboard and communicate insights through visualisation


Job requirements:

Working knowledge of R and SQL
Data sets management, involving data quality, data mapping & integration, user acceptance testing
Minimum 5 years relevant experience in data profiling, data analysis, data story telling, quantitative market research project management
Proven track record in engaging relevant stakeholders (within and outside of the organization)
Experience in using visualisation tools & creating new dashboards (e.g. QlikSense)
Strong presentation and communication skills with ability to express complex ideas in an easy-to-understand manner
Strong command of written and spoken English


Application Status: Shortlisted candidates will be contacted within 2 weeks from the closing date of this job posting. We regret to inform that only shortlisted candidates will be notified.","['QlikSense', 'Dashboard', 'Contract Management', 'ETL', 'Data Quality', 'Data Mining', 'SQL', 'Statistics analysis', 'Scratch', 'Business Intelligence Tools', 'User Acceptance Testing', 'Statistics', 'Storytelling', 'Data Analytics', 'Test Execution', 'Personal Development', 'Test Planning', 'Data Visualisation']"
Junior Data Analyst,"CITY HOUSE, 36 ROBINSON ROAD 068877",Contract,Executive,1 year exp,Others,Monthly,"$3,400to$3,800","Career exposure into government organization!
Yearly renewable contract possible for conversions with good performance!
Monday - Friday, Central location

Responsibility

Design and create surveys in survey system such as building of questions, branching and error prompts; including documentation of system information.
Perform user acceptance testing, gathering feedbacks from testing, debugging of system issues and follow up with users on deployment/system issues.
Collaborate with programmers, engineers, and organizational leaders to identify opportunities for process improvements and recommend system modifications.
Conceptualize data validations and utilize R or Python in development of validation rules, which includes fixing coding errors and updating of codes, to improve data quality.
Oversee and track the progress of data validation and preparing reports for Ops Team.
Use statistical and visualisation tools to interpret data sets, paying attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts.
Ad-hoc data wrangling, trend analysis for exploratory studies.

Requirments

Strong analytical and quantitative skills
Independent in handling surveys end-to-end; including dealing with issues arising from both survey system and data validation processes.
Collaborate and communicate with multiple stakeholders to ensure a smooth workflow throughout the survey
Knowledge of Python, R or Tableau is an advantage


Thank you for your application but we regret only shortlisted applicants will be notified.

PERSOLKELLY Singapore
Pte Ltd | EA License No. 01C4394 • RCB No. 200007268E
EA Registration No.
R1766716 (Ng Yi Ling)

By sending us your
personal data and curriculum vitae (CV), you are deemed to consent to
PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose
your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with
the Privacy Policy.","['Tableau', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Labels', 'Predictive Analytics', 'Data Quality', 'Trend Analysis', 'SQL', 'Attention to Detail', 'Python', 'User Acceptance Testing', 'Debugging', 'Databases']"
Data System Analyst,"WOODLANDS BIZHUB, 190 WOODLANDS INDUSTRIAL PARK E5 757516",Full Time,Professional,8 years exp,Information Technology,Monthly,"$8,000to$11,000","Key Qualifications:
· System Analyst with hands-on experience in implementing data warehouse & analytics platforms
· Good functional knowledge of Retail bank, Wholesale & Global Markets products & business processes -  Mandatory to have at least exposure in any one area (Retail / Wholesale / Global Markets)
· Mandatory to have expertise in either Finance Analytics or Credit Risk Analytics.
· Finance Analytics expertise - Financial Reconciliation, Allocation, Fund Transfer Pricing, Budgeting, Forecasting, Performance Management & Regulatory Reporting
· Credit Risk Analytics expertise – Basel Reporting (Capital provisioning, RWA, EAD, EL), Credit Risk Exposure Reporting (Industry, Disclosures, Country of Risk), NPL, Counterparty Risk Reporting
· Experience in profiling data, query scripting for analysis & testing purposes
· Expertise in designing Data models (Teradata FSDM, Dimensional Models, Reporting Tables)
· Knowledge & experience of mapping attributes from products systems such as Silver Lake Core Banking, Murex, Vision Plus, Intellect Trade Finance, SAP GL, OFSA, Moody’s RaY -  Preferred to have exposure in at least one of the systems.
· Expertise for authoring Functional Specs / Solution documents
· Experience in building test strategy and test scripts for validation
· Experience in implementing data governance processes - reference data management, data lineage, data quality rules, Teradata MDM
· Exposure to Big data tools - Hue, Impala; ETL - Informatica PC, DQ, MM; Teradata MDM,
· Reporting - MS Power BI, Qlik","['Forecasting', 'Teradata', 'Big Data', 'Informatica', 'Scripting', 'Transfer Pricing', 'ETL', 'SAP', 'Banking', 'Budgeting', 'Capital', 'Test Strategy', 'NPL', 'Power BI', 'Performance Management', 'Credit Risk']"
"Senior Analyst, Data Engineering",78 AMOY STREET 069897,"Permanent, Full Time",Executive,2 years exp,"Banking and Finance, Consulting",Monthly,"$5,000to$10,000","Responsibilities:

Work with clients to solve business problems in fraud, compliance and financial crime and present project results
Manage, transform, and cleanse high volume data
Automate data processing to enable on-going alerts on high-risk activity
Work very closely with data scientists to ensure efficient and effective delivery of solutions
Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients on their sites
Use emerging and open-source technologies such as Spark, Hadoop, and Scala
Collaborate on scalability issues involving access to massive amounts of data and information

What we’re looking for:

At least 2 years of experience working in the Financial Services sector on big data project implementations
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines
Strong coding experience in the likes of Scala or Java
Coding experience using Python
Client facing experience, good communication and presentation skills
Bachelor’s Degree in Computer Science, Physics, Mathematics, or similar degree or equivalent
Enthusiasm to learn and develop emerging technologies and techniques
Strong technical communication skills with demonstrable experience of working in rapidly changing client environments
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies

It’s a bonus if you have:

A background in AML, KYC, screening, regulatory compliance or fraud is highly advantageous
Have worked on a variety of complex data orientated projects for financial services clients
Have a good understanding of computer science and preferable come from a software engineering background or other scientific degree incorporating IT modules (e.g., Math/Physics)
Have exposure to Agile, especially SCRUM
Ability and willingness to travel
Experience working with a variety of modern development tooling (e.g., Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g., Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting)
Have an excellent appreciation of what makes a high quality, operationally stable system and how to streamline all areas of development, release and operations to achieve this

Benefits

Snacks & Drinks
Health Insurance
Robust Career Path
Academy Program with Buddy-Mentor

WE

Want to transform what banking means with you!
Are inclusive and diverse
Are committed to creating a flexible, supportive work environment that helps you effectively manage your work and family commitments
Embrace innovate-thinking and entrepreneurship in everything we do
Are award winning and known for our commitment to outcomes
Apply the latest tech and new ways of working
Support your personal growth
","['Git', 'MASSIVE', 'Scalability', 'Scala', 'Big Data', 'Pipelines', 'Hadoop', 'Mathematics', 'Software Engineering', 'Scripting', 'ETL', 'Open Source', 'Python', 'Fraud', 'Docker', 'Java']"
Big Data Developer,"GB BUILDING, 143 CECIL STREET 069542","Contract, Full Time",Senior Management,5 years exp,Information Technology,Monthly,"$6,500to$8,000","
Strong experience in Big Data development using Hadoop, Hive, Spark and Scala, Unix, SQL
Involve in the design, development, testing, deployment of efficient and reliable big data processing workflows
Responsible for implementing and maintaining complex big data projects with a focus on collecting, parsing, managing, and analysing large sets of data to turn information into insights using multiple platforms
Deliver detailed documentation and ensure quality throughout project lifecycle
Mininum 5 years of working experience
Good written and oral communication skills.


","['TDD', 'Oral Communication Skills', 'Scala', 'Big Data', 'Hadoop', 'Unix', 'JUnit', 'SQL', 'Python', 'Writing', 'Banking', 'Performance Tuning', 'Java', 'Apache', 'Databases', 'Software Development']"
IT Executive (Data Administration),"SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623","Permanent, Full Time",Executive,1 year exp,"Admin / Secretarial, Engineering, Information Technology",Monthly,"$2,800to$3,500","Company’s profile
Julian Grey’s client is a well-established elevator engineering Japanese MNC with 50 years’ presence in Singapore. The company is established globally & looking for passionate & dedicated individuals to join their rapidly expanding team.

Work location: West
Working hours: Mon - Fri, 8.30am – 5.45pm

Job Responsibilities

Assist in the planning, organising / leading and controlling of the Information System department
Assist in the development and maintainence of IT based systems, activities and resources
Liaise with users and other support departments, identify and evaluate appropriate IT Tools and techniques
Assist to prepare IS Section Monthly Report and section term budget
Assist to establish and enforce policies and procedures for corporate data management
Initiate and drive continual improvement activity and promote IT Application for work process improvement


Requirements

Educational qualification in IT or equivalent
Working experience with IT data administration / database management
Experience with SAP would be an added advantage
Able to work independently
Good communication skills in English and problem solver


Follow us for more updates, interview tips!
https://www.instagram.com/juliangreygroup/
https://www.linkedin.com/company/juliangreygroup/
https://www.facebook.com/juliangreygroup/
Our telegram channel for job opportunities - https://t.me/jobopportunitiessg

Cassie Chan
Reg No. R2197426
Julian Grey Corporate Advisory Pte. Ltd.
EA License No: 19C9568","['business information systems', 'Microsoft Excel', '.NET', 'Customer Information System', 'Big Data', 'Information Systems', 'Computer Information Systems', 'Data Management', 'Database Management Library', 'Customer Information Systems', 'Information Technology', 'SAP', 'Database Management System', 'System Administration', 'Database Management', 'Administrative Support', 'Data Bases', 'MS Excel Pivot Tables', 'Databases', 'Data']"
 , , , , , , , , , 
Data Scientist,"REPUBLIC PLAZA, 9 RAFFLES PLACE 048619","Permanent, Full Time",Manager,3 years exp,"Engineering, Information Technology",Monthly,"$6,000to$9,000","COMPANY BACKGROUND
Haier is the number one brand of Major Appliances in the world with 9.7 percent of global market share. Headquartered in Qingdao, Haier has over 80,000 employees across 30 countries in the world.
Haier Singapore is one of the holding companies under Haier Group. As the integrated regional centre, Haier Singapore is the main platform to provide procurement, trading, R&D and big data supports to over 80 countries in Asia, Europe, Africa and North America markets.
As the continuous demands from global businesses, we are looking for passionate and creative Data Scientist to join our big data team.
KEY RESPONSIBILITIES
Based in Singapore, you will be part of the global big data team and provide data analysis support to Haier businesses in the world.

Execute research and analytics, including data sources identification, processing, model/algorithm development, turning insights into actionable recommendation, presenting actionable recommendation and drive actions to business value creation.
Mentor junior data scientists and data analyst.
Participate in and lead advanced analytic capability building program.
Be creative problem-solver using Big Data, Machine Learning and other advanced analytics skill alongside leadership and direct engagement of business users.
Design research and analytic frameworks in the context of overall project objectives such as (but not limited to) media effectiveness, consumer engagement, business model optimization, etc.
Collaborate actively and effectively with other functions partners and leaders to accomplish project objectives.

KEY REQUIREMENTS
The ideal candidate should possess:

Have more than 2 years’ experience for data scientist.
Master degree and above, major Engineering, Math, Statistics, Computer Science or similar field focused on quantitative methods.
Demonstrated skills for data mining, machine learning, text analytics or streaming data
Demonstrated leadership and strong analytics skills in applying techniques to deliver actionable insights from data. Has a passion for solving unstructured business problems through analytics.
Demonstrated strong learning capability on new business knowledge, business processes, analytics tools/techniques and methods.
Strong written and verbal communication skills to influence business partners to turn insights into actions.
Demonstrated ability to collaborate within teams.
Demonstrated ability to handle multiple priorities.
Knowledge of Hadoop (Cloudera distribution), Hive / Impala, Spark, Python, R, SAS, Greenplum is a plus.
","['Machine Learning', 'market share', 'Data analyses', 'Data Analysis', 'platform', 'Big Data', 'Hadoop', 'passionate', 'Data Mining', 'Python', 'Statistics', 'Java', 'R', 'Trading', 'Ability to work creatively', 'Data']"
 , , , , , , , , , 
Senior System Analyst (Data Engineering),"THE OCTAGON, 105 CECIL STREET 069534",Full Time,Professional,7 years exp,Information Technology,Monthly,"$5,500to$7,000","We are representing our client (an established leading Hospital Group) looking for a Senior System Analyst to analyse data requirement in new system, perform data mapping from old system to new  system, standardization, migration, testing as well as validation and verification.

Responsibilities:

Define roadmap to transform data architecture focusing on scalability, performance and  flexibility throughout the entire data life cycle (ingestion, storage and consumption). 
Maintain data architecture framework, standards and principles including modelling,  metadata, security, master and reference data. 
Define reference architecture as a set of patterns that can leveraged by diverse parts of  the direction to create and improve data systems. 
Lead architectural designs solution context diagram and conceptual data model to  optimize security, information leverage and reuse, integration, performance, and  availability and ensure solutions developed adhere and aligns to the delivered  architecture. 
Work with Data Migration Lead and Overseas Partner to influence application teams  regarding solutions. 
Collaborate with internal IT and business teams to design and implement effective  technology solutions, while using innovative business and technology processes to  identify and implement improvement initiatives, eliminate redundancies, and maximize  the reuse of data. 
Work closely with Solutioning, Infrastructure and project teams to understand their  needs and ensure the best data architecture is implemented. 
Provide training and share best practices across teams regarding data architecture  design and solution implementation including review and quality assurance. 
Develop and apply industry best practice technology, design and methodology  approaches. 
Research and recommend new emerging technologies, techniques and tools that will  add value to the organisation.

Requirements:

Bachelor's Degree in Computer Science or related discipline.
Minimum 7 years of experience designing and building high performance resilient data  architectures. 
Strong experience with traditional data technologies (ODS, Data Lake, Data Warehouse). 
Strong experience with Structured Query Language, Stored Procedures, Constraints and  Indexes on both MS SQL and Oracle databases. 
Experience in designing data patterns to support micro-service based application  architecture. 
Track record of successfully building container-based big data architectures on top of  Kubernetes. 
Experience in designing systems to efficiently handle real-time and batch use-cases. 
Exposure and understanding in the latest open source technologies across the big data  ecosystem, such as distributed storage, real-time event processing and large scale  distributed OLAP engines. 
Exposure to Data as a Service concepts and data virtualization. 
Working knowledge of data science processes and best practices, with experience in  building scalable architectures through the use of data science workflow orchestrators. 
Hands on experience on DevOps / DataOps / MLOps concepts. 12) Experience in 2 or more Healthcare systems like SCM, Cerner, SRIS or Merlin is  preferred. 
Experience in HL7 standard messages and eLink are an added advantage. 
Ability to articulate thoughts and workflows clearly in both writing and speech is  essential.  
Ability to work under tight schedule and independently is preferred

","['Application Architecture', 'Scalability', 'Kubernetes', 'Oracle', 'Big Data', 'Quality Assurance', 'Healthcare', 'SQL', 'Data Migration', 'Architecture Design', 'Data Architecture', 'OLAP', 'Metadata', 'Articulate', 'Databases', 'Virtualization']"
SEA Data Analysis Lead,1 RAFFLES QUAY 048583,Full Time,Manager,7 years exp,Information Technology,Monthly,"$20,000to$39,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us:
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Data Science team of e-commerce is aiming to provide valuable business insights to the partner teams, including operations, product manager, etc. The business is still expanding globally, and we do wants to get the talented DS/DA/DPMs to join us to make impact together!

What You'll Do:
• Responsible for data analysis for TikTok e-commerce's global business products independently, including merchant product, creator product, etc.; and data analysis of e-commerce operation strategy including Merchant Strategy, Creator Strategy, etc.
• Measure performance of each e-commerce product across countries and regions, and provide product optimization suggestions
• Design the event tracking system for each module of global e-commerce products, verify the accuracy of event tracking system after release, and maintain the event tracking system and specifications in subsequent versions
• Describe the situation of business, explain the fluctuations of business and provide valuable suggestions with reports
• Design the monitoring systems independently to reflect any changes of business in time
• Design A/B test, and give the optimal product design scheme according to the data performance after launch
• Follow up the data analysis of local operation teams in several markets across countries and regions, support the operation effect and give the follow-up optimization suggestions
• Cooperate with PM/Ops/R&D teams to promote the implementation of optimization scheme, and to bring about the actual improvement and growth of business
• Cooperate with R&D and Data PM to build data systems and user-friendly data products to support business

Qualification:
• Bachelor degree or above, major in mathematics, statistics, computer science is preferred; or major in science or engineering or engaged in data statistics, analysis, modeling related working areas after graduation
• At least 7 years of working experience in data science track, and have a good business sense in e-commerce; product analysis is preferred
• At least 3 years of people management experience required
• Proficient in SQL/Hive/Python or R，experienced in massive data manipulation, machine learning & modeling
• Solid technical & knowledge of A/B testing methodologies, can consistently explore and find the best practice
• Insightful data sense and rigorous logical mindset, capable of providing systematic approachs to solve business problems
• Global working experience or analytical experience is preferred
• Written and verbal English skills are required for daily communications with global teams
• Have a strong learning ability and curiosity; familiar with starting a new business; able to lead a team to support business
• Have a strong ability to work under pressure, have the courage to overcome difficulties, and accept challenges

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Tableau', 'Machine Learning', 'MASSIVE', 'Data Analysis', 'Product Design', 'Modeling', 'Mathematics', 'SQL', 'Product Optimization', 'Statistics', 'Data Science', 'Ab Testing', 'People Management Experience', 'Data Visualization', 'Product Analysis']"
JUNIOR DATA ANALYST,1 GREENWICH DRIVE 533865,"Permanent, Full Time",Junior Executive,2 years exp,"Information Technology, Logistics / Supply Chain",Monthly,"$3,200to$6,000","About Us
Are you a motivated, organized person seeking an exciting and rewarding opening in a fast-paced environment?  Would you enjoy being part of a committed team that works together to create a relevant, important difference in the lives of our customers and employees?  If you're looking for change, and you're ready to make changes … we're looking for you.
The Service Logistics Center of Excellence (CoE) is a lean team of highly motivated individuals across the globe, focusing on business initiatives that will enable delivery of the SL strategic objectives.  The CoE will always be forward looking, constantly identifying how best practices and innovation can be brought into the SL way of working.  The team leads and sets the agenda for product development/digitalization, business solutions and analytics for Service Logistics globally.
To support our strategic digitalization and growth plans, Service Logistics has a lean dedicated analytics team within the CoE. This global analytics team is responsible for supporting overall Service Logistics analytics needs. This spans the definition, creation, deployment and adoption of analytics solutions. The team is composed of core members as well as hybrid team members residing in various SL functions & regions plus the extended DPDHL analytics community.
Job Responsibilities
Role of Junior Data Analyst will support projects with data reporting, building dashboards such as PowerBI & providing business intelligence in line with overall business strategy, objectives and needs, Group guidelines and policies.
The key responsibilities in this role include:
· Gather and analyse business intelligence data from different sources to inform business and to support decisions

Apply mathematics and statistics to discover patterns and knowledge      in recorded data
Support the definition of project contents, deliverables and      timelines of data analytics projects, usually of a descriptive or      diagnostic nature
Support predictive / prescriptive data analytics use cases through      data preparation and basic programming (mapping, cleansing, exploratory      analysis) and feature engineering
Build data models, analyses, and dashboards e.g., in Power BI
Support the development of analytics product prototypes and user front      ends (e.g. in PowerBI) for (executive) decision makers
Provide content requirements for data architecture required to      support analytics use cases

You won’t find another job like the one you’ll find with DHL Supply Chain.
Job Requirements
Now here's what we need from you:

Bachelor      of arts/Bachelor of Science degree in a relevant field, such as supply      chain management, analytics, economics or business administration.
2 years      of relevant work experience.
Experience      in data analysis/cleansing/visualisation, PowerBI, SQL, Python(preferable)
Excellent      oral and written communication skills

What you'll need to do next?
If you have a proven track record of achievement to match the requirements for this role and you are looking for your next career move, simply apply online ensuring that a full up to date CV is attached with your application.
We will ensure that all our resourcing activities are fair, transparent and consistent across the Globe. We want to ensure that the candidate experience is of the highest professional standard.
The Company is committed to providing equality of opportunity for all employees. Furthermore, we aim to ensure our workplaces are free from discrimination and that not only employees but also our potential future employees are treated fairly and with dignity and respect. We will ensure that equality of opportunity maintains a high profile in our organisation.","['Business Intelligence', 'Dashboard', 'Labels', 'Data Modeling', 'data cleansing', 'Mathematics', 'Agile', 'Economics', 'Business Strategy', 'SQL', 'Python', 'Data Architecture', 'Communication Skills', 'Supply Chain Management', 'Statistics', 'Data Analytics', 'Power BI', 'Data Visualization']"
Senior Data Product Manager,306 TANGLIN ROAD 247973,Full Time,Senior Executive,4 years exp,"Architecture / Interior Design, Information Technology",Monthly,"$9,000to$14,000","This position will be  responsible for leading the definition and delivery of new client-facing  global data products such as the data & integration platform and  its related applications.
Responsibilities

Lead the definition,  design and delivery of new customer-facing global data products within  Saltmine and related applications, reporting directly to the Director of  Product management.
Work with Data  scientists & engineering in Agile scrum teams on design, definition,  documentation and implementation of features for new applications,  business infrastructure, data security, and data structure
Document and enter user stories in Jira and assist in story point analyses
Document monitor and  revise the following artifacts in support of application development:  product requirements, process maps, use cases, user acceptance test  plans, project plans, and release notes.
Assist in preparing and maintaining the product roadmap which defines product enhancements for short- and long-term releases
Collect and analyze data to determine product direction and define business requirements.
Coordinate and participate in user acceptance testing of functional requirements.
Serve as the internal  and external subject matter expert for product offerings, working with  Sales, Product Marketing and Customer Support groups
Serve as first line in assisting Technology in the resolution of issues and roadblocks hindering product delivery.
Assist in creating  product training and documentation materials in support of the  implementation and launch of Analytics Platform applications.
Assist in developing product pricing and positioning strategies
Conduct research to identify customer needs and market gaps

Qualifications

Bachelor's Degree, Computer Science or Engineering preferred. MBA a plus.
4-5 years experience in product development and building data focused, web-based business applications
Strong data analytics  background with a demonstrated ability to translate business needs into  creative and engaging output. Working knowledge of business  intelligence/reporting tools with related experience analyzing data as  well as writing queries and reports.
Proficiency with software development methodologies such as Agile and experience working with Scrum teams
Experience with Agile software development tools such as Jira or other Agile reporting tools
Demonstrated  capabilities in technical-oriented business analysis techniques and user  acceptance testing processes/methodologies in large, complex,  diversified, global organizations.
Recent involvement in the day-to-day tasks of the user acceptance testing process.
Ability to interpret requirement documents and update test documents accordingly.
Aptitude for understanding, digesting and analyzing complex systems integration.
Excellent  communications skills, both oral and written. Must be able to  communicate effectively and confidently with users, team members and  management.
Must be flexible and willing to undertake a wide variety of challenging tasks.
Ability to work some flexible hours due to varying time zones across Saltmine’s regions.
","['Product Marketing', 'Customer Support', 'Customerfacing', 'Scrum', 'User Stories', 'Business Analysis', 'Agile', 'Application Development', 'Product Management', 'JIRA', 'Product Development', 'Data Analytics', 'Pricing', 'Agile Software Development', 'Software Development', 'Business Requirements']"
Head of Data (Transportation),205 BRADDELL ROAD 579701,Permanent,Manager,1 year exp,"Engineering, Information Technology, Others",Monthly,"$8,000to$16,000","Job Description
As Head of Data, you are responsible for leading the strategy, prioritization, development, and delivery of business objectives that leverages on data. You will apply industry best-practices and approaches, and further customize the practices to deliver innovative data-centered advantages that allow ComfortDelgro Private Mobility Group (PMG) to outpace competitors.

As Head of Data you will

Apply your expertise in data science, statistical analysis, data mining and the visualization of data to derive insights that value-add to business decision making (e.g. hypothesis testing, development of MVPs, prototyping etc)
Work with stakeholders from different functions of PMG to architect and design analytics solution to meet business objectives
Develop an enterprise data science strategy to achieve scale, synergies and sustainability of model deployment across data team
Conduct analysis and cultivate on continuous improvement programmes to improve on quality, productivity and delivery
Undertake rigorous analyses of business problems on structured and unstructured data with advanced quantitative techniques
Building and developing data models, data automation systems, performance metrics, and reporting systems
Develop and train predictive / ML models using a diversity of machine learning tools and frameworks
Overseeing the delivery of insights and reports used for analyzing business functions and performance metrics
Provide strategic leadership and technical knowledge to data team


Requirements:

Master Degree and/or Degree in Computer Science, Data Analytics, Statistics or equivalent
10 years’ experience in quantitative analysis and data science (machine learning / predictive modelling) with at least 3 years of leadership / people management experience
Deep expertise in a range of ML concepts, frameworks and techniques such as logistic regression, clustering, dimensionality reduction, recommendation systems, neural nets etc.
Strong understanding of data infrastructure technologies (e.g. Spark, TensorFlow etc)
Familiar with data engineering methodologies, including SQL, ETL and experience in manipulating data sets with structured and unstructured data using Hadoop, AWS or other big data platforms
Proficient in data visualization and the use of dashboarding tools (e.g. Tableau, Power BI)
Experience with development or delivery of products and solutions with a focus on data driven systems
Experience with development of Data Models
Strong analytical and problem-solving skills
High energy and motivated team player
Able to effectively work across functions and teams to drive projects and key initiatives to completion
","['Tableau', 'TensorFlow', 'Machine Learning', 'Sustainability', 'Data Analysis', 'Logistic Regression', 'Big Data', 'Architect', 'Hadoop', 'Data Management', 'Data Engineering', 'SQL', 'Data Architecture', 'Statistics', 'Data Science', 'Decision Making', 'Data Analytics', 'People Management Experience', 'Data Visualization']"
Junior Data Engineer,"SGX CENTRE II, 4 SHENTON WAY 068807",Contract,Junior Executive,1 year exp,Information Technology,Monthly,"$2,250to$4,500","Responsibilities:

Understanding of complex data analysis and modeling to ensure project teams and clients can successfully extract value from their data
Support hypothesis generation and testing, exploratory analysis, data preparation for statistical modelling/machine learning/deep learning, building machine learning or deep learning models and model interpretations.

Qualifications:

Atleast 1 yr. relevant experience
Practical experience in Microsoft Power BI and SQL
Proficiency and demonstrated experience in working with data sets
Ability to abstract information requirements from real-world processes to understand the information flows
Excellent writing and presentation skills
Team player and can work in a multicultural work environment

EA License No 11C4879","['Machine Learning', 'Scalability', 'Data Analysis', 'Modeling', 'Data Transformation', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Writing', 'Presentation Skills', 'Data Science', 'Microsoft Power BI', 'Java', 'Data Analytics', 'Databases']"
Reporting & Data Analytics Manager,"SGX CENTRE II, 4 SHENTON WAY 068807","Permanent, Full Time",Manager,7 years exp,"Banking and Finance, Insurance",Monthly,"$5,700to$11,400","Singlife is a leading homegrown financial services company, offering consumers a better way to financial freedom. Through innovative, technology-enabled solutions and a wide range of products and services, Singlife provides consumers control over their financial wellbeing at every stage of their lives. In addition to a comprehensive suite of insurance plans, employee benefits, partnerships with Financial Advisor channels and bancassurance, Singlife with Aviva offers investment solutions through its dollarDEX and Navigator platforms.

The mobile-first Singlife Account – with a Singlife Debit Card – allows customers to save, spend, earn and be insured all in one app. Singlife with Aviva was formed by the merger of Aviva Singapore and Singlife. First announced in September 2020 and valued at S$3.2 billion, it was the largest insurance deal in Singapore at the time and created one of the largest homegrown financial services companies in the republic.

Purpose of the role
The Reporting and Data Analytics Manager (RDAM) will develop and maintain the highest levels of data competency, performance reporting and data analytics capacity across the businesses that the Shared Services supports.

Key Responsibilities

Manages overall data architecture and manages, develops, prioritizes and recommends initiatives to improve and build upon the data architecture to support the business
Ensures regular management reports on key performance drivers of the sales channels. (eg: Monthly MI reporting, Daily Sales Report) are delivered on time and accurately
Collaborate with Sales team to provide insights that will help develop superior incentive schemes and monitoring progress thereof
Perform complex analysis and modeling for segment by multiple products for GTM activities, with the goal of maximizing revenue, market share and minimizing risk
Use advanced analytics techniques and models, including statistical models to drive business decisions and impact
Proactively look for new innovative ways to better understand our customers needs and behaviours to drive actionable insights
Continuously look at how we can enrich our data to create new segments and potential target groups

Team
Works with at least two other Reporting executives. Train and develop the reporting executives in data analytics competency.

Requirements

Degree in Statistics, Mathematics, Economics or similar field with at least 7 years of data science and analytical work experience in a related role, ideally 3+ in the financial services sector
Advanced proficiency in Microsoft Excel and data programming tools like Python, R, SQL etc
Experience utilising Visualisation tools – Tableau and PowerBI and strong ability to build powerful dashboards
Quantitative and comfortable working with large amounts of data
A self-starter with strong analytical skills with an eye for impactful business insights.
Demonstrated ability to convert data driven recommendations into business actions and results

If you find yourself able to demonstrate the criteria above, apply with us now. We look forward to your application.","['Tableau', 'Microsoft Excel', 'R Programming', 'Analytical Skills', 'Modeling', 'Economics', 'PowerBI', 'SQL', 'Python', 'Team Management', 'Data Architecture', 'Statistics', 'Reporting', 'Data Science', 'Data Analytics']"
Data Strategy Product Manager,"LAZADA ONE, 51 BRAS BASAH ROAD 189554",Full Time,Manager,2 years exp,Information Technology,Monthly,"$6,000to$8,000","Responsibilities:
-	As a core strategic planner and decision maker, you should be able to understand business requirements on an industry level, assessing how to boost Customer Retention and Profitability so as to further solidify the position daraz holds in E-commerce 

-	You are expected to be a smart, fast and experienced player who can easily understand business logics, relate them it to a specific kind of data product to develop: Dashboards with actionable Methodologies, Alibaba Algorithms, Data Analysis, Pipeline Integrations, Realtime Data Layer upgrades and cluster migrations etc. You are one of the main leaders to set up company data strategies, consolidate the whole year data roadmap, and bridge business teams to your DA/DE/DS team to clearly know what they need to do

-	You are responsible for E2E project lifecycle. Ensuring the user cases and business impacts of the data product are validated, as well as optimal data product visualization design. 

-	You should be able to identify and present a Strategic view of where we currently stand, where we are lacking and finally what actions to prioritize to maximize value and results. 

-	Excellent speech, documentation, excel and PPT reporting skills as you will frequently touch base with C level leaders and core managers throughout the company.

-	You are required to have insights on the competitive landscape including offline and online players as to how they are acquiring and growing sellers and products to derive your opinions in the domain.

-	You would need to exercise excellent analytical and problem-solving skills to generate insights and deliver tools catering to business needs. Also, being able to present product mockup and usage strategies of your product. 

-	Being pro-active in introducing and executing great ideas and innovations to achieve the domain KPIs","['Tableau', 'Tactics', 'Data Analysis', 'Localization', 'Modeling', 'Physics', 'Mathematics', 'Quantitative Analysis', 'Planner', 'Visualization', 'Bridge', 'Business Requirements']"
 , , , , , , , , , 
Data Centre Engineer,"SUNTEC TOWER FOUR, 6 TEMASEK BOULEVARD 038986",Full Time,Professional,3 years exp,Information Technology,Monthly,"$3,000to$5,000","Job Description
Kerry Interim is partnering with a large information technology company to hire a Data Centre Engineer that is experienced in managing the varied requirements coming from the Data Centre.
This role will include the management of the Data Centre’s surveillance system, physical access and control, as well as the space, power and IT inventories. Taking this role, you should be able to define a control process to ensure the team follows suit to upkeep the Data Centre management and manage the Data Centre M&E installation, and incidents and provide updates to management.

Responsibilities
You will be responsible for working closely with respective personnel to ensure the proper upkeep and regular maintenance is performed for Data Centres and ensure Data Centre compliance to all respective country regulatory requirements. You will also produce monthly capacity reports of Data Centre's overall facility and plan for the Data Centre budget
This role will be in a rostered 24x7 response environment and involves travelling overseas for regional support when needed.

Skills and experience required:

Min Diploma or a Degree in IT or related discipline with 2 years of hands-on experience in providing first-line support
You must have the ability to effectively collaborate with team members and think creatively to deliver continuous solutions
You are open to working in a 24x7 support environment

Please apply via the apply button and send us your application in a word format to Nav at navneet@kerryinterim.com

Reg: R1104798 Lic: R1109259","['Troubleshooting', 'Hardware', 'Change Management', 'Data Center', 'HVAC', 'Information Technology', 'Surveillance', 'Compliance', 'Power Distribution', 'Routers', 'Consulting', 'ITIL', 'Cabling', 'Regulatory Requirements', 'Incident Management', 'Facilities Management']"
 , , , , , , , , , 
Director of Data & Analytics,"SUNTEC TOWER ONE, 7 TEMASEK BOULEVARD 038987","Permanent, Full Time",Middle Management,5 years exp,Information Technology,Monthly,"$9,000to$12,000","The Role
Your Responsibilities will include:

Design and build the data warehouse, data pipeline.
Understand the e-commerce metrics to generate meaning insights.
Manage date pipelining and warehousing - Work with engineering to create ETLs and unify multiple data sources (Shopify, paid marketing platforms, Appsflyer, Insider, etc.) into a single source of truth data warehouse.
Champion a data culture - Build a scalable event tracking taxonomy so that our data visualization platform (Mixpanel) can be leveraged by every department at the company.
Lead business intelligence - Define what metrics should be considered true north for our business and is comfortable building reports for executives and investors.
Create the data stack - Decide what tools and services should serve as the backbone for data at the company and own vendor relationships.


Ideal Profile
Skills Required:

At least 5-8 years’ experience working in data architecture, data engineering, data product management, or in data analytics.
Able to work closely with engineers and clearly specify requirements.
Able to map the flow of data from data ingestion (event tracking with GA4, Shopify), data warehousing (BigQuery, MySQL), and data visualization (Data Studio, Mixpanel).
Someone who is willing to initially dive in as an individual contributor, but in time, can scale and hire a team of data analysts and data engineers.
Strong communicator - can equally communicate with engineers as well as explain technical concepts to non-technical stakeholders.
Added advantage if you have experience in specific to e-commerce.
Proficiency in Mandarin / Cantonese in order to be able to effectively liaise with stakeholders in the region.


What's on Offer?

Well Established E-Commerce MNC!
Basic Salary Up to $12,000!
Entitle to Performance Bonus!
Employee Stock Option Plan is Offered!
Work From Home Arrangements!
Outpatient and Dental Insurance Coverage Provided!


About us
Career x Talent Solutions (Pte. Ltd.) is a workforce solutions provider with the key aim of conducting value-based recruitment activities to our business partners in forms of regular and flexible staffing.
We partner with our business partners from start to finish, focusing on their needs developing effective strategies and designing high quality and scalable solutions with the aim to deliver long-term sustainable results through our vast knowledge and experience of our Consultants.

Ref: HIH1W2PC2C

Apply to this role by submitting your CV and completing you profile at https://career3.snaphunt.com/job/HIH1W2PC2C","['Vendor Relationships', 'Warehousing', 'Business Intelligence', 'Taxonomy', 'Hadoop', 'MySQL', 'ETL', 'Cantonese', 'Data Engineering', 'Product Management', 'Finish', 'Data Architecture', 'Data Science', 'Data Analytics', 'Data Warehousing', 'Data Visualization']"
 , , , , , , , , , 
Data Centre Engineer,"SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623",Permanent,Non-executive,4 years exp,Engineering,Monthly,"$2,500to$5,000","about the company
My client is a real estate investment trust that invests in carrier-neutral data centers and provides colocation and peering services. With more than 15 years history, this is a great brand to join at an exciting time in their development.
about the job

Maintaining all building systems and mission critical facilities equipment with the raised floor environment
Conducting routine, ongoing assessment of the building systems operations
Ensure the equipment are functioning by performing tests and rounds, and analyzing data
Ensuring efficient operation of building system & performing preventive maintenance on building equipment
Coordinating maintenance efforts, as needed, with outside contractors, tenant finish personnel and engineers
Assisting in inventory control programs / purchasing parts and supplies.
Responding to emergency situations and customer concerns

skills & experience required

Degree / Diploma / NITEC / O Level
Min 4 years’ experience in mission critical facilities operating / engineering
Knowledge in AutoCAD is a plus
Ability to troubleshoot and repair equipment and systems
Able to travel to work in east side (Loyang, Defu, Changi Alps)

If you are interested in the position , kindly send your CVs in to amy.leo@randstad.com.sg
Please include your availability, expected salary and reason for leaving your current job.
We regret that only shortlisted candidates will be contacted.

EA: 94C3609 / Reg: R22105802

Applicants must be fully vaccinated or have a valid exemption in accordance with MOM’s regulations to allow them to enter the workplace. Applicants may be required to share verifiable COVID-19 vaccination documents or proof of a valid exemption at the point of offer. Randstad Pte. Limited and/or the Client reserves the right to withdraw an offer if the applicant fails to provide verifiable COVID-19 vaccination and/or proof of exemption documents","['Switches', 'Preventive Maintenance', 'Reserves', 'Hardware', 'Data Center', 'Purchasing', 'Tenant', 'Inventory Control', 'Finish', 'Power Distribution', 'AutoCAD', 'Routers', 'Cabling', 'Real Estate', 'Facilities Management']"
 , , , , , , , , , 
Data Analysis Manager,1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$8,000to$15,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Data Science team of e-commerce is aiming to provide valuable business insights to the partner teams, including operations, product manager, etc. The business is still expanding globally, and we do wants to get the talented DS/DA/DPMs to join us to make impact together!

Responsibilities:

Responsible for data analysis for TikTok e-commerce's global business products independently, including merchant product, creator product, etc.; and data analysis of e-commerce overseas operation strategy including Merchant Strategy, Creator Strategy, etc.
Measure performance of each e-commerce product in overseas countries, and provide product optimization suggestions;
Design the event tracking system for each module of global e-commerce products, verify the accuracy of event tracking system after release, and maintain the event tracking system and specifications in subsequent versions;
Describe the situation of business, explain the fluctuations of business and provide valuable suggestions with reports.
Design the monitoring systems independently to reflect any changes of business in time.
Design A/B test, and give the optimal product design scheme according to the data performance after launch; 
Follow up the data analysis of local operation teams in several overseas markets, support the operation effect and give the follow-up optimization suggestions;
Cooperate with PM / Ops team / R&D to promote the implementation of optimization scheme, and to bring about the actual improvement and growth of business;
Cooperate with R&D and Data PM to build data systems and user-friendly data products to support business.


Qualifications

Bachelor degree or above, major in mathematics, statistics, computers is preferred; or major in science or engineering or engaged in data statistics, analysis, modeling related working areas after graduation;
Proficient in SQL and tableau and familiar with Python or R for data analysis.
At least 5 years of working Experience in data analysis, and have a good business sense in ecommerce product analysis is preferred;
Overseas working experience or analytical experience is preferred;
Able to complete English reports and communicate with global staff independently;
Have a strong learning ability and curiosity; ability to quickly pick up domain knowledge in new areas; Can lead a small project team to support business;
Have a strong ability to work under pressure, have the courage to overcome difficulties and accept challenges.


TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Product Design', 'Modeling', 'Financial Planning', 'Mathematics', 'Business Acumen', 'SQL', 'Product Optimization', 'Python', 'Financial Analysis', 'Statistics', 'Data Science', 'Product Analysis']"
Master Data Management Manager,"OXLEY BIZHUB, 67 UBI ROAD 1 408730",Full Time,Manager,2 years exp,"Information Technology, Professional Services",Monthly,"$3,500to$4,000","Job Description
CNCData seeks a Master Data Management Manager to join our team with a strong background with database management, marketing operation, database marketing solutions, CRM solutions to our direct corporate clients. The successful candidate will get excellent career advancement to grow to regional role.

Responsibilities

Involve in planning and scheduling of merging and consolidation of multiple data files from various data sources.
Standardize, format and code records according to our internal standards.
Formulates, implements and enforces proper data collection policies and procedures.
Perform logical check and data hygiene check constantly on existing data files and new data files.
Maintain and manage the master database within our internal data management platform.
Work closely with our internal project management teams (locally and regionally) to ensure accurate and relevant data files are used in all projects.
Establishes data quality standards and works with internal data management team to ensure standards are met at all time.
Performs and documents procedures for data collection, updating, cleansing, standardization and analysis.
Manage the day-to-day communication with project team and reporting with the management and ensure requests and queries are dealt with quickly and effectively.
Assist in other ad-hoc assignments.


Requirements:

Candidate must possess a Degree or Advanced Diploma in Computer Science, Information Technology or Data-related fields with 2 - 3 years of relevant experience
Candidates with prior working experience in Database Management, Database Marketing and Marketing have added advantage.
Strong experience and knowledge in data management platforms such as MS Excel, MS Access and/or MS SQL
Candidates must possess good analytical and logical thinking.
Strong commitment, responsibilities, organized and independent
Highly self-motivated, problems solving skill and is a good team player
Be able to work with tight schedules
Good written and oral communication skills in English is required
Able to work dynamic, under pressure and results oriented
Interested candidates who wish to apply are invited to submit a detailed resume in MS Word format with your most recent passport-size photograph, stating qualification and experience, present and expected salary, contact details to hr.sg@cncdata.co
Only shortlisted candidates will be notified
All applications are treated in strict confidence
","['Oral Communication Skills', 'Consolidation', 'Data Management', 'Data Quality', 'Data Governance', 'SQL', 'Project Management', 'Pressure', 'Team Player', 'Database Marketing', 'Scheduling', 'Master Data Management']"
Data Centre Engineer,"THE OCTAGON, 105 CECIL STREET 069534","Contract, Permanent",Executive,3 years exp,"Engineering, Information Technology",Monthly,"$3,500to$4,500","We are representing our client (An Engineering Firm) to look for a Data Centre Engineer to complement their existing team.  The Data Centre Engineer mainly provides data centre operations and monitoring service. He/She will be expected to have desktop support background to perform desktop support activities as well.

Responsibilities

Use data centre management tools to produce management information and investigate issues where necessary.
Carry out routine audit and checks
Assist in handling all day-to-day operational data centre monitoring activities.
Configuration for servers, networks and infrastructure-related equipment.
Support planned maintenance events and provide support to system and network administrators.
Perform regular backups and restores on a schedule and track offsite storage. Carry out documented configuration for allocation of storage, installation and maintenance of storage system.
Identify operational problems and contribute to their resolution. 
Use standard management and reporting tools to collect and report on storage utilisation, performance and backup statistics.
Perform desktop support roles

Requirements

Minimum Diploma in Information Technology or equivalent.
2 years of experience in data centre operations and DCIM tools and 3 years in desk top support
Experience in VMware, Linux, Windows, network appliances, systems/Active directory, SAN storage and system administration
Good communications and troubleshooting skills.
Job location in the west of Singapore
","['Switches', 'MacOS', 'Troubleshooting', 'Hardware', 'Data Center', 'VMware', 'Desktop Support', 'SAN', 'Information Technology', 'Reliability', 'Windows Server', 'Networking', 'Power Distribution', 'Windows', 'System Administration', 'Statistics', 'Routers', 'ITIL', 'Linux', 'Facilities Management']"
Master Data Executive,"SUNTEC TOWER FOUR, 6 TEMASEK BOULEVARD 038986",Full Time,Executive,1 year exp,Admin / Secretarial,Monthly,"$2,500to$2,800","Description
Kerry Interim is currently hiring a Master Data Executive on a contract term to work onsite with a retail company under the commercial department in supporting the master data team by ensuring the accuracy of data set up in promotion management. This role will be reporting to the Trade Planning Manager.

Responsibilities
This role is responsible for database maintenance to ensure timely and accurate SAP database maintenance of price and promotion. You will also be in charge of the promotion management to Ensure accurate and timely set up of promotions. Work closely with the category team and Group Business Admin to make sure that claims are accurately set up. Preparation of reports, ensuring accuracy, the integrity of data, and ad-hoc duties as assigned.

Skills and Experience Required
· Minimum Diploma in Business Administration or related discipline with at least 1 year of working experience.
· Proficient in MS Excel
· Sense of urgency to meet tight deadlines
· Meticulous and able to manage a large volume of data

To Apply
Should you be interested in learning more about the above opportunity, please kindly share your CV (quoting job title) Catrina at shiling@kerryinterim.com. We regret that only shortlisted candidates will be notified.

Reg: R22111113 Lic: 22C0942","['Recipes', 'SD', 'Business Continuity', 'Enterprise Risk Management', 'Consolidation', 'ERP', 'Problem Solving', 'Administration', 'Data Quality', 'Raw Materials', 'SAP', 'Publishing', 'Business Process', 'Stakeholder Management', 'Master Data Management', 'Mining']"
Data Engineering Architect,"SGX CENTRE II, 4 SHENTON WAY 068807",Full Time,Manager,6 years exp,Information Technology,Monthly,"$8,000to$12,000","Responsibilities

As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client.
Translate business requirements to technical solutions leveraging strong business acumen.
Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.
Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
Design and Build Modern Data Pipelines and Data Streams.
Design and Build Data Service APIs.
Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.
Implement effective metrics and monitoring processes.

Requirements 

Demonstrated experience of turning business use cases and requirements to technical solutions. 
Experience in business processing mapping of data and analytics solutions. 
Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows. 
The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.
Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. 
Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus.

EA Number: 11C4879","['Microsoft Azure', 'Factory', 'Azure', 'Big Data', 'Pipelines', 'T-SQL', 'Architect', 'Data Design', 'Data Engineering', 'SQL', 'Cloud', 'Visualization', 'Cataloging', 'API', 'Databases', 'SQL Azure', 'Business Requirements']"
Business / Data Analyst- E-Wallet,"SUNTEC TOWER TWO, 9 TEMASEK BOULEVARD 038989",Full Time,Professional,3 years exp,"Banking and Finance, Information Technology",Monthly,"$4,000to$6,500","Job Overview: We are seeking a talented and driven Business/Data Analyst to join our team and support the development and launch of our E-wallet product. The ideal candidate will have a strong background in data analysis and a passion for using data to inform business decisions.
Responsibilities:

Conduct market research and competitor analysis to inform product decisions
Analyze customer data to identify trends, patterns, and opportunities for growth
Collaborate with cross-functional teams including product management, engineering, and customer success to ensure data-driven decision making
Develop and maintain key performance indicators (KPIs) to track product performance and identify areas for improvement
Work with the product management team to define and prioritize product features based on customer data and feedback
Prepare data-driven reports and presentations for internal and external stakeholders
Participate in the development of data infrastructure and systems to support ongoing data analysis and reporting
Ensure the accuracy and integrity of data used in analysis and reporting

Requirements:

Bachelor's degree in a relevant field such as Business Administration, Economics, Computer Science, or a related field
3+ years of experience in business/data analysis, with a proven track record of using data to inform business decisions
Strong analytical skills and proficiency in data analysis tools such as Excel, SQL, and Power BI
Excellent communication and presentation skills
Ability to work effectively in a fast-paced and dynamic environment
Strong problem-solving skills and attention to detail

If you are interested in this opportunity, please submit your resume and a cover letter highlighting your relevant experience. We look forward to hearing from you!","['Tableau', 'Market Research', 'Microsoft Excel', 'Data Analysis', 'Analytical Skills', 'Customer Success', 'Administration', 'Economics', 'Product Management', 'SQL', 'Attention to Detail', 'Python', 'Presentation Skills', 'Decision Making', 'Data Analytics', 'Power BI']"
Head of Data,"THE CENTREPOINT, 176 ORCHARD ROAD 238843",Permanent,Senior Management,6 years exp,Information Technology,Monthly,"$6,500to$8,000","Roles & Responsibilities
As Head of Data, you will work closely with the CTO and other stakeholders to lead on strategy, development, and delivery of business objectives that leverage on data and software.
You will apply best practices while establishing and mentoring a strong analytics and data engineering team to innovate, consolidate, standardize, and give us a data-centred advantage in the industry.
You will be diligent in the market research as to provide insights and reports on the current, past, and potential future standings of Singapore’s real estate.

Specific Responsibilities:
● Apply your expertise in data science, statistical analysis, data crawling to bring value in company products and decisions
● Establish and maintain a data warehouse to support teams across the company and establish potential dataset products
● Build and develop data models, data automation systems, performance metrics, and reporting systems
● Develop and train ML models using a diversity of machine learning tools and frameworks

Requirements
● Established experience in the Singapore real estate market.
● Master Degree in Computer Science, Data Analytics, Statistics, Real Estate, or related field
● Basic understanding of Geographical Information Systems (GIS)
● Strong programming skills in common languages used for data engineering, ie Python, SQL, etc
● Deep knowledge of ML concepts, frameworks and techniques such as logistic regression, clustering, dimensionality reduction, recommendation systems, neural nets, etc
● Exceptional skills with data infrastructure technologies, such as Spark, Tensorflow, etc
● Familiar with data engineering methodologies, ETL and experience in manipulating datasets hosted on Hadoop, GCP, AWS etc
● Ability to work independently and as a contributing team player with good interpersonal and communication skills

Nice to Have
● Understanding of Geographical Information Systems (GIS)","['Market Research', 'TensorFlow', 'Mentoring', 'Machine Learning', 'Logistic Regression', 'Strategy Development', 'Ability To Work Independently', 'Hadoop', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Statistics', 'GCP', 'Data Science', 'Data Analytics']"
 , , , , , , , , , 
Data Engineer (Estate Solutions),"CITILINK WAREHOUSE COMPLEX, 102F PASIR PANJANG ROAD 118530",Permanent,Executive,3 years exp,"Building and Construction, Engineering, Information Technology, Real Estate / Property Management",Monthly,"$3,500to$7,000","Responsibilities:

Responsible for data analysis and generate reports for estate sub-system performance
Develop data set processes
Develop analytics programs, machine learning algorithms and statistical method, to make raw data useful for smart estate application
Identify ways to improve data reliability, efficiency and quality
Conduct research and explore for innovative solutions
Monitor compliance to project requirement, performance standards and specifications
Perform overall quality control of the work and report regularly on project status
Cooperate and communicate effectively with product development and operation team for implementation

Requirements:

Relevant Bachelor’s degree or equivalent in electrical/electronic engineering or computing
3+ years' related field and project planning experience
Excellent data science knowledge is required
Programming skill in Python and Java experience is required
Strong analytic skill is required
Knowledge in data management is required
Knowledge in ETL is preferred
Must have strong written and verbal communication skills
Able to work comfortably and independently in a fast-paced environment
","['Machine Learning', 'Data Analysis', 'ETL', 'Project Planning', 'Data set', 'Data Engineering', 'Project Management', 'Analytics', 'Python', 'Engineering', 'Statistical Analysis', 'system performance', 'Product Development', 'Java', 'Data Analytics', 'Software Development', 'Data']"
 , , , , , , , , , 
Big Data Technical Lead,"PARKVIEW SQUARE, 600 NORTH BRIDGE ROAD 188778",Full Time,Middle Management,7 years exp,"Consulting, Engineering",Monthly,"$14,000to$18,000","
Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 6 years, 10 locations and 550+ employees later we still believe that today. We connect the dots within our customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our customers, we are looking for a Technical Lead with a proven track record to join the Quantexa family. 🚀

What does a Technical Lead role at Quantexa look like?
In order to be a successful Technical Lead at Quantexa, you’ll need to be comfortable guiding and mentoring a team of engineers and dealing with both internal and external stakeholders. You will be responsible for a team tasked with managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime. We’re looking for hands-on technical leaders who are comfortable splitting their time between coding and managing the engineering team.

Being Agile is an integral part to the success we have at Quantexa and leading regular team sprints and Scrum meetings with your engineering team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our clients expectations and delivering a first-class service. 🥇

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion and Elasticsearch, with our platform being hosted on both private and public virtual clouds, such as Google cloud, Microsoft Azure and Amazon. Our primary language is written in Scala, but don’t worry If that’s not currently your strongest language, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Typical responsibilities include:

Leading a team and mentoring junior engineers.
Guiding team members through technical issues and challenges.
Ensuring that engineers are following best practices and standards.
Leading SCRUM ceremonies and fostering a collaborative and fun working environment that values high performance and continuous improvement.
Write defensive, fault tolerant and efficient code for data processing.
Automate data processing to enable on-going alerts on high-risk activity.
Participate in customer workshops and refinement sessions, presenting project results to clients both face to face and virtually.
Work very closely with data scientists to ensure efficient and effective delivery of solutions.
Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients, including on their sites.
Work with our expert software development team to produce reusable applications.
Use emerging and open-source technologies such as Spark, Hadoop, and Scala.
Collaborate on scalability issues involving access to massive amounts of data and information.
Take on ad-hoc tasks as required for the running of a small, yet rapidly expanding business.

What do I need to have?

Good time management and prioritisations skills to balance engineering, team management and customer facing responsibilities.
Good communication skills and experience working with different customers, partner organisations and cultures.
Proven big data experience, either from an implementation or a data science prospective.
Have an excellent appreciation of what makes a high quality, operationally stable system and how to streamline all areas of development, release, and operations to achieve this.
Arrive with experience at working with a variety of modern development tooling (e.g. Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g. Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting).
Excellent technical skills including hands-on knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
Experience with MVC frameworks such as AngularJS
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines.
Strong coding experience in the likes of Scala, Java, or Python.
Enthusiasm to learn and develop emerging technologies and techniques.
Exhibit strong technical communication skills with demonstrable experience of working in rapidly changing client environments.
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies.
Strong academic qualifications and come from a software engineering background or other scientific degree incorporating IT modules (e.g. Maths/Physics).
","['Mentoring', 'MVC', 'Git', 'Scalability', 'Scala', 'Scrum', 'AngularJS', 'Hadoop', 'Software Engineering', 'Agile', 'Scripting', 'ETL', 'Open Source', 'Good Communication Skills', 'Docker', 'Java', 'Software Development']"
Data Scientist - Neuroscience,"VISION EXCHANGE, 2 VENTURE DRIVE 608526",Full Time,Executive,3 years exp,Sciences / Laboratory / R&D,Monthly,"$4,000to$8,000","Job Summary:
Biofourmis is looking for smart and capable Data Scientist on our Data Science team to join our ranks. The ideal candidate should have the passion to use healthcare data and advanced machine learning techniques to build services to patients and caregivers. We are building an end-to-end service that integrates seamlessly into the lives of those patients via multiple touchpoints on front-end while providing intelligent analytics on the backend.
Responsibilities:

Analyse complex medical problems by referring to a patient’s history, examining them and conducting neurological tests.
Monitor the behavioral and cognitive side effects of treatment and medication; Interpret the results of neuroimaging studies.
Get involved in developing machine learning model to track patient sleep disorders, neuroimmunology, neuro-oncology, behavioral neurology and neurogenetics.
Documentation which clearly explains how algorithms have been implemented, verified and validated.

Experience / Training:

Hands on experience in monitoring the behavioral and cognitive side effects of treatment and medication; Hands on experience in interpret the results of neuroimaging studies.
Hands on experience in machine learning model to track patient sleep disorders, neuroimmunology, neuro-oncology, behavioral neurology and neurogenetics.

Education:

Master or PhD in Neuroscience or related fields with strong research ability and coding skills.

Skills:

Specialize in one part of the nervous system, such as neurotransmitters, or focus their research on specific behaviors, such as psychiatric disorders. Illnesses based in the nervous system include Alzheimer’s, Parkinson’s, multiple sclerosis, sleep disorder.
Hands on experience with Octave/ Python/ R
Have experience in physiological data (e.g. EEG /ECG/ PPG/ Accelerometer) or electronic health record (EHR) system.
Good research ability and critical thinking skills, publication on top journal is a bonus.
Excellent written and verbal communication skills.
","['Machine Learning', 'Octave', 'Neurology', 'Big Data', 'Treatment', 'Healthcare', 'Critical Thinking', 'Mathematics', 'Data Mining', 'SQL', 'Neuroscience', 'Python', 'Statistics', 'Data Science', 'Data Analytics']"
Data Product Manager,12 Marina Boulevard  018982,Contract,Executive,3 years exp,Information Technology,Monthly,"$8,000to$15,000","Job Description:

Familiar with data engineering and data warehousing fields. A data practitioner with proven experience delivering data-driven business solutions and process augmentation.
Familiar with agile processes and tools so that can understand and develop processes and tools to support the delivery life cycle.
Stakeholder Management – Conversant in Business terms and ability to resolve and explain data analytics issues with Business users and other concerned stakeholders


Job Requirements:

Degree in Computer Engineering, Computer Science, Mathematics, Software Engineering, or        equivalent fields.
Min 3~5 years of relevant data product management experience.
Experience in building data products with a demonstrated ability to drive product planning,        development, and launch.
Excellent interpersonal and communication skills, with the ability to manage different levels of stakeholders across the organization and navigate        through conflicts and differences competently and with ease;
Detail-oriented and analytical, with good problem-solving, organisational skills, and program management knowledge and experience.
Process-oriented, and able to translate complex problems into logical and repeatable processes        and diligently document the proposed technical solution.

EA Personnel: Celine Tan Si Ling
CEI Reg No: R1104662
EA Licence No: 99C4599","['Excellent Communication Skills', 'Computer Engineering', 'Analytical thinking', 'delivery of business solutions', 'Mathematics', 'Software Engineering', 'Agile', 'Data Engineering', 'Product Management', 'Stakeholder Management', 'Data Analytics', 'Data Warehousing']"
 , , , , , , , , , 
Business Intelligence Data Analyst,12 Marina Boulevard  018982,Contract,Executive,3 years exp,Information Technology,Monthly,"$8,000to$15,000","Job Description:
1. Research the different performance of users in the entire life cycle of the platform, conduct multi-dimensional hierarchical research on users through quantitative/qualitative analysis, build user portrait labels, and open them as basic capabilities to product/growth teams;
2. In-depth cooperation with product/growth teams to conduct special user portrait analysis for different projects/purposes;
3. According to the characteristics of platform users, research and analyze to formulate different growth strategies, and have the ability to promote the landing

Job Requirements:
1. Good experience in data analysis is required,   preferably dealing with big customer database and life cycle
2. Proficient in using SQL/Python/SPSS and other data analysis tools, with certain data modelling capabilities;
3. High data sensitivity, and can analyse data and provide solutions from the perspective of business optimisation;
4. Interested in the digital currency/blockchain industry, and have a deep level of participation;
5. Good communication skills, able to maintain good communication and collaboration with multiple teams;
6. Strong self-driven, with strong learning ability and curiosity.


EA Personnel: Celine Tan Si Ling
CEI Reg No: R1104662
EA Licence No: 99C4599","['Qualitative Analysis', 'Excellent Communication Skills', 'Business Intelligence', 'Growth Strategies', 'Data modelling', 'Data Analysis', 'Quantitative Analysis', 'SPSS', 'SQL', 'Python']"
"Operations Analyst II, Data Services (Client Data)","MILLENIA TOWER, 1 TEMASEK AVENUE 039192",Full Time,Executive,3 years exp,Banking and Finance,Monthly,"$5,100to$5,800","TD Bank Group
Headquartered in Toronto, Canada, with more than 90,000 employees around the world, the Toronto-Dominion Bank and its subsidiaries are collectively known as TD Bank Group (TD). TD offers a full range of financial products and services to over 27 million customers worldwide through three key business lines:

Canadian Retail including TD Canada Trust, Business Banking, TD Auto Finance (Canada), TD Wealth (Canada), TD Direct Investing and TD Insurance
U.S. Retail including TD Bank, America’s Most Convenient Bank, TD Auto Finance (U.S.), TD Wealth (U.S.) and TD’s investment in Schwab
Wholesale Banking including TD Securities

TD had CDN$1.9 trillion in assets on October 31, 2022. TD also ranks among the world’s leading online financial services firms, with more than 15 million active online and mobile customers. The Toronto-Dominion Bank trades on the Toronto and New York stock exchanges under the symbol ""TD"".
In Singapore, TD operates as The Toronto-Dominion Bank, Singapore Branch and Toronto Dominion (South East Asia) Limited, which are collectively known as “TD Singapore” since 1979. The key business in Singapore is TD Securities which is part of Wholesale Banking.
Department Overview:
Global Operations and Business Services is a diverse and dynamic group of individuals, whose varied talents and experiences enable us to provide critical infrastructure services that support and/or control the trading, investment, and corporate banking functions of TD Securities. We are committed to innovation with purpose, execution with excellence, and continually improving the employee value proposition. We foster a culture of diversity, inclusion, and community giving. Our dynamic team is divided into four main functional areas: Capital Markets, Financing Operations, Payment and Correspondent Banking Services and Business Services.
The Global Operations team partners with the front office and other groups globally to mitigate risk and deliver world class service to our global client base. They provide operational support and control functions across the trade lifecycle. The team is heavily involved in new product initiatives and process improvements to streamline our support model. They take great pride in ensuring controls are being continuously reviewed and updated while focusing on the customer at every point of contact.
If you are industrious, collaborative, innovative, and enjoy visionary thinking, while also maintaining a commercial view on the market, joining our team could be an ideal opportunity for you.
Role Details:
The Data Services team supports all business divisions located in Singapore (Foreign Exchange, International Fixed Income, Funding, Global Precious Metals, Trade Finance and Equity Derivatives), on a cross functional basis, by performing the setting up and handling of client data, credit lines, settlement instructions (SSI's), inventories and security data, and also the uploading and managing of market data. We play a key role in ensuring that the Global Data Control team, operate effectively, under a Global Delivery Model (GDM).
The primary accountability of the role is to perform daily BAU within the Client Reference Data, Credit Reference Data, and SSI space. You will also have an opportunity to support and enhance processes to improve efficiency.
Job Accountabilities:

Liaise closely with internal stakeholders (eg. Sales and Trading desks, Settlements) to ensure client accounts and SSIs are set up and maintained accurately across source systems
Perform counterparty setup and maintenance for new/existing clients in source system
Liaise with external clients to conduct SSI callbacks in a timely manner
Perform credit limit maintenance in source systems
Contribute to business objectives for operational excellence – identify, suggest and actively participate in improving standards, policies, procedures, and solutions
Actively participate in developing, testing and implementing new or enhanced processes and other process improvement initiatives
Provide accurate and thorough analysis of key process drivers, root or systemic causes of cross functional operational issues, interpret findings and make recommendations
Ensure internal control processes are adequate and documented appropriately
Conduct Business Acceptance Tests for system upgrades and patch releases
Handle first level escalated issues and provide work guidance as a resource to others
Contribute to the production of consolidated or aggregated reporting as appropriate
Coordinate with partners on key initiatives and may act as a project lead/subject matter expert for small-scale projects/initiatives in accordance with project management methodologies

Candidate Requirements:

At least 3 years of SSI and/or Client Reference Data experience in a middle or back-office function with reporting responsibilities and exposure to various traded securities and derivative products
Exposure to operational metrics and emerging regulations would be an asset.
Self-motivated, well organized and positive attitude.
Ability to prioritize multiple tasks and deliver results in a fast-paced environment.
BBG and Reuters knowledge would be an asset
Ability to work individually as well as part of a team.
Excellent analytical skills.
Excellent interpersonal skills both verbally and written
Ability to adhere to strict deadlines and handle high volumes of work in a demanding environment.
Strong knowledge of Microsoft Excel

Inclusiveness:
At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve and creating an environment where every employee has the opportunity to reach their potential.","['Front Office', 'Microsoft Excel', 'Operational Excellence', 'Process Improvement', 'Wholesale Banking', 'Wealth', 'Securities', 'Trade Finance', 'Capital Markets', 'Business Services', 'Visionary Thinking', 'Equity Derivatives', 'Foreign Exchange', 'Fixed Income', 'SSIS', 'Ability to Prioritize']"
Regional CRM Data Administrator,"FUGRO HOUSE, 35 LOYANG CRESCENT 509012","Permanent, Full Time",Executive,3 years exp,"Admin / Secretarial, Marketing / Public Relations",Monthly,"$2,600to$3,800","Job Overview
We are Fugro. We provide the people, equipment, expertise and technology that support the exploration, development, production and transportation of our world’s natural resources. We provide the technical data and information required to design, construct and maintain structures and infrastructure in a safe, reliable and efficient manner.

As our regional CRM (Avalon) Data Administrator, you will support our business management and commercial teams to ensure the data in our customer relationship management system relating to our APAC business provides the highest possible insights into our sales performance. This role will provide you the opportunity to work closely with our regional management.
Your Role

Monitor data quality of our CRM records within our Microsoft Dynamics CRM and Microsoft PowerBI systems.
Work with commercial and business development teams across our APAC offices to highlight areas of data quality improvement.
Supporting our business and operations team with sales and/or commercial administrative support.
After suitable training, conduct training sessions/workshops on best practices for use of our CRM system.
Provide basic troubleshooting to regional users.
Generate monthly/quarterly reports using our integration with PowerBI that will be provided to senior regional management on our Strategic Sales and Commercial performance.
Infrequent specific requests to undertake deep-dive analysis of the datasets using PowerBI for certain parts of the business to have a deeper insight into their sales performance.
Support our ethos of OneFugro by encouraging others to leverage the system to support our strategy of being an integrated service provider.
Be our regional champion, willing to travel to support our regional offices.

Your Track Record

You should have at least 12 months experience in the use of a customer relationship management system.
You should have excellent communication and reporting skills in English (verbal and written).
You need to demonstrate that you are able to take ownership and initiative, think out of the box to suggest and implement improvements.
You should be confident enough to work with and support senior stakeholders in realising the companies global expectations in the use of our CRM.
You will have excellent proficiency in Microsoft Excel.
You have an Analytical mindset with prior experience in performing data analysis.
You ideally will have experience with Microsoft Dynamics CRM and PowerBI.
You ideally can converse fluently in one or more of the following languages in addition to English: Malay, Bahasa Indonesia, Japanese, Korean and/or Cantonese.

Interest applicants, please apply via:
Regional CRM Data Administator (myworkdayjobs.com)

About Us
Fugro is the world’s leading Geo-data specialist, collecting and analysing comprehensive information about the Earth and the structures built upon it. Adopting an integrated approach that incorporates acquisition and analysis of Geo-data and related advice, Fugro provides solutions. With expertise in site characterisation and asset integrity, clients are supported in the safe, sustainable and efficient design, construction and operation of their assets throughout the full life cycle.

Employing approximately 9000 talented people in 61 countries, Fugro serves clients around the globe, predominantly in the energy and infrastructure industries, both offshore and onshore. In 2020, revenue amounted to EUR 1.4 billion. Fugro is listed on Euronext Amsterdam.

Disclaimer for recruitment agencies:
Fugro does not accept any unsolicited applications from recruitment agencies. Acquisition to Fugro Recruitment or any Fugro employee is not appreciated.","['Microsoft Excel', 'Data Analysis', 'Dynamics', 'Quality Improvement', 'Onshore', 'Asset Integrity', 'Data Quality', 'Customer Relationship Management', 'Cantonese', 'PowerBI', 'Bahasa Indonesia', 'Transportation', 'Administrative Support', 'Performance Tuning', 'Japanese']"
Data Product Manager,1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$7,000to$13,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us:
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Data Science team of e-commerce is aiming to provide valuable business insights to the partner teams, including operations, product manager, etc. The business is still expanding globally, and we do wants to get the talented DS/DA/DPMs to join us to make impact together! Now we are looking for talented data product managers to join us, and the main duties include:

Responsibilities

According to the characteristics of the international market, combined with mature experience in the industry, quickly produce data products for the international market; 
Combined with the international market business demand from Merchants/Creators/Partners, to provide Merchants/Creators/Partners with data monitoring and analysis of data products, to help businesses better growth of Merchants/Creators/Partners; 
In-depth understanding of the company's business, mining the business line analysis and decision-making needs, to provide data product support to the internal operation team; 
Reasonable use of various data analysis models and data scientific conclusions, organized and thoughtful planning of data product functions; Reasonable disassembly and formulation of various data indicators for e-commerce, and analysis and guidance of Merchants/Creators/Partners and internal teams of various sizes through data products; 
Reasonable planning of iteration rhythm, writing logical and thoughtful requirements documents; 
Check interaction and vision to ensure that products conform to different types of user experiences in different markets.

Qualifications

Bachelor degree or above, major in computer, mathematics, statistics; 
At least 3 years of data product planning and experience design experience, with merchant data product design experience and other data product design experience is preferred; 
Proficient English listening, speaking, reading and writing skills, a third language is preferred; 
English proficiency is required and any second language ability is preferred  
Have great interest in e-commerce and big data industries, have data analysis and mining skills and keen data insight; 
Proficient in using Axure/Xmind and other design tools, familiar with product flow chart drawing, product requirement document (PRD) and technical function description document writing; 
Proficient in SQL language, able to find problems and solve problems through data from the data platform; 
Have certain project management experience, strong execution, and be able to efficiently promote product improvement and project launch; 
Have excellent team cooperation ability and communication and coordination ability.


TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Tableau', 'Machine Learning', 'Data Analysis', 'Product Design', 'Modeling', 'Mathematics', 'Product Management', 'SQL', 'Product Optimization', 'Python', 'Statistics', 'Data Science', 'Product Development', 'Data Analytics', 'Product Analysis']"
Big Data Business Analyst,"MARINA BAY FINANCIAL CENTRE, 12 MARINA BOULEVARD 018982",Permanent,Professional,10 years exp,Information Technology,Monthly,"$10,400to$18,700","Business Function

Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.

Responsibilities

Work closely with business stakeholders to understand business requirements for MIS Big Data application and translate them into functional requirements
Query and Analyze Big Data to drive requirements analysis
Act as liaison between business team and offshore/onshore developers
Provide relevant facts, figures & justification needed for the business to make informed decisions
Drive verification and validation of functional requirements
Help drive User Acceptance Testing
Ensure that relevant project documentation, confluence pages are all up to date with latest information
Participate in Daily standup calls with scrum team and discuss about open issues, statuses and roll forward action items.
Possess strong understanding of technical and subject matter expertise that can be leveraged to identify and resolve issues in a timely fashion

Requirements

10-15 years’ relevant experience in financial services industry
Degree in Computer Science or Engineering-related field
Prior Experience in a Business Analysis or Development role – preferably having worked with Finance MIS / Performance Management Applications
Proficient in querying and analyzing Big Data
Understand MIS systems technology and design, with exposure to both traditional RDBMS like MariaDB, Oracle, Sybase, MS-SQL Server, and Big Data Hadoop Eco system applications
Experience working on Agile projects and be well-versed with JIRA & Confluence
Experience in Unix shell scripting
Familiarity with CI/CD and associated tools (Jenkins, Bitbucket)
Experience in using MS-Excel for numerical computations
Experience working with diverse stakeholders
Agile mindset, Quick learner, with positive attitude towards initiating and making change happen
Strong communication skills required, be articulate and pro-active in engaging stakeholders
Attention to details and highly organized and able to work under pressure in a time-critical environment
Ability to work with complexity and ambiguity and use it to their advantage
Good knowledge of banking products, financial accounting, MIS concepts and finance processes
Good presentation, analytical and problem-solving skills
","['Confluence', 'Oracle', 'Big Data', 'Scrum', 'Business Analysis', 'Hadoop', 'Agile', 'Requirements Analysis', 'JIRA', 'Revolution', 'Banking', 'User Acceptance Testing', 'Articulate', 'Financial Services', 'MIS', 'Business Requirements']"
 , , , , , , , , , 
ETL Developer(Data stage),"HONG LEONG BUILDING, 16 RAFFLES QUAY 048581",Contract,Professional,3 years exp,Information Technology,Monthly,"$5,500to$6,000","Job Descriptions:

Technical Skill set:
Primary:

Experienced Data Stage Developer (Minimum 3 years exp)

Secondary:
Skill set in order or priority:

PLSQL
Unix Scripting
Job Monitoring tool

JD/R&R:
CRM BAU Support:

Daily batch monitoring( including Sat & Sun)
Batch recovery in case of any failures, using Datastage
Support Users on any data related queries
Support any infra related change activities(patching, upgrades)

CRM BAU Enhancements:

Requirement analysis for any new enhancements along with BA.
Provide effort estimations
Development and delivery to SIT/UAT/PROD using Datastage
Post deployment verifications and support

MY/Great planner Datamart Support:

File receival from DCMS system
Support Malaysia team for loading data into MYDatamart DB in SIT/UAT.
Support enhancement for Great planner from Datamart module using Datastage

Deployment Automation activities:

Need to support any deployment activities

Adhoc Requests:

SIT/UAT data reflow upon request
Run DM jobs as per BA request in SIT/UAT(Corporate challenge & etc.,)
Data validation/verification as per BA request in SIT/UAT/PROD.

Salary: $5500-6k per month","['CRM', 'Business Intelligence', 'Release Management', 'Job Descriptions', 'Informatica', 'Enforcement', 'Scripting', 'ETL', 'Unix', 'Financial Markets', 'Planner', 'SQL', 'Databases', 'Agile Development']"
Data Management Specialist,"XILINX BUILDING, 5 CHANGI BUSINESS PARK VISTA 486040",Permanent,Junior Executive,1 year exp,Logistics / Supply Chain,Monthly,"$2,800to$4,500","THE PEOPLE:
We are looking for a self-motivated, customer service-oriented person to be part of the AMD Global Customer Master Team.

THE PERSON:
A good team player, with good communication skills; has a strong sense of self-motivation and a drive to achieve success for the entire team.

KEY RESPONSIBILITIES:

Required to keep abreast of business changes, while performing Customer Data Management
Expected to contribute towards driving process improvements and system efficiency enhancements
Responsible for (not limited to):
Processing Customer Data within SAP - MDG following set standards and procedures and within established Service Level Agreements (SLAs)
Troubleshooting, and resolving any discrepancies in Customer Master information between source systems and the Hub
Actively engaging with CrossFunctional Business, and IT teams to resolve Customer Data Management issues
Generating Reports and Quality Metrics

PREFERRED EXPERIENCE:

Less than 2 years of experience in managing cross-functional internal customers, with specific expertise in utilizing various information management tools
Good focus, accuracy, and attention to detail are essential
Must demonstrate strong analytical skills with the ability to learn new technical and nontechnical processes quickly
It's good to have 1 year of hands-on experience using SAP business application(s) is Required
Good to have PowerBI, Tableau, or RPA
Some Research or Data Management experience is an advantage
If you are willing to try and don't have any working experience, you are more than welcome to apply!

ACADEMIC CREDENTIALS:

At least a Diploma/Degree in Business Administration/Statistics or any discipline

LOCATION:
Singapore

2022-23586","['Tableau', 'Troubleshooting', 'Analytical Skills', 'Big Data', 'Information Management', 'Data Management', 'Data Quality', 'Data Governance', 'PowerBI', 'SAP', 'Good Communication Skills', 'Attention to Detail', 'Team Player', 'Master Data Management', 'Ability To Learn']"
Data Product Manager,"PLUS, #13-03  20 Cecil Street  049705","Permanent, Full Time",Manager,3 years exp,Others,Monthly,"$8,000to$12,000","About RightShip

Working towards a zero-harm maritime industry since 1991, our mission is to be a trusted innovation partner, charting a safe, sustainable and socially conscious future for the maritime industry vision is a Maritim Industry that causes Zero Harm

For all Maritime Stakeholders, who require transparency in Environmental, Social and Governance practices, the RightShip Platform is the ESG focused Maritime Digital Platform of choice that provides unique data and insights on the world’s cargo carrying vessels and the companies that operate them.

Are you ready to be part of something amazing? Want to work with a team that is passionate about creating great experiences and delivering value? Come join us at RightShip.

About the Role

We are seeking an experienced Data Product Manager who is passionate about leveraging data enrichment practices to create leading data led solutions that our customers love and make a real difference in the lives of everyone in the maritime industry. You will lead our Data Enrichment Practice, and be a data visionary, data champion and a strategic leader.

Aa a Data Product Manager you are responsible for creating and executing product data strategies that extract maximum value from existing data sources and adopts new data sets. You will work in collaboration with Product Managers and our technical data teams to both strategize and implement data enrichment initiatives that ensure our products possess and leverage leading data sets to achieve both RightShips enterpise product strategy and segment strategies for the key markets in focus.

You will recognise that our data is the most important asset that internal and external users trust to inform key decisions and that enriching data allows data consumers to get more meaning than raw data might otherwise provide. You will be responsible for transforming our maritime data by converting unstructured information into structured datasets. 

Meticulously balancing customer value and business benefit, each day you’ll work closely with talented people across our business to determine and deliver the biggest impact to our customers through our data.

This is an amazing opportunity for someone who cares deeply about their craft and wants to be part of a team who celebrates a product-led mindset, championing excellence in product delivery and solving problems.

Key Responsibilities

Owns the data product delivery strategy and roadmap.
Work with internal and external customers to analyze their needs and align data product roadmap to strategic goals.
Develop scope and define backlog items (epics/features/user stories) that guide the Agile software development team.
Solve data product-related problems, make decisions, complete trade-off analysis to stay on track towards business deliverable commitments.
Draft key objectives and results, strategies and apply the data for the product to make business decisions.
Collaborate with stakeholders during the visioning and concept development of a data product to identify what data is available and relevant, including both internal and external data sources
Mine data from primary and secondary sources, then reorganizing said data in a format that can be easily read by either human or machine.
Create appropriate documentation that allows stakeholders to understand each step of the data analysis and enrichment process.
Accountable for the created data product(s), delivering in the product model and communicating the data product needs with business partners.
Assess value, develops cases, and prioritize stories, epics and themes to ensure work focuses on those with a maximum value that are aligned with data product strategy.
Develop and maintain an appropriately prioritized backlog of user stories for implementation.
Act as an ambassador for the data product internally and externally and as the primary contact for queries related to the data product.
Develop appropriately detailed specifications for the data product features so they are clearly understood by the development teams.
A leader and member of the team. Represents team in front of stakeholders, clients or users.
Work collaboratively with a team of Data Engineers, BI developers, Data Scientists, Data Analysts and Data QA. 
Coordinate with the engineering team for all data warehouse related tasks.
Research and analyze market, the users, and the roadmap for the data product.
Follow our competitors and the industry.
Increase an understanding of Agile practices, Lean Start-up, new technologies opportunities and other data trends.

About You

You love being the glue of a team and are motivated, upbeat, customer and team centric. You have experience and evidence in translating data product strategy into reality ensuring maximum value from data products. You will have multiple years experience in data product roles in either B2B or B2BC SaaS offerings. In addition to this:


Hit the ground running. You have a minimum of 3 years of Software Data Product Owner/manager experience with demonstrable success.
You have experience in the Maritime Industry, Maritime Technology space or related field.
You can demonstrate practical knowledge of vessel construction, structures, machinery, operations or inspections and have worked with these data sets before.
Proficient in data extraction, manipulation and presentation.
Leadership is key. You have a track record of empowering and inspiring data product teams to success, and you can provide examples.
You have a passion for people, and you can describe how speaking directly to your stakeholders would be part of your data product process.
You encourage curiosity and empower your teams to run their own experiments wherever possible.
","['Machine Learning', 'Construction', 'Data Analysis', 'User Stories', 'Agile', 'B2B', 'Product Management', 'Customer Value', 'Project Management', 'SaaS', 'Data Science', 'Evidence', 'Product Development', 'Concept Development', 'Agile Software Development']"
 , , , , , , , , , 
Risk Business Analyst (Data Governance),"VISION EXCHANGE, 2 VENTURE DRIVE 608526","Contract, Full Time",Professional,5 years exp,Information Technology,Monthly,"$5,000to$7,500","Role   is a Risk Analyst to support both BAU and project work surrounding data   governance which includes working with lead on

Setting up of new data governance processes /        forums. This may require writeup of processes.
Design and setup of process surrounding RMG        critical data elements.
Running and managing of these processes and forums.
Follow-up and tracking of RMG identified data issues        and gaps to closure

Role   will also be required to understand risk data, reporting and analytics and   work with respective risk areas champions to define and improve RMG data   maturity capability.
Role   may also be involved in projects will drive or improve data governance   capability.
1. Setup   of new data governance process and forums, deisgn and setup of processes   related to RMG critical data elements, running and managing data governance processes   and forums and follow-up and tracking of issues and gaps to closure.
2. Work   with respective risk areas champions to define and improve RMG data   governance capability.
3. Participate   in activities or projects that will drive and improve data governance   capaibility
BAU and Projects Surrounding Data Governance
1. Work   with lead to define, setup data governance processess and forums including   processes related to RMG critical data elements . Able to independently   perform write of proposed processes and flow.
2. Work   with lead to run data governance processes and forums and independently   follow-up and track issues and gaps to closure.
3. Work   with lead and respective risk areas champions to define and improve data   governance capability
4. Able   to independently work on define projects and activities that will drive and   improve data governance capbility.","['UAT', 'Microsoft Excel', 'Analytical Skills', 'User Stories', 'Business Analysis', 'Agile', 'Test Cases', 'Data Governance', 'SQL', 'Project Management', 'Banking', 'Team Player', 'Business Process', 'Business Analyst', 'Business Requirements']"
Data Centre Engineer,"NEW TECH PARK, 151 LORONG CHUAN 556741",Full Time,Senior Executive,8 years exp,Engineering,Monthly,"$3,500to$5,500","The role of a Data Centre Engineer will be responsible for:

Data Centre Facilities Management
· Perform monitoring for all Data Centre Facilities infrastructure (Generators, UPS, CRAC units, Fire suppression gas, etc) to ensure Data Centre is in normal operation.
· Ensure all Data Centre Facilities infrastructure (Generators, UPS, CRAC units, Fire suppression gas, etc) are well maintained and always in tip top working conditions.
· Coordinate with various vendors to troubleshooting any breakdown issues.
· Coordinate and manage maintenance, project works and shutdown with vendors and landlord.
· Update and maintain all DC related documentation such as operation manual, single line diagram, asset listing, service report, etc.
· Ensure incidents are responded and attended to base on critically, impact and SLA.
· Assist in troubleshooting of facility and rack level events within service level agreement.
· Perform root cause analysis to make recommendation for solutions.
· Demonstrates and supports processes and procedures are followed and adhered to work orders
· Remote Hand support for – visual inspection, reboot devices, physical connect/disconnect of HDD, network cable connectivity test, insertion of fibre SFP, laying of fibre cable from rack to rack, installation of servers, rack power cables and rack trays.
· Manage equipment and critical spare parts movement, asset tagging, labelling, and tracking.
· Perform other duties such as access clearance and participate in projects as required.
· To involve and provide idea/suggestion for energy saving program and reduce operation cost.

The Ideal candidate would possess.
· Bachelor of engineering/IT with at least 8 years of experience in DC operation.
· Good knowledge in Data Centre Facilities
· Well verse in Data Centre facility related SOP and EOP
· Ability to multitask and work under pressure in team and independently.
· Able to hand on and perform as required.
· Good communication skills (both verbal and written) and problem-solving skills.
· Flexibility to reschedule priorities as circumstances change.
· Ability to work outside office hours, weekend, public holiday if required.
· Able to attend Emergency call within 2 hours when activated.","['Switches', 'Ability to Multitask', 'Troubleshooting', 'Hardware', 'Data Center', 'Landlord', 'Root Cause Analysis', 'Data Centre Facilities Management', 'Visual Inspection', 'Good Communication Skills', 'Power Distribution', 'Routers', 'Cabling', 'Facilities Management']"
Data Production Engineer,"PLUS, 20 CECIL STREET 049705",Full Time,Professional,3 years exp,"Banking and Finance, Engineering, Information Technology",Monthly,"$10,000to$20,000","Overview
As a data engineer, you need to have a deep insight into data usage across the entire company and support trading, risk management, and product operations.
The job requires the candidate to take on the challenge of keeping curious about cutting-edge technologies in the fields of quantitative trading and data mining, as we are continually looking for new potentially valuable data and leverage them to benefit our trading.

What you’ll do
•Maintain and oversee internal data production pipelines; 
•Develop data ETL pipelines, data management platform, and other relevant data systems; 
•Explore alternative data and perform preliminary data mining

We expect you to have
•A bachelor’s degree in computer science, financial engineering, or related field; 
•Experience in developing data extraction, transformation, and load (ETL) pipelines in Python; 
•Experience with big data or data modeling is preferred; 
•Comprehensive knowledge of relational databases (MySQL/SqlServer/Oracle) and experience with big data infrastructure; 
","['Machine Learning', 'Big Data', 'Data Modeling', 'Pipelines', 'Financial Engineering', 'Data Management', 'ETL', 'Electrical', 'Risk Management', 'Product Engineering', 'Data Mining', 'Python', 'Data Science', 'Data Analytics', 'Databases', 'Failure Analysis']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Migration Test Analyst,"SAMSUNG HUB, 3 CHURCH STREET 049483",Contract,Professional,5 years exp,Information Technology,Monthly,"$7,000to$9,500","Data Migration Test Analyst
Job Requirements:

Experience in performing UAT Test Management Activities with sound knowledge on STLC processes, best practices etc.
Experience with SQL, Python and Hadoop
Good knowledge on ETL/DW Testing
Knowledge on Terradata and Cloudera
Provide end-to-end support on the User Acceptance Test (UAT) and its acceptance criteria (i.e. Test Scripting, Test preparation and Test Execution)

Company Reg No.: 201131609D, Licence No.: 11C4684, Reg No: R1655133","['UAT', 'Hadoop', 'Scripting', 'Information Technology', 'Test Cases', 'Test Automation', 'SQL', 'Data Migration', 'JIRA', 'Python', 'Banking', 'Selenium', 'Test Execution', 'Test Management', 'Test Preparation']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Operations Lead (Healthcare),6 SERANGOON NORTH AVENUE 5 554910,"Permanent, Full Time",Manager,5 years exp,Information Technology,Monthly,"$7,500to$10,000","Summary
DataOperations Lead for a new large-scale National Healthcare IT System


Roles & Responsibilitiesas Data Operations Lead

Report to the Operations Manager, be responsible     for data operations of a new national data repository
Accountable for the fulfilment of the system’s     roles and responsibilities as one of the HealthierSG data single source of     truth
Publish and enforce data definitions for established     data subjects
Establish data contributor and data consumer onboarding     processes with compliance to data governance policy, conduct onboarding with     thorough quality assurance controls
Plan and Prioritise onboarding requests, track and report contributor& consumer onboarding status
Ensure data availability to data consumers, and     provide timely communications in cases of disruptions
Respond to enquiries on data qualityand inform the relevant data contributor promptly
Receive and apply correctionsprovided by data contributors
Identify and establish measures on on-going     basis to proactively detect data quality issues and follow up with the     respective data contributors for timely data corrections, as well as implementation     of preventive measures
Provide regular reporting of data quality issues to internal andexternal stakeholders, data owner, and trackall data quality issues till closure
Ensure compliance to both internal and     external SLAs
Manage team’s support schedule to ensure full     coverage of data operation services, as well as coaching team members to     deliver consistent support service quality
Provide strong leadership for matters relating     to operations support, processes, and guidelines to achieve service     excellence
Advise improvements and assist in the     development of measurable information and SOP / knowledge base / dashboards to assure continued effectiveness of system operations


Specific Requirement/Skillsets

Degree in Computer Science, Information Technology,Management of Information Systems, or related discipline
Minimum 8 years hands on experience in large scale IT applicationoperations, preferably in the area of data operation
Excellent analytical skills with attention to detail
Possesses good verbal     and written communication across all levels of personnel with proven     ability to translate complex, technical subjects into clear and concise communications to a variety of key stakeholders Pro-active, independent, and able to react quickly and resolve issuespromptly
Experience in Healthcare domain is anadded advantage
","['Coaching', 'Leadership', 'Analytical Skills', 'Technology Management', 'Quality Assurance', 'Healthcare', 'Information Technology', 'Data Quality', 'Data Governance', 'Written Communication', 'Compliance', 'Attention to Detail', 'Service Excellence']"
Data Migration Officer | Contract,"ONE FINLAYSON GREEN, 1 FINLAYSON GREEN 049246","Contract, Full Time, Internship/Attachment",Junior Executive,1 year exp,"Banking and Finance, Information Technology",Monthly,"$2,800to$4,000","Responsibilities:

Work on data migration of data within existing outsourcing documents onto outsourcing workflow tool. Interpretation or analysis of data required
Work closelt with outsourcing vendors for information that is not available within existing outsourcing documents
Schedule review sessions and review migrated information post migration with respective owners (and COO Bus. Mgmt) and obtain confirmation of completion of migration / updates

Requirements:

Diploma / Degree holder with relevant internship experience
Meticulous, independent and resourceful. Able to source for information independently.
Knowledge of / exposure to outsourcing will be an advantage.



** This Singapore-based position is opened to Singaporeans only.

Please state your availability, current and expected salary in the resume.

Qualified or interested candidates, please visit our GMP website at www.gmprecruit.com/current_jobs/posting.aspx to apply for this position with GMP Job Code: 21881

Name of consultant: Nurul Amirah (R22108940)
Email: nurul.amirah@gmprecruit.com

We regret that only shortlisted candidates will be notified.
GMP Technologies (S) Pte Ltd   |   EA Licence: 11C3793   |   Nurul Amirah |   Registration No: R22108940","['Microsoft Excel', 'Data Analysis', 'Outsourcing', 'GMP', 'Data Migration', 'Attention to Detail', 'Communication Skills', 'Team Player', 'Data Analytics', 'Databases', 'Able To Work Independently']"
 , , , , , , , , , 
Data Science Manager / Director,"PRUDENTIAL TOWER, 30 CECIL STREET 049712",Full Time,Manager,5 years exp,Engineering,Monthly,"$11,666to$20,000","What you will do:

Lead and grow a globally distributed product analytics team to conduct analytics studies and experimentations to shape a shared, data-informed strategic vision for Airwallex product team (individuals with people management experience can be considered for Data Science Manager role)
Perform as a strategic thought leader for Data Science and cross-functional organizations

What you will bring:

10+ years industry experience and an advanced degree in a quantitative field
5+ years of management experience in data science or other relevant quantitative functions
5+ years of experience communicating the results of analyses to leadership teams to influence the strategy
Passion for management and creating opportunities for career growth for team members
Demonstrated ability to create, drive and execute impactful data roadmaps for the business
Technical mentorship experience with applied statistics or experimentation (i.e. A/B testing) in an industry setting, large data sets and distributed computing (Hive/Hadoop) and packages, such as R, Python, MATLAB, SPSS, SAS, Stata, etc
Experience in technology, financial services and/or a high growth environment is advantageous
","['Mentoring', 'Machine Learning', 'Stata', 'PostgreSQL', 'Experimentation', 'SPSS', 'Economics', 'Strategy', 'Python', 'Statistics', 'Data Science', 'Ab Testing', 'People Management Experience', 'Financial Services']"
Python Data Engineer,"SUNTEC TOWER TWO, 9 TEMASEK BOULEVARD 038989","Permanent, Full Time",Professional,5 years exp,Information Technology,Monthly,"$6,000to$10,000","In Zenika, we are looking for a Python Data Engineer with at least 5 years of experience
You may be a fit if:

You are able to develop, maintain and enhance Python applications processing high volumes of data.
You have experience in Python pandas and Python API/web frameworks such as FastAPI, Flask or Django
You have experience in writing SQL statements and optimizing Python applications performance
You are well versed in business analysis - you are able to converse with business users to understand requirements, to analyse the existing data, to identify the required data transformation and to design the data processing workflow

Who are we?
Are you passionate about complex problem solving through futuristic technology?
Zenika is a global premium IT services consultancy intending to link the organic and the digital worlds. We are a cohesive team of technology enthusiasts and experts who thrive in a collaborative and inclusive environment.
Firm believers in 'Open Source' philosophy, our developers share more than 47K contributions on over 7K projects across several communities.
Curious and pragmatic, we have multiple publications in our name. We share our knowledge by speaking at conferences and supporting companies in their digital transformation journeys through consulting, training, & IT delivery.
As fervent team members, you could join us as we adapt, test and develop innovative new applications for a fintech startup, influence the digital strategy of a banking giant, or create progressive solutions to resolve challenging problems every day for our clients.
Zenika has been recognized as the ""Great Place to Work"" in France for four years in a row (2015 -2018).
We take pride in our employee-first approach and diversity. Know about our values (Gender Equity, Equal Opportunities, Work life Balance, Handicap Mission) and perks - https://www.zenika.com/en-US/pages/values
While joining Zenika Singapore you will get:
Attractive salary package with bonuses
Attractive benefits (Eg: High health insurance coverage, transport allowances, work from home, 20 days annual leave)
Career progression and upskilling opportunities
Internal learning session and events
Monthly and yearly internal social events
Integration in our international developers community (Singapore - France - Canada)
When you join Zenika you join:
A highly qualified team of international professionals
In an outstanding people-first culture
Based on sharing, transparency and fun
Do you like challenges? Do you like freedom?
So, join our passionate team and actively contribute to ""Coding the World"".
Explore open-source technologies & the most innovative methods in the IT world with Zenika today!","['Pandas', 'Tolerance', 'Data Transformation', 'Working With Clients', 'Open Source', 'Web Developers', 'SQL', 'Flask', 'Digital Strategy', 'Python', 'Publications', 'Health Insurance', 'Silicon', 'Django', 'FastAPI']"
Big Data Developer,"SIM LIM TOWER, 10 JALAN BESAR 208787",Permanent,Senior Executive,6 years exp,Information Technology,Monthly,"$7,500to$9,000","• More than 4 years IT experience in development which includes ETL and data processing (E.g. Data warehouse, Data mart, Data pipelines, Data lake development)
• Minimum 2 years’ hands-on experience in Hadoop/Big Data development
• Hands on with Cloudera Hadoop technology stack, including platform tools such as HDFS, Hive, Impala, Spark is a must
• Strong in SQL skills
• Experience in writing Unix shell scripting
• Experience in Informatica Power Center, Data Integration suite of tools and Big Data Management will be an added advantage
• Support project and delivery team all throughout the project implementation","['cloudera', 'data mart', 'Apache Spark', 'Scala', 'Big Data', 'Pipelines', 'Hadoop', 'Informatica', 'Data Management', 'Software Engineering', 'ETL', 'Data Integration', 'SQL', 'Python', 'Writing', 'Unix Shell Scripting', 'Java', 'Apache', 'Data Warehousing']"
Lead Data Analyst (Team Lead),"MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983",Permanent,Manager,8 years exp,Banking and Finance,Monthly,"$8,000to$12,000","ROLE 

The Lead Data Analyst is responsible for the effective design and successful implementation of data management solution, to enable the regional rollout of Data & AI initiatives

KEY ACCOUNTABILITIES

A core team member of Data & AI, responsible for the collective success of the team and the company. The Data & AI team consist of various domain experts including Data Engineers, Data Developers and Data Analysts to perform multi-disciplinary, interrelated activities
Responsible for designing and implementing enterprise-wide data management solutions (SSOT) for all Data & AI initiatives across Eastspring in different countries
Work with business partners to identify, prioritise, and deliver on their most pressing and impactful use case. Advocate and establish data taxonomies that are consistent and comprehensive
Work with relevant stakeholders to establish robust data governance, including clearly defining the roles and responsibilities of data stewards and owners for maintaining and ensuring data quality
Ensure data management processes comply with established framework and policies. Document work and any new procedures so others will be able to interpret, assess and repeat the work
Lead and supervise a small team. Be able to cover the team and get your hands dirty as required. Identify opportunities for enhancements in data management capabilities
Deliver consistent, accurate and quality work. Communicate information and findings in a clear and compelling way

EXPERIENCE / QUALIFICATIONS

At least 8 years of related working experience, e.g., in the areas of Data & AI projects. Familiar with data management framework and data architecture
Strong technical skills in data and database management. Proficient with data wrangling, analytics, and transformation using tools such as SQL, Excel, etc. Python is good to have
Experience in managing stakeholders and requirements
Experience in business intelligence and data analysis. Proficient with data wrangling, analytics, and transformation using tools such as Python, SQL, and Power Query. A strong understanding of Power BI and Power Apps is a plus
Experience in working with asset management data is a plus, e.g., portfolio, security, positions, transactions, cash flows, client, performance, risks
CFA Level 1-3, or good understanding of asset management, is a plus

GENERAL CANDIDATE ATTRIBUTES

Inquisitive, analytical, and problem solver
Attentive to details and comfortable dealing with complex datasets, structured and unstructured
Customer-centric and strive to deliver value by effectively and proactively engaging stakeholders
Able to communicate complex ideas clearly and manage expectations with stakeholders
Able to prioritise and organise, take a flexible approach to workload, and work autonomously when required
","['Work Autonomously', 'Asset Management', 'Business Intelligence', 'Data Analysis', 'Data Management', 'Data Quality', 'Data Governance', 'Attentive', 'SQL', 'Python', 'Data Architecture', 'Team Lead', 'Power BI', 'Data Visualization']"
Data Integration Specialist,"KEPPEL BAY TOWER, 1 HARBOURFRONT AVENUE 098632","Permanent, Full Time",Professional,5 years exp,Information Technology,Monthly,"$5,000to$10,000","About Group Digital Office – Data and Digital team
The folks at Keppel Corporation’s Group Digital Office are digital natives whose goal is to drive digitalization and transformation across the group. Sparking innovation and thought leadership, with core competency as critical thinker, disciplined thinker that is clear, rational, open-minded, and informed by evidence. A lean organization understands the value of its wealth data and strives to derive the sharpest insights to create competitive advantages. Our goal is to deliver those insights and work with the businesses to execute those actions.
We are on the hunt for a data integration specialist who is comfortable working across multiple functions and teams that can help us stich together all the data and systems needed to deliver improved holistic business insights. Your tenaciousness and passion will help to ensure we can see through our missions through from conceptualization to final delivery.

Job Description

The Data Integration specialist is a subject matter expert of data integration solutions and data architecture
You will be responsible for the technical development of any new data integration solution to be plugged in to the overall enterprise data architecture
You will be supporting the Data Engineer to organise data at the macro and micro levels, creating data models that enable the implementation of the intended business architecture, key data entity diagrams, and a data inventory to implement the architecture vision

Responsibilities

Planning and executing data migrations, providing logical data models with business logic needed for creation of data quality rules
Contributing to the Data Quality Improvement Program through application of data management best practices, designing data solutions, implementing future proof fixes, identifying opportunities for driving data process efficiency and data quality
Supporting the Data Engineer to scope out and recommend technologies to enhance data
Extracting, transforming and integrating large and small datasets. Working alongside developers to develop data integration solutions
Maintaining and developing a reliable and efficient master data for the long term
Supporting the development of a reporting data warehouse
Developing and maintaining documentation for each data solution to ensure it reflects current business rules and definitions
Facilitating stakeholders in identifying technology challenges, supporting them in defining requirements of their projects
Collaborating with technology business partners to allow the organisation to absorb and scale into business-as-usual development work
Executing some routine tasks on regular basis, which can include data imports and executing SSIS packages, also to support the Data Operations Team during peak times

Job Requirements

A curious data enthusiast with a passion for technology and problem solving
5 years’ experience working with any of the mainstream RDBMS
Experience with end-to-end data pipeline implementation with cloud services such as Azure Data Factory/AWS Glue
Data manipulation, data integration design and development including T-SQL, SSIS and APIs
Datawarehouse tech: experience developing OLAP cubes and/or in memory data models
Business Intelligence technology (e.g., Power BI)
Good understanding of data lifecycle and architecture best practices.
Systems integration experience with SAP systems is a bonus
Understanding of Data Protection Legislation is a plus
Good communication and excellent listening skills. Strong relationship building skills and a collaborative attitude towards everyday working
Empathetic when dealing with colleagues
Ability to work with modern workplace technology (such as MS Teams) from home and in the office
","['Missions', 'Listening Skills', 'Technical Analysis', 'Azure', 'TIBCO', 'T-SQL', 'Quality Improvement', 'Inventory', 'Systems Integration', 'Problem Solving', 'Data Integration', 'SAP', 'Data Architecture', 'JMS', 'OLAP', 'SSIS']"
Lead Data Engineer (AWS),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,6 years exp,Information Technology,Monthly,"$8,000to$13,500","The Lead Data Engineer will be responsible for the design, develop, and maintain:

Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases.
Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”.
Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda .
Batch Pipeline Orchestration using on Apache Airflow and Jenkins.
Auto Scalable platform using Kubernetes on EKS.
Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine.
Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD).
Structure Tables with Partitioning and Clustering to increase Cost & Performance Benefits.
Guide Data Analysts and Data Scientists to write efficient queries and workloads.
Data Sharing with On-Demand Encryption/Decryption which can operate at Scale.
Running Containerized ETL workflow at scale.

Qualifications

Bachelor Degree in Computer Science, IT or equivalent.
At least 6-7 years of data engineering experience with team leading/guiding/mentoring experience.
Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc
Strong Data modeling and managing Distributed Computing Platforms for Data Processing.
Advance knowledge of SQL and writing resource-efficient queries.
Have at least 2+ years of professional programming experience in Python.
Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL.
Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lamda, etc...
Have a good understanding of how Kubernetes clusters work and scale on-demand.
Have adequate experience using Containers for Data Engineering workload.
Implemented manual or automated tools for Data Quality, Catalog, and Lineage.
Uphold the sense of Frugality across Data Engineering teams.
Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders.
","['Kubernetes', 'Oracle', 'Data Modeling', 'AWS', 'Hadoop', 'MySQL', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Data Architecture', 'AWS Lambda']"
 , , , , , , , , , 
Data Scientist (Contract),"APERIA, 8 KALLANG AVENUE 339509",Contract,Senior Executive,4 years exp,Information Technology,Monthly,"$9,000to$13,500","
Collaborate on a wide array of product and business problems with a diverse set of cross-functional partners across Product, Engineering, Research, Data Engineering, Marketing, Sales, Finance and others. 
Focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches
Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches
Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses.
Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends.
Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations.
Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.

Requirement:

Graduate degree in an analytical field
Demonstrated problem-solving experience with experience providing actionable business insights and recommendations data and fact-based
Demonstrated experience in storytelling with data
Experience working collaboratively with cross-functional stakeholders and partners
5+ years of SQL experience (creating and updating queries)
Experience with data visualization tools such as Tableau or packages in R/Python
Experience with reporting systems and data pipeline architecture
Communication experience in articulating issues to both technical and non-technical audiences.
","['Tableau', 'Machine Learning', 'Forecasting', 'Product Innovation', 'Quantitative Analysis', 'Product Engineering', 'Data Engineering', 'Data Mining', 'SQL', 'Statistics', 'Data Visualization']"
Data Scientist,48 CHANGI SOUTH STREET 1 486130,"Permanent, Full Time",Senior Executive,2 years exp,"Engineering, Information Technology",Monthly,"$6,000to$11,000","We are looking for talented Data Scientists, who will join our Data Science Team and help us build the state-of-the-art Data Science capabilities powering the future of our platform.

Roles and Responsibilities

Design, develop and maintain machine learning models / optimization methods to support business and operational processes.
Develop the pipelines to train, validate and deploy these models across various environments.
Design product experiments and interpret the results yielding impactful conclusions.
Perform statistical data analysis & visualization to find answers and new insights to important business questions.
Participate in technical discussions across the team through code reviews, RFC or architecture review sessions.

Requirements

At least 2 years of experience working as a Data Scientist or an advanced (Masters, PhD) degree in a related field (computer science, statistics or mathematics, economics, etc).
Deep knowledge of data science fundamentals and statistics, with a focus on time series forecasting, optimization such as linear programming, pricing strategies.
Experience with modern software development practices: version control, unit tests, refactoring.
Good understanding of experimental design and methodologies such as A/B testing or multi-arm bandits.
Proficient in Python or R, SQL (PostgreSQL preferred). 
Experience applying data science in end-to-end production use cases: from data cleaning, feature engineering through to model training and inference.

Preferred qualifications

Experience with geospatial analysis.
Experience with real-time inference.
Hands-on experience with ride-hailing/car-sharing use cases, consumer apps, or adtech/martech use cases.
Familiarity with AWS data analytics services.
Experience with FastAPI (Python), Flask (Python), Plumber (R), or similar.
Experience with Spark.
Experience deploying models to production.
","['Machine Learning', 'Data Cleaning', 'PostgreSQL', 'Pipelines', 'SQL', 'Flask', 'Experimental Design', 'Python', 'Statistics', 'Data Science', 'Visualization', 'Ab Testing', 'FastAPI']"
 , , , , , , , , , 
"Staff Engineer, Data","CAPITAGREEN, 138 MARKET STREET 048946",Permanent,Professional,6 years exp,Engineering,Monthly,"$6,500to$13,000","Rakuten Group, Inc. is the largest e-commerce company in Japan, and third largest e-commerce marketplace company worldwide, with over 1.5 billion registered users worldwide. The Rakuten brand is recognized worldwide for its leadership and innovation, and provides a variety of consumer and business-focused services including e-commerce, e-reading, travel, banking, securities, credit card, e-money, portal and media, online marketing and professional sports. The company is expanding globally and currently has operations throughout Asia, Western Europe, and the Americas.
Rakuten Viki is a premier global entertainment streaming site where millions of people discover and consume primetime shows and movies subtitled in more than 200 languages, by our community of fans. With billions of videos viewed and more than 1 billion words translated, Viki brings global entertainment to fans everywhere!
Based in Singapore, this Staff Engineer, Data role reports into Engineering Manager and will play a critical role in building the pioneer Data Engineering Team at Viki!
About the Data Engineering Team
Viki is establishing a Data Engineering team from the ground up, for the purpose of addressing the business’s growing data needs. This team is going to be responsible for designing and implementing a data architecture that is able to provide reliable data systems and clean data for various stakeholders across Viki including but not limited to

Data Analysts who need to spend a lot of time finding insights from the data, build reports to track business performance against OKRs,
Product Managers who need to understand our customers’ behaviors, their journey on our platform, understand customer funnels,
Marketing teams to be able to build customer segments for marketing campaigns,
Content Operations to track the performance of our shows across various markets and customer segments,
CRM team to understand our customer and manage our relationships with them, and so on

Building this overall data architecture includes designing and building the ingestion systems for different data formats (files, databases, events), designing processing pipelines that can scale with data volume, data management strategies (Data Lake, Data Warehouse) that’s optimal for long term storage, queries for reporting / visualization, building APIs as well as ML models on top of and data sharing with third-party applications for both batch and streaming data. While doing so, set up proper data governance practices and policies for data retention, compliance, PII handling, GDPR/PDPA/CCPA handling, among other things.
In addition to this, in the longer term, the team is expected to build abstractions and data models that can enable future needs with building systems for content recommendations, search recommendations, building as well as operationalizing machine learning models for subtitle translations, recommendations, churn prediction and so on.
Key Responsibilities:

Working with product and analytics teams and the engineering manager to understand the business, technical direction and make system/architecture decisions that support longer term needs and extensibility of the data architecture
Evaluating SaaS and PaaS platforms that can be used to solve parts of the data architecture and integrate them into the architecture
Providing subject matter expertise with designing the pipelines to be efficient and scalable to grow with the 3 Vs of Data (volume, velocity and variety), as well as with data modeling
Building and operating the data platform service, including defining and tracking its SLA.
Contributing to and conducting system design reviews for systems and pipelines that are being designed and implemented for various business use cases
Working with the Engineering Manager to establish the right data engineering practices and ensure that they are followed well and that includes proper automation testing, CI / CD, logging, monitoring and alerting
Identifying patterns in code and refactor them into modules that are easy to extend / reuse
Creating and ensuring that guidelines to uphold and maintain the quality of the codebase and system is being adhered to by the team, and lead the way in doing so
Making calls on when to take up tech debt, vs paying it off, and ensuring that we’re maintaining healthy levels of debt
Creating reusable and extensible automation test suite that makes it easy for the team to add, and maintain a robust test suite for all services and pipelines
Performing code reviews of the team’s PRs and ensuring high standards of code quality, in addition to ensuring that development guidelines are followed
Guiding less experienced members of the team on technically complex aspects of the system, coaching them on systems thinking and architecture
Making sure the overall integrity of the architecture is preserved and system documentations are kept up to date

Requirements:

B.S. or M.S. in Computer Science or a related field
8-12 years of experience in developing professional grade software.
6-8 years of experience in data engineering
Strong knowledge of software concepts, design patterns, refactoring and automated testing
Great judgment and diligence to know what patterns to use, when and where, and are able to confidently hold constructive conversations on it with the team, and peers
Strong communication skills and are able to explain technical and non-technical concepts to less experienced members of the team, as well as the peers and managers
Strong hands-on experience building APIs using: Java, Scala, Golang and /or Python, or willingness to pick one of them / Relational and / or NoSQL DBs (Postgresql or Mysql or MongoDB or equivalent) / Caching technologies like Redis or Memcache
Advanced SQL knowledge and experience working on query optimization, data modeling in Data Lake and Data Warehouse architectures
Advanced knowledge and experience building and scaling both batch and streaming pipelines, and challenges that come with it
Strong experience with working with / using one or more of the following: Data Warehousing technologies such as Redshift, BigQuery, Snowflake or other big data storages like CockroachDB, Cloud Spanner, BigTable, etc / Any Data Processing frameworks and technologies such as Spark, Apache Beam, Dataflow, EMR, AWS Glue / Messaging systems such as Kafka, PubSub and Stream processing / Open File Formats such as Parquet, ORC, etc / Building and operating data applications in cloud environments (AWS or GCP) / 3rd-party solutions and technologies such as Fivetran, Snowplow, Segment, or the likes of it
Experience establishing Data Governance policies and practices
Added advantage if you have experience working with Delta Lake, Streaming-only architectures, Data Marts and operationalising ML Models.

Rakuten is an equal opportunity employer. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status. Women, minorities, individuals with disabilities and protected veterans are encouraged.","['Translations', 'Data Sharing', 'Orc', 'Systems Thinking', 'Design Patterns', 'Advanced SQL', 'Professional Sports', 'CockroachDB', 'Data Engineering', 'EMR', 'SQL', 'System Design', 'Python', 'Java', 'Databases']"
Data Engineer - ETL,"MIDVIEW CITY, 22 SIN MING LANE 573969",Full Time,Professional,5 years exp,Information Technology,Monthly,"$6,500to$9,500","Key Requirements: 

Experience in banking applications using ETL, Oracle, and Teradata.
Expertise in Oracle PL/SQL and Teradata BTEQ scripting
Expertise in Informatica tools like Power Center, Data Quality, Metadata manager, BG, and BDM 
Working experience in scripting using Shell script and awk programming.
Worked with CI/CD automated deployment using Bitbucket and Github.

","['Teradata', 'Oracle', 'Big Data', 'Informatica', 'Scripting', 'ETL', 'SQL', 'Banking', 'Github', 'Databases']"
Assoc Data Engineer,6 SERANGOON NORTH AVENUE 5 554910,"Part Time, Permanent",Professional,5 years exp,Information Technology,Monthly,"$3,500to$6,000","Role and Responsibilities

Obtain and confirm the Budgetary Quotations from the source systems and vendors
Review and critique vendors’ quotations
Write funding / requirement approval papers
Review the data designs, ETL design, table designs and perform data analysis
To ensure the interface specifications meet the IHiS data governance, guidelines and policies
Monitor the data deliverables and ensure timely availability of data for development, UAT and production
Plan and coordinate end-user training for any system implementations / enhancements / Change Requests (CRs)
Manage vendors to achieve Key Performance Indicators / Service Level Agreements and reviews of contractual Terms & Conditions (when necessary)
Assist manager in formulating application implementation strategies / best practices
Identify data and business gaps within organization’s information systems by analyzing existing systems and workflows.
Recommend effective and cost saving solutions
Support positive project-vendor relationships and resolve conflicts
Support the team in defining project requirements, tracking and documentation
Manage and track project risk and issues

For each project, support the following tasks:

Develop an application Project Charter / variation charter for source system's integration and Module Schedule
Develop risk assessment and mitigation plans
Work closely with other source systems to assess the impact and dependencies
Review project progress and ensure that the project meet the project milestones on time
Review plan, conduct and co-ordinate the data UAT by working with the end-users
Assist the managers and users to sign-off the deliverables
Ensure audit conformance throughout the project life cycle
Prepare post implementation review

Requirements / Qualifications

At least 3 years’ experience in IT Projects
Experience in all phases of project lifecycle
Experience in budgeting (costing, cost evaluation analysis etc.)
Experience in various procurement methodology e.g. RFQ, RFP etc.
Experience in writing approval papers
Must have the knowledge and experience to perform root cause analysis
","['Charter', 'Project Risk', 'Data Analysis', 'Predictive Analysis', 'Assurance', 'Root Cause Analysis', 'Systems Integration', 'ETL', 'Data Governance', 'Operating Systems', 'Fraud', 'Business Intelligence Tools', 'Internal Audit', 'Microsoft Power BI', 'Business Analyst', 'Audit']"
 , , , , , , , , , 
Data Engineer - Big Data,"MIDVIEW CITY, 22 SIN MING LANE 573969",Full Time,Professional,5 years exp,Information Technology,Monthly,"$7,000to$9,500","Requirement
• Experience in developing banking applications using ETL, Hadoop, and Teradata
• Experience in Teradata (SQL, BTEQ scripting) and Hadoop (Hive, Impala, Kudu). 
• It is desirable to have working experience in No SQL and virtualized Database Environment.
• Experience in Teradata FSLDM in Finance industry,
• How BI tools integrate with Data Mart and Data Lake (Qlik Sense, Power BI)
• Scripting using Shell script and awk programming
• Good understanding of CI/CD automation, bitbucket, and Github.
• Data Modeling using industry-standard data model (FSLDM)
• Good understanding of Hadoop, In memory, No SQL




","['Teradata SQL', 'Teradata', 'Big Data', 'Data Modeling', 'Hadoop', 'Scripting', 'ETL', 'SQL', 'Banking', 'Github', 'Power BI']"
Senior Data Anlayst,"ECON INDUSTRIAL BUILDING, 2 ANG MO KIO STREET 64 569084",Full Time,Senior Executive,3 years exp,Information Technology,Monthly,"$6,000to$8,000","Job Description 
• Assigned to support Data Domain Systems. • Analyse data o Clean databases to remove duplicated, outdated, or irrelevant information o Develop solutions and recommendations to address information needs. o Gather data from internal systems and external sources. o Mine data to identify trends, patterns, and correlations. o Perform data validation and quality control checks. • Identify business needs o Recommend types of data and data sources needed. o Support the translation of business needs into analytics and data requirements. o Work with stakeholders to define business and information needs

Responsibilities 
• Provide technical advisory and support to Income’s Data Steward in the execution of data  management activities to comply with data governance policies and guidelines. • Create and maintain technical data documentation. • Provide the technical expertise around source systems, extract, transform, and load (ETL) processes,  data stores, data warehouses, and Business intelligence tools. • Explain how a system or process works/doesn’t work. • Check code, SQL, internal database structures, and other programming constructs in search of how  the information is structured, how the data moves, and how the data transforms within Data Lake  or between systems.

At least 3-6 years hands-on experience in data management or a related field. • Business Needs Analysis. • Data Strategy. • Stakeholder Management. • Data Engineering – able to write SQL scripts and stored procedure • Insurance domain knowledge or/and, experience in Impala/HUE and Data Governance is added  advantage.","['Tableau', 'Microsoft Excel', 'Quality Control', 'Labels', 'Data Management', 'Translation', 'Technical Advisory', 'Data Governance', 'Business Needs Analysis', 'Data Engineering', 'SQL', 'Business Intelligence Tools', 'Stakeholder Management', 'Databases', 'Data Strategy']"
Senior Data Anlayst,"ECON INDUSTRIAL BUILDING, 2 ANG MO KIO STREET 64 569084",Full Time,Executive,3 years exp,Information Technology,Monthly,"$6,000to$8,000","Job Description & Requirements

Metadata (for mid/Senior role) or Data Quality (for junior/senior role)
Experience in managing SLA and DQ (must have for both roles)
ETL or ELT experience (must have for both roles
Minimum 3-5 years as Data Analyst/ data scientist capacity. 

------------------------------------------------------------------------------------------------------
Additional Requirement:

Senior candidates with experience as a Product Owner/Change Analyst on a relevant project.
Knowledge of CIB and CB business segments, client types and product offerings, KYC, FATCA, compliance etc
Knowledge and experience in both the Agile/Scrum delivery model and Waterfall delivery model within the banking industry
","['Tableau', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Big Data', 'Labels', 'ETL', 'Data Quality', 'SQL', 'Python', 'Banking', 'Statistics', 'Visualization', 'Metadata', 'KYC', 'Data Analytics']"
 , , , , , , , , , 
Data Centre Facilities Manager,"STARHUB GREEN, 67 UBI AVENUE 1 408942","Permanent, Full Time",Manager,15 years exp,"Engineering, Telecommunications",Monthly,"$7,000to$10,000","Job Title: Data Centre Facilities Manager
Job Description
Purpose:

Lead a Data Centre team to operate and maintain our critical DC infrastructure and facilities, and ensure 100% availability of services
Comply with all SLAs, including legal, budget and audit requirements
Manage stakeholders and achieve corporate KPIs including Sustainability award, Green Mark certification, etc

Responsibilities

Lead a DC team to operate, maintain, ensure 100% availability of all critical facilities and associated equipment (ie M&E, fire safety, plumbing, ACMV, security)
Comply with agreed SLAs, legal, budget, audit requirements
Plan and recommend work plans, including resource efficiency, preventive maintenance programs, sustainability framework, to ensure they are equipped to deliver short and mid-term objectives in the most cost effective and simplified manner
Manage other stakeholders to implement the approved strategies in a timely and proper manner
Develop and review DC operating policies, SOPs and Emergency Operating Procedures; Implement service improvement programs
Manage all onsite operational incidents and major issues; Lead incident investigations and change management processes, and minimise impact to customers’ services including any change management activities
Prepare and present periodic reports for management reviews and meetings
Carry out vendor evaluations; review and recommend budget plans in compliance with procurement policy for replacement parts, equipment, etc
Review and advocate safe work procedures, risk management practices, and adhere with safety laws and regulations
Lead all FM/ DC-related certifications, ensure compliance by internal and external customers
Ensure satisfactory customer experiences at all times, including project planning, design and implementation

Qualifications

An appropriate qualification in Engineering, with at least 15 years of relevant experiences in a 24x7 critical infrastructure/ DC/ telco environment
Demonstrated experiences in managing and mentoring a team of Engineers/ Specialists to achieve strategic and operational goals
Possesses relevant DC and/or FM related certifications, such as CDCP, CDCS
Familiar with certifications standards, such as LEED Gold, ISO 20000 / 22301 / 27001, TIA 942, Uptime Institute Tier III, Green Mark, etc
Hands-on experiences and knowledge in M&E and building related systems, eg CRAU, chillers, PDU, UPS, Switch Gears Ops, DX cooling, Network structure cabling, Security
Lead major DC activities during non-office hours where appropriate
Proven stakeholder/ vendor management skills and collaboration abilities with cross functional teams
Proficient with MS Office tools
","['Fire Safety', 'Sustainability', 'LEED', 'Preventive Maintenance', 'Vendor Management Skills', 'ISO', 'Risk Management', 'Project Planning', 'Procurement', 'Gold', 'Advocate', 'Cabling', 'TIA', 'Audit', 'Facilities Management']"
 , , , , , , , , , 
Senior Data Architect,"21 COLLYER QUAY, 21 COLLYER QUAY 049320",Permanent,Manager,5 years exp,Others,Monthly,"$8,000to$16,000","Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/en-US/amplifyhealthexternal/job/Senior-Data-Architect_JR-35656
What you will do?
The role entails designing the architecture for the data platform layer, data cleansing layer, reporting and analytical layers within a cloud environment. Work closely with Data Scientists to understand model features and link back to transactional environment to understand data quality, data relationships and data availability. Document and define frameworks with the Data Engineer to build the data platform. Together these teams will enable data driven actionable insights.
The role is based in Singapore.
Core responsibilities include:

Provide Data Architecture (DA) support for the Data Engineering team
Define DA for the Data Science teams and participate in review and walk-through sessions for model fit and model productionization
Assist with the definition of custom meta data models for ELT/ETL
Direct data automation capabilities with the Data Engineer and Data Scientist
Profile new data sources in a variety of formats including Json, XML, etc
Define data quality rules with Data Scientists to clean data
Define data mapping and transformation rules between source and datawarehouse and data lake
Work closely with Data Engineer to facilitate Data Governance including access and security control
Documentation of DA for new data sources, metadata and productionized information flow
Knowledge of Master Data design and implementation
Define data sharing architecture and framework for data ingress and egress

What skills do you need?
Behavioural skills

A passion for programming and working with data
Self-starter
Willingness to learn and grow exponentially
A restless curiosity in learning new technology
Ability to work cohesively in a team environment and balance multiple priorities
A team player who can work alone when required and without supervision
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude
Ethical and able to maintain confidentiality and manage boundaries

Technical understanding

Advanced to expert knowledge in SQL - on any database platform
Advanced to expert data architecture and data model design eg DataWarehouse, Data Lakehouse, Data Mesh, Data Vault
Experience working on large and complex datasets
Working with design tools eg Enterprise Architect, Power Designer
Working with Data teams to design and implement solutions
Advanced knowledge working with technologies on MS Azure
DevOps/DataOps and CI/CD experience

Qualifications
The following requirements are essential:

Honours or Master’s degree in BSc Computer Science
Honours or Master’s degree in Engineering or Software Engineering with solid experience in data mining and machine learning
Other qualifications will also be considered if accompanied by the relevant experience
5 to 10 years of experience is preferred
","['Machine Learning', 'JSON', 'Data Sharing', 'Predictive Analysis', 'Architect', 'Data Quality', 'Data Governance', 'Data Design', 'Data Engineering', 'Data Mining', 'SQL', 'Attention to Detail', 'Data Architecture', 'Data Science', 'Metadata']"
 , , , , , , , , , 
Data /  Social Media Analyst,61 TAI SENG AVENUE 534167,Full Time,Non-executive,3 years exp,Advertising / Media,Monthly,"$2,800to$3,200","Transforming raw data into meaningful insights through the following:

Measure and analyze activity with data-driven insights
Build reporting dashboards and working the teams to provide statistics or business data that can help to drive business insights for the company
Data analyst to deliver insights, reports, visualization and analytics to solve business problems and optimize growth opportunities
Be passionate about working with multiple sources data to define
Perform deep dive analysis in relation to social media/KOL stats and conduct ad-hoc analyses to support cross functional projects
To be well versed with excel and other data analytical tools are a plus

BAU Business as Usual

Collect data and analyze the growth of Titan Digital Media’s YouTube, TikTok, and Instagram uploads and creators under the Titan Creator Network on a weekly basis through quantitative and qualitative analysis
Track and monitor content across Titan Digital Media Channels
Strategize new ways to increase channels’ viewership and engagement
Identity habits of target audience and channels
Research on emerging trends across various social media networks

Client Campaigns

Perform research to gain an in-depth understanding of clients and their customer profiles
Provide comprehensive post-campaign reports through quantitative and qualitative analysis

Reports to Churn Out:

Weekly/Monthly Growth of Channels and Videos
Post-Campaign Reports - 7Day and 30Day
Ad-hoc project reports


Only open to Singaporean/PR","['Tableau', 'Market Research', 'Producing', 'Microsoft Excel', 'Data Analysis', 'Process Improvement', 'Mathematics', 'Linguistics', 'Data Governance', 'SQL', 'Python', 'Statistics', 'Data Analytics', 'Databases', 'Data Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Snr Data Engineer,"ST ENGINEERING HUB, 1 ANG MO KIO ELECTRONICS PARK ROAD 567710",Permanent,Senior Executive,4 years exp,Engineering,Monthly,"$4,000to$7,000","Participate in the design, development, and testing of an open architecture, open source based, and cloud native data analytics platform product • Explore and evaluate modern data management and MLOps components for continuous improvement of data analytics platform product • Contribute to the design and integration of data management & data governance capabilities for the product • Establish best practices and guidelines to be followed by engineers working on data pipelines • Assist in the setup and maintenance of big data, machine learning and Kubernetes clusters • Work with Data Scientists, Data Analysts, and other internal stakeholders to assist with datarelated technical issues and support their data pipeline infrastructure and data preparation needs Job Requirements: • Bachelor or Master’s degree computer science, software engineering, information systems or related field. • The candidate should have at least 5 years of technical experience in Information Technology with at least 2 years, preferably 2 years in Big Data, Data Warehousing or Business Intelligence technology with knowledge of analytics and AI technologies • Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in Hadoop based technologies such as HDFS, Hive, Spark, Kafka etc. • Deep understanding of relational, NoSQL, NewSQL database technologies such as PostgreSQL, Oracle DB, CitusDB, SingleStore, Cassandra, MongoDB, Neo4J etc. • Good knowledge in programming languages such as Java, Python or Scala on Linux/Windows platforms. • Experience in Kubernetes and Kubeflow is a plus point • Experience in Big Data visualization and reporting software. • Experience in designing ETL/BI solutions. • Experience in DevOps and DataOps • Familiar with Linux/UNIX system administration • Experience in operational support in delivering Big Data solutions. • Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job.","['Machine Learning', 'MongoDB', 'Scala', 'Big Data', 'Pipelines', 'Hadoop', 'Data Management', 'Software Engineering', 'Cassandra', 'Data Governance', 'Open Source', 'Python', 'Java', 'Data Analytics', 'Data Warehousing', 'Data Visualization']"
Data Consultant,"OUE Downtown Gallery, 6A Shenton Way 068815",Full Time,Junior Executive,1 year exp,Consulting,Monthly,"$5,950to$7,854","Key Areas of Responsibility

As a Consultant, your typical day will be focused on:
● Deliver the highest standards of quality on your projects;
● Ensure the highest level of quality of output to your clients.
● Analyze complex information, synthesize and produce clear written outcomes and recommendations
● Collaborate across different team such as data scientist and data software engineer to come up with the best possible solution for our client’s need
● Generate, manage and deliver project deliverables in a timely manner
● Develop a sustainable relationship with our client
A big difference compared with other consulting firms is that you will be working closely with the data scientists and data engineers to use big data analytics to crack the toughest Executive level problems.

Competences & Skills

● Undergraduate degree or above with outstanding record of academic achievement is required;
● You have demonstrated success in your first year of career at a tier 1 consulting firm, with functional knowledge or passion in Digital Technology, eCommerce, IT strategy consulting, etc;
● Demonstrated aptitude for analytics;
● Fresh graduates are welcome to apply.
● Ability to work collaboratively in a team environment;
● Ability to work effectively with people at all levels in an organization;
● Skills to communicate complex ideas effectively;
● Fluent in English is a must.","['Management Consulting', 'Web Services', 'Classroom', 'Big Data', 'Hadoop', 'Business Acumen', 'ETL', 'Predictive Analytics', 'Brand Equity', 'Revolution', 'Data Science', 'Consulting', 'IT Strategy', 'Data Visualization']"
Data Collection Analyst,"ONE GEORGE STREET, 1 GEORGE STREET 049145",Permanent,Junior Executive,1 year exp,Banking and Finance,Monthly,"$3,500to$5,500","About EDHEC Business School
EDHEC Business School, one of Europe’s leading business schools and a member of the select group of institutions worldwide to have earned all three international academic accreditations (AACSB, EQUIS, AMBA). Since 2001, EDHEC Business School has been pursuing an ambitious policy in terms of international research. This policy, known as “Research for Business”, aims to make EDHEC an academic institution of reference for the industry in a small number of areas in which the school has reached critical mass in terms of expertise and research results.

About the EDHEC Singapore Infrastructure Investment Institute
The creation of the EDHEC Singapore Infrastructure Investment Institute springs from the past 4 years of research on infrastructure investment at EDHEC-Risk Institute and the continuous support of the Monetary Authority of Singapore in supporting cutting hedge research that can bring new and valuable knowledge to institutional investors, asset managers and regulators. Based in Singapore, EDHEC infra aims to create a global repository of financial knowledge and investment benchmarks about infrastructure equity and debt investment, with a focus on delivering applied research in finance for investors in infrastructure. We aim to deliver the best available estimates of financial performance and risks of reference portfolios of privately held infrastructure investments, and thus provide investors with important insights about their strategic asset allocation choices to infrastructure, as well as support the adequate calibration of the relevant prudential frameworks. EDHEC infra benefits from unparalleled access to the financial data of infrastructure projects and firms, especially private data, that is either unavailable to market participants or too cumbersome and difficult to collect and aggregate. We also bring advanced asset pricing and risk measurement technology designed to answer investors’ information needs about long-term investment in privately held infrastructure, from asset allocation to prudential regulation and performance attribution and monitoring.
EDHEC Singapore Infrastructure Investment Institute, part of EDHEC Business School is looking for an analyst to help develop a database of infrastructure project financial statements under the supervision of the Institute’s Head of Data Collection (ACCA).

The position
This is an opportunity for recent graduate with accounting, finance or economics majors to develop in-depth knowledge of infrastructure projects and the financial arrangements that support them. Beginning with the analysis and input of financial statements, the role will require research and analysis of infrastructure projects, and companies with a focus on collecting and updating financial data in the largest worldwide database of unlisted infrastructure assets.
The candidate must be detail oriented with a willingness to learn. An understanding of financial accounts is desirable and willing to spend time reading detailed project documentation to extract the relevant information and populate a data file. Prior knowledge of Microsoft Office Suite is essential. Knowledge of a European language would be an advantage.
This is a full-time, on-going position.
Remuneration is competitive and includes a bonus for meeting performance objectives.
Attractive salary and bonus, healthcare and pension plan coverage.
The salary will be determined according to EDHEC's pay scale, the candidate's qualifications and experience.
To apply for this offer, please send a CV and a cover letter to: recruitment@edhec-dbd.com.
To know more about EDHECinfra: https://edhec.infrastructure.institute/mission","['Forecasting', 'Microsoft Office', 'Asset Allocation', 'Data Analysis', 'Analytical Skills', 'Investment Analysis', 'Investments', 'Variance Analysis', 'Data Quality', 'Financial Accounting', 'Economics', 'Estimates', 'Accounting', 'Attention to Detail', 'Financial Statements', 'Financial Analysis', 'Data Analytics', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Coordinator,"Cavendish, 85 Science Park Drive 118259","Permanent, Full Time",Junior Executive,1 year exp,"Admin / Secretarial, Healthcare / Pharmaceutical, Sciences / Laboratory / R&D",Monthly,"$2,800to$4,000","Job Description

Track case report forms;
Clean and update the clinical database, which includes generating and resolving data clarifications;
Reconcile clinical data
Maintain study documentation
Perform QC audits of the clinical database


Job Requirements

Bachelor's degree in a health related field with strong attention to detail and working knowledge of Excel and Word
1-2 years of experience in a pharmaceutical or CRO setting preferred
Knowledge of medical terminology is preferred; and
Able to work on rotational Saturdays and Public Holidays
","['Microsoft Office', 'Microsoft Excel', 'Verbal Communication', 'Strong Attention To Detail', 'CRO', 'Interpersonal Skills', 'Translating', 'Medical Terminology', 'Data Entry', 'Clinical Trials', 'Database Administration', 'Attention to Detail', 'Audits', 'Flash', 'Excel', 'Databases']"
Information Technology - Senior Data Sciences & Analytics Engineer (Data Science Track),"TechSQ, 722 Upper Changi Road East 486854","Permanent, Full Time",Professional,2 years exp,Information Technology,Monthly,"$5,000to$10,000","Job Description
SIA Group has multiple positions for senior data scientists to drive our AI, data science and business analytics initiatives. Responsibilities include the following:

Member of the in-house AI and data science development team that works on challenging problems in machine learning (including NLP, computer vision and recommender system using deep learning methods), mathematical optimization, game theory, and experimental design.
Work closely with business stakeholders to create impactful and intelligent features/services in AI, data science and data analytics. Propose and build scalable ML/DL solutions. Deploy them as API microservices for use by software applications and business users for faster and more effective decision making.
Oversee the technical work of external technology partners and provide them datasets to deliver products/services in AI and data science. Support business users in the assessment/ validation of partner-supplied prediction models and in their deployment to production cloud.
Help business units create Tableau dashboards with relevant datasets. Extract insights through data visualization.
Work closely with application development teams to help them operationalize and integrate AI/ML capabilities to their software systems.
Note: You could be posted to any subsidiary in SIA Group.

Requirements
BS in Computer Science, Mathematics, Statistics, Physics or related discipline is required. PhD and MS degrees related to machine learning and other AI disciplines are preferred.
Advanced programming skills in Python. Conversant with algorithm design/analysis, data structure and SQL. Familiarity with functional/object-oriented software development using modern programming languages such as Scala, JavaScript, Java and C# is a plus.
At least 2 years of relevant industry experience in two or more of the following areas:


At least intermediate-level hands-on skills in shallow machine learning or information retrieval. Some exposure to GPU-accelerated deep learning frameworks (such as TensorFlow and PyTorch) for more advanced AI work is a plus.
Knowledge and working experience in workflow, map-reduce or stream processing systems such as Spark and Kafka.
Familiar with Bayesian statistics and inference. Exposure to the application of Bayesian and causal networks for probabilistic reasoning is a plus.
Knowledge and working experience with data visualization tools like Tableau or Power BI.



Some hands-on experience with AWS, GCP or similar public cloud environment.
Excellent interpersonal & communication skills for working with both technical staff and non-technical business users.
Experience with Agile/Scrum/Kanban methodologies is a plus.
","['Tableau', 'TensorFlow', 'Machine Learning', 'Scala', 'Physics', 'Mathematics', 'Computer Vision', 'Python', 'Business Analytics', 'Statistics', 'Data Science', 'Java', 'Data Analytics', 'Power BI', 'Data Visualization']"
"Operations Analyst II, Data Services (Market Data)","MILLENIA TOWER, 1 TEMASEK AVENUE 039192",Full Time,Professional,3 years exp,Banking and Finance,Monthly,"$5,100to$5,800","TD Bank Group
Headquartered in Toronto, Canada, with more than 90,000 employees around the world, the Toronto-Dominion Bank and its subsidiaries are collectively known as TD Bank Group (TD). TD offers a full range of financial products and services to over 27 million customers worldwide through three key business lines:

Canadian Retail including TD Canada Trust, Business Banking, TD Auto Finance (Canada), TD Wealth (Canada), TD Direct Investing and TD Insurance
U.S. Retail including TD Bank, America’s Most Convenient Bank, TD Auto Finance (U.S.), TD Wealth (U.S.) and TD’s investment in Schwab
Wholesale Banking including TD Securities

TD had CDN$1.9 trillion in assets on October 31, 2022. TD also ranks among the world’s leading online financial services firms, with more than 15 million active online and mobile customers. The Toronto-Dominion Bank trades on the Toronto and New York stock exchanges under the symbol ""TD"".
In Singapore, TD operates as The Toronto-Dominion Bank, Singapore Branch and Toronto Dominion (South East Asia) Limited, which are collectively known as “TD Singapore” since 1979. The key business in Singapore is TD Securities which is part of Wholesale Banking.
Department Overview:
Global Operations and Business Services is a diverse and dynamic group of individuals, whose varied talents and experiences enable us to provide critical infrastructure services that support and/or control the trading, investment, and corporate banking functions of TD Securities. We are committed to innovation with purpose, execution with excellence, and continually improving the employee value proposition. We foster a culture of diversity, inclusion, and community giving. Our dynamic team is divided into four main functional areas: Capital Markets, Financing Operations, Payment and Correspondent Banking Services and Business Services.
The Global Operations team partners with the front office and other groups globally to mitigate risk and deliver world class service to our global client base. They provide operational support and control functions across the trade lifecycle. The team is heavily involved in new product initiatives and process improvements to streamline our support model. They take great pride in ensuring controls are being continuously reviewed and updated while focusing on the customer at every point of contact.
If you are industrious, collaborative, innovative, and enjoy visionary thinking, while also maintaining a commercial view on the market, joining our team could be an ideal opportunity for you.
Role Details:
The Data Services team supports all business divisions located in Singapore (Foreign Exchange, International Fixed Income, Funding, Global Precious Metals, Trade Finance and Equity Derivatives), on a cross functional basis, by performing the setting up and handling of client data, credit lines, settlement instructions (SSI's), inventories and security data, and also the uploading and managing of market data. We play a key role in ensuring that the Global Data Control team, operate effectively, under a Global Delivery Model (GDM).
Job Accountabilities:

Responsible for the daily cleansing, analysis and maintenance of MVP data in the Asset Control system and for the accuracy of the same data within the source systems.
Ensure instruments are set up accurately on TD Securities source systems in a timely manner
Ensure that all late or missing market data uploads and related process metrics are recorded, documented and explained appropriately.
Contribute to the broader Global Operations and Business Services group as a subject matter authority on market data
Contribute to business objectives for operational excellence – identify, suggest and actively participate in improving standards, policies, procedures, and solutions
Actively participate in developing, testing and implementing new or enhanced processes and other process improvement initiatives
Provide accurate and thorough analysis of key process drivers, root or systemic causes of cross functional operational issues, interpret findings and make recommendations
Ensure internal control processes are adequate and documented appropriately
Conduct Business Acceptance Tests for system upgrades and patch releases
Handle first level escalated issues and provide work guidance as a resource to others
Contribute to the production of consolidated or aggregated reporting as appropriate
Coordinate with partners on key initiatives and may act as a project lead/subject matter expert for small-scale projects/initiatives in accordance with project management methodologies

Candidate Requirements:

At least 3 years of Market Data experience in a middle or back-office function with reporting responsibilities and exposure to various traded securities and derivative products.
Market knowledge and a general understanding of the fundamentals of valuation
Exposure to operational metrics and emerging regulations would be an asset.
Self-motivated, well organized and positive attitude.
Ability to prioritize multiple tasks and deliver results in a fast-paced environment.
BBG and Reuters knowledge would be an asset
Ability to work individually as well as part of a team.
Excellent analytical skills.
Excellent interpersonal skills both verbally and written
Ability to adhere to strict deadlines and handle high volumes of work in a demanding environment.
Strong knowledge of Microsoft Excel

Inclusiveness:
At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.","['Front Office', 'Operational Excellence', 'Process Improvement', 'Valuation', 'Wholesale Banking', 'Securities', 'Trade Finance', 'Capital Markets', 'Business Services', 'Visionary Thinking', 'Equity Derivatives', 'Foreign Exchange', 'Fixed Income', 'SSIS', 'Ability to Prioritize']"
Data Infrastructure Engineer,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,5 years exp,Information Technology,Monthly,"$6,500to$10,500","Income is looking for a Data Infrastructure Engineer to join our Data Engineering team in Singapore. Our team owns and runs the Enterprise Datalake used by thousands of users and hosted across AWS, GCP and On-Premises servers.
As a Data Infrastructure Engineer, you will design, build, maintain and improve our data infrastructure on Cloud, which enables us to make Income data driven organisation. In this role, you would also get the opportunity to work with world-class big data and cloud services, such as: AWS/GCP, Glue, Spark, DBT, Airflow, Tableau and PowerBI.
Responsibilities

Work with data engineering and machine learning teams to improve our data infrastructure for increased reliability, maintainability, and scalability.
Architect and design solutions to improve our data delivery capabilities, data quality monitoring, and data pipeline lifecycle.
Architect and administer our cloud applications such as AWS Glue, Sagemaker, LakeFormation, Iceberg Lakehouse, etc.
Managing Regression Testing Suite, Continuous Integration and Continuous deployment Pipelines.

Qualifications

Bachelors Degree in Computer Science, Information Technology or other relevant fields
5 years of designing and building Large Scale Infrastructure and ETL deployment and management pipelines using Terraform, Jenkins, AWS CodePipeline and AWS CodeBuild.
Broad experience in SQL and Python.
Hands-on experience of writing, building and deploying Containerised applications using ECS or EKS or GKE.
Experience in cloud application architecture & administration in AWS with the stacks such as: EC2 instances, Glue, Terraform (build & manage script), Jenkins, CodePipeline, CodeBuild, RDS (PostGres) instances, S3, Airflow
Experience in Deployment and implementation of AWS Glue with basic knowledge of SQL and Python - able to read and understand.
Hands-on experience designing, building, and operationalizing large-scale enterprise data solutions and applications.
Background in in custom ETL design, implementation, and maintenance.
Hands-on experience with strong exposure to AWS CLI and BOTO3 Python libraries.
","['RDS', 'Big Data', 'AWS', 'SageMaker', 'Information Technology', 'EC2', 'Data Engineering', 'PowerBI', 'SQL', 'Python', 'S3']"
Real Estate Data Analyst,"SUNTEC TOWER TWO, 9 TEMASEK BOULEVARD 038989",Permanent,Professional,2 years exp,Information Technology,Monthly,"$4,500to$6,000","The Data Analyst will be involved in analyzing various sources of data and writing efficient code to cleanse data and implement complex business logic as needed. The data analyst will have opportunities to work on various cutting edge data science projects that provide data-driven insights to business in the areas of business growth, risk management, productivity etc.

Specific Responsibilities:

Assist in analysing data, loading and cleaning data from different sources
Work closely with business users to interpret business requirements and codify the requirements into business rules.
Conducting assessment and examination of data from the source to ensure consistency
Provide insights through data visualization and presentations to deliver productivity, identify root cause of a situation and to provide actionable insights.

Competencies

Programming skills (python, sql)
Enhance problem solving skills using hands on data analysis
Excellent Excel skills
A good story teller on providing insights
Ability to work independently and as a contributing team player with good interpersonal and communication skills.

Qualification

Degree in Computer Science, Statistics, Data Analytics, or related disciplines;
","['Tableau', 'Data Analysis', 'Ability To Work Independently', 'Property', 'Risk Management', 'Python', 'Financial Modelling', 'Writing', 'Statistics', 'Data Science', 'Team Player', 'Real Estate', 'Data Analytics', 'Data Visualization', 'Business Requirements']"
Real Estate Data Analyst,"61 ROBINSON, 61 ROBINSON ROAD 068893",Contract,Senior Executive,4 years exp,Information Technology,Monthly,"$5,500to$7,500","Salt is looking for an Analyst who will support a leading client's APAC RE Planners to gather data from various sources, inspect, clean and model the data to discover useful information that the business needs, including structuring their findings into easy-to-read reports, presentations and dashboards.

On a daily basis, the Business Analyst will be expected to:
· Gather data from various sources, review and curate into meaningful metrics, insights and create visualizations for analysis, presentations, reports and dashboards
· Identify, track down and resolve data quality and code issues to ensure that databases and dashboards remain error-free and organized
· Prepare data model, regular management reports, analysis and quarterly performance metrics
· Maintain trustworthy and reliable forward-looking forecast data; strong commitment to accuracy and thoroughness in all aspects of data collection and curation
· Define, develop & document business processes and procedures to improve administrative efficiency
· Support Planners on other adhoc requirements such as forecasting and supply planning.

Skill/Experience/Education
Mandatory4 - 5 years working knowledge and experience with data, databases, reporting, or similar (will consider great candidates if they have 2 years of experience) Advanced spreadsheet skill and familiarity with management reporting. Intermediary SQL skill and familiarity with data modelling. Strong analytical, troubleshooting and data / information organizational skills.   Strong design and development skills with meticulous attention to detail. Strong communication and business partnering skill. Bachelor’s degree in a quantitative field, prior corporate real estate experience is a plus.

(CEI No: R1654663 / EA No: 07C3147)","['Forecasting', 'UAT', 'Troubleshooting', 'Microsoft Excel', 'Data Analysis', 'User Stories', 'Business Analysis', 'Data Quality', 'SQL', 'Attention to Detail', 'Banking', 'Business Analyst', 'Databases', 'Corporate Real Estate', 'Business Requirements']"
Technical Data Steward (IFRS 17),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,3 years exp,Information Technology,Monthly,"$4,500to$8,500","As a part of IT Data team, the candidate will be responsible to support data management activities in Income. You will be supporting Insurance Data Domain Systems, the job responsibilities includes:

Analysing data

1. Clean databases to remove duplicated, outdated, or irrelevant information
2. Develop solutions and recommendations to address information needs
3. Gather data from internal systems and external sources
4. Mine data to identify trends, patterns, and correlations
5. Perform data validation and quality control checks

Identify business needs

1. Recommend types of data and data sources needed
2. Support the translation of business needs into analytics and data requirements
3. Work with stakeholders to define business and information needs

Provide technical advisory and support to Income’s Data Steward in the execution of data management activities to comply with data governance policies and guidelines.
Create and maintain technical data documentation.
Provide the technical expertise around source systems, extract, transform, and load (ETL) processes, data stores, data warehouses, and Business intelligence tools.
Explain how a system or process works/doesn’t work.
Check code, SQL, internal database structures, and other programming constructs in search of how the information is structured, how the data moves, and how the data transforms within Data Lake or between systems.
Assist in identifying where business data elements are physically implemented in a system.
Business Needs Analysis - Work with stakeholders to analyse, design and implement technical solutions to resolve data issues or fulfil data requests

Requirements:

Minimum Diploma in computer science related area
At least 3 years hands-on experience in data management or a related field as Data Analyst
Data Engineering – able to write SQL scripts and stored procedure
Good verbal and written communication skills with strong stakeholder management skills
Highly organised, adaptable, meticulous with a strong sense of responsibility and ability to follow-through
Insurance domain knowledge or/and, experience in Impala/HUE and Data Governance is added advantage.
Good knowledge of Data Storytelling and Business Needs Analysis skills
","['Tableau', 'Data Analysis', 'Data Management', 'ETL', 'Data Quality', 'Business Needs Analysis', 'Data Mining', 'SQL', 'Power BI', 'Data Visualization']"
Data Analyst (MNC  /  West),75 AYER RAJAH CRESCENT 139953,Permanent,Senior Executive,3 years exp,Others,Monthly,"$3,000to$3,800","Job Responsibilities:

Lead and execute      Digital Transformation projects for process improvement
Participate in      business processes analysis to gather reporting and dashboard requirements
Translate business      requirements into technical specifications and develop data download from      multiple data sources
Develop a deployment      test plan and ensure a successful transition to the business team
Provide technical      support to ensure the availability and performance of developed reports      and dashboards for users
Design and implement      technology best practices with given guidelines
Able to perform      duties independently with minimal supervision

Job Requirements:

Bachelor’s Degree in      Information Technology or Business Analytics
Experience working      with users in requirements gathering & analysis role
Understanding of      data integration issues (validation and cleaning), familiarity with      complex data and structures
Understand the      concept of a digital control tower (Visibility, Alerts, Analytics &      Autonomous)
Experience with Blue      Prism, UFT, Power BI, Power Apps, Automated Flow, and other RPA tools
Experience in      Microsoft SQL, Post SQL, stored procedures, SSRS, SSIS Job package, Python
Excellent      interpersonal (verbal and written) communication skills to lead and work      on projects
Ability to manage      multiple priorities, and assess and adjust quickly to changing priorities


Janet Lim Chia Ee
EA License: 11C2878
EA Registration No: R1981865","['Requirements Gathering', 'Dashboard', 'Process Improvement', 'Data Integration', 'Information Technology', 'Microsoft SQL', 'SQL', 'Business Analytics', 'Uft', 'SSIS', 'Power BI', 'Business Requirements', 'SSRS', 'Technical Support']"
"Vice President, Data Engineering",78 AMOY STREET 069897,"Permanent, Full Time",Senior Executive,6 years exp,"Banking and Finance, Consulting",Monthly,"$7,000to$14,000","Responsibilities:

Work with clients to solve business problems in fraud, compliance and financial crime and present project results
Manage, transform, and cleanse high volume data
Automate data processing to enable on-going alerts on high-risk activity
Work very closely with data scientists to ensure efficient and effective delivery of solutions
Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients on their sites
Use emerging and open-source technologies such as Spark, Hadoop, and Scala
Collaborate on scalability issues involving access to massive amounts of data and information
Guide junior consultants in the best practices of data engineering

What we’re looking for:

At least 6 years of experience working in the Financial Services sector on big data project implementations
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines
Strong coding experience in the likes of Scala or Java
Coding experience using Python
Client facing experience, good communication and presentation skills
Bachelor’s Degree in Computer Science, Physics, Mathematics, or similar degree or equivalent
Enthusiasm to learn and develop emerging technologies and techniques
Strong technical communication skills with demonstrable experience of working in rapidly changing client environments
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies

It’s a bonus if you have:

A background in AML, KYC, screening, regulatory compliance or fraud is highly advantageous
Have worked on a variety of complex data orientated projects for financial services clients
Have a good understanding of computer science and preferable come from a software engineering background or other scientific degree incorporating IT modules (e.g., Math/Physics)
Have exposure to Agile, especially SCRUM
Ability and willingness to travel
Experience working with a variety of modern development tooling (e.g., Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g., Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting)
Have an excellent appreciation of what makes a high quality, operationally stable system and how to streamline all areas of development, release and operations to achieve this

Benefits

Snacks & Drinks
Health Insurance
Robust Career Path
Academy Program with Buddy-Mentor

WE

Want to transform what banking means with you!
Are inclusive and diverse
Are committed to creating a flexible, supportive work environment that helps you effectively manage your work and family commitments
Embrace innovate-thinking and entrepreneurship in everything we do
Are award winning and known for our commitment to outcomes
Apply the latest tech and new ways of working
Support your personal growth

Apply by sending us CV and a short summary of you.","['MASSIVE', 'Big Data', 'Hadoop', 'Software Engineering', 'Agile', 'Scripting', 'Data Engineering', 'Python', 'AML', 'Java']"
Data Lead (Hadoop),30A KALLANG PLACE 339213,Full Time,Professional,8 years exp,Information Technology,Monthly,"$7,000to$11,000","Duties & Responsibilities:

Consult, design and build high quality data lake solutions for customers and internal teams
Design highly scalable and reliable data pipelines to consume, integrate, and analyse large amounts of data from various data sources
Perform data engineering to extract, transform, load for data science analysis
Create technical documentation for deployed systems
Carry out technical enablement for junior team members and sales
Support existing data lake environment as a subject matter expert
Identity, evaluate and recommend new technologies that would be relevant to big data analytics

Requirements:

Overall 8+ years IT experience, with at least 4+ years of production experience working with Hadoop and/or NiFi, data engineering
Hands-on experience with all aspects of developing, testing and implementing low-latency big data pipelines
Demonstrate production experience in data engineering, data management and/or cluster management
Experience designing data queries against data in the HDFS environment using tools such as Apache Hive
Experience in implementing MapReduce, Spark jobs
Experience setting up multi-node Hadoop clusters
Experience in systems administration or DevOps experience with one or more open-source operating systems
Experience implementing operational best practices such as alerting, monitoring, and metadata management
Strong understanding with various enterprise security practices and solutions such as LDAP and/or Kerberos
Experience using configuration management tools such as Ansible, Puppet or Chef
Familiarity with scripting tools such as bash shell scripts, Python and/or Perl
Experience with Apache NiFi is desired
Experience with writing to network-based APIs, preferably REST/JSON
Knowledge on Isilon storage, S3 file systems is added advantage
Ability to understand and translate customer requirements into technical requirements
Excellent verbal and written communications
","['Technical Documentation', 'Puppet', 'Systems administration', 'Hadoop', 'Data Management', 'MapReduce', 'Data Engineering', 'Ansible', 'Metadata Management', 'Apache']"
Big Data Developer,30A KALLANG PLACE 339213,Full Time,Senior Executive,2 years exp,Information Technology,Monthly,"$5,000to$10,000","Duties and Responsibilities:

Familiarize with Ensign’s business domain and objectives to develop and deploy big data analytics applications that meet internal business requirements and the needs of partners and customers
Lead the design, development, testing, deployment of efficient and reliable big data processing workflows
Design, develop, manage data warehouse architecture and relational databases
Provide monitoring, maintenance and support for system operations as part of M&S as required in commercial projects
Embrace the challenge of dealing with terabytes to petabytes of data on a daily basis
Manage different experimentation, development, staging, production environments to provide overall system functionality, health, scalability, resiliency, and security
Responsible for implementing and maintaining complex big data projects with a focus on collecting, parsing, managing, and analysing large sets of data to turn information into insights using multiple platforms
Deliver detailed documentation and ensure quality throughout project lifecycle

Requirements:

Bachelor’s degree in Computer Science/Information Systems/Computer Engineering or equivalent
Minimum 5 years of experience working on big data analytics development (e.g. Hadoop, Apache Spark, MPP DBs)
Good in-depth knowledge of Hadoop ecosystem (HDFS, Impala, Kafka, Spark, NiFi, Elasticsearch, etc.), associated tools and cloud-based technologies (e.g. EMR, Redshift, S3, etc.)
Extensive experience in programming (Python, Scala, Java) for data processing and analytics
Understanding of modern software engineering tools such as Git, Bitbucket, Jenkins, Maven
Highly proficient at reading, profiling, parsing, transforming, cleansing and integrating data from various sources (structured, semi-structured and unstructured)
Strong awareness of data security, data governance and performance, with an ability to deliver these key non-functional requirements
Excellent technical skills
","['Apache Spark', 'Big Data', 'Hadoop', 'Data Security', 'Data Governance', 'Technical Skillset', 'Python', 'Java', 'Data Analytics', 'Databases']"
 , , , , , , , , , 
Data Architecture and Governance,"SAMSUNG HUB, 3 CHURCH STREET 049483",Full Time,Manager,10 years exp,Information Technology,Monthly,"$13,000to$16,000","Who We Are
Revantage is a Corporate Services affiliate of The Blackstone Group, the world’s largest alternative investment firm. In Pursuit of Better, we deliver exceptional customer experiences to Blackstone and its portfolio companies that enable them to thrive. Revantage provides a highly skilled employee base and state-of-the-art technology to further our key focus on providing best in class Corporate Services to multiple Blackstone real estate portfolio companies. Sectors include Hospitality, Industrial, Multi-Family, Office, Retail, Senior Housing, and Manufactured Homes.
Revantage Asia, headquartered in Singapore, is one of three global offices that includes Revantage Europe and Revantage Americas.
What We Value: Our Culture
Creating a culture that inspires change and momentum requires the right team. We know what it takes to lead an industry, and are looking for leaders who seek constant growth, want to excel, and continuously improve upon themselves and the industry. The culture at Revantage is built on our shared core values and commitment to be:
· Leaders - We commit to continuously improve our performance.
· Learners – We learn from our challenges, successes and the diversity of our people.
· Achievers – We expect high standards for ourselves and enable the success of our teams.
· Enthusiasts - We face challenges with optimism and believe anything is possible.
· Partners - We deliver value and positive impact to our partners.
Why This Role Is Valuable
The Data Architect is responsible for creating, maintaining, and managing a data strategy aligned with business needs, reflecting best practices, and increasing option value for the organization. The position is required to interpret, use, and apply their knowledge and expertise in data architecture to inform a range of projects. The role is responsible for creating and maintaining data models and designing associated components related to data transformation, data quality, meta data management, reporting and analytics. The role is expected to ensure that the data, integration, and analytics architecture complies with overall portfolio standards and is designed for appropriate extensibility, security, and quality. The Data Architect also serves as a subject matter expert informing data governance initiatives.
They are expected to be committed, passionate, energetic, responsible and exhibit good judgement. They will have a collaborative spirit and ability to adapt to working with other technologists, business leaders and the larger community of portfolio company architects.
How You Add Value
(including but are not limited to)

Be comfortable to work within a start-up mindset/environment and be capable and willing to bring order and maturity to the environment.
Lead data architecture efforts to structure, integrate, govern, store, describe, model, and maintain data in the enterprise for optimal accuracy and usage
Lead and champions the deployment of a data and analytics platform that integrates varied sources of data with focus on delivering business value.
Be comfortable to leverage existing frameworks and methodology and working with multiple stakeholders to deliver initiatives.
Provide leadership, guidance and coordinate development and deployment of data and analytics related projects across development teams
Understand current enterprise data quality capabilities and strive for continuous improvement though the use of data quality dashboards and driving corrective actions with stakeholders
Play a leading role in establishing a data governance framework including ownership, governance committees, governance processes and enabling technologies
Work with data governance committee to help define data related policies and procedures and their enforcement
Champion the use of visual modeling tools (e.g., Sparx Enterprise Architect) for defining data architectures
Collaborate with wider portfolio community across APAC in sharing best practices, lessons learned. Constantly updates the data architecture based on evolving technologies and products.
Facilitate and deploy a master data management strategy across the APAC region
Take on the role of Data Privacy officer to review and provide guidance related to data privacy, security, retention and archival.
Understand and communicate data requirements related to future infrastructure needs, working with other IT architects (in-house, partners and vendors) to develop an approach that fits the current and planned needs of the organization.

What You Bring To The Role:
Required:

Experience in delivering Finance or ERP project
Create Operating Platform Model diagrams
Agile experience: Write Epics and Personas
Create detailed functional requirements, including acceptance criteria
Create detailed requirement for data transfer or interfaces
Design business processes via activity diagrams
Write and execute test cases that tie to design requirements
Thoughtful practitioner of multiple methodologies and frameworks
Vendor management experience
Project Management experience, including MS Project or similar
Organize own work and that of team

Important:

UML BPML knowledge and modelling experience
Create a Business Domain Model or Data Model
Create and manage testing plans
Capture bugs and enhancements requests
Experience with management consulting or system integrations
Experience in full life cycle of complex software deployment projects
Proficiency with Microsoft Office 365
Good practices for version control of artifacts

Desirable, but not required:

Collaborate with Technology Team to document some artifacts: Deployment Model and Sequence Diagram
Contribute to deployment plans
Experience in strategic planning and execution
Sufficient Six Sigma knowledge
Experience with Jira or similar
Financial or accounting knowledge
","['Vendor Management Experience', 'UML', 'Modeling', 'Architect', 'Data Transformation', 'Data Management', 'Architects', 'Data Integration', 'Data Quality', 'MS Project', 'Data Governance', 'Data Architecture', 'Master Data Management', 'Data Strategy']"
 , , , , , , , , , 
 , , , , , , , , , 
Principal Data Engineer,"ST ENGINEERING HUB, 1 ANG MO KIO ELECTRONICS PARK ROAD 567710",Permanent,Manager,8 years exp,Engineering,Monthly,"$7,000to$10,000","Participate in the design, development, and testing of an open architecture, open source based, and cloud native data analytics platform product • Explore and evaluate modern data management and MLOps components for continuous improvement of data analytics platform product • Contribute to the design and integration of data management & data governance capabilities for the product • Establish best practices and guidelines to be followed by engineers working on data pipelines • Assist in the setup and maintenance of big data, machine learning and Kubernetes clusters • Work with Data Scientists, Data Analysts, and other internal stakeholders to assist with datarelated technical issues and support their data pipeline infrastructure and data preparation needs Job Requirements: • Bachelor or Master’s degree computer science, software engineering, information systems or related field. • The candidate should have at least 8 years of technical experience in Information Technology with at least 4 years, preferably 6 years in Big Data, Data Warehousing or Business Intelligence technology with knowledge of analytics and AI technologies • Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in Hadoop based technologies such as HDFS, Hive, Spark, Kafka etc. • Deep understanding of relational, NoSQL, NewSQL database technologies such as PostgreSQL, Oracle DB, CitusDB, SingleStore, Cassandra, MongoDB, Neo4J etc. • Good knowledge in programming languages such as Java, Python or Scala on Linux/Windows platforms. • Experience in Kubernetes and Kubeflow is a plus point • Experience in Big Data visualization and reporting software. • Experience in designing ETL/BI solutions. • Experience in DevOps and DataOps • Familiar with Linux/UNIX system administration • Experience in operational support in delivering Big Data solutions. • Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job.","['Management Skills', 'Scala', 'Oracle', 'PostgreSQL', 'Big Data', 'Pipelines', 'Hadoop', 'Software Engineering', 'Cassandra', 'Data Governance', 'Open Source', 'Python', 'Visualization', 'Data Analytics', 'Data Warehousing', 'Data Visualization']"
"Executive, CRM & Data Analytic","PLUS, 20 CECIL STREET 049705",Permanent,Junior Executive,1 year exp,Marketing / Public Relations,Monthly,"$3,000to$4,000","CRM & Data Analytic

Assist in the formulation and execution of CRM marketing automation, journeys, and processes to achieve business efficiency.
Leverage CRM tools to analyse customer database, derive insights and execute recommendations together with cross functional team.
To be the data custodian for the brand. Maintain, monitor, and ensure customer database is updated in line with internal data quality policy.
Support leads assignment and monitor follow-up tasks closely by the sales team.
Generate and analyse CRM campaign result, draw insights and propose data-driven ideas and recommendations.
Identify and propose suitable target audiences / segments for sales / aftersales marketing campaigns.
Plan and build customer journeys in SFMC
Identify and extract target database on SFMC
Set up and schedule eDM blast
Customer Interaction Centre Management

Day-to-day operations

Leads assignment for Sales team.
Customer account creation for new leads.
Campaign tagging for customers account.
Customer profiling, data mining and customer need analysis
Assist with events such as sending of invitation, confirmation, registration and ensuring target attendance is met.
Track, generate and analyse weekly sales funnel and campaigns reports.

Job Requirements:

Diploma/Degree holders in Marketing / CRM / Business Administration.
1-2 years of Marketing/CRM-related experience.
Knowledge of CRM principles and customer journeys.
Meticulous and well-organised with the ability to multitask under pressure.
Takes initiative to lead projects and improve job processes.
Agile and keen to learn new skills.
Peoples oriented mindset.
Keen interest in CRM & Data Visulisation platform such as Salesforce, SFMC, GDMS and / or Tableau
Comfortable in CRM technical aspects such as integration, API and etc.
5 days week, Alexandra

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Kindly email your resume in a detailed Word format to ashley@peopleprofilers.com

We regret that only shortlisted candidates will be notified

People Profilers Pte Ltd
Tel: 6950 9753
EA Registration Number: R1111375
EA licence number 02C4944
EA Personnel: Lee Hui En Ashley","['CRM', 'Tableau', 'Ability to Multitask', 'Aftersales', 'BLAST', 'Customer Interaction', 'Formulation', 'Agile', 'Administration', 'Data Quality', 'Data Mining', 'Pressure', 'Python', 'API', 'Data Analytics', 'Customer Journeys']"
Principal data Scientist,"ST ENGINEERING HUB, 1 ANG MO KIO ELECTRONICS PARK ROAD 567710",Permanent,Manager,8 years exp,Engineering,Monthly,"$10,000to$13,000","The Data Analytics Strategic Technology Centre (DA STC) is a Corporate R&D centre for Data Analytics & Artificial Intelligence that aims to develop key data analytics technologies to support ST Engineering’s global growth plans across all our business sectors
Job Description:

Lead a team of researchers to explore and develop new or improved analytical techniques through both organic and collaborative R&D efforts
Develop POCs to demonstrate viability of DA/AI technologies for our different MRO businesses
Demonstrate research efficacy by publishing conference papers, journal articles and other means of asserting IP ownership
Work with our Group Engineering Centre and lines of businesses to translate research outcomes into commercially viable products or services

Requirements:

Master's or PhD in Science/Engineering/Mathematics with at least 8 years of working experience in research & analytical work in the MRO domain
In-depth technical knowledge and experience in any of the following:


Anomaly Detection
Forecasting
Computational Fluid Dynamics
Digital Twins
Computational Intelligence
Operations Research
Deep Learning
Social & Cognitive Computing
Knowledge Representation
Agent-based Simulation
Computer Vision
Behavioural Modelling
Interpretable/Explainable AI


Good experience with end-to-end analytics process – ideation/value elicitation, requirements definition, data profiling, analytical modelling, testing, validation, visualization, and solutioning
Strong problem solving skills and passion for artificial intelligence and data science research
Experienced in SQL (any flavour), Python, R, Matlab, Java, C++/ C
Experienced in preparing research papers using standard document preparation tools such as Microsoft Word or Latex
Familiar with distributed computing, modelling & simulation, optimization, and visualization tools
Excellent coordination and time management skills to handle complex projects
Willing and enthusiastic about continuous learning
","['Artificial Intelligence', 'Computer Vision', 'SQL', 'Publishing', 'IP', 'Python', 'Data Science', 'Visualization', 'Analytical Modelling', 'Microsoft Word', 'Analytical Techniques', 'Data Analytics']"
Assistant Principal Data Scientist,"ST ENGINEERING HUB, 1 ANG MO KIO ELECTRONICS PARK ROAD 567710",Permanent,Manager,8 years exp,Engineering,Monthly,"$7,000to$10,000","ST Engineering is an integrated Maintenance Repair and Overhaul (MRO) service provider. We offer solutions that optimise the life cycle of customer vehicle assets (air, land and sea), including maintenance to ensure equipment serviceability and smooth vehicle fleet operations.
The candidate shall be responsible for the application of Machine Learning techniques and Data Science-related technology in the area of Predictive Maintenance for various vehicular systems.
Job Description

Recorded vehicle-related (air, land and sea vehicles) sensor & defect report data understanding, cleansing, uploading to database.
Tap knowledge from vehicle domain experts and write SQL scripts to manage & query databases to extract & generate required data for analysis.
Compare & assess various machine learning methods to generate insights, detect anomalies and predict remaining useful life of vehicle components and engines.
Ability to implement the developed and tuned model(s) in SQL and/or C# is preferred.
Ability to develop dashboards to show the results for internal & external customers is preferred.

Requirements

Degree in Engineering or Computer Science or IT, with Data Science elective
At least 8 years work experience in Data Analytics, Python programming and SQL scripting
Good team player and communicator
Experience in developing web-based or Tableau dashboards and C# programming will be added advantages
","['Tableau', 'Biochemistry', 'Machine Learning', 'Analytical Chemistry', 'Overhaul', 'Predictive Maintenance', 'Biotechnology', 'Biology', 'SQL', 'Grants', 'Food Science', 'Data Science', 'Team Player', 'C#', 'Python Programming', 'Data Analytics']"
Assistant Principal Data Scientist,"ST ENGINEERING HUB, 1 ANG MO KIO ELECTRONICS PARK ROAD 567710",Permanent,Manager,5 years exp,Engineering,Monthly,"$7,000to$10,000","The Data Analytics Strategic Technology Centre (DA STC) is a Corporate R&D centre for Data Analytics & Artificial Intelligence that aims to develop key data analytics technologies to support ST Engineering’s global growth plans across all our business sectors
Job Description:

Lead a team of researchers to explore and develop new or improved analytical techniques through both organic and collaborative R&D efforts
Develop POCs to demonstrate viability of DA/AI technologies for our different MRO businesses
Demonstrate research efficacy by publishing conference papers, journal articles and other means of asserting IP ownership
Work with our Group Engineering Centre and lines of businesses to translate research outcomes into commercially viable products or services

Requirements:

Master's or PhD in Science/Engineering/Mathematics with at least 5 years of working experience in research & analytical work in the MRO domain
In-depth technical knowledge and experience in any of the following:


Anomaly Detection
Forecasting
Computational Fluid Dynamics
Digital Twins
Computational Intelligence
Operations Research
Deep Learning
Social & Cognitive Computing
Knowledge Representation
Agent-based Simulation
Computer Vision
Behavioural Modelling
Interpretable/Explainable AI


Good experience with end-to-end analytics process – ideation/value elicitation, requirements definition, data profiling, analytical modelling, testing, validation, visualization, and solutioning
Strong problem solving skills and passion for artificial intelligence and data science research
Experienced in SQL (any flavour), Python, R, Matlab, Java, C++/ C
Experienced in preparing research papers using standard document preparation tools such as Microsoft Word or Latex
Familiar with distributed computing, modelling & simulation, optimization, and visualization tools
Excellent coordination and time management skills to handle complex projects
Willing and enthusiastic about continuous learning
","['Dynamics', 'Artificial Intelligence', 'Computer Vision', 'SQL', 'Publishing', 'IP', 'Python', 'Data Science', 'Visualization', 'Analytical Modelling', 'Microsoft Word', 'Analytical Techniques', 'Data Analytics']"
 , , , , , , , , , 
Data Migration Analyst,"ANSON CENTRE, 51 ANSON ROAD 079904",Full Time,Senior Executive,5 years exp,Information Technology,Monthly,"$7,500to$11,000","Finance Data Business Analyst is key in defining, managing, and implementing changes within the organisation. The Business Analyst must elicit, analyse, refine, validate and formally document business requirements, so that optimal solution to the requirement can be identified and implemented. For smaller initiatives the Business Analyst will also play the role of Project Manager.

Key Accountabilities

Requirements Gathering:
Elicits Data Migration requirements from stakeholders, applying effective elicitation methods/ standards/tools.
Work with Finance SME’s from LBU’s and 3rd Party Vendors to define the scope of data extraction from various source systems
Work with Finance SME’s from LBU’s and SI Partner to define the scope of data requirements for the Target Applications.
Performs data analysis to cleanse & standardize data and to ensure data consistency and quality.
Work with Finance SME’s to Transform / Enhance the extracted data and prepare the data migration templates for Business Sign-Off
Work with the SI Team on error resolution for data uploads and facilitate data reconciliation and signoff’s from Finance SME’s post migration.
Performs gaps and resolutions analysis. Ensures requirements are complete.
Documents requirement/processes using industry standard notations.

Solution Assessment And Validation
Facilitates workshops sessions with internal and external stakeholders to drive out solution options and works closely with them to complete solution design documents.
Supports functional and integration testing.
Change Management And Implementation Support
Supports Change Management activities by providing information as required to facilitate effective communications.
Provides project support to the impacted teams during implementation phases, including answering queries, trouble shooting, liaison with service provider, providing regular reporting.
Contributes to project management processes, including status reporting, risk, issue, change, compliance management
For smaller projects acts as the project manager as well as BA to deliver the project.

Domain Specific Attributes
Must have at least 3 full lifecycle hands-on experience in preparing ADFdi, FBDI and HDL templates for Migration into Oracle Cloud Financials.
Working knowledge of Oracle Cloud Financial modules
Experienced in dealing directly with Finance End Users.
Proficient with data wrangling, analytics, and transformation using tools such as SQL, Excel, etc. Python is good to have.
Experience in data projects is a plus.","['Requirements Gathering', 'Oracle', 'Data Analysis', 'Change Management', 'Oracle Financials', 'Financials', 'SQL', 'Data Migration', 'Compliance', 'Project Management', 'Python', 'Excel', 'Business Analyst', 'Integration Testing', 'Business Requirements']"
Information Technology - Senior Data Sciences & Analytics Engineer (Data Engineering Track),"TechSQ, 722 Upper Changi Road East 486854","Permanent, Full Time",Professional,3 years exp,Information Technology,Monthly,"$5,500to$11,000","Job Description

We have multiple senior data engineer positions available in the Data Engineering team. The senior data engineer is a senior software developer with strong software engineering skills who is responsible for building custom open-source-based data ingestion and MLOps platforms. He/she has deep appreciation of the complexity of the data engineering process, such as the challenges of data ingestion involving large or near-real-time datasets, the maintenance of high data quality, and the importance of automation for increasing pipeline robustness and reducing the need for human intervention.

Responsibilities:

Be an effective distributed-system implementer in the following core activities:


Design and develop data engineering services and their ecosystem using distributed databases (relational, columnar, graph, in-memory); orchestration (Apache Airflow); and distributed stream/batch data processing (Kafka, Kinesis, Spark).
Design and develop MLOps production pipelines; provide technical support to data scientists/ML engineers by getting their ML/DL models deployed at scale and meeting SLAs on both cloud and on-premises GPU and CPU instances.
Design data models for mission-critical, high-volume, near-real-time/batch data; build idempotent/atomic production data pipelines to make data ingestion more fault tolerant.
Design and develop intuitive, highly automated, self-service data platform functions for business users.


Explore, evaluate and champion the introduction of next-generation technologies in the data-ingestion workflow. Participate in project planning and provide technical guidance on cloud architecture for data projects.

Requirements

BS in Computer Science or other related discipline is required. Advanced degrees in Computer Science (PhD, MS) are highly desirable.
3+ years of relevant industry experience in some or most of the following technical areas:


Advanced programming skills in Python. Conversant with data structures and algorithm design.
Experience in building data pipelines (including data collection, warehousing, processing, analysis, monitoring, and governance) using open-source data ingestion platforms.
Intermediate-level knowledge and experience with AWS cloud components and best practices. Good understanding in deploying data stores such as S3, RedShift, Elasticache, PostgreSQL, and ClickHouse.
Prior experience in modern software development is required (such as web frontend UI, backend API microservices, understanding of CI/CD and Scrum/Kanban agile development). Strong grasp on object-oriented or functional programming (using e.g. Python, Java, Scala, or C#).
","['Warehousing', 'Scala', 'PostgreSQL', 'Pipelines', 'ClickHouse', 'Data Structures', 'Data Quality', 'Project Planning', 'Data Engineering', 'Algorithm Design', 'Orchestration', 'S3', 'Apache', 'Agile Development']"
Data Center,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979","Contract, Full Time",Executive,1 year exp,Information Technology,Monthly,"$1,500to$3,000","Role: Data Center

JD:
Responsibilities

Rack, Build, cable, configure, and provision Intel and AMD Servers
Rack, cable, and deploy Cisco Layer 2 networking equipment
Troubleshoot, test, quality assurance of Server hardware
Professionally resolve hardware issues via trouble ticket
Desired Experience:
1 Years of experience
Experience in PC Hardware and Server Hardware (on Job training provided)
Operating System Installation - Windows Server, Linux, Unix
PC Assembly and HW troubleshooting
Understanding of basic hardware troubleshooting and applying logical methods of resolution
Basic Networking Knowledge
Experience with RAID levels is a plus
","['Switches', 'Asset Management', 'Troubleshooting', 'Hardware', 'Quality Assurance', 'Data Center', 'Inventory', 'VMware', 'SAN', 'Unix', 'Auditing', 'Windows Server', 'Networking', 'Cabling', 'Assembly', 'Linux']"
 , , , , , , , , , 
 , , , , , , , , , 
Head of Data,383 Sin Ming Drive 575717,Full Time,Manager,8 years exp,"Information Technology, Others",Monthly,"$13,000to$16,500","Responsibilities:


Apply your expertise in data science, statistical analysis, data mining and the visualization of data to derive insights that value-add to business decision making (e.g. hypothesis testing, development of MVPs, prototyping etc)
Work with stakeholders from different functions of PMG to architect and design analytics solution to meet business objectives
Develop an enterprise data science strategy to achieve scale, synergies and sustainability of model deployment across data team
Conduct analysis and cultivate on continuous improvement programmes to improve on quality, productivity and delivery
Undertake rigorous analyses of business problems on structured and unstructured data with advanced quantitative techniques
Building and developing data models, data automation systems, performance metrics, and reporting systems
Develop and train predictive / ML models using a diversity of machine learning tools and frameworks
Overseeing the delivery of insights and reports used for analyzing business functions and performance metrics
Provide strategic leadership and technical knowledge to data team


Requirements:

Master Degree or Degree in Computer Science, Data Analytics, Statistics or equivalent
8 years’ experience in quantitative analysis and data science (machine learning / predictive modelling) with at least 3 years of leadership / people management experience
Deep expertise in a range of ML concepts, frameworks and techniques such as logistic regression, clustering, dimensionality reduction, recommendation systems, neural nets etc.
Strong understanding of data infrastructure technologies (e.g. Spark, TensorFlow etc)
Familiar with data engineering methodologies, including SQL, ETL and experience in manipulating data sets with structured and unstructured data using Hadoop, AWS or other big data platforms
Proficient in data visualization and the use of dashboarding tools (e.g. Tableau, Power BI)
Experience with development or delivery of products and solutions with a focus on data driven systems
Experience with development of Data Models
Strong analytical and problem-solving skills
","['TensorFlow', 'Machine Learning', 'Big Data', 'Hadoop', 'Quantitative Analysis', 'Data Engineering', 'SQL', 'Statistics', 'Data Science', 'Decision Making', 'Data Analytics', 'People Management Experience', 'Data Visualization']"
 , , , , , , , , , 
Data Scientist,"THE CENTRAL, 6 EU TONG SEN STREET 059817",Permanent,Professional,2 years exp,Sciences / Laboratory / R&D,Monthly,"$6,000to$12,000","Overview
This position is responsible for researching and developing advanced algorithms with the knowledge of data science or optimization to solve the real problems in the manufacturing process. 

Roles & Responsibilities

Data Analytics: Multivariate time-series analysis, Forecasting models, Data mining, Pattern recognition
Optimization: Linear/Nonlinear Programming, Heuristic algorithms, Stochastic Process
Lead or participate in the project which aims for solving diverse problems from the automotive industry covering acquiring data, algorithm development, and system implementation
Drive research from concepts to feasible output to determine the viability of ideas that leverage the knowledge of data analytics or optimization. 
Acquire the state of the art technologies and present ways to use them for solving real-world problems
Operate and develop models/services deployed in the manufacturing process
Publishing papers in journals/conferences or applying for patents as a result of the research conducted							


Requirements

Bachelor's or Master's degree in Industrial Engineering, Computer Science, Mathematics, or equivalent practical experience 
At least two years of research or development experience in data analytics, or optimization
Research experience in the manufacturing industry is preferred but not required								
Experience in publishing papers or articles from the research practices
Programming skills to implement a novel idea and show their feasibility in the problem solving
Experience in the following: Regression/Classification/Clustering models, Large scale data analysis, Time series analysis, Forecasting models, or Kernel-based methods
Expertise in machine learning or data mining frameworks such as PyTorch, TensorFlow, Scikit-learn, or MLlib
Expertise in processing large scale datasets in distributed data frameworks (Hadoop, Spark, or Hive)
Experience in the following: mathematical modeling and algorithm development using Mathematical programming (Linear programming, Mixed-integer programming), (Meta)Heuristic algorithms, Stochastic Process, or Combinatorial Optimization
Expertise in mathematical programming solvers including GUROBI, or CPLEX							


About Hyundai Motor Group Innovation Center in Singapore (HMGICS)
Hyundai Motor Group Innovation Center in Singapore is Hyundai Motor Group’s initiative to accelerate its innovation efforts for the human-centered mobility ecosystem. A one-stop advanced manufacturing hub, housing a vibrant ecosystem of researchers, technology, training providers and factory of the future, located in Singapore’s Jurong Innovation District. The center will explore business ideas and technologies that will help define the future businesses direction for the company.","['TensorFlow', 'Machine Learning', 'Forecasting', 'Time Series Analysis', 'Data Analysis', 'Mathematical Modeling', 'Hadoop', 'Mathematics', 'Industrial Engineering', 'Data Mining', 'PyTorch', 'Algorithm Development', 'Automotive Industry', 'Data Science', 'Pattern Recognition', 'Data Analytics']"
SAP Data Migration,"TRADEHUB 21, 18 BOON LAY WAY 609966","Contract, Full Time",Executive,3 years exp,"Consulting, Information Technology, Professional Services",Monthly,"$4,000to$10,000","Job Descriptions: •
a) Have a degree in IT or equivalent.
b) Have at least 2+ years of working experience in the SAP Data Migration
c) Have Knowledge in SAP Cross modules and Master Data
d) Able to provide Data migration solutions which including designing, Analyzing implementing, and documenting data migration for SAP S4 Hana
e) Must be able to create Data Migration Architecture, including data loading templates, data mapping, data reference and transformation, data rehearsals, migration cutovers and post-live support.
f) Must have experience with Master Data in Material Master, GL accounts, Centers.
g) Must be able to perform verification and validation of data.
h) Must be able to transform data using Fiori apps.
i) Have good interpersonal and communication skills.","['SAP Implementation', 'Troubleshooting', 'Job Descriptions', 'SAP data management', 'SAP', 'Data Migration', 'Communication Skills', 'Business Process', 'SAP ABAP BAPI', 'Debugging', 'Business Requirements']"
Data Analyst - Trading,"BYLANDS BUILDING, 135 MIDDLE ROAD 188975","Permanent, Full Time",Executive,3 years exp,"Banking and Finance, Information Technology",Monthly,"$7,000to$10,000","A global investment firm is hiring for a Data Analyst for their trading desk. 

You will work alongside Portfolio Managers to:

Develop new reports and analysis tools to support traders and researchers in daily risk management
Develop tools for continuous monitoring of investment portfolio and strategic deep dives


Skills required:

Advanced degree in a quantitative field such as data science, statistics, mathematics, physics or engineering
Coding skills required in at least one programming language (e.g. Python + SQL, VBA) and capacity to work on large datasets
Experience in finance is a plus
Excellent communication skills


Learning opportunities you will have:

Mentorship from industry professionals
Detailed practical hands-on experience with portfolio management and analysis
Contribution to high level decision making on global businesses
Exposure to large scale data analysis technology


EA Reg. No.: R1435970 | EA Licence: 17C8713","['Excellent Communication Skills', 'Asset Management', 'Investment Strategies', 'Quantitative Research', 'Data Analysis', 'VBA', 'Risk Management', 'SQL', 'Portfolio Management', 'Python', 'Team Player', 'trading strategy']"
 , , , , , , , , , 
SAP DATA MIGRATION consultant,"SHENTON HOUSE, 3 SHENTON WAY 068805",Full Time,Middle Management,6 years exp,Information Technology,Monthly,"$8,000to$13,000","Responsibilities:

 Data Migration Detailed activity planning and tracking – Master Plan.
 Data migration Approach Preparation and Scrutinization.
 Data Migration Briefing and walkthrough with client for each DM cycle.
 Data Migration requirement gathering (Transformation rules/mapping rules/selection rules) with Business Users.
 Data Migration Issue logging and tracking.
 Pre-load Validations of Data load templates.
 Data load activity tracking and scenarios execution with SNP.
 Reconciliation Execution and Address deviations if any in Pre and Post Load.
 Sign off execution and Tracking.
 Strong organizational skills and ability to multi-task
 Provides management with regular project updates, creates, and maintains trusting relationships, identifies, and manages project issues, identifies project risks early and assists by providing prudent and timely recommendations for risk response.
 Partners with various functional and technical teams within the SAP program
 Communicates effectively with stakeholders and team members.
 Reports on the status, issues, and key activities

Requirements:


 Bachelor's degree from an accredited college or university is preferred
 Minimum of 6+ years of experience
 Excellent communication skill; able to speak and write well in English
 Ability to understand business processes from a customer perspective
 Ability to work in a team environment, effectively interacting with others
 Ability to effectively develop presentations and present ideas and proposals to all levels of
management
 Excellent verbal/written communication, collaboration, analytical and presentation skills
","['Negotiation', 'CRM', 'Ability to Multitask', 'Customer Relationship', 'Lifestyle', 'Social Media', 'Legislation', 'Trusting Relationships', 'Logging', 'SAP', 'Data Migration', 'Compliance', 'Presentation Skills', 'Team Player', 'Activity Planning', 'Conflict']"
Director-Data Science,"ONE MARINA BOULEVARD, 1 MARINA BOULEVARD 018989",Permanent,Senior Management,8 years exp,Banking and Finance,Monthly,"$14,300to$22,500","You Lead the Way. We’ve Got Your Back.

With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities, and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.

At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.

Join Team Amex and let's lead the way together.

Functional Description

Unleash your analytical skills to define the future of how we serve our customers. How we serve our customers is consistently evolving and is a challenge we gladly accept. Whether you are finding new ways to prevent identity fraud or enabling customers to start a new business, you can work with one of the most valuable data sets in the world to identify insights and actions that have a meaningful impact on our customers and our business. And, with opportunities to learn from leaders who have defined the course of our industry, you can grow your career and define your own path. Find your place in risk and analytics in #teamamex.

The Credit and Fraud Risk Team of American Express is looking for a Director to lead and develop a diverse team of high-performing risk professionals to build, implement and enhance predictive models that enable better new account underwriting decisions for consumer portfolios at American Express.

Responsibilities

Developing and managing machine learning models for new account underwriting, and interacting with business partners to integrate models with business decisions
Planning and delivering of high performing models, meeting agreed deadlines and ensuring accurate, efficient implementation of models in production systems
Performing annual reviews, performance monitoring reviews, retrains and remediation activity on models as required
Ensuring all deliveries conform to AXP’s Model Risk Governance Framework and regulatory requirements and producing robust, clear documentation
Learning industry developments and best practices, conducting research and development to incorporate best in class modelling methodologies and share with the team

Qualifications

Excellent analytical skills helping to develop and implement predictive machine learning models on large data sets in Hadoop environments using tools such as Hive, Python, and SQL
Strong people leader and team player with a demonstrated ability to develop team members and create highly effective and results-driven culture
Strong relationship management and proven track record of positively collaborating and partnering with stakeholders
Two or more years of experience in credit, fraud or compliance risk management practices in a Financial Services company

Offer of employment with American Express is conditioned upon the successful completion of a background verification check, subject to applicable laws and regulations.","['Machine Learning', 'Customer Experience', 'Hadoop', 'Predictive Analytics', 'Research and Development', 'SQL', 'Underwriting', 'Python', 'Fraud', 'Data Science', 'Financial Services']"
 , , , , , , , , , 
 , , , , , , , , , 
Senior / Data Engineer,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,3 years exp,Information Technology,Monthly,"$6,000to$9,500","The Senior Data Engineer will be responsible for the design, develop, and maintain:

Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases.
Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”.
Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda .
Batch Pipeline Orchestration using on Apache Airflow and Jenkins.
Auto Scalable platform using Kubernetes on EKS.
Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine.
Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD).
Structure Tables with Partitioning and Clustering to increase Cost & Performance Benefits.
Guide Data Analysts and Data Scientists to write efficient queries and workloads.
Data Sharing with On-Demand Encryption/Decryption which can operate at Scale.
Running Containerized ETL workflow at scale.

Qualifications:

Bachelor Degree of Computer Science, IT or equivalent
at least 3 - 4 years of data engineering experience
Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc…
Strong Data modeling and managing Distributed Computing Platforms for Data Processing.
Advance knowledge of SQL and writing resource-efficient queries.
Have at least 2+ years of professional programming experience in Python.
Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL.
Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lambda, etc...
Have a good understanding of how Kubernetes clusters work and scale on-demand.
Have adequate experience using Containers for Data Engineering workload.
Implemented manual or automated tools for Data Quality, Catalog, and Lineage.
Uphold the sense of Frugality across Data Engineering teams.
Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders.
","['Kubernetes', 'Oracle', 'Data Modeling', 'AWS', 'Hadoop', 'MySQL', 'ETL', 'Data Quality', 'Data Engineering', 'SQL', 'Python', 'Continuous Integration', 'AWS Lambda']"
Data Architect,"SHAW CENTRE, 1 SCOTTS ROAD 228208","Contract, Permanent, Full Time",Executive,5 years exp,Information Technology,Monthly,"$8,000to$13,000","Job Requirements

- As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client.

- You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers.

- Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. 

- In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. 

- You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. 

- You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics.

• Translate business requirements to technical solutions leveraging strong business acumen.
• Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.
• Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
• Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
• Design and Build Modern Data Pipelines and Data Streams.
• Design and Build Data Service APIs.
• Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
• Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.
• Implement effective metrics and monitoring processes.
• Travel as needed


Saghana Sithara | Registration Number: R1550224","['Microsoft Azure', 'Azure', 'Big Data', 'Pipelines', 'Architect', 'Hadoop', 'Business Acumen', 'Data Design', 'Data Engineering', 'PowerBI', 'Planning and Implementation', 'Data Architecture', 'Visualization', 'API', 'Databases', 'Business Requirements']"
Lead Data Engineer,"CROSS STREET EXCHANGE, 18 CROSS STREET 048423",Full Time,Professional,5 years exp,"Consulting, Information Technology",Monthly,"$11,000to$18,000","Are you at your most vibrant when you’ve successfully distilled data into its simplest, most meaningful form?
Thoughtworks is a global software consultancy with an aim to create a positive impact on the world through technology. Our community of technologists thinks disruptively to deliver pragmatic solutions for our clients' most complex challenges. We are curious minds who come together as collaborative and inclusive teams to push boundaries, free to be ourselves and make our mark in tech.
Our developers have been contributing code to major organizations and open source projects for over 25 years. They’ve also been writing books, speaking at conferences and helping push software development forward, changing companies and even industries along the way. We passionately believe that software quality is driven by open communication, review and collaboration. That’s why we’re such vehement supporters of open source and have made significant contributions to open source tools for testing, continuous delivery (GoCD), continuous integration (CruiseControl), machine learning and healthcare.
As consultants, we work with our clients to ensure we’re evolving their technology and empowering adaptive mindsets to meet their business goals. You could influence the digital strategy of a retail giant, build a bold new mobile application for a bank or redesign platforms using event sourcing and intelligent data pipelines. You will learn to use the latest Lean and Agile thinking, create pragmatic solutions to solve mission-critical problems and challenge yourself every day.
Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.
You’ll spend time on the following:
You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems
You will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy, support and operate data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product
Seamlessly incorporate data quality into your day-to-day work as well as into the delivery process
Here’s what we’re looking for:
You are equally happy coding and leading a team to implement a solution
You have a track record of innovation and expertise in Data Engineering
You’re passionate about craftsmanship and have applied your expertise across a range of industries and organizations
You have a deep understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
You’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments
Working with data excites you: you have created Big data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systems
Advocate your data engineering expertise to the broader tech community outside of Thoughtworks, speaking at conferences and acting as a mentor for more junior-level data engineers
Assure effective collaboration between Thoughtworks’ and the client’s teams, encouraging open communication and advocating for shared outcomes","['Machine Learning', 'Cloud solutions', 'Cloud Applications', 'Big Data', 'Hadoop Database', 'Pipelines', 'Architect', 'Hadoop', 'Data Quality', 'Data Engineering', 'EMR', 'Security Strategy', 'Data Architecture', 'cloud-based platform', 'Databases', 'Software Development']"
"Data Governance, Consultant / Principal","AIA TOWER, 1 ROBINSON ROAD 048542","Permanent, Full Time",Senior Executive,4 years exp,Information Technology,Monthly,"$9,000to$13,000","The Data Governance Consultant will be responsible in the development and execution of Data Strategies and Data Governance initiatives of AIA Singapore

Job Description

Plan the development and execution of Data strategies that supports the Enterprise Data roadmap and Govern and set the future enhancement strategy on AIA’s enterprise data warehouse by working with the data owners & champions across the business
Form best practices on data management via the Data Governance Framework and work with IT and data owners/champions to roll out across the organization
Execution of Data Quality assessment for key systems and critical data elements and Implementation of Data Governance tools like metadata management, reference data management, master data management and data quality
Own the approach and structure to the data model in EDW by structuring it to the business needs
Set and execute strategies that will incrementally improve data quality, consistency, currency and completeness and eliminate redundancy
Oversee governance of data quality through fit-for-purpose data quality reporting to the Data Management Council
Build and maintain strong and effective relationships with key internal and external business stakeholders to ensure that data meets the expectation of key business stakeholders
Collaborate with IT to develop data infrastructure and architecture strategies that promote data quality, seamless data sharing and data accountability

Requirements

Bachelor’s degree and above in Analytics, Information Systems Management, Computer Science or related fields with 5-8 years of experience in data governance master data management, data quality related projects.
Able to thrive in a fast paced, highly challenging environment
Proven and demonstrable ability in implementing business intelligence and reporting frameworks to influence and drive management decisions on strategies
Able to manipulate and analyse complex, high-volume and high-dimensionality data from various sources
Good understanding of design and architecture principles
Team player who is detailed and deadline oriented, with a strong work ethic
Excellent verbal , written communications (English) and presentation skill
Strong analytical, problem solving and critical thinking skills
Expert on any of the Data Governance related tool namely Data360. Knowledge of IDQ, AXON, EDC will be a plus. Hands-on experience in SQL, Alteryx, Tableau or BI Tool is ideal.
Strong project management skills and ability to manage multiple priorities
","['Tableau', 'Management Skills', 'Business Intelligence', 'Data Sharing', 'Currency', 'Data Management', 'EDC', 'Data Quality', 'Data Governance', 'SQL', 'Written Communications', 'Project Management', 'Analytical Problem Solving', 'Accountability', 'Master Data Management']"
Data Monitoring Engineer,"SUNTEC TOWER FIVE, 5 TEMASEK BOULEVARD 038985",Permanent,Junior Executive,1 year exp,Information Technology,Monthly,"$3,000to$5,000","About MSIGHTS
Founded in 2004, MSIGHTS (msights.com) provides cloud-based marketing data integration services to some of the world’s most sophisticated global advertisers. As marketing channels proliferate, so do the data sources marketers must examine in order to quantify results and guide strategy. MSIGHTS services make marketers more efficient and successful by providing a single view of overall marketing performance with actionable insights on what works and what doesn’t. The MSIGHTS Platform automatically collects and reconciles disparate data, making it immediately available to fuel a wide variety of analytical and visualization tools. The Data Monitoring Engineer Position is offered in our Singapore office.

Location: Singapore

Company Core Values

Help Clients Win
Own Every Step
Do What You Say
Support Your team
Be an Expert

Job Summary

Monitor all daily operations through the data value chain
QA data based on boards and daily data intake
Interest in data (Trending, rules, behavior)
As part of the MSIGHTS Technology team, this position requires a great capacity to innovate, take initiative, an ability to consistently deliver above expectation, a passion for continuous improvement, and a willingness to work hard and be rewarded.

Responsibilities and Duties

Will need perform daily data operations at specific times (early morning shift or late night shift).
Monitor daily intake of data through its various channels (API, Email, FTP) and solve problems as they arise
Daily QA of data to spot inconsistencies, unusual trending or errors and communicate findings
The candidate is required to document, generate ideas, and follow established work procedures and methodologies.

Qualifications and Skills

1+ years of IT related experience.
SQL Server knowledge is a necessity. PostgreSQL, SSIS, or AWS Services (Athena, Spectrum, GLUE) are desirable.
Must be a self-starter, willing to take the initiative and propose innovation in MSIGHTS products and/or processes.
Strong communications skills — both written and verbal — and the ability to work well with an internal team.
Must be detail-oriented, committed to quality, responsible, punctual and client-focused, all while being flexible and entrepreneurial in a fast-paced international work environment.
Analytical and problem-solving skills, and experience applying these skills to resolve potential issues
Bachelor’s Degree or equivalent.
","['Ability to Multitask', 'PostgreSQL', 'Ability To Work Independently', 'Data Management', 'ETL', 'Data Integration', 'Data Quality', 'Data Governance', 'Marketing', 'SQL', 'Attention to Detail', 'SQL Server', 'SSIS', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
"Data Analyst(.Net, Tableau)","THE OCTAGON, 105 CECIL STREET 069534","Contract, Full Time",Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$10,000","Required resource with data mining/analyst skill and developer (.NET, SQL) skills

• Leverage on data analytics knowledge & experience to facilitate to uncover the business pattern.
'• Perform Data mining work and analysis, present result in a clear manner for the deployment of IAM Roled Based.
• Processing, cleansing, and verifying the integrity of data used for analysis
• Able to articulate clearly the business objective and the corresponding technical work to accomplish this.
o Expect him to build up the required report in Tableau/3rd party Tool
o Documenting and communicating the results of your efforts.
• Expect him to provide support on Tableau / UAT/ 3rd party tool , as business is embarking on self-service journey for business intelligence platform.
• Managing users requests and user roles.
• Handling confidential data and information according to guidelines.
• Developing dashboards for analysis using Tableau/3rd party tool from multiple production systems.
• Managing and designing the reporting environment, including data sources, security, and metadata.
• Supporting initiatives for data integrity and normalization.
• Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.
• Troubleshooting the reporting database environment and reports.
• Evaluating changes and updates to source systems.
• Training end users on new reports and dashboards.
• Providing technical expertise on data storage structures, data mining, and data cleansing.

","['Tableau', 'UAT', 'Business Intelligence', 'Troubleshooting', '.NET', 'Assessing', 'Data Mining', 'Metadata', 'Articulate', 'Data Analytics']"
Manager - Data Science,"ONE MARINA BOULEVARD, 1 MARINA BOULEVARD 018989",Full Time,Manager,2 years exp,Information Technology,Monthly,"$10,000to$13,000","You Lead the Way. We’ve Got Your Back.
With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities, and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
Join Team Amex and let's lead the way together.
Functional Description
Decision Science colleagues will serve as a key member of the Credit and Fraud Risk organization. We seek a thought-leader and a problem-solver who can blend business, technical, and industry best practices when it comes to developing the analyses, models, and algorithms that power our customers’ digital experiences.
This critical team is responsible for managing enterprise risks throughout the customer lifecycle, across our consumer and commercial businesses, and across all our global products. We develop industry-first data capabilities, build profitable decision-making frameworks, create machine learning-powered predictive models, and improve customer servicing strategies.
Our Decision Science teams use industry leading modeling and AI practices to predict customer behavior. We develop, deploy and validate predictive models and support the use of models in economic logic to enable profitable decisions across credit, fraud, marketing and servicing optimization engines.
Responsibilities:

Work with massive amounts of digital data (Web, App, API) and sophisticated tools in an industry leading Big Data environment.
Build everything from basic reports to advanced machine learning models and algos to drive improvements to our customer’s online and mobile app experiences.
Work with product owners to revolutionize the product and content design with a data-driven approach
Collaborate with tech partners to test, implement and deploy modeling solutions to production system.
Develop insights into customer behavior and introduce new approaches to transform complex behavioral data into actionable information
Leverage the power of closed loop through Amex network to make decisions more intelligent and relevant
Innovate with a focus on developing newer and better approaches using big data & machine learning solutions

Qualifications:

PhDs in a quantitative field (Computer Science, Statistics, Mathematics, Physics, Operation Research and etc.) with hands-on experience leveraging sophisticated analytical and machine learning techniques. PhD degree with practical experiences NLP is a significant plus.
Expertise in an analytical language (Python, R or the equivalent), and experience with databases (Hive, SQL, or the equivalent). Knowledge of SAS is a plus but not required.
Deep understanding of machine learning/statistical algorithms such as deep learning and boosting. Experience with data visualization is a plus
Demonstrated ability to frame business problems into mathematical programming problems, leverage external thinking and tools (from academia and/or other industries) to engineer a solution and deliver business insights.
Ability to work effectively in a team environment
Independent thinker who’s organized, has great attention to detail, and can multi-task
Strong communication skills
Ability to learn quickly and work independently with sophisticated, unstructured initiatives
Ability to integrate with cross-functional business partners worldwide
Proficient in presentation tools, including Excel and PowerPoint
","['Machine Learning', 'Modeling', 'Big Data', 'Physics', 'Mathematics', 'SQL', 'Attention to Detail', 'Python', 'Fraud', 'Statistics', 'Databases', 'Data Visualization']"
Data Operations Lead (HealthTech),6 SERANGOON NORTH AVENUE 5 554910,"Permanent, Full Time",Manager,5 years exp,Information Technology,Monthly,"$7,500to$10,000","Summary
DataOperations Lead for a new large-scale National Healthcare IT System

Roles & Responsibilitiesas Data Operations Lead

Report to the Operations Manager, be responsible for data operations of a new national data repository
Accountable for the fulfilment of the system’s roles and responsibilities as one of the HealthierSG data single source of truth
Publish and enforce data definitions for established data subjects
Establish data contributor and data consumer onboarding processes with compliance to data governance policy, conduct onboarding with thorough quality assurance controls
Plan and Prioritise onboarding requests, track and report contributor& consumer onboarding status
Ensure data availability to data consumers, and provide timely communications in cases of disruptions
Respond to enquiries on data qualityand inform the relevant data contributor promptly
Receive and apply correctionsprovided by data contributors
Identify and establish measures on on-going basis to proactively detect data quality issues and follow up with the respective data contributors for timely data corrections, as well as implementation of preventive measures
Provide regular reporting of data quality issues to internal andexternal stakeholders, data owner, and trackall data quality issues till closure
Ensure compliance to both internal and external SLAs
Manage team’s support schedule to ensure full coverage of data operation services, as well as coaching team members to deliver consistent support service quality
Provide strong leadership for matters relating to operations support, processes, and guidelines to achieve service excellence
Advise improvements and assist in the development of measurable information and SOP / knowledge base / dashboards to assure continued effectiveness of system operations


Specific Requirement/Skillsets

Degree in Computer Science, Information Technology,Management of Information Systems, or related discipline
Minimum 8 years hands on experience in large scale IT applicationoperations, preferably in the area of data operation
Excellent analytical skills with attention to detail
Possesses good verbal and written communication across all levels of personnel with proven ability to translate complex, technical subjects into clear and concise communications to a variety of key stakeholders Pro-active, independent, and able to react quickly and resolve issuespromptly
Experience in Healthcare domain is anadded advantage
","['Coaching', 'Leadership', 'Analytical Skills', 'Technology Management', 'Quality Assurance', 'Healthcare', 'Information Technology', 'Data Quality', 'Data Governance', 'Written Communication', 'Compliance', 'Attention to Detail', 'Service Excellence']"
Technical Data Steward,"ECON INDUSTRIAL BUILDING, 2 ANG MO KIO STREET 64 569084",Full Time,Senior Executive,4 years exp,"Consulting, Information Technology",Monthly,"$5,500to$7,500","Responsibilities 
• Provide technical advisory and support to Data Steward in the execution of data  management activities to comply with data governance policies and guidelines. 
• Create and maintain technical data documentation. 
• Provide the technical expertise around source systems, extract, transform, and load (ETL) processes,  data stores, data warehouses, and Business intelligence tools. 
• Explain how a system or process works/doesn’t work. 
• Check code, SQL, internal database structures, and other programming constructs in search of how  the information is structured, how the data moves, and how the data transforms within Data Lake  or between systems. 
• Assist in identifying where business data elements are physically implemented in a system.

Experience / Skills
• Bachelors degree in IT/ Computer science or equivalent.
• Highly organised, adaptable, meticulous with a strong sense of responsibility and ability to followthrough.
• At least 4 years hands-on experience in data management.
• Strong in Business Needs Analysis.
• Hands-on in Data Strategy.
• Stakeholder Management.
• Data Engineering – familiar to write SQL scripts and stored procedure
• Insurance domain knowledge or/and, experience in Impala/HUE and Data Governance is added
advantage","['Data Sharing', 'Agile Project Management', 'TIBCO', 'Information Management', 'Data Management', 'Technical Advisory', 'Sanitation', 'Data Governance', 'Business Needs Analysis', 'Data Engineering', 'SQL', 'Business Intelligence Tools', 'Stakeholder Management', 'Master Data Management', 'Data Strategy']"
Data Platform Specialist,"ROBINSON 77, 77 ROBINSON ROAD 068896",Full Time,Professional,5 years exp,"Education and Training, Information Technology, Others",Monthly,"$5,600to$9,000","Responsibilities

Translate business needs to technical specifications.
Analyze business requirements, understand underlying data sources, transformation requirements, data mapping, data modelling and metadata for reporting solutions.
Design EDW data layer with appropriate enterprise considerations like scalability, performance, security, maintainability, automation etc.
Build infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.
Incrementally build IB’s enterprise data warehouse.
Evaluate and improve existing BI systems.
Write code, conduct unit testing, documentation and troubleshooting.
Create visualizations and reports for various business units.
Participate in technical sharing and peer review sessions with team members.

Requirements

BSc/BA in Computer Science, Engineering or relevant field.
Building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.
Able to integrate multiple data sources & user-end applications with databases into one system. (to store the data and its retrieval from the databases)
Solid experience in designing and implementing robust data pipelines and ETL framework.
Proven experience as a data warehouse architect & developer, including full implementation of data warehousing solution.
Good understanding of enterprise design concepts: re-usability, continuous integration, security, scheduling, monitoring, etc.
In-depth understanding of database management systems, online analytical processing (OLAP), SQL queries (Azure SQL DB).
Expertise with Azure Resource Management and templates is an added advantage.
Exposure to cloud technologies (MS Azure, AWS) & desire to learn and deliver new things on a needs-basis (big data, BI, data science, etc.).
Strong expertise in data warehouse design methodologies and technologies, data modelling(data vault experience is preferable), data quality and metadata.
Effective oral, written communication and presentation skills.
Strong interpersonal skills. Self-motivated with a keen attention to detail.
","['Business Intelligence', 'Data modelling', 'Data Analysis', 'Highly self-motivated', 'Interpersonal Skills', 'Business Analysis', 'Close Attention to Detail', 'SQL', 'Project Management', 'Data Warehousing', 'SQL Azure', 'Technical Design']"
 , , , , , , , , , 
Accounts Assistant  /  Data Entry,"WCEGA TOWER, 21 BUKIT BATOK CRESCENT 658065",Full Time,Non-executive,1 year exp,Accounting / Auditing / Taxation,Monthly,"$1,800to$2,700","In Chambers, our top priority is to provide the best ONE STOP professional services to our clients, both in the public and private sector. Ultimately Chambers success is due to her endless pursuit of excellent service.
Benefits

Work-life balance
Career Progression
Medical benefits
Dental benefits
Training & Development
Friendly working environment

Job Description & Requirements

Diploma in Accounting or equivalent
Min 1~2 years accounting experience
Able to start work immediately with short notice

Please remember to input the following information in your resume: -
1) Current salary
2) Expected salary
3) Reasons for leaving (Past and present employment)
4) Notice period
5) Position applied for in the email

Applications will be treated in strict confidence. Personal data collected will be used for recruitment purposes only.","['Accounts Payable', 'Microsoft Office', 'Microsoft Excel', 'Accounting System', 'Data Entry', 'Accounts Receivable', 'Accounting', 'Team Player', 'Microsoft Word', 'Able To Work Independently']"
Head of Data Solutions,43 AMOY STREET 069869,Full Time,Senior Management,10 years exp,"Banking and Finance, Information Technology",Monthly,"$10,000to$15,000","EXPERIENCE & QUALIFICATIONS: 

Degree or Masters' Degree from recognized university ideally in a Computer related discipline
More than 10 years of working experience with at least 5 years leadership experience in delivery of Data Governance initiatives.
Proven experience in designing, evaluating, and implementing large Data solutions and delivering large scale change.
Proven experience of providing strategic and technical leadership (experience managing multi geography and multi-disciplinary teams is an advantage)
Detailed understanding of Information Security, Data Privacy, Metadata , Data Taxonomy including working knowledge of global data protection laws and practices
Knowledge of the contemporary digital landscape of organisations and experience of working in multi-disciplinary teams to drive sustainable improvements in business performance
Experience working at senior level leading large scale technology projects (including engineering, solution design and complex implementations)
Fluency in English
Ability to commit up to 10% business travel


Preferred

Strong work background in Data related or technology role within international financial services .
Previous exposure managing data risks including data protection & privacy, data handling and data classification including (but not limited to) Data and application protection, cross border data restrictions, data classification, data discovery, data governance, data loss prevention, back-up/recovery, and retention etc.
","['Information Security', 'Machine Learning', 'Leadership', 'Taxonomy', 'Big Data', 'DynamoDB', 'Data Governance', 'Business Travel', 'Geography', 'Python', 'Data Science', 'Metadata', 'Technical Leadership', 'Loss Prevention', 'Financial Services']"
Lead Data Scientist,306 TANGLIN ROAD 247973,Full Time,Manager,8 years exp,"Architecture / Interior Design, Information Technology",Monthly,"$14,000to$18,000","As a Lead Data Scientist, you will  lead a team of Data Scientists and undertake data collection,  pre-processing, and analysis, originating from different data sources.  Fuse data and find patterns, correlations, ways to measure performance  indicators, and build models to address tough business problems.
Specific responsibilities

Identify valuable data sources and support collection processes automation
Undertake pre-processing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Fuse data sources to create insights and recommendations
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Build data products to extract valuable business insights and recommendations that drive optimal actions
Lead and mentor a team of data scientists
Collaborate with stakeholders across the organization, including engineering, product, and SMEs
Write scientific and technical documentation
Report directly to the CTO

Requirements, experience, and skills

Master's degree in a quantitative field (e.g. mathematics, statistics, computer science, etc.), Ph.D. is a plus
Proven experience of at least 8 years as a Data Scientist or similar role, lead position experience is an advantage
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets
Knowledge of advanced statistical techniques and concepts, and experience with applications
Knowledge of a variety of machine learning techniques and their real-world advantages/drawbacks
Experience using business intelligence and data frameworks
Knowledge of software development principles and architectures
Solid oral and written communication skills, especially around analytical concepts and methods

Personal competencies

Someone who’s passionate about their work and fun to work with
Excellent communication and teamwork skills
Problem Solver and Get Things Done!
Ability to thrive in a fast-paced, global start-up environment
Results-oriented, highly self-motivated, and quick-to-learn personality
","['Machine Learning', 'Technical Documentation', 'Business Intelligence', 'Scala', 'Big Data', 'Mathematics', 'SQL', 'Python', 'Statistics', 'Data Science', 'Product Development', 'Teamwork Skills', 'Databases', 'Software Development', 'Data Visualization']"
Head of Data Science (APAC),"TWENTY ANSON, 20 ANSON ROAD 079912","Permanent, Full Time",Manager,10 years exp,Information Technology,Monthly,"$20,800to$25,000","Our client is a leading provider of consulting, engineering, and project management services. With 50, 000 employees across 80 countries, they design, build, operate, and finance various critical infrastructure projects. 
Responsibilities: 
First and foremost, the Head of Data Science will be accountable and responsible for driving the innovation and execution of the data science practice. This includes providing hands-on leadership by prototyping data science models to validate/in-validate hypothesis and then driving execution to productize those models to ensure speed of execution along with scalability, performance, and maintainability of the models. 
The ideal candidate will demonstrate knowledge of Machine Learning and utilizing data to obtain new insights and turning those insights into revenue generating commercial offerings. 
Requirements: 

Tertiary Degree in Computer Science or Engineering
10+ years of hands-on data science experience where you are personally creating data science models. This includes performing data preparation (using SQL or Python). Creating data pipelines, practical experience in implementing machine learning algorithms for clustering, classification, regression use cases
Track record of building and managing data science teams
Strong knowledge of Python to create data science models
Familiar and comfortable performing ETL activities on data sets
Track record working on a large-scale data platform in a data-intensive environment
Experience collaborating with architects, engineers, development managers, and product management to assist in the implementation and productization of your data science models
Strong focus on the customer and a clear understanding of the customer problems we're leveraging data science to solve. 
Demonstrate desire to operate with a sense of urgency and bring solutions to market as quickly as possible (while ensuring they satisfy use cases and are implemented with high quality)

Interested parties please get in touch with Zain via zain.hussain@ethosbc.com for a confidential discussion.
Reg No: R1981018
BeathChapman Pte Ltd 
Licence No 16S8112
","['Machine Learning', 'Leadership', 'Scalability', 'Pipelines', 'Architects', 'ETL', 'Product Management', 'Energy Efficiency', 'SQL', 'Project Management', 'Experimental Design', 'Python', 'Statistics', 'Data Science', 'VCA', 'Consulting Engineering']"
Data Architect (AWS),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,12 years exp,Information Technology,Monthly,"$10,000to$16,000","As Singapore’s leading composite insurer, Income Insurance Limited knows that a data-driven culture is key to doing good business and ultimately, helping our customers reach their financial goals. With data collection already part of the way we work, our data team is pivotal in making data meaningful and actionable, so that we can all work smarter, make better decisions and create the best experiences for our customers, whether that’s in-person with Income advisors or on our online touchpoints.

This omnichannel customer experience is made possible by several artificial intelligence (AI) solutions, that provide customized offerings and increased efficiency for our customers. Our customers rest with complete peace of mind as we walk this journey with them. From developing innovative, data-driven mindsets to promoting continuous skills development, we’re also proud to say that our employees are with us on our transformational data journey. We know it will take everyone working together to build even further on our rich legacy and create value for both our customers and ourselves.
This role will be part of the Data team within our Information Technology department, focusing on transforming the existing data architecture and build the next generation data platform across Income to support the Digital Transformation. The successful candidate will bring a vision to modernize the data architecture and develop a multi-year roadmap to bring that vision to life, collaborating with business and technology leads, application architects, data science and data engineering teams across the organisation to enable large scale machine learning and analytics use cases. He/She will act as a thought leader for the organization, defining data platform processes and best practices – engaging senior stakeholders across the group to ensure their continued buy-in on strategic data initiatives.

Design, build and implement end-to-end data driven solutions
Define roadmap to transform data architecture focusing on scalability, performance and flexibility throughout the entire data life cycle (ingestion, storage and consumption).
Maintain data architecture framework, standards and principles including modelling, metadata, security, master and reference data
Define reference architecture as a set of patterns that can leveraged by diverse parts of the direction to create and improve data systems
Lead architectural designs solution context diagram and conceptual data model to optimize security, information leverage and reuse, integration, performance, and availability and ensure solutions developed adhere and aligns to the delivered architecture
Consult and influence digital application teams regarding solutions. Collaborate with other staff to design and implement effective technology solutions, while using innovative business and technology processes to identify and implement improvement initiatives, eliminate redundancies and maximize the reuse of data
Work closely with Solutioning, Infrastructure and project teams to understand their needs and ensure the best data architecture is implemented
Provide training and share best practices across teams regarding data architecture design and solution implementation including review and quality assurance
Develop and apply industry best practice technology, design and methodology approaches to design data architecture. Research and recommend new emerging technologies, techniques and tools that will add value to the organization
Working with project teams to ensure architecture requirements are captured and addressed by designs that uphold the enterprise principles and standards
Designing and delivering data architecture on cutting edge green field Data Lake
Designing data integration architecture based on solution requirements e.g. real-time, near real-time, batch
Architecting conceptual, logical and physical architecture and data models for operational enterprise data and analytics solutions using recognised data modelling approaches (e.g. 3NF relational, Kimball dimensional) in standard modelling tools using UML and the ArchiMate modelling language
Owning the definition of data architecture components for information management solutions to facilitate storage, integration, usage, access, and delivery of data assets across the enterprise in both the operational and analytics spaces
Working to accelerate the wider Income business by developing and maintaining long-lasting relationships with senior stakeholders, both during and outside of project delivery
Engaging talent and helping us diversify our talent force by leading data architecture capability and driving further development of the team
Provide direction on linkages between different systems to ensure the information flow is aligned with the information architecture
Provide guidance on the implementation of information architecture
Recommend innovative solutions to increase efficiencies around the integration of complex systems
Assess existing systems to evaluate their usability, usefulness, visual design and content
Communicate the design and recommendations to stakeholders
Develop strategies for seamless and low-risk migration of data between systems
Guide alignment of information management standards with the enterprise architectural plan and information security standards
Identify the desired state of a coordinated information flow through the organization

Qualifications

Bachelor's Degree in Computer Science or related discipline
Min 12-15 years of experience of designing and developing high performance resilient data driven applications, hands on experience in data analytics, data integration, data modelling
Strong experience with AWS tech stack, build data migration/date warehouse from scratch (analyze current system/market, create end-to-end strategy/roadmap), and experience in large scale imgration from on-premises data warehouse to cloud server.
Know ""how"" to load new data saources/integrating new system/entity, implement and runnig cloud server
Experience in designing data patterns to support micro-service based application architecture
Track record of successfully building container-based big data architectures on top of Kubernetes
Experience in designing systems to efficiently handle real-time and batch use-cases
Exposure and understanding in the latest open source technologies across the big data ecosystem, such as distributed storage, real-time event processing and large scale distributed OLAP engines
Exposure to Data as a Service concepts and data virtualization
Working knowledge of data science processes and best practices, with experience in building scalable architectures through the use of data science workflow orchestrators
Hands on experience on DevOps / DataOps / MLOps concepts
Strong data architecture and data modelling skills
Understanding of how data architecture fits with other architecture disciplines
Familiarity with working in agile and waterfall approaches
In-depth understanding and knowledge of business and technology trends
Good understanding of end-to-end application development - data integration for backend API development and front end UI development
Expertise in RDBMS (Teradata/Oracle, PostgreSQL, Vertica etc), PL/SQL, data modeling & ETL/ELT, Snowflake, SingleStore or similar platforms
Expertise in Big Data Technologies like Hive, Pig, Impala, Spark.
Working knowledge on BI tools like Tableau/ Power BI.
Experience in performance tuning, capacity planning and sizing
Good understanding of cloud methodologies and experience with AWS or GCP tool suites and services
Proven track record in strategic planning, individual/team development and service delivery
Embodies a collaborative approach in bringing both business and technology stakeholders together to deliver technology solutions that enable tangible business benefits
TOGAF/DAMA certification would be good to have
At least 2 years of experience in implementing Data Governance
Data Integration & Federation: e.g. Informatica BDE, Python and other scripting and integration technologies
Data Repositories: e.g. SQL Server, Google BigQuery, Amazon Redshift, cloud storage
Experience in implementing RESTful API and services using frameworks such as Springboot or flask
","['Data Modeling', 'AWS', 'Data Integration', 'Data Governance', 'Data Engineering', 'SQL', 'Python', 'Architecture Design', 'Data Architecture', 'Information Architecture', 'AWS Lambda', 'Data Analytics']"
Enterprise Data Management Developer,1 DEPOT CLOSE 109841,"Permanent, Full Time",Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$10,500","Project Description:Leading bank in the Asia headquartered at Singapore looking to implement enterprise wise market data management system. this system will replace banks' existing legacy application and interface with several other downstream systems to provide real time market data feed and interfaces.
Responsibilities:
- Participate in the configuration of EMDMS software solutions based on Bank's requirement.
- Responsible for their configuration and unit testing within Bank's EMDMS implementation project.
- Provide best practice guidance and technical expertise of existing Bank's ecosystem and industry experience to NeoXam PM and consultants.
- Participate in the test support activities - including support of Bank's test team to reproduce and potentially fix bugs and provide feedback to the test team.
- Identify and resolve any implementation issues post-EMDMS go-live.

Mandatory Skills Description:
- Engineering, Computing & Information System - Master's degree / Bachelor's degree or equivalent.
- 3+ years of experience with software implementation and IT Projects in the banking / financial industry within APAC region. Preferably of a financial technology vendor solution
- Strong knowledge of Banking technology ecosystems, especially for systems in scope within the EMDMS project, such as Neoxam / Murex / T24
- Capable of writing rules in scripting language comparable to VBA.
- Experience with RDBMS (SQL language), Data Modeling (conceptual/object oriented thinking).
- Understanding of Enterprise Data Management and ETL techniques and processes.
- Experience of financial data provider feeds such as Bloomberg, Refinitiv, ICE and others.
- Knowledge of financial instruments such as Equities, Fixed Income and Derivatives and rates (FX/MM).
- Project experience with involvement in multiple stages of the project development life cycle.
- Operates independently, takes initiative, good interpersonal skills and ""feels accountable"".
- Proactive and a real team player.

Nice-to-Have Skills:Understanding of Murex/T24 or Neoxam applications","['Bloomberg', 'Derivatives', 'Quality Control', 'Temenos T24', 'Data Modeling', 'Interpersonal Skills', 'Architect', 'Unit Testing', 'Data Management', 'MySQL', 'Scripting', 'ETL', 'SQL', 'Writing', 'Banking', 'Team Player', 'Fixed Income', 'FEED', 'Murex', 'Equities']"
Data Center Administrator (PRIT),"CITY HOUSE, 36 ROBINSON ROAD 068877",Full Time,Senior Executive,2 years exp,Admin / Secretarial,Monthly,"$3,000to$5,000","This Data Center Administrator position offers you the opportunity to expand your skills and experience as you support the Data Center Operations team through a variety of administrative tasks and more.
What you’ll do

Support and administrator maintenance activity planning and purchasing activities
Update and upload Customer Report and Manage maintenance record
Supporting audits and budgetary planning
Maintenance of Contracts Management

What you’ll need

IT Degree or Diploma Holder
Good interpersonal, communication and presentation skills
Good analysis skill
Able work under pressure and fast-paced environment
Good team player and able to compete task assigned in timeline


Interested candidates, who wish to apply for the above position, please send in your resume to priyanka_tewari@persolkelly.com
We regret to inform that only shortlisted candidates will be contacted.
PERSOLKELLY Singapore Pte Ltd
EA License No. 01C4394
EA Reg No: R1875348 (Tewari Priyanka)
**********************************
By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with the Privacy Policy.**********************************","['Vendor Management Experience', 'Third Party Vendor Management', 'Vendor Management Skills', 'Data Center', 'Purchasing', 'Administration', 'Vendor Management', 'Audits', 'Presentation Skills', 'Team Player', 'Contract/ Vendor Management', 'Contract/Vendor Management', 'Activity Planning', 'knowledge of data center']"
Accounting Data Entry Specialist,"VERTEX, 33 UBI AVENUE 3 408868",Contract,Fresh/entry level,1 year exp,Accounting / Auditing / Taxation,Monthly,"$2,200to$2,400","The Position:
Come work at Clixer+, one of the growing companies in our field in the Information Technology and Cyber Security area. We are looking for a focused Accounting Data Entry Specialist to continuously update our company’s accounting system. This accounting data entry role involves entering data manually from paper formats into the company accounting system in a timely and accurate manner for processing and management. Reporting to the Finance Manager, you will identify and correct errors, and swiftly bring them to the attention of Finance team where necessary.
The candidate working in data entry will need to efficiently manage a large amount of information that is often sensitive and confidential. Henceforth, understanding of data confidentiality principles is compulsory. Attention to detail is essential, as mistakes can lead to more significant problems within the company. If you are excited to be part of the winning team, Clixer+, is a great place to grow your career.
Below outlined the job description and skills.
Accounting Data Entry Specialist (Entry level are most welcome)
Responsibilities:
1. Perform data entry into accounting system by maintaining accurate, and complete account transactions
2. Verify data by comparing it to source document
3. Analyze financial information in order to identify discrepancies
4. Resolve discrepancies in information and obtaining further information for incomplete document
5. Maintain confidentiality of all financial data
6. Interpret and apply accounting policies, rules, and regulations to all work in order to ensure compliance with applicable standards
7. Perform regular data backups to ensure data preservation as part of a contingency plan for ISMS compliance
8. Any other duties which may be assigned from time to time
Requirements:
1. Diploma in Finance or Accountancy with 0-1 years of hands-on accounting experience in a similar capacity
2. Highly organised and flexible
3. Meticulous and possess an eye for detail with a high degree of accuracy
4. Inform relevant parties regarding errors encountered
5. High personal integrity and ability to handle sensitive, confidential information
6. Knowledge of word processing tools and spreadsheets (Microsoft Office Applications, including Outlook, Excel, and word)
7. Possess good communication and interpersonal skills and coupled with strong analytical mindset
8. Proficient touch typing skills
9. Basic understanding of accounting software system is beneficial
10. Ability to concentrate for lengthy periods and perform accurately with adequate speed
We regret to inform that only shortlisted candidates will be notified. All applications will be treated with the strictest confidence.
By submitting any application or resume to us, you will be deemed to have read and agreed to the terms of our Privacy Policy, and consented to us collecting, using, retaining and disclosing your personal information to prospective employers for their consideration. You may refer to the Company Privacy Policy at https://www.clixer.com/privacy for more information.","['Microsoft Office', 'Touch Typing', 'Interpersonal Skills', 'Accounting System', 'Data Entry', 'Word Processing', 'Accounting', 'Attention to Detail', 'Spreadsheets', 'Team Player']"
Data Scientist,4 KAKI BUKIT AVENUE 1 417939,"Permanent, Full Time",Professional,5 years exp,"Engineering, Sciences / Laboratory / R&D",Monthly,"$5,000to$10,000","We are seeking a strong candidate with AI & analytics experience to work with an exciting robotics intelligence project in Delta Research Centre. The role will be responsible for executing analysis that deliver valuable insights, providing predictive analytic solutions with high quality and making sure the deployment with sound business sense. Candidate will participate and execute project through contribution of analytics research and deliver impactful research and business outcomes.

Job Description

Contribute to the development of on-going or new research and development effort in perception, navigation, material handling for robotics intelligence
Design, implement and evaluate robotic perception, cognitive computing and decision making framework for intelligent mobile robot
Develop solutions and insights based on image/signal processing, modelling, machine learning and data fusion methods
Perform on-site or off-site data collection, data organization and processing
Perform algorithm modification, training, testing and validation under different conditions

Job Requirements

Programming skills: Python, C/C++
Must be result-orientated, independent and a self-driven team player
Strong in written and verbal communication
","['Tableau', 'Machine Learning', 'Verbal Communication', 'Big Data', 'Hadoop', 'Mathematics', 'Research and Development', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Data Science', 'Robotics', 'Team Player', 'Decision Making', 'Data Analytics']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Scientist - Asset Management,"UOB PLAZA, 80 RAFFLES PLACE 048624","Permanent, Full Time",Professional,2 years exp,Banking and Finance,Monthly,"$5,000to$10,000","Investment Company of the People’s Republic of China (Singapore) Pte Ltd is a fully owned subsidiary of the People’s Bank of China. The company manages a part of foreign exchange reserve within the scope authorized by the People’s Bank of China, undertakes and transacts various kinds of investment businesses.

Job Description:
As an asset management data scientist, your responsibilities will include, but not limited to:

Develop and leverage on statistical and state of the art machine learning models on macro economy and financial markets time series to improve the investment performance. Develop tools and dashboards to improve the investment process.
Spot market opportunities, and develop and backtest fixed income and currencies investment strategies within the company’s mandate, with a focus on emerging markets.
Identify and mine reliable internal and external data sources, build machine learning pipelines from ideation, prototyping, development, tuning, and deployment. Create and present reports and dashboard to demonstrate findings and recommendations


Requirements:

Master’s degree in Computer Science, Applied Mathematics, Statistics, Machine Learning, or a related quantitative field from top Tier Institutes.
At least 2 years work experience in a data scientist role, with 1+ Years of experience with time series, with a strong understanding and knowledge in time series forecasting; Solid track record of deploying machine learning algorithms in production environment.
Strong programming skills in Python, and advanced data science toolsets, i.e. tensorflow, pytorch, scikit learn etc.
Strong problem solving and analytical ability, as demonstrated by an outstanding academic track record or similar achievement.
Fluent in both Mandarin and English (liaise with Chinese speaking associates)
Demonstrable passion for data science - Kaggle, open source contributions etc.
Demonstrable an understanding of economics and financial markets
Knowledge and hands-on experience of Bayesian Inference, Deep Learning


We offer a competitive salary which commensurate with experience, or beyond the stated salary range for unicorns.","['Emerging Markets', 'Asset Management', 'Investment Strategies', 'Asset Allocation', 'FX Options', 'Equity Research', 'Investments', 'Enforcement', 'Risk Management', 'Financial Markets', 'Strategy', 'Investment Management', 'Compliance', 'Portfolio Management', 'Trading Strategies', 'Excel', 'Team Player', 'Fixed Income', 'Equities']"
 , , , , , , , , , 
Data Scientist (Ref:DMSMC),"NATIONAL CANCER CENTRE SINGAPORE, 11 HOSPITAL CRESCENT 169610","Contract, Full Time",Senior Executive,4 years exp,Sciences / Laboratory / R&D,Monthly,"$4,500to$6,700","We are looking for highly motivated and talented individual with passion in oncology and genomics research to join the Precision Radiation Oncology Program and the Data and Computational Science Core at the National Cancer Centre Singapore. You will primarily work with the Principal Investigator (PI) and the current research and clinical teams. The selected individual is expected to contribute actively to our genomics and radiomics research that is focused on using electronic medical records, next-generation sequencing (NGS) and radiological imaging datasets to developing biomarkers predictive of clinical responses in cancer patients. Specifically, the Research Fellow will be expected to perform genomics and radiomics data processing, statistical analyses, feature extraction for statistical/machine learning and survival analysis, and other relevant computational analyses to better understand the complexity of cancer progression and treatment resistance of head and neck and prostate cancers. You will also be required to guide research discussions with other scientists and mentor students. There will also be ample opportunities for inter-departmental and cross-institution collaborations with oncologists, pathologists, and scientists.

For more information, please feel free to refer to the laboratory website - www.chualabnccs.com.

Requirements:
(Required)
- PhD or Master in Computational Biology or Computer Science or Mathematics or Biostatistics or Biophysics
- Highly motivated, organised, meticulous and committed to high quality standards
- Prior experience in handling data sets (e.g. data curation, cleaning and organisation)
- Competency in python/R or other computing language

(Good to have)
- Demonstrable data analysis skills with a portfolio on relevant datasets (e.g. TCGA, Kaggle)
- Familiarity with command line shells (e.g. bash, zsh)
- Prior experience working with high-performance computing clusters and job schedulers
- Knowledge and experience in biostatistical analyses of clinical datasets
- Knowledge and experience in genomics analyses (e.g. analyses of WES, RNASeq data)
- Able to work independently under pressure as well as in a team
- Strong organizational, interpersonal and presentation skills
- Responsible, analytical and self-confident with a mature personality
- Keen interest to solve clinical problems.","['Genomics', 'Data Analysis', 'Biomarkers', 'Oncology', 'Characterization', 'Computational Biology', 'Publications', 'Laboratory', 'Able To Work Independently', 'Biostatistics']"
Python Developer  /  Senior Data Engineer,"THE OCTAGON, 105 CECIL STREET 069534",Permanent,Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$13,000","A large global investment bank is looking for experienced python data engineer to join their data engineering team.
Roles and Responsiblities :

Carry out development of ETL pipeline to migrate data from source systems to data solution
Data analysis and data mapping and modelling
Perform a range of activities including data analysis, data cleansing and root cause analysis.
Document and store assets in line with standard BI processes
building clould datawarehouse
Developing analytics dashboards for business purpose
Providing consultation on data related projects to business users

Requirements :

Min 4 years of experience with strong coding experience in Python and sql
Experience working with big data / Azure data stack is a plus
Prior experience in building / developing ETL applicatins
Strong data analysis , data modelling experience
Good experience with OO concepts
Experience with CI / CD
Basic knowledge of Machine learning / AI and some libraries including Numpy, Pandas, PyTorch, etc
Strong analytical skills

Interested candidates please email your latest resume to subagio@tangspac.com","['Machine Learning', 'Pandas', 'Data Analysis', 'Analytical Skills', 'Azure', 'Big Data', 'Pipelines', 'Root Cause Analysis', 'ETL', 'Data Engineering', 'PyTorch', 'Python', 'Databases', 'Django']"
 , , , , , , , , , 
 , , , , , , , , , 
Senior Data Scientist,"PRUDENTIAL TOWER, 30 CECIL STREET 049712",Full Time,Senior Executive,5 years exp,Engineering,Monthly,"$11,000to$20,000","What you will do:

Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations
Work with large and complex data sets to solve a wide array of business problems using different analytical and statistical approaches
Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends.
Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions

What you will bring:

5+ years industry experience and an advanced degree in a quantitative field
Experience with communicating the results of analyses to executives and cross-functional teams to influence the strategy
Expert in data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R), experience in schema design and dimensional data modeling a plus
Ability to perform statistical analysis to drive data-informed decisions
Experience in technology, financial services and/or a high growth environment is advantageous
","['Machine Learning', 'Forecasting', 'Big Data', 'Data Modeling', 'Experimentation', 'Mathematics', 'Quantitative Analysis', 'Scripting', 'Product Engineering', 'Strategy', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Data Science', 'Financial Services']"
Admin Assistant (Data Entry),"PH BUILDING, 76 LORONG 19 GEYLANG 388512","Permanent, Full Time",Fresh/entry level,1 year exp,Admin / Secretarial,Monthly,"$1,800to$2,200","
Data entry – update and maintain inventory
Upload discount details
Change and update tag price
Provide general administrative task in the product team

Requirement

Minimum NITEC in office skills
Minimum 1 year of relevant experience in administration.
Fresh graduate are welcome to apply
A committed team player with an eye for detail
Knowledge of MS Office
","['data tagging', 'Microsoft Office', 'Microsoft Excel', 'Inventory', 'Arranging', 'Administration', 'Data Quality', 'packing orders', 'Data Entry', 'MS Office', 'Administrative Support', 'Team Player', 'Microsoft Word']"
Senior / Data Infra Engineer,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,4 years exp,Information Technology,Monthly,"$6,000to$10,500","Description:
Income is looking for a Senior/Data Infrastructure Engineer to join our Data Engineering team in Singapore. Our team owns and runs the Enterprise Datalake used by thousands of users and hosted across AWS, GCP and On-Premises servers.
As a Senior/Data Infrastructure Engineer, you will be at the design, build, maintain and improve our data infrastructure on Cloud, which enables us to make Income data driven organization. In this role, you would also get the opportunity to work with world-class big data and cloud services, such as: AWS/GCP, Glue, Spark, DBT, Airflow, Tableau and PowerBI. Apply now to start taking your career to the next level.
Responsibilities

Work with data engineering and machine learning teams to improve our data infrastructure for increased reliability, maintainability, and scalability.
Architect and design solutions to improve our data delivery capabilities, data quality monitoring, and data pipeline lifecycle.
Architect and administer our cloud applications such as AWS Glue, Sagemaker, LakeFormation, iceberg lakehouse, etc.
Managing Regression Testing Suite , Continuous Integration and Contnuous deployment Pipelines.

Qualifications:

Bachelor Degree in Computer Science or equivalent
4+ years of designing and building production data pipelines from ingestion to consumption in a cloud environment using SQL and Python.
Experience in cloud application architecture & administration in AWS or Azure.
Hands-on experience designing, building and operationalizing large-scale enterprise data solutions and applications. (Airflow, Databricks, Snowflake, Serverless Functions, Cloud storage preferred).
Background in in custom ETL design, implementation, and maintenance.
Hands-on experience with Unix/Linux Command Line Interface (CLI).
","['Tableau', 'Scalability', 'Big Data', 'Pipelines', 'AWS', 'ETL', 'Data Quality', 'Reliability', 'Data Engineering', 'SQL', 'Python', 'GCP']"
Principal Data Scientist,"BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908","Permanent, Full Time",Senior Executive,5 years exp,"Banking and Finance, Information Technology",Monthly,"$10,000to$13,000","Our client is an investment holding company with a strong presence in the region. They are hiring for a Principal Data Scientist to join the team.
RESPONSIBILITIES:

Understand business requirements from senior stakeholders and present data solutions in a clear and concise manner
Develop and implement advance analytics solutions to provide useful business insights
Deploying AI techniques including time-series forecasting and NLP to solve business problems in production environment
Mentoring the data science team and sharing of AI industry best practices

REQUIREMENTS:

Bachelor’s or Master’s in Data Science, Computer Science or equivalent with at least 5 years of data analytics experience
Proficient in Python and SQL
Excellent experience in time-series forecasting and NLP
Must be able to explain complicated Data analytics to C-suite in an easy-to-understand manner
Proven work experience implementing ML solutions in production environment
Experience in KDB and Sagemaker will be preferred

Please contact Xavier Yap at XavierY@charterhouse.com.sg for a confidential discussion.
EA License no: 16S8066 | Reg no.: R1980978
Only successful candidates will be notified.","['Mentoring', 'Machine Learning', 'Forecasting', 'Scala', 'SageMaker', 'Recruiting', 'Artificial Intelligence', 'Data Engineering', 'SQL', 'Python', 'Fraud', 'Statistics', 'Data Science', 'Visualization', 'Data Analytics', 'Business Requirements']"
 , , , , , , , , , 
"Senior Manager / Manager, Data Engineering","MND BUILDING, 5 MAXWELL ROAD 069110","Permanent, Full Time",Manager,5 years exp,Engineering,Monthly,"$4,500to$7,000","
To ensure that source data generated via AIC’s multiple business-specific systems are organized and transformed in ways that support business users’ needs and Business Intelligence applications.
To work closely with Business Intelligence (BI) and Advance Analytics and Modelling (AAM) colleagues in the Research Department, and partner with program development, sector development, outreach, and grants divisions in AIC to understand the business requirements and translate them into long-term data solutions.
To work with key external partners within the existing IT development processes, monitor and provide input to influence the;


Design, development, and optimization of scalable data warehouses;
Building of data pipelines across data systems both internal and external to AIC’s data ecosystem; and
Optimizing of existing data structures so that it supports self-service reporting requirements

Job Requirements:

Bachelor degree in Computer Science, Applied Mathematics, or Engineering.
Professional Data Engineer certification will be considered favorably.
At least 5 years of relevant experience developing, testing, and maintaining data warehouses, preferably in health or social care settings.
Experience in


Data mapping and integration processes;
Building and managing ETL processes;
Handling large data systems with relational databases;
Building pipelines to automate data interface pipelines; and


Familiarity with Excel, SQL, Informatica, Python, Tableau;
Be an advocate for best practices and lifelong learning;
Able to work well independently and in teams;
Excellent written and oral communication skills; and
Flexible, self-motivating, and able to manage multiple projects efficiently.
","['Tableau', 'Data Mapping', 'Business Intelligence', 'Pipelines', 'Data Structures', 'Informatica', 'Data Engineering', 'SQL', 'Python', 'Advocate', 'Applied Mathematics']"
Senior / Data Architect (AWS),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,12 years exp,Information Technology,Monthly,"$10,000to$16,500","As Singapore’s leading composite insurer, Income Insurance knows that a data-driven culture is key to doing good business and ultimately, helping our customers reach their financial goals. With data collection already part of the way we work, our data team is pivotal in making data meaningful and actionable, so that we can all work smarter, make better decisions and create the best experiences for our customers, whether that’s in-person with Income advisors or on our online touchpoints.

This omnichannel customer experience is made possible by several artificial intelligence (AI) solutions, that provide customized offerings and increased efficiency for our customers. Our customers rest with complete peace of mind as we walk this journey with them. From developing innovative, data-driven mindsets to promoting continuous skills development, we’re also proud to say that our employees are with us on our transformational data journey. We know it will take everyone working together to build even further on our rich legacy and create value for both our customers and ourselves.
This role will be part of the Data team within our Information Technology department, focusing on transforming the existing data architecture and build the next generation data platform across Income to support the Digital Transformation. The successful candidate will bring a vision to modernize the data architecture and develop a multi-year roadmap to bring that vision to life, collaborating with business and technology leads, application architects, data science and data engineering teams across the organisation to enable large scale machine learning and analytics use cases. He/She will act as a thought leader for the organization, defining data platform processes and best practices – engaging senior stakeholders across the group to ensure their continued buy-in on strategic data initiatives.

Design, build and implement end-to-end data driven solutions
Define roadmap to transform data architecture focusing on scalability, performance and flexibility throughout the entire data life cycle (ingestion, storage and consumption).
Maintain data architecture framework, standards and principles including modelling, metadata, security, master and reference data
Define reference architecture as a set of patterns that can leveraged by diverse parts of the direction to create and improve data systems
Lead architectural designs solution context diagram and conceptual data model to optimize security, information leverage and reuse, integration, performance, and availability and ensure solutions developed adhere and aligns to the delivered architecture
Consult and influence digital application teams regarding solutions. Collaborate with other staff to design and implement effective technology solutions, while using innovative business and technology processes to identify and implement improvement initiatives, eliminate redundancies and maximize the reuse of data
Work closely with Solutioning, Infrastructure and project teams to understand their needs and ensure the best data architecture is implemented
Provide training and share best practices across teams regarding data architecture design and solution implementation including review and quality assurance
Develop and apply industry best practice technology, design and methodology approaches to design data architecture. Research and recommend new emerging technologies, techniques and tools that will add value to the organization
Working with project teams to ensure architecture requirements are captured and addressed by designs that uphold the enterprise principles and standards
Designing and delivering data architecture on cutting edge green field Data Lake
Designing data integration architecture based on solution requirements e.g. real-time, near real-time, batch
Architecting conceptual, logical and physical architecture and data models for operational enterprise data and analytics solutions using recognised data modelling approaches (e.g. 3NF relational, Kimball dimensional) in standard modelling tools using UML and the ArchiMate modelling language
Owning the definition of data architecture components for information management solutions to facilitate storage, integration, usage, access, and delivery of data assets across the enterprise in both the operational and analytics spaces
Working to accelerate the wider Income business by developing and maintaining long-lasting relationships with senior stakeholders, both during and outside of project delivery
Engaging talent and helping us diversify our talent force by leading data architecture capability and driving further development of the team
Provide direction on linkages between different systems to ensure the information flow is aligned with the information architecture
Provide guidance on the implementation of information architecture
Recommend innovative solutions to increase efficiencies around the integration of complex systems
Assess existing systems to evaluate their usability, usefulness, visual design and content
Communicate the design and recommendations to stakeholders
Develop strategies for seamless and low-risk migration of data between systems
Guide alignment of information management standards with the enterprise architectural plan and information security standards
Identify the desired state of a coordinated information flow through the organization

Qualifications

Bachelor's Degree in Computer Science or related discipline
Min 12-15 years of experience of designing and developing high performance resilient data driven applications, hands on experience in data analytics, data integration, data modelling
Strong experience with AWS tech stack, build data migration/date warehouse from scratch (analyze current system/market, create end-to-end strategy/roadmap), and experience in large scale imgration from on-premises data warehouse to cloud server.
Know ""how"" to load new data saources/integrating new system/entity, implement and runnig cloud server
Experience in designing data patterns to support micro-service based application architecture
Track record of successfully building container-based big data architectures on top of Kubernetes
Experience in designing systems to efficiently handle real-time and batch use-cases
Exposure and understanding in the latest open source technologies across the big data ecosystem, such as distributed storage, real-time event processing and large scale distributed OLAP engines
Exposure to Data as a Service concepts and data virtualization
Working knowledge of data science processes and best practices, with experience in building scalable architectures through the use of data science workflow orchestrators
Hands on experience on DevOps / DataOps / MLOps concepts
Strong data architecture and data modelling skills
Understanding of how data architecture fits with other architecture disciplines
Familiarity with working in agile and waterfall approaches
In-depth understanding and knowledge of business and technology trends
Good understanding of end-to-end application development - data integration for backend API development and front end UI development
Expertise in RDBMS (Teradata/Oracle, PostgreSQL, Vertica etc), PL/SQL, data modeling & ETL/ELT, Snowflake, SingleStore or similar platforms
Expertise in Big Data Technologies like Hive, Pig, Impala, Spark.
Working knowledge on BI tools like Tableau/ Power BI.
Experience in performance tuning, capacity planning and sizing
Good understanding of cloud methodologies and experience with AWS or GCP tool suites and services
Proven track record in strategic planning, individual/team development and service delivery
Embodies a collaborative approach in bringing both business and technology stakeholders together to deliver technology solutions that enable tangible business benefits
TOGAF/DAMA certification would be good to have
At least 2 years of experience in implementing Data Governance
Data Integration & Federation: e.g. Informatica BDE, Python and other scripting and integration technologies
Data Repositories: e.g. SQL Server, Google BigQuery, Amazon Redshift, cloud storage
Experience in implementing RESTful API and services using frameworks such as Springboot or flask
","['Tableau', 'Apache Spark', 'Data Modeling', 'AWS', 'Data Integration', 'Data Governance', 'Data Engineering', 'SQL', 'Python', 'Data Architecture']"
Data Architect,"IBM PLACE, 7 CHANGI BUSINESS PARK CENTRAL 1 486072",Full Time,Professional,12 years exp,Consulting,Monthly,"$14,400to$20,700","As a DTT Engineer/Architect, you will guide the technical evaluation phase as well as during the design and development phase in a hands-on environment in the area of Data Platform, Internet of Things (IoT) and Automation, Analytics including AI and Machine Learning, as well as Blockchain. You will be a technical advisor internally to the sales and delivery team, and work with the product (analytics or data) team as an advocate of your customers in the field. You’ll grow as a leader in your field, while finding solutions to our customers’ biggest challenges in big data, IoT, automation, data engineering and data science and analytics problems.

As a Data engineer or Solution Architect you will provide services to clients in the analytics or data related solutioning and delivery of complex projects/programs for cloud and non-cloud environments, including complex application and/or system integration projects. You will help our customers to achieve tangible data-driven outcomes through the use of Data Engineering frameworks or Data Platform or in the area of Automation and Blockchain, helping data and analytics teams complete projects and integrate our platform into their enterprise Ecosystem.

You will be responsible in terms of stitching together architectural landscape starting from data acquisition, ingestion and transformation before loading the same in the desire data warehouses in form of datamarts as per the requirement. You will also facilitate the process of how the curated data could be consumed by downstream application in order to meet the business requirement in form of Management Information System or Analytics solutions. The solution architect will build architectures & coordinate with other architects to build an end to end prescriptive guidance across network, storage, operating systems, virtualization, RDBMS & NoSQL databases, and mid-tier technologies that include application integration, in-memory caches, and security.

Required Technical and Professional Expertise

Overall 12+ years of (consulting) experience focused in data and analytics.
Have a good understanding of data warehousing, ETL, complex event processing, data engineering, Big Data principles and data visualization, Data Sciences, Business Intelligence, Analytics products etc
Experienced in working in a hybrid cloud environment and exposure to Big Data framework is a must.
Proficient understanding of distributed computing principles
Deep experience with distributed systems, large scale non-relational data stores, map-reduce systems, data modelling, database performance, and multi-terabyte data warehouses
Knowledge in the area of internet of things including IoT related device knowledge is a must for the role
Desired knowledge in the area of containerization framework like Kubernetes or Red Hat Open Shift is an added advantage for the role
Desired knowledge in the area of API/ Microservices development is a good to have skills
Exposure in managing and implement integrations between internal and external solutions
Demonstrated experience in collaborating with domain architecture leadership
Extensive development expertise in Spark and other Big Data processing frameworks (Hadoop, Storm, Kafka etc)
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Knowledge of various ETL techniques and frameworks, such as Flume and stream processing systems like Storm or Spark-Streaming
Programming knowledge and skill with SQL, NoSQL, Python and PySpark
Working knowledge of other BI / Analytics / Big Data tools (IBM Cognos, QlikView, HortonWorks, Cloudera, Azure Data Factory, Automation Anywhere, BluePrism) is a plus
Experience in creating end to end blueprint, estimating the effort, pricing and risk assessment of the solution
Excellent communication skills with an ability to lead right level conversations
","['Machine Learning', 'Kubernetes', 'Azure', 'Big Data', 'Architect', 'Architectural', 'Hadoop', 'Architects', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Data Science', 'Data Warehousing', 'Databases', 'Data Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Solution Architect,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,15 years exp,Information Technology,Monthly,"$9,000to$15,000","Description:

Design and implement effective Datawarehouse / database / Cloud solutions and models to store and retrieve company data.
Examine and identify Cloud / database structural necessities by evaluating client operations, applications, and programming.
Assess Cloud / Datawarehouse / database implementation procedures to ensure they comply with internal and external regulations.
Formalize Design Principles / Coding Standards / Governance processes
Install and organize information systems to guarantee company functionality.
Prepare accurate Cloud / Datawarehouse / database design and architecture reports for management and executive teams.
Oversee the migration of data from legacy systems to new solutions.
Monitor the system performance by performing regular tests, troubleshooting, and integrating new features.
Recommend solutions to improve new and existing Datawarehouse systems.

Qualifications:

Master / Bachelor’s degree in computer science, computer engineering, or relevant field.
A minimum of 15+ years’ experience in a similar role.
Strong knowledge of Datawarehouse / database / Cloud systems and data mining.
Excellent organizational and analytical ab
","['Tableau', 'Big Data', 'AWS', 'Data Management', 'ETL', 'Data Integration', 'Data Governance', 'SQL', 'Python', 'Data Architecture', 'Databases', 'Data Visualization']"
"Senior Solution Designer, Data Solutions","COMCENTRE, 31 EXETER ROAD 239732",Permanent,Manager,5 years exp,Information Technology,Monthly,"$6,500to$13,000","This role is accountable for the solution architect and design of Business Intelligence (BI), Reporting, Visualization and Analytics capabilities across Singtel Data Platform – Data Lake, Enterprise Data Warehouse (EDW) and Operational Data Store (ODS) capabilities within Group.

Responsibilities:

Establish and govern BI, EDW and ODS design guidelines along with standards and best practices
Have an end-to-end vision, and see how a logical data model design will translate into physical data model and integration solutions through the layered architecture within enterprise data warehouse
Have an understanding of end-to-end data platform and data warehouse architecture and capabilities including integration with upstream and downstream systems
Drive and support continuous improvement and optimization activities in BI, EDW and ODS area to ensure they remain relevant, scalable and operational
Identify and drive process improvement in design review and overall change management cycle
Establish templates to capture standard data requirements of different business process for requirement and testing. Champion cause to simplify business requirement gathering and UAT process in overall delivery cycle.
Understand business requirements and objectives in order to analyze / assess the relevant customer data-sets needed
Consult and guide users on their new initiatives or enhancements
Able to validate and challenge user requirements to ensure that appropriate due diligence is placed on requirements
Perform solution design and implementation related to EDW and ODS that is in accordance with defined Strategy & Architecture
Deliver or support the development of cost estimates based on the solution design
Review and validate solution design and cost estimation provided by IT vendors
Review and validate solutions implemented are in accordance with approved solution design
Provide User Acceptance Test (UAT) support to users
Work with internal IT teams & Partners/Vendors to deliver/implement solutions from requirements till post go-live, and ensure they deliver solutions on-time, on-budget that fulfill business requirements and functionality, operational and scalable.
Drive or support the team in RFP and proposal responses

We are committed to a safe and healthy environment for our employees & customers and will require all prospective employees to be fully vaccinated.

The ideal candidate should possess:

Bachelor’s degree in IT, Computer Science, Software Engineering, Business or equivalent.
Minimum 10 years of experience in the area of BI, Data Warehouse or big data platform
Minimum 6 years of experience in gathering business requirement and performing requirement mapping within data warehouse applications
Strong experience in solution architect, designing and building complex end-to-end data warehouse with layered architecture and multiple upstream/downstream systems
Strong experience in converting business requirement into technical requirement and providing end to end solution flow for data warehouse application
Strong experience in designing and building integration solution to extract data from multiple sources and document data flow design for data warehouse.
Good understanding of Telco data warehouse solutions and data models
Good experience with distributed systems, large scale non-relational data stores, big data platforms, and large-scale data warehouses in Telco environment
","['UAT', 'Business Intelligence', 'Due Diligence', 'Big Data', 'Change Management', 'Process Improvement', 'Architect', 'Software Engineering', 'Upstream', 'Estimates', 'Vendor Management', 'Distributed Systems', 'Data Warehouse Architecture', 'Business Process', 'Business Requirements']"
 , , , , , , , , , 
"Distinguished, Data Engineering",78 AMOY STREET 069897,"Permanent, Full Time",Senior Management,8 years exp,"Banking and Finance, Consulting",Monthly,"$20,000to$25,000","Responsibilities:

Acquire new clients and grow the accounts substantially, ensuring that revenue and contribution from these accounts are at the expected and agreed levels with management. This includes identification, qualification, offering and contracting.
Identify new business opportunities and secure these opportunities via personal network or development of products to access new markets
Demonstrated experience applying data science concepts and techniques to a wide range of business situations within the Financial Services industry, resulting in well-formulated solutions for clients
Effectively interpret and communicate results from analysis to the business and our client’s stakeholders
Drive and develop the Data Engineering practise within Synpulse by recruiting team members and showing guidance to your juniors

What we’re looking for:

At least 8 years of experience working in the Financial Services sector on big data project implementations
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines
Strong coding experience in the likes of Scala or Java
Coding experience using Python
Client facing experience, good communication and presentation skills
Bachelor’s Degree in Computer Science, Physics, Mathematics, or similar degree or equivalent
Enthusiasm to learn and develop emerging technologies and techniques
Strong technical communication skills with demonstrable experience of working in rapidly changing client environments
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies

It’s a bonus if you have:

A background in AML, KYC, screening, regulatory compliance or fraud is highly advantageous
Have worked on a variety of complex data orientated projects for financial services clients
Have a good understanding of computer science and preferable come from a software engineering background or other scientific degree incorporating IT modules (e.g., Math/Physics)
Have exposure to Agile, especially SCRUM
Ability and willingness to travel
Experience working with a variety of modern development tooling (e.g., Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g., Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting)
Have an excellent appreciation of what makes a high quality, operationally stable system and how to streamline all areas of development, release and operations to achieve this

Benefits

Snacks & Drinks
Health Insurance
Robust Career Path
Academy Program with Buddy-Mentor

WE

Want to transform what banking means with you!
Are inclusive and diverse
Are committed to creating a flexible, supportive work environment that helps you effectively manage your work and family commitments
Embrace innovate-thinking and entrepreneurship in everything we do
Are award winning and known for our commitment to outcomes
Apply the latest tech and new ways of working
Support your personal growth
","['Scala', 'Big Data', 'Pipelines', 'Recruiting', 'Hadoop', 'Mathematics', 'Software Engineering', 'Agile', 'Scripting', 'ETL', 'Data Engineering', 'Python', 'Docker', 'Data Science', 'Java', 'Financial Services']"
"Director, Data Initiatives, Sustainability","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981","Permanent, Full Time",Middle Management,7 years exp,"Banking and Finance, Risk Management",Monthly,"$10,000to$20,000","The Role Responsibilities
Key responsibilities

Standard Chartered has announced ambitious      targets to reach net-zero carbon emissions from its financed activity by      2050, including interim 2030 targets for the most carbon-intensive      sectors. The Bank has also announced plans to mobilise USD300 billion in green      and transition finance by 2030.
We are seeking an individual passionate about      Sustainability and data with strong commercial acumen, strategic thinking      and project management experience to drive our Sustainable Finance and Net      Zero agenda via data initiatives and partnerships. The individual will      lead the end-to-end execution of data projects internally and externally,      from partner sourcing, evaluation, commercial negotiation, proof of      concept implementation, and commercialisation. This is an exciting      opportunity for candidates with experience in strategy consulting,      partnerships, ESG, and/ or data science.

Data initiative and partnership strategy

Align with key business stakeholders on      operational and strategic priorities to source, advise and deliver data      initiative and partnership opportunities.
Evaluate co-creation initiatives and drive the      right partnerships forward.
Develop compelling business cases to secure      senior management buy-in.
Drive leadership in partner selection,      execution and integration to support and enable strategic and commercial      objectives in Sustainability, ultimately driving the returns on tangible      equity of the Bank.
Stay up-to-date on the latest industry trends      and developments in sustainability practices and technologies in order to      identify new opportunities for partnerships.

Project management

Oversee the end-to-end lifecycle of data &      solution partnerships, from sourcing to commercialisation.
Develop thorough understanding of prioritised      use cases, map and identify potential partners with potential impact at      scale pan-bank, focusing on revenue generation and efficiency.
Lead the commercial negotiation and      collaboration model design with partners.
Manage the onboarding and contracting with      partners.
Orchestrate cross-functional workgroups to      implement and commercialise partnerships through rigorous project      management with clear milestones.
Systematically track performance of live      partnerships and manage partnership pipeline against targets and KPIs.
Adopt proactive approach to risk management on      an ongoing basis in identifying, assessing, monitoring, mitigating risks      related to partner selection and integration.

Stakeholder management

Lead cross-functional teams through evaluation      and commercialisation of partnerships using robust frameworks.
Secure and align appropriate internal      resources in close collaboration with Technology, Operations, and relevant      business/product stakeholders.
Manage internal and partners timelines for      build and integration.

Key Stakeholders

Chief Sustainability Office Team
CCIB Digital Channels and Data Analytics      (DCDA)
CCIB Client Coverage Team
CCIB Business Development Team
Group & CCIB Data Governance Team
CCIB Architecture Team
Product and Functional Partners

Our Ideal Candidate

7+ years of experience in management consulting,      data, sustainability, and/ or strategic partnerships.
Track record of data and solution partnership.
Track record of delivering complex project,      managing timeline and budget.
Strong business acumen, ability to understand      business needs, translate into data use cases, and develop business cases      and commercialization strategy.
Excellent interpersonal skills, strong verbal      and written communication skills.
Track record in collaborating with multiple      stakeholders and driving results.
Excellent business analysis problem-solving      skills.
Good writing and communication skills, and      experience with project management.

Role Specific Technical Competencies

Market Knowledge
Processes & Products
Risk Management Knowledge

About Standard Chartered
We're an international bank, nimble enough to act, big enough for impact. For more than 160 years, we've worked to make a positive difference for our clients, communities, and each other. We question the status quo, love a challenge and enjoy finding new opportunities to grow and do better than before. If you're looking for a career with purpose and you want to work for a bank making a difference, we want to hear from you. You can count on us to celebrate your unique talents. And we can't wait to see the talents you can bring us.
Our purpose, to drive commerce and prosperity through our unique diversity, together with our brand promise, to be here for good are achieved by how we each live our valued behaviours. When you work with us, you'll see how we value difference and advocate inclusion. Together we:

Do the right thing and are assertive,      challenge one another, and live with integrity, while putting the client      at the heart of what we do
Never settle, continuously striving      to improve and innovate, keeping things simple and learning from doing      well, and not so well
Be better together, we can be ourselves,      be inclusive, see more good in others, and work collectively to build for      the long term

In line with our Fair Pay Charter, we offer a competitive salary and benefits to support your mental, physical, financial and social wellbeing.

Core bank funding for retirement savings,      medical and life insurance, with flexible and voluntary benefits      available in some locations
Time-off including annual, parental/maternity (20      weeks), sabbatical (12 weeks maximum) and volunteering leave (3 days),      along with minimum global standards for annual and public holiday, which      is combined to 30 days minimum
Flexible working options based around      home and office locations, with flexible working patterns
Proactive wellbeing support through Unmind, a      market-leading digital wellbeing platform, development courses for      resilience and other human skills, global Employee Assistance      Programme, sick leave, mental health first-aiders and all sorts of      self-help toolkits
A continuous learning culture to support your      growth, with opportunities to reskill and upskill and access to physical,      virtual and digital learning
Being part of an inclusive and values driven      organisation, one      that embraces and celebrates our unique diversity, across our teams,      business functions and geographies - everyone feels respected and can      realise their full potential.

Recruitment assessments - some of our roles use assessments to help us understand how suitable you are for the role you've applied to. If you are invited to take an assessment, this is great news. It means your application has progressed to an important stage of our recruitment process.
Visit our careers website www.sc.com/careers","['Creative Problem Solving Skills', 'Management Consulting', 'Sustainability', 'Interpersonal Skills', 'Business Analysis', 'Business Acumen', 'Risk Management', 'Data Governance', 'Project Management', 'market knowledge', 'Commercialization', 'Banking', 'Finance', 'Driving Results', 'Stakeholder Management', 'Senior Stakeholder Management', 'Strategic Partnerships', 'Oral & Written Communication Skills']"
"Manager, Data Science 1","SUNTEC TOWER FIVE, 5 TEMASEK BOULEVARD 038985",Permanent,Manager,5 years exp,Information Technology,Monthly,"$7,900to$11,300","PayPal’s rapidly growing Buy Now, Pay Later (BNPL) payment suite is trusted by millions of consumers globally to flexibly purchase the products they love. As PayPal continues to bring innovative and customer-centric BNPL products to newer markets and channels, the BNPL Analytics team is looking for an experienced data scientist who will look at data, customer, and merchant feedback to analyze and evaluate trends to drive improvements in KPIs and overall CX, engagement and program profitability. This person will assist with identifying areas of opportunity to help build a best-in-class experience for our customers. This includes sizing and prioritizing opportunities and measuring impacts of changes post implementation across product and operations. 

•	You believe in data-driven decisions and use data to answer business questions
•	You are hyper-analytical, intellectually honest, and extremely passionate about data and testing (e.g., A/B experimentation)
•	You are a highly motivated, result-oriented self-starter, enjoy working in a fast- paced environment, and can deliver successful results with minimal guidance
•	You are energized, fun-loving and an adventurous team player
Job DescriptionJob Description
Core Responsibilities:

Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with PayPal’s Buy Now Pay Later consumer products
Work cross-functionally with product, engineering, and user experience design teams to design hypothesis-driven experiments; make clear, coherent and holistic recommendations based on test results
Identify trends, distill insights, and build dashboards to find opportunities to help identify product, training, and other operational opportunities
Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and merchant products
Work with partners across the business measure and evaluate the performance of various initiatives and product changes to KPIs
Investigate and document current customer journeys and internal processes and flows to determine opportunities


Requirements:

Data-driven mindset with a degree in any quantitative discipline such as Engineering, Computer Science, Economics, Statistics or Mathematics
5+ years of experience in analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions
Expertise in SQL, Excel, and visualization tools such as Tableau
Experience with a statistical programming language like R or Python preferred
Strong written and verbal communication skills to influence stakeholders
Prior work experience with consulting, financial or product-based companies is highly valued
Experience in managing and mentoring junior analysts is a must

","['Tableau', 'Statistical Programming', 'Mentoring', 'Experimentation', 'Mathematics', 'Quantitative Analysis', 'Consumer Products', 'Product Engineering', 'Economics', 'Data Mining', 'SQL', 'User Experience Design', 'Python', 'Statistics', 'Visualization', 'Customer Journeys']"
Data Modeler,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616","Permanent, Full Time",Executive,3 years exp,"Information Technology, Insurance",Monthly,"$5,000to$8,000","Contribute to the deliverables of Client's Data projects, focusing on data modelling and data mapping projects development and support.

Responsibilities

Provide support for Data platform on projects requiring data modelling and data mapping works.
Ensuring data model best practices, industry standards and ability of data model to answer important business questions.
Responsible for driving implementation of internal data modelling delivery projects and participate in different phases of delivery projects.
Participate in vendor delivery project review, ensure data modelling and data mapping project delivery quality.
Responsible for receiving the transferred project from vendor and supporting the enhancement, development and maintenance of data models.
Participate in solving the technical difficulties encountered in the research and development of data modelling.
Provide regular reports to data management team

Requirements

Computer related major with good data engineering experience
Cloud platform knowledge in Azure and AWS
Highly proficient in data development technology related to data engineering processes including data modelling, and relevant experience in real-time data processing.
Experience in various data modelling techniques.
Familiar with the design and construction of enterprise data warehouse, have experience in management and design of large-scale data warehouse.
Solid understanding of Azure Data Management Solution

Those who are keen for the role and would like to discuss the opportunity further, please click ""Apply Now"" or email Kin Long at kfok@morganmckinley.com with your updated CV.

Only shortlisted candidates will be responded to, therefore if you do not receive a response within 14 days, please accept this as notification that you have not been shortlisted.

Morgan McKinley Pte Ltd
EA Licence No: 11C5502 | EAP Registration No: R2095054","['Azure', 'Big Data', 'Data Modeling', 'Erwin', 'Hadoop', 'Data Management', 'ETL', 'Data Integration', 'Data Engineering', 'Python', 'Data Architecture', 'Apache Kafka', 'Project Delivery', 'Databases', 'Data Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Clinical Data Analyst,"NATIONAL CANCER CENTRE SINGAPORE, 11 HOSPITAL CRESCENT 169610","Contract, Full Time",Executive,2 years exp,"Healthcare / Pharmaceutical, Others",Monthly,"$3,200to$4,500","About Us
The National Cancer Centre Singapore (NCCS) is a leading national and regional tertiary cancer centre, attending to the majority of cancer cases in Singapore’s public healthcare sector. We offer world class oncology care by having the best talent, doing robust clinical and translational research and leading education efforts to improve cancer outcomes. Join us to build a meaningful career and offer patients hope for a cancer-free tomorrow.

About the Role
You will be part of the Department of Cancer Informatics that seeks to support clinical and research activities of NCCS by providing leadership in Cancer Informatics, rationalizing current & future IT clinical application resources to present an integrated, practical and user-friendly interface for clinician use. As a Clinical Data Analyst, you will be involved in the development, implementation, evaluation and operational aspects of clinical database projects, as well as data and quality management of clinical database.

Some of the Key Responsibilities Include

Perform clinical data abstraction, data quality management, and data entry & coding using appropriate classification systems
Analyse and interpret cancer trends such as analysing and interpreting disease and survival trends, undertaking statistical modelling to assess impact of health promotion programmes
Provide support in the planning & developing of cancer-related data collection systems, maintaining of policies & procedures and reports
Attend and record minutes of department meetings & various workgroups, and participate actively in institutional activities


Job Requirements

Degree in Nursing, Health Sciences, Biomedical Sciences or equivalent with 2 years of relevant of working experience
Prior experience in the field of clinical database project or clinical coding or health-related data analytics or data management in clinical research project would be an advantage
Experience in predictive analytics and proficiency with using R/Python, SPSS, STATA and Tableau will be an advantage
Organized, meticulous and independent with good interpersonal, verbal and written communication skills
Resourceful and creative in problem solving and ability to handle multiple projects
Proficient in Microsoft Office
","['resourceful', 'Microsoft Office', 'Interpersonal Skills', 'Healthcare', 'ability to juggle multiple projects', 'Pay Attention to Detail', 'SPSS', 'organised', 'Data Entry', 'Analytical Problem Solving', 'SATA', 'Administrative Support', 'Nursing', 'Data quality management', 'Writing minutes', 'Reports', 'Written & Verbal Communication Abilities', 'Able To Work Independently']"
Data Center Engineer,"61 ROBINSON, 61 ROBINSON ROAD 068893",Contract,Professional,3 years exp,Information Technology,Monthly,"$4,500to$6,000","We are seeking a highly motivated, best-in-class Data Centre Network Technician to join the growing team for one of the Multinational consumer goods corporations on 12-months & renewable contract role.

Data Centre Network Technician will work with minimum supervision in a dynamic environment to drive the stability and sustainability of our next-generation networks and to develop innovative ways to automate and scale our network as we expand.

The Data Centre Network Technician will:

Scale support of several data centre locations and day to day      assistance with capacity management
Work closely with both internal customers and external      vendors to facilitate smooth project execution as directed by Technical      Program Managers
Deliver sustainable and repeatable solutions and processes      always with an eye on improvement
Work closely with our Network Engineering & Network      Technical Project Manager teams to ensure fast, smooth roll out of new      designs and products
Collaborate with various stakeholders to remove project      obstacles.

QUALIFICATIONS

Educated in Information Systems, Computer Science, or      Information Assurance
3-5+ years of mid-level and/or enterprise experience as a      technician or engineer; or an equivalent combination of education and  experience
1+ year(s) experience with cabling infrastructure best      practices and methodologies
1+ year(s) experience with completing customer requests via      Remedy trouble ticketing system
Experience in large scale data centre network implementations      and support

If this role describes you, please hit the apply button for a confidential chat alternatively you may reach out to me Jaya jvenkataraman@welovesalt.com 

CEI No: R1659595 / Licence No: 07C3147","['Switches', 'Sustainability', 'Troubleshooting', 'Network Engineering', 'Hardware', 'Ticketing', 'Data Center', 'VMware', 'SAN', 'Information Assurance', 'Auditing', 'Windows Server', 'Windows', 'ITIL', 'Cabling', 'Linux']"
Data Scientist,"SINGAPORE POOLS BUILDING, 210 MIDDLE ROAD 188994",Permanent,Professional,4 years exp,Others,Monthly,"$6,000to$9,800","We are looking for a passionate and professional Data Scientist to join our team to help us with our mission of helping us define and analyze the data across the company.
Based in Singapore and reporting into the Director, Strategy & Analytics, the Data Scientist will work on team projects and individual projects. The right candidate will have day-to-day responsibility of ensuring accuracy of data for business decisions.
However, we also recognize that each Data Scientist has a unique blend of skills. Whether your strength is in data modeling or in analytical, we want to talk to you.
What You'll Do

You will identify, undertake and implement analytics projects including formulation of use cases, gathering of data, development, implementation and maintenance of models.
You will support the development of Singapore Pools' in house analytic capabilities through the implementation of structured methodologies and creation of infrastructural capabilities to process and analyze data
You will work with strategy to identify opportunities to enable the implementation and realization of the long term strategic vision of Singapore Pools.
You will manage and mentor the team, providing supporting and guidance as required, and working with the Strategy Team to identify potential business opportunities and problems in the medium term
You will design, develop and productionize analytical models for commercial and social goals of the company.
You will play a strategic role in formulating new and creative ideas for leveraging the business’s vast collection of data in the databases.
You will play an analytical role in researching, designing, implementing, and deploying full-stack scalable data analytics vision and machine learning solutions to challenge various business issues.
You will provide advanced expertise on statistical and mathematical concepts for the Analytics department.
You will drive adoption of structured analytic methodology (AMP) for identification and implementation of analytics project.
You will supports relevant stakeholders through quantitative analytics, and the application of appropriate advanced analytics for the business’s key initiatives.

Who You Are

You will need to be a graduate in Computer Science, Economics, Mathematics or Statistics.
Postgraduate degree majoring in data analytics or machine learning preferred.
You will need minimum 3 years of relevant work experience.
You should have experience with statistical and analytical modeling and knowledge of analytic tools and big data technologies.
You should be able to work with tools to clean, transform, manipulate, model and visualize large amounts of data.
You should have the ability to communicate complex ideas to technical and non-technical audiences.
You should have deep experience with languages like R, Python, SQL, Excel.
You should have experience in Data Cleaning, Sampling, Balancing, Imputation.
You should have experience in Hypothesis Testing like t-test, Anova, chi-sq.
You should have experience in modeling like Regression, Decision trees, Random Forests, Neural Networks, Clustering, Classification, K-cross validation.
You should have knowledge of Big Data frameworks/ technologies such as Spark, Hive or similar frameworks.

Benefits

Competitive salaries
Flexi Benefits
Staggered working hours
Medical Insurance
Corporate Mobile Plans

Singapore Pools welcomes you not for how you look, where you come from, or differences you may have. We want you here for who you are. Diversity at the company helps us see a greater picture represented by different voices, helping us in contributing back to the society. So, feel free to express who you are, and be proud of your heritage and personal experience as you begin your journey with us!
Singapore Pools was established by the Government on 23 May 1968 to provide safe and trusted betting to counter illegal gambling. As a not-for-profit organisation, all of Singapore Pools' surplus is channeled to Tote Board to fund a wide range of causes in social service, community development, sports, the arts, education and health. Currently, Singapore Pools contributes about $2 billion annually to the Government in the form of taxes and duties, and for the funding of good causes.","['Tableau', 'Machine Learning', 'PySpark', 'Big Data', 'Data Modeling', 'Hadoop', 'Mathematics', 'Formulation', 'Strategy', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Data Science', 'Data Analytics', 'Community Development']"
Data Scientist [Search],"HONG LEONG BUILDING, 16 RAFFLES QUAY 048581","Permanent, Full Time",Senior Executive,5 years exp,Information Technology,Monthly,"$10,000to$14,000","Ahrefs is looking for an experienced Data Scientist to join our Data Science team, to be based in our Singapore office. In this role, you will research, prototype, deploy to production and maintain information retrieval and search systems.
What You'll Do

Research, prototype, build and maintain systems for information retrieval, search, document classification, and Q&A
Create comprehensive product requirements together with Product Development, Design and Marketing teams
Work closely with the Engineering teams (frontend and backend) to implement, deploy, and maintain production systems
Write thorough documentation
Effectively communicate highly technical results to various teams

Basic Requirements

Preferably at least a Master’s degree in any quantitative discipline: Mathematics, Computer Science, Statistics, etc.
Experience with search, information retrieval, and natural language processing is a must
Experience with streaming algorithms and applications
Experience in Python, SQL (clickhouse dialect is a plus), Git, CI/CD
Experience with (at least one) deep learning framework: TensorFlow, Pytorch, Theano
Experience with big data platforms such as Spark and Hadoop
Experience with Lucene-based search engines: Solr and/or Elasticsearch
Strong interpersonal and communication skills
Familiarity with functional languages such as OCaml or Haskell is a big plus
","['Information Retrieval', 'Algorithm Analysis', 'Search', 'Data Analysis', 'Big Data', 'Lucene', 'Natural Language Processing', 'Search Engines', 'Data Mining', 'ElasticSearch', 'Data Science', 'Data Analytics', 'Data']"
 , , , , , , , , , 
Data Center Engineer,2 KAKI BUKIT AVENUE 1 417938,Full Time,Executive,1 year exp,"Engineering, Information Technology",Monthly,"$2,800to$3,600","Responsibilities
Responsible for the management &technical support of servers/routers/switches/network in Data Center environment
Configuration changes of the network and debugs of Data Center network, fault troubleshooting, system installation and configuration, equipment operation in Data Center
Management of DC Capacity Specification and proactively detect & resolve the potential issues related to DC Network or Servers
Perform changes to system services and configuration
Requirements
Higher Diploma or above in Computer Science/ Telecommunication/ Engineering or a related subject
Minimum 1-year relevant experience
Basic knowledge in Data Centre domain
Able to speak Mandarin in order to liaise with Mandarin speaking associates and customers
Shift operation is required (7x24）
Immediately available is preferred","['Switches', 'Troubleshooting', 'Hardware', 'Data Center', 'VMware', 'SAN', 'Auditing', 'Reliability', 'Telecommunication', 'Windows Server', 'IP', 'Windows', 'ITIL', 'Cabling', 'Linux', 'Technical Support']"
Data Product Lead,1 RAFFLES QUAY 048583,Full Time,Manager,8 years exp,Information Technology,Monthly,"$10,000to$18,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Data Science team of e-commerce is aiming to provide valuable business insights to the partner teams, including operations, product manager, etc. The business is still expanding globally, and we do wants to get the talented DS/DA/DPMs to join us to make impact together!

Responsibilities

Responsible for the data product matrix of the SEA e-commerce business. According to the
characteristics of the SEA e-commerce business, combined with the mature ideas in the industry,
lead the team to complete the planning, design and implementation.
Externally, empower sellers, creators and service providers to provide business whole-link
analysis and data-based diagnostic suggestions; Internally, support business expansion in various
key scenarios such as industry expansion and marketing promotion, quickly discover
abnormalities and formulate solutions, follow-up strategy
In-depth research on the business models and data pain points of sellers, creators and service
providers in the SEA market, and formulate a reasonable business iteration rhythm; in-depth
understanding of e-commerce business development planning and key points, combined with the
operation organization model, watching the moving lines and plan operations Data product
architecture
Combine local American culture and data analytics capabilities to provide efficient, intelligent
and localized user experience
Deeply explore the difficulties of data interpretation in e-commerce business, collaborate with
horizontal strategy teams such as data analysts and scientists, and explore innovative data
products, such as growth models and strategy optimization suggestions;

Qualifications

Bachelor degree or above, major in Computer, Mathematics or Statistics;
More than 8 years of experience in data products and more than 3 years of management
experience
Business sensitivity, data insight, algorithm perspective, experience in e-commerce platforms,
brand e-commerce or algorithm projects is preferred
Proficient in using design tools such as Axure or Xmind, familiar with drawing product flowchart
and product requirement doc (PRD) and technical function description doc writing;
Excellent communication and expression skills, strong ability to withstand pressure, and good
abllity to coordinate


TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Travel Technology', 'Tape', 'Usability', 'Mathematics', 'User Experience', 'Drawing', 'XMind', 'Online Travel', 'FOCAL', 'Strategy', 'Axure', 'Travel Agency', 'Pressure', 'Statistics', 'Data Science', 'Data Analytics']"
 , , , , , , , , , 
Head of Data Science,52 JOO CHIAT ROAD 427374,Full Time,Middle Management,5 years exp,Others,Monthly,"$14,000to$20,000","Cialfo is a leading platform connecting students, higher education institutions, and counselors through technology-driven solutions. Launched in 2017 with a mission to make education accessible to 100 million students, Cialfo provides a range of mobile and web solutions to students, K-12 institutions, and higher education institutions. We’re one of the fastest-growing tech startups in the region, consistently charting new heights!
Job Description
We are looking for a Head of Data Science to lead and expand the data science function in Cialfo and help us gain useful insight out of our data gold mines. Data is the way forward and this role will give you the opportunity to build/mentor an ideal team to pave the way forward! This role will require responsibilities such as hiring and managing a lean data science team, planning projects, be hands-on in building analytics models and production / deployment. You should have a strong problem-solving ability and a knack for statistical analysis. If you’re also able to align our data products with our business goals, we’d love to meet you. This position will be part of our Product team (yes, our wonderful colleagues who make our platform a reality!!) and your ultimate goal will be to help improve our products and business decisions by making the most out of our data.
Responsibilities

Manage a team of data scientists, machine learning engineers and big data specialists
Lead data mining and collection procedures
Ensure data quality and integrity
Interpret and analyze data problems, turning business problems into data insights
Conceive, plan and prioritize data projects
Build analytic systems and predictive models
Test performance of data-driven products
Visualize data and create reports
Experiment with new models and techniques
Has in-depth knowledge and expertise in the process of converting an unstructured problem to useful and actionable insights using data science/analytics.
Align data projects with organizational goals
Planning data projects
Building analytic systems and predictive models
Managing a team of data scientists, machine learning engineers and big data specialists
Collaborating with stakeholders across teams to execute projects.

Requirements

Proven experience as a Data Scientist or similar role, with 5 - 8 years experience.
Demonstrate the ability to distil complex business problems, solutionize and turn them into measurable, actionable and optimizable outcomes.
Have experience in building, maintaining and evaluating models in a production (real time and offline) environment. Design and build scalable systems (a short SLA only excites you like there's no tomorrow!)
Experience building a team from scratch with a strategic vision on how Cialfo can be even more data driven.
You've done production (real time and offline), hands down you've got this. A short SLA only excites you like there's no tomorrow!
Strong in the common data science tongues (R, Python, Scala, …), with deep expertise in common data science tools/package (sklearn, mllib, tensorflow, torch, etc.)
Experience with SQL and NoSQL databases
Experience building a team from scratch with a strategic vision. Earn extra stripes if you can demonstrate your talent retention ability.
Stakeholder management is your strong suit, you know how to use data for stakeholder buy-in.
Strong organizational and leadership skills, with a bias to action
Masters Degree or PhD in Computer Science, Data Science, Mathematics or similar field
","['Higher Education', 'TensorFlow', 'Machine Learning', 'Scala', 'Big Data', 'Mathematics', 'Data Quality', 'Data Mining', 'Gold', 'SQL', 'Scratch', 'Python', 'Data Science', 'Stakeholder Management', 'Web Solutions']"
 , , , , , , , , , 
Data Center Operator,1 1 117438,"Permanent, Full Time",Junior Executive,5 years exp,Information Technology,Monthly,"$2,000to$3,000","Duties and Responsibilities
• Review, monitor, investigate and escalate alerts triggered to the respective escalation stakeholders
• Determination whether triggered alerts warrant further investigation and verification
• Make end-to-end follow ups with respective escalation stakeholders where applicable
· First level troubleshooting on Systems accordingly to System SOPs
· Perform basic health check and performed operation SOPs
· Access to System break-glass accounts for emergency SOPs for first level troubleshooting
· Individual Privilege accounts to Servers to perform first level checking: Services up& running, Restart services/server, and instructions from L2 for administrative actions
· Non-Privilege Access to monitoring dashboards
· ITSM

Qualifications
· Singaporean or PR
· Have basic knowledge about data centre system infrastructure
· Have 1-2 years’ experience in datacentre operations
· Able to work 12-hr shifts (about 3-4 days’ work in a week)
· Willing to support 24x7 operation hour
· Certificates or Diploma in Computer engineering or equivalent

Interested applicants are open to apply through this job ad with your most updated Resume/CV.
EA Reg No: R1988435
EMBRIO CONSULTING PTE. LTD.
EA License Number 10C4154","['Switches', 'Tape', 'Troubleshooting', 'Tape Management', 'Hardware', 'Wiring', 'Data Center', 'Inventory', 'Investigation', 'Auditing', 'CCTV', 'Scratch', 'Consulting', 'ITIL', 'Cabling', 'Linux']"
Jr Medical Data annotator,"KEWALRAM HOUSE, 8 JALAN KILANG TIMOR 159305",Permanent,Junior Executive,2 years exp,"Healthcare / Pharmaceutical, Hospitality",Monthly,"$3,000to$4,500","Medical Data annotator
Description
Pactera EDGE is looking for detail-oriented individuals for an data annotation project, in which you will annotate clinical notes and medical records. You will work with a growing multidisciplinary team that works at the intersection of clinical knowledge and AI data labeling. The ideal candidate for this role is someone with clinical or healthcare background, has great attention to detail, and is comfortable conducting repetitive work with medical data.
Purpose
The core aspect of this role is the annotation of clinical data- to make it easier for software, analytics & data science teams to improve the quality of health AI NLP services.
Main Requirements
. Thoroughly familiar with general medical concepts and terminology
· Basic knowledge of SNOMED-CT, ICD-10, CPT, LOINC, MULTUM ETC
· Ability to perform a repetition of annotation tasks with consistency, quality, and speed
· Candidates should have educational background in biotechnology, biochemistry, Biochemistry, Pharmacology, computational linguistics, B.Pharm & M.Pharm etc.
Desired Qualifications
· Proven clinical data domain expertise preferably as a clinician, clinical coders, medical billing, and coding (2+ year and more)
· Experience with Annotation software.
· Certification in AAPC is a plus
Responsibilities
· As a data Annotator, you will be responsible for annotating and/or quality-reviewing clinical data for symptoms, diagnosis, treatment procedures, medications, adverse events, laboratory results etc.
· Apply your comprehensive knowledge in medical terminology, and coding procedures for data curation and database modeling
· A commitment for 40 hours/week is required","['Biochemistry', 'Clinical Research', 'Modeling', 'Medical Billing', 'CPT', 'Treatment', 'Healthcare', 'Medical Terminology', 'Translation', 'Clinical Development', 'Clinical Trials', 'Biotechnology', 'Computational Linguistics', 'Attention to Detail', 'Pharmacology', 'Data Science', 'Medical Records', 'Terminology', 'Laboratory']"
"Distinguished, Data Scientist",78 AMOY STREET 069897,"Permanent, Full Time",Senior Management,10 years exp,"Banking and Finance, Consulting",Monthly,"$20,000to$25,000","Responsibilities:

Acquire new clients and grow the accounts substantially, ensuring that revenue and contribution from these accounts are at the expected and agreed levels with management. This includes identification, qualification, offering and contracting.
Identify new business opportunities and secure these opportunities via personal network or development of products to access new markets
Demonstrated experience applying data science concepts and techniques to a wide range of business situations within the Financial Services industry, resulting in well-formulated solutions for clients
Effectively interpret and communicate results from analysis to the business and our client’s stakeholders
Drive and develop the Data Science practise within Synpulse by recruiting team members and showing guidance to your juniors

Requirements:

Demonstrated at least 10 years of relevant experience in the Financial Services industry.
Experience in building up a practise – including recruiting, leading, and organising the team.
Uncanny ability to remove the complexities from complex data science methods and theories
Seasoned consulting professional who is comfortable operating in a client-facing role
Fluency of at least one scripting language (e.g. Python) and its related frameworks and libraries
Strong domain experience in one of the following areas: Fraud Risk Management, Transaction Monitoring, AML, KYC, Trade Surveillance, or Market Conduct
Deep experience and knowledge of data processing, machine-learning, and data analytics techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Identify patterns in data. This includes having a keen sense of pattern detection and anomaly detection.
Critical thinking and problem-solving skills are essential for interpreting data.
","['Product Innovation', 'Blogging', 'NLTK', 'Critical Thinking', 'Scripting', 'Artificial Neural Networks', 'Organizational Development', 'Distributed Systems', 'Python', 'Anomaly Detection', 'Data Science', 'Technical Leadership', 'Data Analytics', 'Fraud Risk Management', 'Django', 'Financial Services']"
Senior Data Protection Specialist,"CROSS STREET EXCHANGE, 22 CROSS STREET 048421",Permanent,Middle Management,5 years exp,"Information Technology, Legal",Monthly,"$7,000to$9,000","What we do
Founded in 2011, Coda Payments (“Coda”) is the leading provider of secure, cross-border monetisation solutions for digital products and services in more than 60 markets. Through our three services: Codashop, xShop, and Codapay, we help top digital content publishers worldwide such as Activision Blizzard (Call of Duty: Mobile, Diablo Immortal), Riot Games (VALORANT, League of Legends: Wild Rift), Moonton (Mobile Legends: Bang Bang), Garena (Free Fire), Tencent (PUBG Mobile), beIN, Bigo Live, Tinder, and Viu to monetise their content and unlock new revenue streams.
Headquartered in Singapore, Coda has 11+ offices and 35+ remote locations worldwide. To date, we have over 500 employees of 42 nationalities working together towards the same mission: to offer our customers the best value, experience and entertainment every day, without fail.
In 2022, we have also been named the 5th fastest growing fintech company in the APAC by the Financial Times, the 13th fastest growing company in Singapore by the Straits Times, and a Technology Pioneer by the World Economic Forum.

Responsibilities: 

Promoting and encouraging a culture of data privacy across the organization by implementing privacy awareness plans, updating training materials and by providing frequent privacy training.
Help build and support a network of privacy champions across business functions in order to scale the program in delivering assessments, training and resolve queries.
Managing the communications with data subjects and handling any request they have and supporting the DPO regarding privacy complaints.
Updating ROPA’s, data mapping sheets and executing privacy impact assessments.
Maintaining privacy control over third party vendors via third party risk assessments and supporting the privacy counsel with data processing agreements.
Advice and monitor data breach incidents by managing the breach investigations, notification assessment to the regulators as well as our partners and vendors.
Managing user consents and cookies through OneTrust platforms.
Undertake legal research and horizon scanning and report to the DPO on emerging privacy and data protection laws and guidance.
Work to ensure that data protection and relevant best practices are fully integrated into the compliance framework of the business.

Requirements: 

Qualified to practice law and in good standing in APAC jurisdiction.
5 or more years' of post qualifications experience, at least 3 years in managing privacy legal and regulatory matters.
OneTrust Privacy Professional certification.
CIPP - E / A/ US certification or readiness to get one.
Knowledge of global data protection laws and practices, including EU-GDPR, UK-GDPR, Singapore PDPA, CCPA, CPRA and LGPD.
Proven work experience in dealing with EU-GDPR, UK-GDPR, Singapore PDPA, CCPA and CPRA.
Proven experience with privacy accountability, including ROPA’s, Privacy Impact Assessment, Breach Analysis and Reporting, Data Mapping and Third Party Control.
Proven experience with privacy awareness, including privacy training and implementing awareness plans.
Proven experience with data subjects, including handling of DSRR and cookie management.
Prior experience in a global FinTech, eCommerce and payments services industry.
Excellent written and communication skills with keen attention to detail and the ability to build relationships with a variety of stakeholders across the business.
","['data protection', 'data protection regulation', 'Microsoft Excel', 'Entertainment', 'Legal Research', 'Investigation', 'data protection legislation', 'Risk Management', 'Personal Data Protection', 'Compliance', 'implementing data protection', 'Attention to Detail', 'privacy and data protection', 'Audits', 'Accountability', 'Communication Skills', 'Data Protection Management', 'Business Requirements']"
Data Scientist,"TAHIR BUILDING, 140 ROBINSON ROAD 068907",Full Time,Professional,3 years exp,Engineering,Monthly,"$5,000to$8,500","Join and Grow with us!
At FOMO Pay, we are committed to breakthrough innovation in payment methods to disrupt tradition. Here, you will work alongside Company leaders who are pioneers in the industry with proven experience in leading and building the future of digital payment technologies and solutions. We offer an inclusive, supportive, and continuous learning culture where everyone can grow to be their best selves and advance in their personal and professional goals.

Key Responsibilities:

Research and devise innovative statistical models for data analysis
Build data products to extract valuable business insights, trends and patterns
Work with large and/or complex data sets to solve a wide array of business problems using different analytical and statistical approaches
Identify and integrate new datasets that can be leveraged through our product capabilities, and work closely with the engineering team in the development of data products
Devise and utilise algorithms and models to mine big-data stores; perform data and error analysis to improve models; clean and validate data for uniformity and accuracy
Collaborate with product design and engineering teams to develop an understanding of needs
Keep current with technical and industry developments

Requirements:

Bachelor’s degree (or equivalent) in Statistics, Applied Mathematics, or a related discipline
Proven experience in pattern recognition and predictive modeling
Proficient in Excel, PowerPoint, Tableau, SQL, and programming languages (Java/Python/Scala)
Strong ability to perform statistical analysis to drive data-informed decisions
Proven experience and knowledge of the payment industry is strongly desired
Ability to multitask under pressure

Our Perks and Benefits

Competitive Compensation and Benefit Package
Group Hospitalisation and Medical Insurance
Fun and Dynamic Environment with plenty of learning and growth opportunities
Career Advancement
Professional Development Training Workshops
Team Building Sessions
","['Tableau', 'Ability to Multitask', 'Machine Learning', 'Data Analysis', 'Product Design', 'PowerPoint', 'SQL', 'Predictive Modeling', 'Pressure', 'Python', 'Statistics', 'Data Science', 'Pattern Recognition', 'Applied Mathematics']"
 , , , , , , , , , 
Data Centre Technician,"THE TOPIARY, 11 FERNVALE LANE 797495","Permanent, Full Time",Executive,5 years exp,Information Technology,Monthly,"$4,600to$6,600","What this Job Entails:

The Data Center Technician is responsible for the installation of hardware into racks, asset tagging and scanning, cabling, data center maintenance, documenting processes and server installations.

Roles and Responsibilities:

Responsible for installing, moving, and decommissioning hardware including cabinets, shelves, power strips, rails, fiber/copper/other cables and cable management, servers, storage, and other devices in the Data Center.
Confirm and label devices, rack and cables.
Work in a standard ticketing system, providing clear, timely, and appropriate customer communications.
Work under the direction of Site Operations Supervisor and/or Operations Manager) and follow Standard Operating Procedures (SOPs), Program Policies, Safety Policies, and Security Policies, while meeting requirements for quality and quantity of work.
Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position

Required Qualifications/Skills:

High school diploma or general education degree (GED) and 5 to 8 years’ related experience and/or training; or equivalent combination of education and experience
Networks with senior internal and external personnel in own area of expertise
Demonstrates good judgment in selecting methods and techniques for obtaining solutions
Excellent verbal and written communication skills in English
Ability to respond to any On-Call request within 1 hour, while on-call.
Experience cabling systems (power/copper/fiber/other) correctly based on ticket requirements and SOP standards
Experience working with CAT5e and CAT6 copper cable and multi-mode and single-mode fiber
Proven ability to adapt to changing priorities, conditions, and circumstances
Strong organization skills
Working knowledge of computer hardware
Understanding of networking components and infrastructures
Knowledge of copper and fiber testers
Excellent troubleshooting skills
Understanding of Data Center best practices (i.e. basic fault tolerance, cable routing, calculating power usage)
Experience with cable management and knowledge of how to run fiber and copper in a data center
Knowledge of Data-Center electrical, HVAC, and bandwidth infrastructures as well as fiber/copper topologies
Able to operate material handling equipment – server lifts, pallet jacks, and forklifts (if certified)
Proficiency working with standard desktop PC tools and applications, such as MS Office, MS Outlook, web browsers, etc.
Ability to learn new software
Must provide own transportation to work locations

Preferred Qualifications:

Hands on experience in electrical, HVAC, and data center infrastructures
Working knowledge of networking components and infrastructures, including Wi-Fi
Certification in data center technologies is an advantage 

","['Outlook', 'Troubleshooting', 'Hardware', 'Ticketing', 'Data Center', 'Inventory', 'HVAC', 'Electrical', 'Computer Hardware', 'Routing', 'Copper', 'Networking', 'Cabling']"
 , , , , , , , , , 
Data Scientist  /  Engineer,"21 COLLYER QUAY, 21 COLLYER QUAY 049320",Full Time,Professional,1 year exp,Information Technology,Monthly,"$5,000to$8,000","AiDA Technologies (AIDA) is a specialist AI/Machine Learning company focused on providing products and solutions to the banking and insurance industry. The company was started by leaders from Singapore’s top Research Institutes and they have over 100 years of working experience among themselves.Our solutions assist our customers to increase Revenue, automate processes and manage Risks and Compliance using AI/ML. The team has delivered over 35 predictive analytics solutions and have established a name for themselves in the FSI sector as a leading provider of advanced AI/ML solutions for the industry.
We are looking for a Data Scientist / Engineer as part of our Data Management Team. The ideal candidate will leverage strong collaboration skills and ability to extract valuable insights from highly complex medical & insurance data sets to ask the right questions and find the right answers. You will have a great opportunity to work with other Data Scientists to understand and learn about how we can leverage AI/ML in the health insurance & medical field to detect fraud & waste, improve automation efficiency & promote vitality.

Duties and Responsibilities
● Analyse large scale of data: assessing quality, cleansing, structuring for downstream processing
● Be heavily involved to bring analytical prototypes to production with modelling & dev-ops teams
● Become a subject-matter expert in the health & insurance domain
● Generate actionable insights for business improvements
● Help to develop customizable reports / production-ready dashboards for clients
Requirements
● Bachelor's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)
● At least 1 - 2 years' of experience in quantitative analytics, data modelling or software engineering
● Ability to write robust code in Python and Java
● Good understanding of Database Systems (MSSQL, Postgres, MySQL) and SQL
● Deep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms
● A strong self-motivated and able to work with minimal supervision
● Ability to work in a dynamic, fast moving and growing environment
● Critical thinker with problem-solving skills
Good to have:
● Experience in troubleshooting, debugging, analysing logs and tracing of logs.
● Familiarisation with CI/CD systems such as GitLab
● Familiarisation with Java Spring Boot Framework
● Experience with cloud infrastructure and services, and resources administration (i.e. AWS, Azure)","['Machine Learning', 'Product Innovation', 'Data Analysis', 'Azure', 'NLTK', 'Mathematics', 'Data Management', 'Software Engineering', 'MySQL', 'Quantitative Analytics', 'Predictive Analytics', 'SQL', 'Python', 'Fraud', 'Statistics', 'Data Science', 'Java', 'Data Analytics', 'Power BI', 'Django']"
Temp Data Entry,160 ROBINSON ROAD 068914,Contract,Non-executive,1 year exp,Admin / Secretarial,Monthly,"$2,000to$2,200","A local MNC situated in Changi Business Park is inviting applicants for the below role

Job Title : Temp Data Entry Assistant (6 months contract)

Job Description:

View documents, perform data entry and document scanning as part of admin team
Possess good experience in MS office, especially Excel
Experience and track record in data entry preferably in bank

Job Requirements:

Min ‘O’ Level with some administrative experience
Good communication and interpersonal skills with a positive work attitude
Ability to work independently and in a team with minimum supervision
Proficient in Microsoft Word and Excel
Able to start work immediately and commit 6 months assignment

To apply:
Interested applicants please email your latest resume in word or pdf format to carrie@eps.com.sg
Please kindly indicate your current, expected salaries with latest availability.
All applications will be treated in the strictest confidence.
We regret that only shortlisted candidates will be notified.","['Microsoft Office', 'Microsoft Excel', 'Ability To Work Independently', 'Interpersonal Skills', 'Customer Information', 'Administration', 'Data Quality', 'Data Entry', 'MS Office', 'Attention to Detail', 'Spreadsheets', 'Excel', 'Team Player', 'Microsoft Word']"
Data Scientist (Machine Learning),"VERTEX, 33 UBI AVENUE 3 408868",Full Time,Junior Executive,1 year exp,Information Technology,Monthly,"$3,000to$6,500","Avensys is a reputed global IT professional services company headquartered in Singapore. Our service spectrum includes enterprise solution consulting, business intelligence, business process automation and managed services. Given our decade of success we have evolved to become one of the top trusted providers in Singapore and service a client base across banking and financial services, insurance, information technology, healthcare, retail and supply chain.
We are currently looking to hire Data Scientist (Machine Learning) who has proven track record in IT Industry. This is an exciting opportunity to expand your skill set, achieve job satisfaction and work-life balance. More details as below
*Freshers are welcome to apply with strong C++ coding exposure in academic projects
*Bachelor’s degree in Computer Science/Computer Engineering from a top-tier university
Job Description:

1-2 years of professional work experience developing systems for automatic speech recognition (ASR), speech synthesis, and natural language understanding
Experience in C/C++ and Python
Good experience with machine learning frameworks like Tensorflow, PyTorch
Solid knowledge of ML/DL techniques, algorithms and tools with exposure to CNN, RNN (LSTM), Transformers
Excellent problem solving, critical thinking and communication skills
Excellent data analytical skills
Ability to work well in a team
Ability to work independently with minimal guidance
Ability to work in a fast-paced development environment
Build core technologies for audio processing (including but not limited to speech recognition, speech synthesis, audio tagging), and pursue and explore cutting-edge algorithm technologies in the industry
Adapt to the existing code base and be able to own and work on new or existing components
Improve performance for existing algorithms
Debug and fix issues with current algorithms

WHAT’S ON OFFER:
You will be remunerated with an excellent base salary and entitled to attractive company benefits. Additionally, you will get the opportunity to enjoy a fun and collaborative work environment, alongside a strong career progression
To submit your application, please apply online or email your UPDATED CV in Microsoft Word format to nisha@aven-sys.com Your interest will be treated with strict confidentiality.
CONSULTANT DETAILS:
Consultant Name : Nisha
Avensys Consulting Pte Ltd
EA Licence 12C5759
Privacy Statement: Data collected will be used for recruitment purposes only. Personal data provided will be used strictly in accordance with the relevant data protection law and Avensys' privacy policy","['TensorFlow', 'Machine Learning', 'Managed Services', 'Process Automation', 'Scala', 'Data Analysis', 'Analytical Skills', 'Big Data', 'Ability To Work Independently', 'Artificial Intelligence', 'Data Mining', 'PyTorch', 'Speech Recognition', 'Python', 'Data Science', 'C#', 'Benchmarking', 'Audio Processing', 'C++', 'Data Visualization']"
Data Scientist - NLP,"BYLANDS BUILDING, 135 MIDDLE ROAD 188975","Permanent, Full Time",Executive,3 years exp,"Banking and Finance, Information Technology",Monthly,"$7,000to$10,000","A global investment firm is building a new Data Science function in Singapore. They are hiring for Data Scientists with expertise in natural language processing (NLP) to join their team.

Your future role 

Evaluate alternative datasets in collaboration with quantitative researchers 
Use NLP techniques to analyse datasets and identify potential investment opportunities 
Automate the extraction of predictive features
Manage the full lifecycle of data science projects: data acquisition, exploration, engineering, prototyping, and production
Work alongside data engineers and quantitative researchers

Your present skillset

Post Graduate degree in Data Science, Computer Engineering, Mathematics or Statistics
3+ years of data science/engineering experience with NLP expertise
Advanced programming experience in Python, C/C++, C# is a plus
Cloud platforms (AWS, GCP) expertise
Intellectual curiosity to identify emerging and alternative data
Capacity to work with autonomy within a global team (researchers and data engineers)

EA Reg. No.: R1435970 | EA Licence: 17C8713","['Machine Learning', 'Autonomy', 'AWS', 'Natural Language Processing', 'NLP', 'Data Mining', 'Python', 'C Programming', 'Algorithm Design', 'GCP', 'Data Science', 'C#']"
DATA ENTRY CLERK,"SUNGEI KADUT INDUSTRIAL ESTATE, 4 SUNGEI KADUT STREET 2 729226","Permanent, Full Time",Non-executive,1 year exp,Building and Construction,Monthly,"$1,400to$1,600","To perform data entry of all transaction.
2. To assist the office in filing duties.
3. To get water for guest and prepare for the meeting room.
4. To organize forms, made photocopies, filed records and faxed documents.
5. Any other duties assigned by your immediate superior.
Requirements & Skills
1. Willing to multi-task
2. With or without experience
3. Good knowledge of MS Office especially Microsoft Excel
4. High school diploma is welcome to apply
5. Good working and willing to learn
6. Good team player
Kindly include the following:

Reason for leaving (All past and present employment)
Last drawn Salary
Expected Salary
Availability and Notice Period

We regret that only short-listed candidates will be notified.","['Microsoft Office', 'Water', 'Microsoft Excel', 'Literacy', 'Inventory', 'Data Entry', 'MS Office', 'Spreadsheets', 'Communication Skills', 'Administrative Support', 'Team Player', 'Microsoft Word', 'Customer Service']"
Lead Data Engineer (Cloud),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,6 years exp,Information Technology,Monthly,"$7,000to$12,500","Description:

Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases.
Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”.
Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda.
Batch Pipeline Orchestration using on Apache Airflow and Jenkins.
Auto Scalable platform using Kubernetes on EKS.
Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine.
Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD).
Structure Tables with Partitioning and Clustering to increase Cost & Performance Benefits.
Guide Data Analysts and Data Scientists to write efficient queries and workloads.
Data Sharing with On-Demand Encryption/Decryption which can operate at Scale.
Running Containerized ETL workflow at scale.

Qualifications:

Bachelor Degree of Computer Science, IT or equivalent.
At least 6-7 years of data engineering experience with team leading/guiding/mentoring experience.
Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc.
Strong Data modeling and managing Distributed Computing Platforms for Data Processing.
Advance knowledge of SQL and writing resource-efficient queries.
Have at least 2+ years of professional programming experience in Python.
Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL.
Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lamda, etc.
Have a good understanding of how Kubernetes clusters work and scale on-demand.
Have adequate experience using Containers for Data Engineering workload.
Implemented manual or automated tools for Data Quality, Catalog, and Lineage.
Uphold the sense of Frugality across Data Engineering teams.
Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders.
","['Oracle', 'Data Modeling', 'AWS', 'Hadoop', 'MySQL', 'ETL', 'Data Quality', 'Data Engineering', 'SQL', 'Python', 'Data Architecture', 'AWS Lambda']"
 , , , , , , , , , 
Data Scientist (JD#8312),"THE SIGNATURE, 51 CHANGI BUSINESS PARK CENTRAL 2 486066",Permanent,Senior Executive,5 years exp,Insurance,Monthly,"$5,000to$7,500","Job Summary
We are seeking an experienced and highly skilled Data Scientist. The successful candidate will use mathematical, statistical, and programming skills to extract insights and knowledge from data, and play a crucial role in the development and implementation of data-driven solutions for an insurance company.
Mandatory Skill-set

Masters or BS in Business Analytics, Computer Science, Statistics or equivalent;
5 to 7 years of experience with data science or data analytics projects;
Experienced with SQL and Python;
Had used open source libraries such as TensorFlow, scikit-learn, numpy;
Experienced in statistical and machine learning techniques such as GLM, Regression, Random Forest, Boosting, Trees, Text Mining, Network Analysis;
Good communication and written skills;
Highly dependent and and adaptable to new changes.

Desired Skill-set

Experienced with Tableau for data visualization;
Experienced with BigQuery, Google Analytics, Amazon SageMaker;
Experienced with insurance or financial service industry.

Responsibilities

In a team of data scientists, handle the delivery of group wide data science initiatives;
Build and enhance data science models on structure, semi structured, unstructured data to derive business insights to drive business performance;
Organize, analyze and interpret data to identify trends and communicate how these findings help increase business value;
Ensure projects comply with internal and external policies, guidelines and regulations;
Work with stakeholders and different teams across the company for integration and adoption of analytics insights to communicate business benefits provided by data insights;
Support build of visual dashboards to monitor data science projects;
Provide group level support to data science teams in the region.


Should you be interested in this career opportunity, please send in your updated resume to apply@sciente.com at the earliest.
When you apply, you voluntarily consent to the disclosure, collection and use of your personal data for employment/recruitment and related purposes in accordance with the SCIENTE Group Privacy Policy, a copy of which is published at SCIENTE’s website (https://www.sciente.com/privacy-policy).
Confidentiality is assured, and only shortlisted candidates will be notified for interviews.
EA Licence No. 07C5639","['Tableau', 'TensorFlow', 'Machine Learning', 'Amazon SageMaker', 'Open Source', 'Adaptable', 'SQL', 'Python', 'Written Skills', 'Business Analytics', 'Statistics', 'Data Science', 'Google Analytics', 'Data Analytics', 'Text Mining', 'Data Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
"Counsel, Data & Privacy","PRUDENTIAL TOWER, 30 CECIL STREET 049712",Full Time,Executive,6 years exp,Risk Management,Monthly,"$10,000to$17,000","Role
This role will be a part of the nucleus of the newly established global Data & Privacy department operating within the broader award winning legal, compliance and risk team. Reporting to the Director, Data & Privacy, in this role you will lead on all aspects of helping Airwallex to meet the China privacy and data security legal framework and the provision of legal advisory to the Product, Engineering, Commercial and Marketing teams in respect of China and other APAC data & privacy rules to support Airwallex’s continued growth and expansion.
Responsibilities:

In partnership with the Business leadership and the Engineering, Product and Information Security functions respectively, lead the implementation of China data rules (PIPL, DSL and Cyber Security laws) and develop the appropriate compliance programme.
Privacy counselling to Product teams in relation to China data rules, in conjunction with the Product and Legal Regulatory team, including the necessary privacy by design, privacy impact assessment and contractual support work.
Lead and/or support on other APAC privacy counselling or contracting support.
Support the Director, Data & Privacy on formulation of data strategy for China business and operations, and international data flows for the rest of Airwallex Group.
Take on other strategic data initiatives from time to time, with the opportunity to take on work for EU, US and other geographic regions.

You will bring:

6-10 years of post qualification experience, preferably from a fast growth digital, fintech or technology company.  Either China bar admission or common law qualification.
General privacy experience of at least 3 years. China data laws (Personal information Protection Law (PIPL), Data Security Law, Cyber Security law) working knowledge and familiarity.
Working knowledge of GDPR or another major privacy regime (CCPA, PDPA, PIPEDA).
Professional proficiency in both English and Mandarin.
A super commercial and practical mindset, and a self-starter that can identify and prioritise opportunities to focus on.
Experience of product and privacy counselling in an agile environment.
A global outlook coupled with deep local knowledge
Excellent written and verbal communication and presentation skills.
Adept at working across multiple functions and demonstrated success in influencing a broad stakeholder group.
Technology, financial services and/or experience in a high growth environment is advantageous.
","['Outlook', 'Information Security', 'Leadership', 'Verbal Communication', 'Cyber Security', 'Formulation', 'Agile', 'Product Engineering', 'Marketing', 'Compliance', 'Presentation Skills', 'Legal Compliance', 'Financial Services', 'Data Strategy']"
SEO Senior Data Analyst,"OXLEY @ RAFFLES, 30 RAFFLES PLACE 048622","Permanent, Full Time",Professional,3 years exp,"Information Technology, Travel / Tourism",Monthly,"$4,500to$5,500","About Klook
Klook is the go-to travel and leisure e-commerce platform for experiences and services anytime, anywhere. Founded in Hong Kong in 2014 out of passion for discovery, our purpose today is to inspire and enable more moments of JOY. Even when the COVID-19 pandemic hit, we held on to our conviction and successfully unlocked the domestic travel business. To date, we are already offering over 490,000 activities in over 1,000 destinations. With cross-border travel resuming, we have made it our mission to reshape the world of travel. Isn’t this exciting?!

It certainly is for our international community of over 1,200 employees, based in over 20 locations globally! Joymakers at heart, Klookers are not only curating joyful experiences for others, but also co-creating our world of joy in the Klookiverse. We are on a journey to foster a strong company culture that supports a high-performing and successful business, and we are guided by our core beliefs - Push boundaries, Ask for and give feedback, Take ownership, and Help each other - in everything we do. We are excited about building and realizing endless possibilities in the new era of travel. Care to be a part of this revolution?


What you’ll do:

Strategize and work within SEO and tech team on data collection to enable SEO decisions, such as optimization strategies
Analyze SEO data regularly to identify business opportunities and mitigate traffic loss
Conduct in-depth analytical SEO studies combining external research data and internal analytics to facilitate management decisions
Collaborate with tech and business lines to automate reporting and insight generation on metrics such as revenue, traffic, CVR, and ranking.
Design comprehensive and user friendly dashboard for business line teams
Stay up to date with the latest SEO trends and best practices.
Complete ad-hoc tasks and projects as assigned


What you’ll need:

At least 1-3 years of experience in business analysis with a Bachelor's degree in Mathematics, Statistics, Computer Science, Business or Economics
Experience in programming or analytic tools such as SQL, VBA, Google Data Studio, Tableau, Google Analytics and Adobe Analytics
Experience in travel, ecommerce, or tech startups is a plus Track record of successfully driving cross departmental projects
Fluent in spoken and written English
Eager to work in a fast-paced environment
A start-up attitude – highly collaborative with an entrepreneurial, roll-up-your sleeves attitude that’s not afraid to work independently when required
Globally-minded and comfortable working with people from different cultural background and in different time zones
Experience in SEO reporting - monthly and/or weekly dashboards, is a plus
Comfortable in cross-functional collaboration and knowledge sharing.
Experience in Google Analytics and Google Search Console
","['Tableau', 'Dashboard', 'Data Analysis', 'Analytical Skills', 'Business Analysis', 'SQL', 'Python', 'Adobe Analytics', 'Visualization', 'Google Analytics', 'SEO']"
 , , , , , , , , , 
 , , , , , , , , , 
Lead Data Scientist,"HONG LEONG BUILDING, 16 RAFFLES QUAY 048581",Full Time,Senior Executive,10 years exp,Information Technology,Monthly,"$8,000to$15,000","Ahrefs is looking for an experienced Lead Data Scientist who is proficient in working with large amounts of data to extract all kinds of insights and regularities from it. We're also building our own models of calculating the ‘power’ of a web page and its likelihood of ranking high in search results.
What We Need

Good knowledge in a wide variety of advanced data analysis and machine learning techniques and experience in developing solutions in response to real-world business problems
Proficient with programming languages such as Python and R
Experience in scaling Machine Learning models related to Information Retrieval (Web Search in production is a huge plus)
Experience in full stack data science is preferred
Knowledgeable in Language Modelling, and experience with open source NLP library such as NLTK, Gensim, Spacy, Pytorch, etc.
Experience with mainstream big data platforms such as Spark and Hadoop
Experience in Tensorflow, Theano, or other deep learning frameworks preferred
Experience with Elasticsearch or similar DB, and ability to conduct independent research utilising large unstructured data sets
Knowledge on visualisation using open source tools

What You'll Do

Research, prototype, build and maintain systems for information retrieval, search, document classification, and Q&A
Create comprehensive product requirements together with Product Development, Design and Marketing teams
Work closely with the Engineering teams (frontend and backend) to implement, deploy, and maintain production systems
Write thorough documentation
Effectively communicate highly technical results to various teams
Lead and manage the existing Data Science team
Lead and manage the hiring of Data Science team members, including interns

Basic Requirements

Preferably at least a Master’s degree in any quantitative discipline: Applied Mathematics, Computer Science, Statistics, etc.
Experience with search, information retrieval, and natural language processing is a must
Experience with streaming algorithms and applications
Experience in Python, SQL (clickhouse dialect is a plus), Git, CI/CD
Experience with (at least one) deep learning framework: TensorFlow, Pytorch, Theano
Experience with big data platforms such as Spark and Hadoop
Experience with lucene-based search engines: Solr and/or Elasticsearch
Strong interpersonal and communication skills
Familiarity with functional languages such as OCaml or Haskell is a big plus
","['TensorFlow', 'Machine Learning', 'OCaml', 'Big Data', 'ClickHouse', 'Natural Language Processing', 'NLTK', 'Hadoop', 'PyTorch', 'SQL', 'Python', 'Team Lead', 'Statistics', 'Data Science', 'Product Development', 'Applied Mathematics']"
Global Data Stewart,"223 @ MOUNTBATTEN, 223 MOUNTBATTEN ROAD 398008",Full Time,Senior Executive,3 years exp,General Management,Monthly,"$4,000to$4,500","Sodexo’s Facilities Management function has commenced a Data Transformation Program with the objective to deliver world class business processes and supporting tools to the teams’ delivering services across our wide array of client sites.
To enable us to advance on this journey we’re recruiting an experienced Global Data Steward to lead and embed data governance tools and processes that enables us to source, manage, structure and use our data across the organisation, also having a real passion and appetite to improve data knowledgebase and quality of data. This is a pivotal role that will see you working across business, IS&T and data organization.
You will be a strong communicator and demonstrate a mastery of the Data Governance process to align data sources and metrics around common standards and create clear, actionable practice for unified data knowledge, improve data quality, and secure and efficient data sharing to help achieve business objectives.
Navigating Sodexo’s matrix organisation on a global scale won’t come without its challenges, you’ll need to be able to build relationships and your internal networks quickly, be organised and delivery focused and have a positive, flexible and can-do attitude to your role. Previous experience working on a global scale or within a facilities management function would be a huge advantage.
Main Responsibilities

Executes the Data Quality Management process      (diagnosis, remediation, Follow up)
    
Contribute to Data quality Monitoring capabilities (dashboard       etc.).
Capture, document and promote business validity rules.
Make a day-to-day follow up of Data quality levels, make       diagnosis to identify issues root causes, build and execute Data quality       remediation plans
Build data quality guidance and direction and ensure is       applied throughout the entire data lifecycle, most importantly upfront.
Overseeing the implementation of approved data quality improvements.
Support regional and local data stewards with their       responsibilities related to data quality and ensure clear accountability       for stewardship of the organisations.


Lead to build the Data Knowledge in FM domain by      maintaining the objects in the enterprise data catalogue tool
    
Capture and document Business Glossary & terms, to define       Master Data in common, data dictionaries and associated business       processes.
Lead the development and maintenance of data lineage with       assigned ownerships.


Participates in initiatives related to the Sharing of, Access      to, and Availability of Data within its scope.
    
Acts as an SME for Data part of the domain
Advice on the right Data usage (following the data sharing       policy)
Grant (by delegation) or redirect to business domain leader       access requests


Consulted and informed on topics and projects related to data      protection.
    
Share Data controls referential
Participates in enriching the controls referential at all       levels of the business.
Defines and executes actions plans related to the update of       controls referential


Demonstrate strong stakeholder management skills and ensure      agreed governance and reporting is followed.
The ability to analyse data models to deliver logical      conclusions
Understand and promote the commercial usage of data that meets.

The Ideal Candidate
What’s essential:

Experience of facilities management business processes.
Proven business analysis and improvement experience and be able      to review and advise on suitable changes to streamline processes.
Excellent stakeholder management skills, working across teams      and all levels of stakeholders and be able to work with virtual teams      across multiple functions being sensitive to different cultures
Ability to translate the diagnosis, remediation and      requirements from business to technical language and vice versa.
Knowledge of existing and emerging data technologies and      practices including sourcing, compliance, data modelling, data quality,      transformation etc.
Operational exposure to data management tools
Experience working in a data governance related role ideally in      a large, data-led and consumer-focused organisation
Experience of implementing and supporting data stewards within      an organisation
Experience of managing data quality issues and reporting them      to relevant bodies and stakeholder groups
Experience of creating data standards, data processes, and      writing data policies
Data Analysis, e.g., using SQL , Power BI etc. to identify data      quality issues and perform data quality profiling
Excellent communications skills and fluency in English.

Where we can be flexible:

Previous experience working in Agile delivery teams using Scrum      or Kanban is not essential but is a distinct advantage.
Experience of working with Maximo, MS Power platform, CRM tools      and SAP finance data will be plus.
French is a plus.
","['Management Skills', 'Data Sharing', 'Agile Project Management', 'Data Analysis', 'TIBCO', 'Business Analysis', 'Data Management', 'Agile', 'Data Quality', 'Data Governance', 'Stewardship', 'SQL', 'Accountability', 'Stakeholder Management', 'Master Data Management', 'Sourcing']"
Data Center Technician III,"HB CENTRE 1, 12 TANNERY ROAD 347722","Permanent, Full Time",Senior Executive,5 years exp,Information Technology,Monthly,"$4,600to$6,600","What this Job Entails:

The Data Center Technician III is responsible for the installation of hardware into racks, asset tagging and scanning, cabling, data center maintenance, documenting processes and server installations.

Scope:

Works on assignments that require considerable judgment  and initiative. Makes recommendations for solutions
Works within guidelines and takes ownership of results. May act as a mentor to less experienced team members.

Your Roles and Responsibilities:

Responsible for installing, moving, and decommissioning hardware including cabinets, shelves, power strips, rails, fiber/copper/other cables and cable management, servers, storage, and other devices in the Data Center.
Confirm and label devices, rack and cables.
Work in a standard ticketing system, providing clear, timely, and appropriate customer communications.
Work under the direction of Site Operations Supervisor and/or Operations Manager) and follow Standard Operating Procedures (SOPs), Program Policies, Safety Policies, and Security Policies, while meeting requirements for quality and quantity of work.
Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position

Required Qualifications/Skills:

High school diploma or general education degree (GED) and 5 to 8 years’ related experience and/or training; or equivalent combination of education and experience
Networks with senior internal and external personnel in own area of expertise
Demonstrates good judgment in selecting methods and techniques for obtaining solutions
Excellent verbal and written communication skills in English
Ability to respond to any On-Call request within 1 hour, while on-call.
Experience cabling systems (power/copper/fiber/other) correctly based on ticket requirements and SOP standards
Experience working with CAT5e and CAT6 copper cable and multi-mode and single-mode fiber
Proven ability to adapt to changing priorities, conditions, and circumstances
Strong organization skills
Working knowledge of computer hardware
Understanding of networking components and infrastructures
Knowledge of copper and fiber testers
Excellent troubleshooting skills
Understanding of Data Center best practices (i.e. basic fault tolerance, cable routing, calculating power usage)
Experience with cable management and knowledge of how to run fiber and copper in a data center
Knowledge of Data-Center electrical, HVAC, and bandwidth infrastructures as well as fiber/copper topologies
Able to operate material handling equipment – server lifts, pallet jacks, and forklifts (if certified)
Proficiency working with standard desktop PC tools and applications, such as MS Office, MS Outlook, web browsers, etc.
Ability to learn new software
Must provide own transportation to work locations

Preferred Qualifications:
Certifications in Data Center technologies are desired

Hands on experience in electrical, HVAC, and data center infrastructures
Working knowledge of networking components and infrastructures, including Wi-Fi

Physical Demand & Work Environment:

Physically assist in moving and racking equipment.
Able to safely lift and move a minimum of fifty (50) pounds
Must have the ability to perform office-related tasks which may include prolonged sitting or standing
Must have the ability to move from place to place within an office environment
Must be able to use a computer
Must have the ability to communicate effectively
Some positions may require occasional repetitive motion or movements of the wrists, hands, and/or fingers

What can Astreya offer you?

Employment in the fast-growing IT space providing you with a variety of career options
Opportunity to work with some of the biggest firms in the world as part of the Astreya delivery network
Introduction to new ways of working and awesome technologies
Career paths to help you establish where you want to go
Focus on internal promotion and internal mobility - we love to build teams from within
Free 24/7 accessible Professional Development through LinkedIn Learning and other online courses to give you opportunities to upskill at your own pace
Education Assistance
Dedicated management to provide you with on point leadership and care
Numerous on the job perks
Market competitive compensation and insurance, health and wellness benefits
","['Outlook', 'Troubleshooting', 'Hardware', 'Ticketing', 'Data Center', 'Inventory', 'HVAC', 'Electrical', 'Computer Hardware', 'Routing', 'Copper', 'Networking', 'Transportation', 'Cabling']"
Data Tech Lead,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979",Permanent,Senior Executive,10 years exp,Information Technology,Monthly,"$7,000to$9,000","Role:Data Tech Lead

Job Descriptions:

Development of new data management layers and build data processes.
Solutioning and Tech Designing for Data Systems
Tech Led to drive data engineering activities
Provide support for enhancements and any BAU issues on the new data management layers and existing data lakes.
Support and migration of existing on-premises databases to AWS cloud.
Understanding the existing applications, data architecture, and suggest improvements
Lead business requirements and plan deliveries.
Handle data extractions and data analysis for the requirements.

Job Requirements:

Minimum of 10+ years of experience with Information Technology using RDBMS and Non-RDBMS and Cloud databases.
8+ years of strong hands-on experience on any of the databases like SQL/PLSQL, Oracle, MS-SQL server, Postgres, and Snowflake.
3+ years of strong experience in AWS Cloud.
Good understanding of Data integration, Data Flows, Data Quality, Data Architecture and Data Engineering.
Technical expertise in data models, data mining and segmentation techniques.
Experience in Tech Design and Solution Designing for data systems
Experience with full SDLC lifecycle and Lean or Agile development methodologies.
AWS tools and components knowledge is a plus.
CI/CD and GIT exposure
Experience on UNIX shell scripts.
Ability to work in team in diverse/multiple stakeholder environment
Ability to communicate complex technology solutions to diverse teams namely, technical, business and management teams
","['Oracle', 'Solutioning', 'Segmentation', 'Job Descriptions', 'Unix shell', 'Data Integration', 'SDLC', 'Information Technology', 'Data Quality', 'Data Engineering', 'Data Mining', 'Data Architecture', 'GCP', 'Databases', 'Business Requirements', 'Agile Development']"
Data Scientist,"6TH FLR, TOWER 1, THE METROPOLIS, 9 NORTH BUONA VISTA DRIVE 138588",Contract,Professional,2 years exp,"Information Technology, Others",Monthly,"$8,000to$9,800","Contract Role for 12 Month
Working Location: Buona Vista
Working Hours: 8 am - 5.00 pm

Where you fit in?
Shell’s global Trading and Supply business is one of the largest energy trading operations in the world with key hubs in Singapore, Dubai, Houston, London, and Rotterdam, trading in crude oil, natural gas, LNG, electrical power etc.
Our business in Asia has set huge growth targets for the coming years with major focus on green and sustainable energy. To accommodate this demand, we are looking for talented and enthusiastic Data Scientist based in Singapore to support existing and new projects in the Asia space.

What’s the role?
We are looking for Data Scientists to help expand the trading desk’s quantitative ability by providing development support and best practices to market analysts.

The data scientist will work in a high paced environment in tandem with the product team to build scalable models and support front office traders with their analysis and modelling needs.

They will apply different ML (Machine Learning) techniques such as deep learning, reinforcement learning, predictive modelling and building forecasting models to equip the Shell trading desks with right strategies to best position them in the market.


Requirement:

Must legal authorized to work in Singapore without sponsorship of work/ employment visa requirement.
Certification or degree in data science
2-3 years of experience in a Data Scientist role
Expertise in statistical software packages, modelling techniques/ software, including Python
Proficiency and hands-on experience in machine learning, including data mining, statistical analysis, pattern recognition and predictive modelling
Proven ability / track record in translating the data models to long lasting business value and outcome
Able to credibly interface between technical teams and business stakeholders.
Analytical problem solver
Excited about analytical models and algorithms
Able to multi-task


Preferred:

Experience in trading preferred
Experience in time series modeling and forecasting/ prediction with regression model preferred
PhD or Master's in Statistics, Applied Math or Computer Science or equivalent
Tech stack experience: Databricks, GIT, Microsoft Azure Data Lake, Azure Table/Blob stores, SQL
Can explain software engineering best practice e.g., CI/CD, 12-factor, git branching strategies, test automation
Experience in time series analysis / predictive modelling with low granularity time series data, preferably in a trading domain (Commodity/Security)
Story telling of Machine Learning models to business problems
Agile Delivery techniques (e.g., SCRUM), user stories, tools such as Azure DevOps
","['Machine Learning', 'Forecasting', 'Time Series Analysis', 'Modeling', 'Azure', 'Natural Gas', 'Translating', 'Software Engineering', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Data Science', 'Pattern Recognition', 'Trading', 'Algorithms']"
Data Entry Clerk,01-07 70 ALPS AVENUE 498801,Contract,Non-executive,2 years exp,Logistics / Supply Chain,Monthly,"$1,400to$1,800","
Monday to Friday (9am - 6pm)
Contract (Part Time)
$10 / per hr
Proficient typing skils
Computer skills
Basic literacy and numeracy skills
Administrative skills
Good communication skills, both written and verbal
A polite phone manner
Good customer service skills
Self-motivation
The ability to work independently and as part of a team
A conscientious and responsible working attitude
Accuracy and good attention to detail
The ability to do the same task for long period of time
The ability to work under pressure and to tight deadlines
Good spelling, punctuation and grammar
A positive approach in a busy working environment
A good understanding of data confidentiality issues
preferably to be stayed in the east
","['Customer Service Skills', 'Microsoft Office', 'Microsoft Excel', 'Ability To Work Independently', 'Literacy', 'Data Entry', 'Good Communication Skills', 'Attention to Detail', 'Spreadsheets', 'Team Player', 'Microsoft Word', 'polite']"
 , , , , , , , , , 
Data Engineers,"SHAW CENTRE, 1 SCOTTS ROAD 228208","Contract, Permanent, Full Time",Executive,6 years exp,Information Technology,Monthly,"$7,000to$10,000","Job Requirements

- As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client.

- You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers.

- Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. 

- In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. 

- You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. 

- You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics.

• Translate business requirements to technical solutions leveraging strong business acumen.

• Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.

• Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.

• Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.

• Design and Build Modern Data Pipelines and Data Streams.• Design and Build Data Service APIs.

• Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.

• Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.

• Implement effective metrics and monitoring processes.


Saghana Sithara | Registration Number: R1550224","['Microsoft Azure', 'Azure', 'Big Data', 'Pipelines', 'Architect', 'Business Acumen', 'Supply Chain', 'ETL', 'Data Design', 'Data Engineering', 'PowerBI', 'Planning and Implementation', 'Visualization', 'API', 'Databases', 'Business Requirements']"
Data Engineers,"SHAW CENTRE, 1 SCOTTS ROAD 228208","Contract, Permanent, Full Time",Executive,6 years exp,Information Technology,Monthly,"$7,000to$10,000","Job Requirements

- As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client.

- You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers.

- Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. 

- In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. 

- You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. 

- You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics.

• Translate business requirements to technical solutions leveraging strong business acumen.

• Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.

• Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.

• Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.

• Design and Build Modern Data Pipelines and Data Streams.• Design and Build Data Service APIs.

• Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.

• Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.

• Implement effective metrics and monitoring processes.


Saghana Sithara | Registration Number: R1550224","['Microsoft Azure', 'Azure', 'Big Data', 'Pipelines', 'Architect', 'Business Acumen', 'Supply Chain', 'ETL', 'Data Design', 'Data Engineering', 'PowerBI', 'Planning and Implementation', 'Visualization', 'API', 'Databases', 'Business Requirements']"
Software Engineer (Data Express) - Data Platform,1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$10,000to$20,000","About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

The product will:
- Enable users to manage large scale data assets in the underlying data engine securely and effortlessly
- Improve the overall system observability, helping our users gain more transparency in the healthiness, resource utilization of the system

What you will be doing:
- Responsible for building core functionalities in the data loading domain
- Drive the design, development, and delivery of data loading features to integrate with mainstream upstream ecosystems
- Lead the optimization of both streaming and batch loading engines to provide low-latency and high-throughput in respective scenarios
- Lead the solution design on data loading resource management over hundreds of thousands of loading jobs
- Ensure service quality through the whole software development lifecycle

Qualifications

What you should have:
- Bachelor's Degree or Post Graduate in Computer Science.
- At least 5 years of backend experience
- Good coding skills in mainstream languages such as GoLang, Java, or Scala
- Good domain knowledge of ETL and data warehousing
- In-depth knowledge in distributed real-time or batch data processing systems, such as Spark, Flink, Kafka, etc
- Experience in optimizing systems like Spark, Flink, Storm, Kafka.
- Knowledge of big data ecosystems such as Kafka, Redpanda, Kinesis, Redshift, Hive is a plus
- Good communication and interpersonal skills

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Apache Spark', 'Scalability', 'Scala', 'Big Data', 'Data Engineering', 'Spark', 'Distributed Systems', 'Apache Kafka', 'Java', 'C#', 'Data Warehousing', 'Databases']"
"Software Engineer (Data Express), Data Platform",1 RAFFLES QUAY 048583,Full Time,Professional,3 years exp,Information Technology,Monthly,"$6,500to$13,000","3About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

The product will:
- Enable users to manage large scale data assets in the underlying data engine securely and effortlessly
- Improve the overall system observability, helping our users gain more transparency in the healthiness, resource utilization of the system

What you will be doing:
- Responsible for building core functionalities in the data loading domain
- Drive the design, development, and delivery of data loading features to integrate with mainstream upstream ecosystems
- Lead the optimization of both streaming and batch loading engines to provide low-latency and high-throughput in respective scenarios
- Lead the solution design on data loading resource management over hundreds of thousands of loading jobs
- Ensure service quality through the whole software development lifecycle

Qualifications

What you should have:
- Bachelor's Degree or Post Graduate in Computer Science.
- At least 3 years of backend experience
- Good coding skills in mainstream languages such as GoLang, Java, or Scala
- Good domain knowledge of ETL and data warehousing
- In-depth knowledge in distributed real-time or batch data processing systems, such as Spark, Flink, Kafka, etc
- Experience in optimizing systems like Spark, Flink, Storm, Kafka.
- Knowledge of big data ecosystems such as Kafka, Redpanda, Kinesis, Redshift, Hive is a plus
- Good communication and interpersonal skills

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Apache Spark', 'Scalability', 'Scala', 'Big Data', 'Data Engineering', 'Spark', 'Distributed Systems', 'Apache Kafka', 'Java', 'C#', 'Data Warehousing', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Protection Officer,17 CHANGI SOUTH STREET 2 486129,"Permanent, Full Time",Executive,4 years exp,"Accounting / Auditing / Taxation, Admin / Secretarial, Legal, Logistics / Supply Chain, Professional Services",Monthly,"$3,850to$5,000","General Job Description: 
• Reports to Head, HSSE, Trade Compliance and Privacy
• Responsible for supporting the company’s Personal Data Protection Management Programme in compliance with the Personal Data Protection Act (PDPA).
• Ensuring company’s processes are in line with the Global Directives. 
• Ensuring organization’s compliance to the PDPA by monitoring, conducting data protection audits, analyzing audit findings and proposing changes to address identified gaps. 
• Responsible for the development of Data Protection Policies and Procedures. 
• To conduct Data Protection Impact Assessments (DPIA) to identify, assess and address business risks, based on the organisation’s functions, needs and processes.
• Propose appropriate measures to manage risks associated with the collection, use, disclosure and storage of personal data.
• Manage and report all suspected and / or confirmed data breaches in accordance with the data breach management plan
• Assist in preparing notifications to affected individuals, senior management and regulatory authorities in the event of data breaches.
• Document data breach incidents and post-breach responses in accordance with the data breach response plan.
• Support the data incident response and data breach notification procedures.
• Assist in the conduct of investigations relating to data protection breaches and ensure proper closure of investigations and complaints. 
• Maintain the organisation’s awareness of PDPA requirements by keeping abreast of PDPA requirements and 
amendments to regulations and guidelines. 
• To raise awareness on PDPA and fostering a data protection culture, provide scheduled training for all staffs on PDPA requirements, regulations and guidelines. 
• Provide appropriate advice to staff on the organisation’s data protection policies and procedures.
• Handles queries, complaints and disputes on the organisation’s management of personal data.
• Respond to queries that may arise in the organization’s collection, use and/or disclosure of personal data.
• Maintain logs of queries, complaints and disputes relating to the organisation’s collection, use and/or disclosure of personal data.
• Analyse and escalate complaints and disputes relating to the organisation’s management of personal data and respond with remedial action.
• Ensure a balanced approach in resolving data protection and data innovation issues.
• Participate in data innovation projects to provide guidance on regulatory and compliance requirements.
• Act as the organisation’s subject matter expert in data protection matters and provide strategic opinion when required.
• Other duties as and when assigned by HOD

Specific Accountability: 
• Ensure organization’s compliance to the PDPA
• Manage risks associated with collection, use, disclosure and storage of personal data.
• Drive PDPA requirements in the organization.
• Advise on data innovation projects in the organization.

Skills Required: 
• At least Diploman / Degree holder from a recognized institution
• Recognized Data Protection certification such as Advanced Certificate in Data Protection Operational Excellence
• Able to work in a multi-cultural environment

Experience and Qualification:
• Good understanding and application of PDPA 
• At least 4 years of experience focused on data privacy in Singapore
• Able to work independently
• Keen attention to detail
• Excellent written and verbal communications skills in English
• Knowledge in information security
• Good negotiation and influencing skill
• Good understanding of GDPR 
• CIPP certifications with sound understanding in the supply chain industry will have added advantage","['Negotiation', 'Information Security', 'Operational Excellence', 'Legislation', 'Supply Chain', 'Compliance', 'Attention to Detail', 'Trade Compliance', 'Employee Training', 'Audits', 'Accountability', 'Legal Compliance', 'Data Protection Management', 'Audit', 'Able To Work Independently']"
Data Privacy Specialist,"PARKVIEW SQUARE, 600 NORTH BRIDGE ROAD 188778",Full Time,Junior Executive,2 years exp,Information Technology,Monthly,"$3,300to$6,000","Your role:
· Review the personal data life cycle for clients
· Highlight areas of non-compliance to PDPA, GDPR or other relevant data privacy laws
· Formulate cost effective and business friendly solutions for personal data control gaps
· Draft reports and present to senior management
· Act as data protection officer for the Firm
· Assist in other ad-hoc governance and risk management projects

Your expertise:
· Academic degree in relevant area, such as Accountancy, Business Administration or Law.
· At least 2 years proven relevant experience in data privacy or related area, preferably with leading institutions, business consultancies or supervisory authorities.
· Deep knowledge of major Data Privacy and Security Laws and ability to translate requirements into operational implications
· Certification by the International Association of Privacy Professionals (IAPP) is a plus.
· Excellent verbal and written communication and presentation skills.","['Microsoft Excel', 'Invention', 'Teamorientated', 'Cyber Security', 'Interpersonal Skills', 'Trusting Relationships', 'Investigation', 'Risk Management', 'Administration', 'Written Communication', 'Data Entry', 'Project Management', 'Legal Advice', 'Communication Skills', 'Presentation Skills', 'Human Resources']"
Data Scientist,"PLAZA 8 @ CBP, 1 CHANGI BUSINESS PARK CRESCENT 486025",Contract,Senior Executive,5 years exp,Information Technology,Monthly,"$10,000to$12,000","This is a 12-month fixed-term contract role.
Product leadership: You will use data to shape product development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and the company. You will help your partner teams prioritize what to build, set goals, and understand their product’s ecosystem.
Analytics: You will guide teams using data and insights. You will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them.
Communication and influence: You won’t simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.
Responsibilities:

Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches.
Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of      businesses.
Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends.
Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations.
Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions.

Minimum Qualifications:

Bachelor’s degree (BA or BS)
4-6 years' experience in data and product analytics within the tech industry.
Intermediate proficiency in SQL and data visualization tools (e.g. Tableau, Python, etc.).
Problem-solving skills and experience collaborating with global XFN teams.

UEN: 199700895N","['Tableau', 'Liaising with cross functional teams', 'Data Analysis', 'Quantitative Analysis', 'problem solving skills', 'SQL', 'Python', 'Data Science', 'Data Analytics', 'Data Visualization', 'Product Analysis']"
Data Modeler,"21 COLLYER QUAY, 21 COLLYER QUAY 049320",Permanent,Professional,5 years exp,Others,Monthly,"$8,000to$16,000","Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/en-US/amplifyhealthexternal/job/Senior-Data-Modeler_JR-35658-1
What you will do?
The role entails designing data models for the data platform layer, data cleansing layer, reporting and analytical layers within a cloud environment. Work closely with Data Scientists to understand model features and link back to transactional environment to understand data quality, data relationships and data availability. Document and define frameworks with the Data Engineer to build the data platform. Together these teams will enable data driven actionable insights.
The role is based in Singapore.
Core responsibilities include:

Analyse data sources
Design data model to support analytics and reporting
Support Data Engineers with ETL pipelines and Data Scientists with data understanding and model development
Profile new data sources in a variety of formats including Json, XML, etc
Define data quality rules with Data Scientists to clean data
Define data mapping and transformation rules between source and target
Documentation of data models for new data sources, metadata and productionized information flow

What skills do you need?
Behavioural skills

A passion for programming and working with data
Self-starter
Willingness to learn and grow exponentially
A restless curiosity in learning new technology
Ability to work cohesively in a team environment and balance multiple priorities
A team player who can work alone when required and without supervision
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude
Ethical and able to maintain confidentiality and manage boundaries

Technical understanding

Advanced to Expert knowledge in SQL – on any database platform
Modern datawarehouse design skills eg DataWarehouse, Data Lakehouse, Data Mesh, Data Vault
Experience working on large and complex datasets
Working with design tools eg Enterprise Architect, Power Designer
Working with Data Architects to design and implement solutions

Nice to have

Health Care or Health Insurance data experience
Strong communicator (verbal and written)

Qualifications
The following requirements are essential:

Honours or Master’s degree in BSc Computer Science
Other qualifications will also be considered if accompanied by the relevant experience
5 to 10 years of experience is preferred
","['Designer', 'JSON', 'XML', 'Erwin', 'Pipelines', 'Architect', 'Data Management', 'Architects', 'ETL', 'Data Quality', 'SQL', 'Data Architecture', 'Metadata', 'Health Insurance']"
"Data Steward Supervisor, OpenData (Vietnam)","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Senior Executive,1 year exp,"Education and Training, Information Technology, Others",Monthly,"$3,500to$6,500","Directly reporting to the OpenData Research Center Manager, we are looking for a Data Steward Supervisor who will be responsible for the direct supervision of data stewardship team members for the data offering in Vietnam.
You will also be responsible and retain all the responsibilities of a Data Steward, such as updating the attributes of records to improve core data, calling Group Practices, and updating provider affiliation information.
If you have a passion for data and quality – this is a great opportunity for you! Your role will be based in the Veeva Office in Singapore.

What You'll Do

Recruit, coach, motivate, appraise and retain team members
Deliver all necessary training to Data Stewards
Monitor, improve and give feedback on individual and team performance
Allocate work and resources to meet project deadlines
Design, document and optimise processes to ensure best-in-class delivery of data quality
Audit the data quality of Data Stewards
Ensure the team meets and exceeds productivity and quality standards
Run the daily operations in the Data Stewardship team
Report progress to direct line manager
Execute other duties and ad-hoc tasks related to data stewardship as assigned by the management

Requirements

BA/MA or equivalent degree
Vietnamese language is required for facilitating phone / web research validation to both build and maintain the product. (The data sources need to be either phone or web validated with the respective hospitals, clinics or pharmacies to ensure the data is accurate.)
Ability to learn quickly and independently
Problem solving and efficient time management skills
Proficiency in Windows, Google apps, MS Office and other office software
People and result oriented
Strong interpersonal skills
Highly organized, attention to detail and focus on quality
Able to balance qualitative and quantitative performance of the team
Able to motivate and communicate clearly
Able to meet expectations and project deadlines
Obtain and refresh the most current version of various data elements using standard methods of research such as verification through internet and outgoing phone calls
Apply new verified data elements to core database records
Assure that new data elements are not duplications of existing core data elements for Healthcare providers (HCP’s) and Healthcare Organisations (HCO’s)
Proactive maintenance of existing data and handling customer requests
Removal of incorrect data elements from core databases

Nice-to-have

Experience working with MDM (master data management applications)
Local Health Care market understanding
Knowledge of medical terminology and data quality standards within the life sciences industry
Previous experience or interest in data, databases
","['Coaching', 'Agile Project Management', 'Process Improvement', 'Interpersonal Skills', 'People and Performance Management', 'Medical Terminology', 'Problem Solving', 'Data Quality', 'Vietnamese', 'Stewardship', 'Project Timeline', 'Team Leadership', 'Attention to Detail', 'Time Management', 'Office Software', 'Life Sciences', 'Master Data Management', 'Databases', 'Ability To Learn']"
"Data Scientist Lead, SAPMENA","OCEAN FINANCIAL CENTRE, 10 COLLYER QUAY 049315",Permanent,Manager,10 years exp,Information Technology,Monthly,"$14,000to$18,000","Who are we?
At L’Oréal, there is never a dull day, the beauty lies in the freedom to go beyond with our empowering entrepreneurial culture. We take pride in developing young talents who have the passion and ambition to make an impact in the beauty industry. We currently offer a wide range of career opportunities for undergraduates and fresh graduates across the region.

SAPMENA (South Asia Pacific, Middle East & North Africa) is home to 40% of the world's population & some of the fastest-growing economies. Headquartered in Singapore, we have over 6,800 diverse talents in 15 subsidiaries with 34 International Brands, 4 factories & 2 research centres. As the leading beauty tech company, we offer endless exciting career opportunities.

You will:
In your role, you will be expected to understand business challenges and and build data products/statistical modelling solutions to tackle
them. You will have a critical role working with our stakeholders to make recommendations to the business.

Explore and choose the algorithms which have best performance

Develop, train and finetune the model

Work with ML engineers to support the industrialization
Responsible for engaging with key stakeholders within the organization, the Delivery Team, Data Engineers, BI Developers, analytics analyst, IT PMO and business to build an exceptional product.
Working closely with a product owner and effectively captures stakeholder assumptions and translates them into hypothesis driven outcomes.
Be accountable for the end-to-end results and delivery of your product
Collaborate with stakeholders on model/product launch communication, training and enablement and ongoing product adoption tactics, where applicable.
Support and champion, where applicable, ongoing initiatives driving data analytics culture
Act as a subject matter expert and provide guidance to the project team throughout the project.  This includes (but not limited to):
    
Knowing which sources of data to explore
Identifying and communicating the key trends, data limitations
Support scoping of the business problem out so that the project team can determine the best model/analysis/solution
Assess reasonability of the data and/or model prior to sharing with the key business stakeholders



You have:

Master or above degree in Computer Science, Machine Learning, Mathematics or Statistics

Strong mathematical and statistical knowledge
Experience in managing a team
10+ years of relevant experience, including the following areas:
    
Creating analytics models/products and delivering results
Implementing solutions for business preferably in consumer goods areas with knowledge and understanding of consumer goods data with the knowledge of industry trend
Professional experience in advanced analytics


Proficient in Python/R, advanced ML/AI algorithms, SQL, optimization
Experience with data science frameworks (e.g. Scikit-learn/Pandas etc.) and deep learning frameworks (e.g. Keras/Pytorch etc.)

Experience with R/Python, advanced AL/AI algorithms, SQL, optimization
Preferred but not essential: GCP certifications, DAX
Excellent problem solving skills, communication skills & stakeholder management, with the ability to simplify technical output into business language
Strong project management experience and flexibility to work across multiple time zones
Growth mindset with ability to stay current with solution trends
","['Machine Learning', 'SQL', 'Problem Management', 'Value Creation', 'Data Architecture', 'Statistics', 'GCP', 'Data Science', 'Statistical Knowledge', 'Stakeholder Management', 'Data Analytics']"
Data Scientist,30A KALLANG PLACE 339213,Full Time,Executive,3 years exp,Information Technology,Monthly,"$4,000to$7,000","Duties and Responsibilities

Familiarize with Ensign’s business domain and objectives to implement cyber security analytics solutions that meet internal business requirements and the needs of industry partners and customers
Develop, evaluate, tune, deploy, maintain and document production-grade data analytics models that provide cyber security insights.
Work on large volume of raw, structured and unstructured data from internet traffic, logs and other forms of data sources using Apache Spark, MPP DB, NoSQL, Hadoop, Scala, Python, R, Tableau etc on daily basis.
Evaluate potential solutions relating to data analytics and make recommendations to solve business problems
Liaise and work with in-house developers, data engineers, big data architects, visualization engineers and project managers to better understand the requirements of developing, deploying and productizing models
Ensure the analytics models are running in optimal condition and perform trouble-shooting when the models are having issue
Advocate and ensure security best practices

Requirements

Degree in Statistics, Data Science, Mathematics, Computer Science, Engineering or any other related quantitative field
Minimum 3 years of experience working in a data science position, preferably in the cyber security industry and has worked with security logs/network data
Experience and expertise in probability and statistical modelling, inclusive of machine learning, experimental design, evaluation and optimization
Proficiency in Scala, Python, R, Java, Spark and SQL, among others
Ability to perform rapid prototyping and proof of concept using visualization and dashboarding tools such as Tableau
Experience with machine learning and deep learning frameworks and tools such as TensorFlow, Keras, Caffe, MxNet, Spark, Hadoop, R, pandas
Solid technical background with hands-on experience in conceptualizing, designing, implementing and deploying statistical or machine learning models in the big data environment (e.g. Hadoop)
Excellent client-facing and internal communication skills
Solid organizational skills including attention to detail and multi-tasking
Team-player, result-oriented, proactive, self-driven, requiring minimal supervision
Creative problem-solving skills, highly organized, with ability to handle multiple simultaneous tasks, prioritize and meet tight deadlines
","['Machine Learning', 'Pandas', 'Scala', 'Statistical Modeling', 'Cyber Security', 'Hadoop', 'SQL', 'Python', 'Data Science', 'Team Player']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Facility Engineer (Data Center),"AIA TOWER, 1 ROBINSON ROAD 048542","Permanent, Full Time",Senior Executive,5 years exp,Engineering,Monthly,"$4,000to$8,000","As a Facility Engineer in a Data Center Engineering environment, you will be responsible for the on-site management of the colocation (Colo) service providers in state-of-the-art critical infrastructure facilities. Based in Singapore you will have the opportunity to assist in the design, implementation, commissioning and build out of new facilities. Work with key business leaders to manage & implement projects to increase current facility capacity, efficiency, sustainability & reliability. As a subject matter expert in the critical services industry, you will review the Colo’s management of both routine maintenance and emergency services on a variety of critical systems.
At Amazon, our mission is to be the most customer-centric company in the world, your focus will be on the delivery of great customer service and satisfaction.

As part of the technical team, you will get to work with some of the most talented and brightest engineers in the industry. Not only would you be working with the most experienced, you would be developing your skills and furthering your career within one of the most innovative and progressive technology companies in the world.
If you’re up for the challenge, we’d love to hear from you!

Key job responsibilities
• Liaise with Colo vendors for all Mechanical & Electrical maintenance servicing to Data Halls
• Responds to emergency incidents and work closely with Colo vendors to resolve it
• handles day to day operation related activities for the data halls (creation of access, escorting, power monitoring, thermal hot spot issues, power up or down of racks, audits)","['Sustainability', 'Hardware', 'Data Center', 'Electrical', 'Emergency Services', 'Reliability', 'Cabling', 'Customer Service', 'Manufacturing', 'Linux', 'Commissioning', 'Mechanical Engineering', 'Facilities Management']"
Data Scientist,"100 PASIR PANJANG, 100 PASIR PANJANG ROAD 118518",Full Time,Executive,2 years exp,"Engineering, Healthcare / Pharmaceutical, Information Technology",Monthly,"$5,000to$10,000","Overview of the role
The role provides a tremendous opportunity for a candidate to work in a fast-growing startup with a million users (and growing) by deriving value from the massive volume of data we capture.
This is your chance to deploy Algorithms & Pipelines at SCALE. Over the coming years, those will be progressively supporting some, if not all, of the following: user classification from multimodal data, simple NLP supporting data capture & classification, providing AI Diagnosis, Prediction of treatment opportunities, inference of Health events from time series, Context inference from Geo-data & weather, etc. (i.e., prior knowledge of medical etc. is not expected).
As the Data Engineer+Scientist, you are responsible for designing and implementing data-driven services and solutions (Ie: Pipelines & Algorithms). You must be comfortable deploying your solutions (algorithms) to the cloud, ready to scale, and have a proven track record of designing pipelines for batch as well as streaming needs.
Roles & Responsibilities

Develop data pipelines that ingest data from a variety data sources to enable better data-informed decision-making within the business
Design and implement data science solutions / algorithms that provide smart features to our users
Contribute to an ongoing effort to improve data reliability, efficiency and quality

Skills/Experience should include some of those (by order of importance):

Experience in Python, REST APIs, and SQL
Familiarity with data warehousing concepts and data-modeling
Experience in using AWS cloud infrastructure and solutions such as Kinesis, Glue, S3, Redshift, ECS
Experience with ELT processing and workflow orchestration using Airflow and dbt
Experience with development systems such as Bitbucket & Docker

We want someone who is:

Able to deliver your work in a planned and timely manner
Able to work across cross-functional teams to gather requirements and come up with solutions

Qualities:

Rigor: 5/10 *
Self-Learning: 7/10
Initiative/Enthusiasm: 6/10
Team-Work: 6/10 **

*You will have the opportunity to learn good practices and methods to nurture Rigor. Rigor is critical to scale models & data collection.
** Team-Work is also critical for scalability, but keep in mind that here this is teamwork across functional teams, not within a silo. It will be about passing the ball to the person working on the UX showing the output from your algorithm, receiving the ball from the product manager, and even about understanding how the algorithm is impacted by the feelings of the user doing input.
Other info

Work Location: Singapore
COVID-19 Vaccination Requirement: Fully Vaccinated

If you are passionate and motivated to join our efforts in improving patient’s quality of life, please send your CV and brief description of your successful growth campaigns (if available) to careers@healint.com","['MASSIVE', 'Weather', 'Scalability', 'Pipelines', 'Treatment', 'SQL', 'Python', 'Docker', 'Data Science', 'Orchestration', 'UX', 'S3', 'Data Warehousing']"
Affiliate Data Analyst,12 Marina Boulevard  018982,Contract,Executive,3 years exp,Information Technology,Monthly,"$8,000to$15,000","Job Description:

· Identify data sources and data requirements of the team, analyzing datasets and derive insights
· Responsible for developing, maintaining and   extracting information and data insights from internal and external data sets
· Perform an in-depth analysis of business performance, generate regular/on-demand analytical report
· Design market/business detailed reports, performance measurement tools and other data products.
· Explore business issues/opportunities, uncover insights and/or identify targeted areas for business and user growth.
· Communicate with various teams to roll out products/services, develop data applications
· Build and maintain data pipelines used for a diverse range of data products
· Implement best practices for managing versions and source control for data product development

Job Requirements:
· Min. Bachelor’s Degree in Computer Science/Data Analytics, Engineering, Mathematics, and other related courses
· Solid skills in data analytics/ data science/ business intelligence
· Highly motivated, structured and methodical with a high degree of initiative.
· Results and detail-oriented, with strong intuitions on how to solve problems creatively and quickly
· Must be a team player, eager to learn, empathetic and open-minded
· Advanced understanding and/or experience working in a Cryptocurrency/Blockchain/Fintech/Finance Trading domain preferred
· Good hands on experience of data visualization tools, such as Tableau/Power BI/Amplitiude
· Must be comfortable to write SQL and Python scripts

EA Personnel: Celine Tan Si Ling
CEI Reg No: R1104662
EA Licence No: 99C4599","['Tableau', 'Business Intelligence', 'Data Analysis', 'Computer Science', 'PowerBI', 'SQL', 'Python', 'business performance analysis', 'Data Science', 'Product Development', 'Performance Management', 'Data Visualization']"
Data Engineer_Advanced,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979",Contract,Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$8,000","Role:Data Engineer_Advanced

JD:
• Hands-on experience in Enterprise-grade Production Database administration and Support
• Expertise in Relational and No SQL database is required.
• Hands-on experience in databases like Sybase, MongoDB and MariaDB is preferred
• Database schema creation, management, and ensuring data integrity.
• Performance management tuning, Implementing robust backup and recovery
• Run SQL code reviews and walk-through application teams. Have necessary procedural skills
• Experience in capacity planning and general Linux/Unix system/networking skillsets is required.
• Good know-how about storage management, replication setup of database.
• Hands-on experience in automation and scripting.
• Familiar with batch jobs, shell scripts, enabling monitoring and dashboarding for database stacks.
• Experience in DevOps toolsets and Container platform deployments would be a plus
• Self-driven, strong, committed, and reliable team player. Ability to contribute to discussions on design and strategy. Good written and oral communication skills.
• Minimum of 7 years technology experience (preferably in the financial industry).

Job responsibilities

• Perform administration and support of Enterprise grade critical production database.
• Play a key role in architecting database architecture and relevant infra deployment.
• Plan, design and set standards for database operations.
• Hand-on implementation and troubleshooting in multiple database technologies like Sybase, MongoDB and MariaDB
• Manage schema, access controls, and perform regular optimization checks.
• Implement database level replication, configure database backup, and assist OS platform team in configuring VCS high availability.
• Implement monitoring and alerting using scripts and automation. Deploy the code via CI/CD pipeline.
• Perform Database upgrades, patching, archiving to S3 object storage.
• Perform database tuning, SQL code reviews, assist application in optimizing LRQ and relevant troubleshooting.
• Configure batch jobs using schedulers like TWS.
• Build Grafana/Kibana dashboards, ingest the relevant DB logs in logging platforms, build monitoring metrics using custom SQL query for continuous monitoring.
• Build docker image for database, author custom scripts to deploy DB as a container.
• Perform continuous engagement with application support team and assist in preparing audit reports.
• Prepare management reports, presentations and run workshops, sessions for user community","['MongoDB', 'Oral Communication Skills', 'Archiving', 'High Availability', 'Scripting', 'MariaDB', 'Tuning', 'Replication', 'Logging', 'SQL', 'Database Administration', 'VCS', 'Docker', 'S3', 'Databases']"
Data Entry Clerk (Manufacturing),"NORTH VIEW BIZHUB, 6 YISHUN INDUSTRIAL STREET 1 768090",Full Time,Non-executive,2 years exp,Admin / Secretarial,Monthly,"$1,800to$2,000",#NAME?,"['Microsoft Excel', '5S', 'Purchasing', 'Data Entry', 'Protocol', 'Office Administration', 'SPC', 'Filtration', 'Spreadsheets', 'Administrative Support', 'Presentation Skills', 'Customer Service', 'Data Analytics', 'Manufacturing', 'Mechanical Engineering']"
 , , , , , , , , , 
MT - Data Center Operator,"20 COLLYER QUAY, 20 COLLYER QUAY 049319",Full Time,Professional,1 year exp,Information Technology,Monthly,"$3,500to$4,500","Data Center Operator

ITCS Group is an IT Managed Services, Outsourcing and Talent-Sourcing company. We provide customised IT Consulting Solutions, Project Management, IT resourcing and on/off-shore Application Development Services across the Asia Pacific region. With offices strategically located in Hong Kong, Tokyo, Singapore, Sydney, and Mumbai. ITCS Group is the preferred technology partner for leading MNCs, including Global Investment Banks, Fortune 500 companies, across Asia Pacific. 
 
We are currently looking for a Data Center Operator to join our banking and financial team in Singapore to provide hardware support for network, server, and storage devices.

Responsibilities:
- Daily routine check and reporting of hardware equipment status according to SOP
- Issue daily reports, handover documents, and monthly documentation.
- Install and removal of physical hardware with advice from technical team
- Inventory management of spare parts and status
- Coordination of suppliers and vendors, including site access management.

Requirements:
- Experienced in Data Center operations or relevant experience
- Knowledge in basic cabling
- Good documentation and communication skills

Additional Information:
- Location: Tai Seng / HarbourFront (2 headcount, either location but not both)
- Working hours: 5-day work week, weekend and public holiday inclusive
- Shift hours: (7 am - 4 pm), (12 pm - 9 pm), 8 + 1 hour break per shift","['Tape', 'Managed Services', 'Troubleshooting', 'Hardware', 'Outsourcing', 'Data Center', 'Inventory', 'Application Development', 'Electrical', 'Inventory Management', 'Scratch', 'Banking', 'Consulting', 'ITIL', 'Cabling']"
"Data Scientist, Risk Data Mining - Singapore",1 RAFFLES QUAY 048583,Permanent,Professional,3 years exp,Information Technology,Monthly,"$10,000to$20,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Business Risk Integrated Control (BRIC) team is missioned:
- To protect TikTok users, including and beyond content consumers, creators, advertisers;
- By securing platform health and community experience authenticity;
- Through building infrastructures, platforms and technologies, as well as to collaborate with many cross-functional teams and stakeholders.

The BRIC team works to minimize the damage of inauthentic behaviors on TikTok, covering multiple classical and novel community and business risk areas such as account integrity, engagement authenticity, anti spam, API and growth health, live streaming security and financial safety (ads or e-commerce), etc.

In this team you'll have a unique opportunity to have first-hand exposure to the strategy of the company in key security initiatives, especially in building scalable and robust, intelligent and privacy-safe, secure and product-friendly systems and solutions. Our challenges are not some regular day-to-day technical puzzles -- You'll be part of a team that's developing novel solutions to first-seen challenges of a non-stop evolvement of a phenomenal product eco-system. The work needs to be fast, transferrable, while still down to the ground to making quick and solid differences.

Responsibilities
- Build rules, algorithms and machine learning models, to respond to and mitigate business risks in ByteDance products/platforms. Such risks include and are not limited to abusive accounts, fake engagements, spammy redirection, scraping, fraud, etc.
- Analyse business and security data, uncover evolving attack motion, identify weaknesses and opportunities in risk defense solutions, explore new space from the discoveries.
- Define risk control measurements. Quantify, generalize and monitor risk related business and operational metrics. Align risk teams and their stakeholders on risk control numeric goals, promote impact-oriented, data-driven data science practices for risks.

Qualifications
- Bachelor or degrees above in computer science, statistics, math, internet security or other relevant STEM majors (e.g. finance if applying for financial fraud roles).
- Solid data science skills. Proficiency in statistical analytical tools, such as SQL, R and Python.
- Familarity with machine learning or social/content online platform analytics. Bonus given to proficiency in modern machine learning applications.
- Ability to think critically, objectively, rationally. Reason and communicate in result-oriented, data-driven manner. High autonomy.
- Minimum 3 - 5 years relevant work experience from a large-scale internet business

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Machine Learning', 'Classical', 'Autonomy', 'Big Data', 'Defense', 'Mathematics', 'Strategy', 'Data Mining', 'SQL', 'Python', 'Fraud', 'Statistics', 'Data Science', 'API', 'Data Analytics']"
"Data Scientist, SAPMENA","OCEAN FINANCIAL CENTRE, 10 COLLYER QUAY 049315",Permanent,Professional,4 years exp,Information Technology,Monthly,"$7,000to$9,000","Who are we?
At L’Oréal, there is never a dull day, the beauty lies in the freedom to go beyond with our empowering entrepreneurial culture. We take pride in developing young talents who have the passion and ambition to make an impact in the beauty industry. We currently offer a wide range of career opportunities for undergraduates and fresh graduates across the region.
SAPMENA (South Asia Pacific, Middle East & North Africa) is home to 40% of the world's population & some of the fastest-growing economies. Headquartered in Singapore, we have over 6,800 diverse talents in 15 subsidiaries with 34 International Brands, 4 factories & 2 research centres. As the leading beauty tech company, we offer endless exciting career opportunities.

You will:
In your role, you will be expected to understand business challenges and and build data products/statistical modelling solutions to tackle​ them. You will have a critical role working with our stakeholders to make recommendations to the business.

Explore and choose the algorithms which have best performance​
Develop, train and finetune the model ​
Work with ML engineers to support the industrialization
Responsible for engaging with key stakeholders within the organization, the Delivery Team, Data Engineers, BI Developers, analytics analyst, IT PMO and business to build an exceptional product.
Working closely with a product owner and effectively captures stakeholder assumptions and translates them into hypothesis driven outcomes.
Be accountable for the end-to-end results and delivery of your product
Collaborate with stakeholders on model/product launch communication, training and enablement and ongoing product adoption tactics, where applicable.
Support and champion, where applicable, ongoing initiatives driving data analytics culture
Act as a subject matter expert and provide guidance to the project team throughout the project.  This includes (but not limited to):
    
Knowing which sources of data to explore
Identifying and communicating the key trends, data limitations
Support scoping of the business problem out so that the project team can determine the best model/analysis/solution
Assess reasonability of the data and/or model prior to sharing with the key business stakeholders



You have:

Master or above degree in Computer Science, Machine Learning, Mathematics or Statistics​
Strong mathematical and statistical knowledge ​
4+ years of relevant experience, including the following areas:
    
Creating analytics models/products and delivering results
Implementing solutions for business preferably in consumer goods areas with knowledge and understanding of consumer goods data with the knowledge of industry trend
Professional experience in advanced analytics


Proficient in Python/R, advanced ML/AI algorithms, SQL, optimization
Experience with data science frameworks (e.g. Scikit-learn/Pandas etc.) and deep learning frameworks (e.g. Keras/Pytorch etc.)​
Experience with R/Python, advanced AL/AI algorithms, SQL, optimization
Preferred but not essential: GCP certifications, DAX
Excellent problem solving skills, communication skills & stakeholder management, with the ability to simplify technical output into business language
Strong project management experience and flexibility to work across multiple time zones
Growth mindset with ability to stay current with solution trends
","['Machine Learning', 'Data Analysis', 'Big Data', 'Artificial Intelligence', 'Data Mining', 'Python', 'Statistics', 'Data Science', 'Visualization', 'Data Analytics', 'Databases', 'Data Visualization']"
 , , , , , , , , , 
DevOps Engineer - Data Platform,1 RAFFLES QUAY 048583,Full Time,Professional,3 years exp,"Engineering, Information Technology",Monthly,"$10,000to$20,000","Responsibilities

About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

What you will be doing:
- Build tools, automation, monitoring for distributed data platforms running as SaaS and on-premises deployment.
- Collaborate with engineering, infrastructure, security, and product teams to implement DevOps solutions to ensure scalability, reliability of the system.
- Contribute to the architecture, design, and improvement of our DevOps processes.

Qualifications
- Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience.
- At least 3 years of production-level experience in either Python, Java, or Go.
- Expertise in DevOps technologies like Ansible, Terraform, Salt, Bash Scripting, etc.
- Expertise in containerization technologies including Docker and Kubernetes.
- Expertise in automating, analyzing, and troubleshooting large-scale distributed systems.
- Experience in building solutions with AWS, Google, Azures, AliCloud or other cloud services.
- Familiar with Unix/Linux operating systems.","['Troubleshooting', 'Scalability', 'Kubernetes', 'ClickHouse', 'Scripting', 'Reliability', 'Distributed Systems', 'Python', 'Operating Systems', 'Architecture Design', 'SaaS', 'Docker', 'Ansible', 'Java']"
"DevOps Engineer, Data Platform",1 RAFFLES QUAY 048583,Full Time,Professional,1 year exp,"Engineering, Information Technology",Monthly,"$6,500to$13,000","Responsibilities

About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

What you will be doing:
- Build tools, automation, monitoring for distributed data platforms running as SaaS and on-premises deployment.
- Collaborate with engineering, infrastructure, security, and product teams to implement DevOps solutions to ensure scalability, reliability of the system.
- Contribute to the architecture, design, and improvement of our DevOps processes.

Qualifications
- Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience.
- At least 1 year of production-level experience in either Python, Java, or Go.
- Expertise in DevOps technologies like Ansible, Terraform, Salt, Bash Scripting, etc.
- Expertise in containerization technologies including Docker and Kubernetes.
- Expertise in automating, analyzing, and troubleshooting large-scale distributed systems.
- Experience in building solutions with AWS, Google, Azures, AliCloud or other cloud services.
- Familiar with Unix/Linux operating systems.","['Troubleshooting', 'Scalability', 'Kubernetes', 'ClickHouse', 'Scripting', 'Reliability', 'Distributed Systems', 'Python', 'Operating Systems', 'Architecture Design', 'SaaS', 'Docker', 'Ansible', 'Java']"
Data Scientist,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616",Permanent,Professional,5 years exp,Banking and Finance,Monthly,"$7,000to$10,000","Our client is looking for an experienced data scientist with an investment banking or wealth management background to join their centralized Data team and drive development of analytics products for Data and digital transformation across the company.

Mandatory Skills:

Degree in computer science or statistics with minimum 5 years of data experience in Banking industry.
Strong in Python, SQL and experience with techniques such as Regression models, Decision Trees, Clustering, Optimization algorithms, Boosted models, Random forest, Ensemble algorithms, SVM, Dimensionality Reduction, Natural language processing, Neural network models.
Good understanding of FS industry fundamentals and business problems to find new ways to leverage data.
Sound understanding of functional areas and analytics problems in areas of Customer, Marketing, Channel, Pricing, Digital, Operations, HR/Corporate analytics.
Possess strong communication skills and be able to explain highly technical problems in simple layman form.
Able to articulate the impact of decisions and recommend improvements.
Ability to collaborate / virtually manage multi-cultural, multi-disciplined, globally dispersed teams.

Desired Skills:

Experience with cloud technologies such as AWS and Snowflake.
Prior experience with TensorFlow or PyTorch.

Responsibility:

With strong analytics experience & technical skills involve in data/information preparation, data insight & visualization using BI (or similar tools), and advanced data prediction using AI, ML, DL, etc.
Lead and explain/educate to all levels people across the company in these areas; Analytics, Coding, Structured & Unstructured Databases, Statistical algorithms and Models, Machine learning and AI, Frameworks and Libraries.
Contribute to the development of company’s data products. Use analytics expertise plus FS domain & functional knowledge, problem solving skills and independent thinking to create Company’s data, information & analytics products.
Be a team player & an individual contributor. Work with centralized team and other business function people as part of larger deliveries, as well as being able to work independently or in small teams to continuously deliver business value across the company.
Be a trusted partner. Someone that anyone in the company can come to for help with creating analytics driven business transformation.

Those who are keen for the role and would like to discuss the opportunity further, please click ""Apply Now"" or email Alimpan at amukherjee@morganmckinley.com with your updated CV.

Only shortlisted candidates will be responded to, therefore if you do not receive a response within 14 days, please accept this as notification that you have not been shortlisted.

Alimpan Mukherjee
Morgan McKinley Pte Ltd
EA Licence No: 11C5502
EA Registration Number: R2198629","['Tableau', 'Snowflake Cloud Data Warehouse', 'Wealth Management', 'Deep learning', 'TensorFlow', 'Machine Learning', 'Natural Language Processing', 'Investment Banking', 'Customer Marketing', 'PyTorch', 'SQL', 'Python', 'Statistics', 'Visualization', 'Articulate', 'Business Transformation', 'Power BI', 'Databases']"
Senior / Data Platform Engineer,"SGX CENTRE I, 2 SHENTON WAY 068804","Permanent, Full Time",Executive,5 years exp,Information Technology,Monthly,"$8,500to$12,500","The ideal candidate is someone who is self-motivated and has strong interest in data. He/she will be working in the Data and Analytics team to deliver both on-prem and cloud-based enterprise-grade data platforms that will enable the company's data analytics needs.

Responsibilities

Work with internal stakeholders to understand the business requirements and propose scalable and sustainable solutions.
Build integration and connectivity interfaces to internal and external systems to enable seamless flow of data
Perform analysis on existing data infrastructure and platforms to identify enhancements required to enable data best practices.
Work closely with external stakeholders to review vendor's deliverables (functional/ technical/ design documentation) to ensure they meet business requirements and conform to the company's policies and guidelines.

Qualifications

Bachelor degree Computer Science, Computer Engineering or any other related field
At least 5 years of relevant working experience in data ingestion, data storage and data analytics
Proven experience in data engineering and platform (Cloud Data Platforms, Data Virtualization, Business Intelligence, Data Management)
Experience working with Linux OS
Proficient in programming in Java and Python
Experience/ knowledge in AWS  and SDLC will be advantageous
Strong analytical and problem solving skills and ability to think up innovative ideas to solve problems and challenges
Strong communication skills with good ability to interact with users, technical colleagues and vendors
","['Requirements Gathering', 'Business Intelligence', 'AWS', 'Data Management', 'SDLC', 'Data Engineering', 'Python', 'Continuous Integration', 'Java', 'Data Analytics', 'Virtualization', 'Linux', 'Business Requirements', 'Technical Design']"
Senior Cybersecurity Data Scientist,30A KALLANG PLACE 339213,Full Time,Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$10,000","Duties and Responsibilities

Familiarize with Ensign’s business domain and objectives to implement cyber security analytics solutions that meet internal business requirements and the needs of industry partners and customers
Develop, evaluate, tune, deploy, maintain and document production-grade data analytics models that provide cyber security insights
Work on large volume of raw, structured and unstructured data from internet traffic, logs and other forms of data sources using Apache Spark, MPP DB, NoSQL, Hadoop, Scala, Python, R, Tableau etc on daily basis
Evaluate potential solutions relating to data analytics and make recommendations to solve business problems
Liaise and work with in-house developers, data engineers, big data architects, visualization engineers and project managers to better understand the requirements of developing, deploying and productizing models
Ensure the analytics models are running in optimal condition and perform trouble-shooting when the models are having issue
Advocate and ensure security best practices
Manage technical data science projects and improve data science workflow and processes periodically
Coach and review the work of junior data scientists
Able to manage and resolve difficult and complex technical problems with minimal supervision

Requirements

Minimum Degree in Statistics, Data Science, Mathematics, Computer Science, Engineering or any other related quantitative field
Minimum 5 years of experience working in a data science position, preferably in the cyber security industry and has worked with security logs/network data
Experience and expertise in probability and statistical modelling, inclusive of machine learning, experimental design, evaluation and optimization
Proficiency in Scala, Python, R, Java, Spark and SQL, among others
Ability to perform rapid prototyping and proof of concept using visualization and dashboarding tools such as Tableau
Experience in implementing projects using machine learning and deep learning frameworks using tools such as TensorFlow, Keras, Caffe, MxNet, Spark, Hadoop, R, pandas
Solid technical background with hands-on experience in conceptualizing, designing, implementing and deploying statistical or machine learning models in the big data environment (e.g. Hadoop)
Excellent client-facing and internal communication skills
Solid organizational skills including attention to detail and multi-tasking
Team-player, result-oriented, proactive, self-driven, requiring minimal supervision
Creative problem-solving skills, highly organized, with ability to handle multiple simultaneous tasks, prioritize and meet tight deadlines
","['Troubleshooting', 'Big Data', 'Cyber Security', 'Hadoop', 'SQL', 'Rapid Prototyping', 'Python', 'Data Science', 'Visualization', 'Team Player', 'Data Analytics']"
Lead Cybersecurity Data Scientist,30A KALLANG PLACE 339213,Full Time,Professional,5 years exp,Information Technology,Monthly,"$10,000to$17,000","Duties and Responsibilities

Familiarize with Ensign’s business domain and objectives to implement cyber security analytics solutions that meet internal business requirements and the needs of industry partners and customers
Develop, evaluate, tune, deploy, maintain and document production-grade data analytics models that provide cyber security insights
Work on large volume of raw, structured and unstructured data from internet traffic, logs and other forms of data sources using Apache Spark, MPP DB, NoSQL, Hadoop, Scala, Python, R, Tableau etc on daily basis
Knowledge of cloud (AWS, Azure, GCP) and ability to develop and deploy models that leverage on cloud resources using appropriate cloud architecture
Evaluate potential solutions relating to data analytics and make recommendations to solve business problems
Liaise and work with in-house threat analysts, threat researchers, malware analysts, developers, data engineers, big data architects, visualization engineers and project managers to better understand the requirements of developing, deploying and productizing data science models
Ensure the analytics models are running in optimal condition and perform trouble-shooting when the models are having issue
Advocate and ensure security best practices
Manage technical data science projects and improve workflow and processes periodically
Coach and review the work of junior data scientists and participate in technical interviews of potential new hires
Able to manage and resolve complex technical problems with minimal supervision
Participate and provide technical leadership in the scoping of customer projects
Plan and lead the delivery of projects and front customer related technical discussion
Actively engage various stakeholders and Business Units to solicit used cases and lead the end-to-end delivery of solutions to meet the needs of identified used cases
Lead the exploration and application of SOTA data science techniques/algorithms to address challenging problems in the cyber domain
Champion Research and Innovation within and across various teams and generate Intellectual Property (IP) that will uplift the reputation of Ensign

Requirements

Minimum Degree in Statistics, Data Science, Mathematics, Computer Science, Engineering or any other related quantitative field
Minimum 5 years of experience working in a data science position, preferably in the cyber security industry and has worked with security logs/network data
Experience and expertise in probability and statistical modelling, inclusive of machine learning, experimental design, evaluation and optimization
Proficiency in Scala, Python, R, Java, Spark and SQL, among others
Ability to perform rapid prototyping and proof of concept using visualization and dashboarding tools such as Tableau
Experience in implementing projects using machine learning and deep learning frameworks using tools such as TensorFlow, Keras, Caffe, MxNet, Spark, Hadoop, R, pandas
Solid technical background with hands-on experience in conceptualizing, designing, implementing and deploying statistical or machine learning models in the big data environment (e.g. Hadoop)
Excellent client-facing and internal communication skills
Solid organizational skills including attention to detail and multi-tasking
Team-player, result-oriented, proactive, self-driven, requiring minimal supervision
Creative problem-solving skills, highly organized, with ability to handle multiple simultaneous tasks, prioritize and meet tight deadlines
","['Tableau', 'TensorFlow', 'Machine Learning', 'client facing skills', 'Scala', 'Statistical Modeling', 'Big Data', 'Cyber Security', 'Hadoop', 'Python', 'Data Science', 'Visualization']"
"Lead Data Scientist, Risk Data Mining, BRIC - Singapore",1 RAFFLES QUAY 048583,Permanent,Professional,3 years exp,Information Technology,Monthly,"$14,000to$28,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Business Risk Integrated Control (BRIC) team is missioned to:
- Protect ByteDance users, including and beyond content consumers, creators, advertisers;
- Secure platform health and community experience authenticity;
- Build infrastructures, platforms and technologies, as well as to collaborate with many cross-functional teams and stakeholders.

The BRIC team works to minimize the damage of inauthentic behaviors on ByteDance platforms (e.g. TikTok, CapCut, Resso, Lark), covering multiple classical and novel community and business risk areas such as account integrity, engagement authenticity, anti spam, API abuse, growth fraud, live streaming security and financial safety (ads or e-commerce), etc.
In this team you'll have a unique opportunity to have first-hand exposure to the strategy of the company in key security initiatives, especially in building scalable and robust, intelligent and privacy-safe, secure and product-friendly systems and solutions. Our challenges are not some regular day-to-day technical puzzles -- You'll be part of a team that's developing novel solutions to first-seen challenges of a non-stop evolvement of a phenomenal product eco-system. The work needs to be fast, transferrable, while still down to the ground to making quick and solid differences.

Responsibilities
- Enable and contribute to establishing fast and continuous threat response, in partnership with risk data mining engineers and product partners, by building advanced analytical tools and derive data insights.
- Analyze security and product data to uncover latest attacker techniques and abuse vectors. Generalize them into data mining opportunities in product features; modeling signals, labels and algorithms; measurement and process effectiveness.
- Enable and contribute to establishing robust, powerful and privacy-aware automated defense, in partnership with risk data mining engineers, by leveraging risk systems, machine learning tools and business resources to build and improve risk control rules, models and products.
- Abstract and build risk measurements that best connect risk research, risk operation, risk defense and business/community health with data stories, drive strategic and tactical risk control roadmaps with such metrics collaboratively with product/business/engineering stakeholders.
- Uphold adversarial threat response in a specific business area (e.g. TikTok, growth, live streaming, ads, e-commerce, Lark) to be consistently prompt, rigorous and clean. Define and uphold data science practice excellence and metric-driven decision making process. Bridge technical and communication gaps between engineering, product and business teams.

Qualifications
- Bachelor, master or PhD degree in an advanced field of technology or management or other equivalent majors. E.g. Computer science, statistics, internet security, finance.
- Proficiency in data analysis and statistical analysis tools such as SQL, R and Python.
- 4+ years of strong industry experience in predictive analytics and/or statistical modelling. Successful tracking records in solving large scale data mining problems such as relevance, recommendation, anti-fraud and relevant financial problems.
- Strong technical leadership combined with hands-on data mining and machine learning application experience, and passion to work with ByteDance's data scale and business complexity. Be able to identify, plan and lead to execute both quick win tactics and long term strategies against abusers on our platforms.
- Strong ownership, communication and collaboration skills to end-to-end own one or more critical platform/community security business fronts that are highly adversarial, ever expanding, and by nature widely cross functional.
Preferred
- Experience in risk analytics in multiple areas: account takeover, fraud, spam, abuse and etc. OR strong experience in data/statistical analysis on general internet or financial business. OR deep understanding about modern Machine Learning theory, applications, industry best practice.
- Consistency at exercising data science best practice in modern internet industry or academic world. Persistence in reasoning with data, interpreting data objectively, and making data-driven decisions.
- Minimum 3 - 5 years relevant work experience from a large-scale internet business

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Machine Learning', 'Classical', 'Labels', 'Predictive Analytics', 'Interpreting', 'Data Mining', 'SQL', 'Python', 'Fraud', 'Statistics', 'Data Science', 'Technical Leadership', 'Decision Making']"
 , , , , , , , , , 
"Data Steward Supervisor, OpenData (Thailand)","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Senior Executive,1 year exp,"Education and Training, Information Technology, Others",Monthly,"$3,500to$6,500","Directly reporting to the OpenData Research Center Manager, we are looking for a Data Steward Supervisor who will be responsible for the direct supervision of data stewardship team members for the data offering in Thailand.
You will also be responsible and retain all the responsibilities of a Data Steward, such as updating the attributes of records to improve core data, calling Group Practices, and updating provider affiliation information.
If you have a passion for data and quality – this is a great opportunity for you! Your role will be based in the Veeva Office in Singapore.

What You'll Do

Recruit, coach, motivate, appraise and retain team members
Deliver all necessary training to Data Stewards
Monitor, improve and give feedback on individual and team performance
Allocate work and resources to meet project deadlines
Design, document and optimise processes to ensure best-in-class delivery of data quality
Audit the data quality of Data Stewards
Ensure the team meets and exceeds productivity and quality standards
Run the daily operations in the Data Stewardship team
Report progress to direct line manager
Execute other duties and ad-hoc tasks related to data stewardship as assigned by the management

Requirements

BA/MA or equivalent degree
Thai language is required for facilitating phone / web research validation to both build and maintain the product. (The data sources need to be either phone or web validated with the respective hospitals, clinics or pharmacies to ensure the data is accurate. The product being built for Thailand will be built in Thai and English.)
Ability to learn quickly and independently
Problem solving and efficient time management skills
Proficiency in Windows, Google apps, MS Office and other office software
People and result oriented
Strong interpersonal skills
Highly organized, attention to detail and focus on quality
Able to balance qualitative and quantitative performance of the team
Able to motivate and communicate clearly
Able to meet expectations and project deadlines
Obtain and refresh the most current version of various data elements using standard methods of research such as verification through internet and outgoing phone calls
Apply new verified data elements to core database records
Assure that new data elements are not duplications of existing core data elements for Healthcare providers (HCP’s) and Healthcare Organisations (HCO’s)
Proactive maintenance of existing data and handling customer requests
Removal of incorrect data elements from core databases

Nice-to-have

Experience working with MDM (master data management applications)
Local Health Care market understanding
Knowledge of medical terminology and data quality standards within the life sciences industry
Previous experience or interest in data, databases
","['Coaching', 'Data Sharing', 'Thai Language', 'Agile Project Management', 'Process Improvement', 'Interpersonal Skills', 'People and Performance Management', 'Medical Terminology', 'Problem Solving', 'Data Quality', 'Stewardship', 'Project Timeline', 'Team Leadership', 'Attention to Detail', 'Time Management', 'Office Software', 'Life Sciences', 'Master Data Management', 'Databases', 'Ability To Learn']"
Data Modeler,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,2 years exp,Information Technology,Monthly,"$5,500to$10,500","Description

Strong functional knowledge of Insurance products and business processes
Strong knowledge & experience of mapping attributes, profiling from various composite business source system and channels
Problem solving & analytical skills with the ability to collect , organize, analyse, and disseminate significant amount of information with attention to detail and accuracy
Good communication and interpersonal skills – Ability to engage multiple stake holders across the business operation & technology teams
Implementing large scale projects involving agile methodology

Data Mapping & Modeling

Strong experience in building data model based on industry-based accord standards , preferably Insurance Domain
Strong experience in mapping attributes, data profiling , data cleansing , and technical data quality etc.
Strong experience in Ansi SQL and in-depth knowledge with structured , semi-structured & unstructured data
Strong experience on Star Schema , Snowflake , Data Vault & Domain based data models & should have clear understanding on the levels of data normalization , de-normalization etc.
Experience in data Modeling tools such as Erwin , ER/Toad Studio or equivalent

Data Warehousing and Big Data Tools

Must have good knowledge of data lake and working experience of migration projects in cloud with providers like AWS or AZURE or GCP
Good to have experience in working with No SQL, Spark SQL using AWS Glue, and columnar data store
Good to understand data security features like data masking, data encryption , role based & fine grain access control mechanisms etc.

BI Tools

Working knowledge on how BI tools integrate with enterprise-wide Curated Data Mart and Data Lake using Tableau , Power BI

Data Analysis

Formulate reconciliation strategies between various source systems to destination systems on cloud and driving the data quality rules for Data Ops
Formulate technical data quality and remediation strategies for various source systems based on column level profiling
Formulate functional data quality and remediation strategies by driving discussions with source systems data owners and custodians

Data Governance & Catalogue

Knowledge of data governance tools preferably Alation, Informatica AXON is an added advantage
Knowledge of data catalogue tools preferably AWS Glue catalogue , Informatica EDC , Alation is an added advantage
Knowledge of data quality tools preferably AWS Data Brew , Informatica Data Quality is an added advantage

Qualifications

At least 2-3 years of data Modeling and profiling experience
Experience in working on cloud migration, business glossary and catalogue will be highly preferred
Bachelor’s Degree in computer science, IT or equivalent
","['Tableau', 'Data Analysis', 'Modeling', 'Big Data', 'Data Modeling', 'Erwin', 'Informatica', 'Data Quality', 'Data Governance', 'SQL', 'Power BI', 'Data Warehousing']"
 , , , , , , , , , 
"Data Steward Supervisor, OpenData (Philippines)","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Senior Executive,1 year exp,"Education and Training, Information Technology, Others",Monthly,"$3,500to$6,500","Directly reporting to the OpenData Research Center Manager, we are looking for a Data Steward Supervisor who will be responsible for the direct supervision of data stewardship team members for the data offering in the Philippines.
You will also be responsible and retain all the responsibilities of a Data Steward, such as updating the attributes of records to improve core data, calling Group Practices, and updating provider affiliation information.
If you have a passion for data and quality – this is a great opportunity for you! Your role will be based in the Veeva Office in Singapore.

What You'll Do

Recruit, coach, motivate, appraise and retain team members
Deliver all necessary training to Data Stewards
Monitor, improve and give feedback on individual and team performance
Allocate work and resources to meet project deadlines
Design, document and optimise processes to ensure best-in-class delivery of data quality
Audit the data quality of Data Stewards
Ensure the team meets and exceeds productivity and quality standards
Run the daily operations in the Data Stewardship team
Report progress to direct line manager
Execute other duties and ad-hoc tasks related to data stewardship as assigned by the management

Requirements

BA/MA or equivalent degree
Filipino language is required for facilitating phone / web research validation to both build and maintain the product. (The data sources need to be either phone or web validated with the respective hospitals, clinics or pharmacies to ensure the data is accurate.)
Ability to learn quickly and independently
Problem solving and efficient time management skills
Proficiency in Windows, Google apps, MS Office and other office software
People and result oriented
Strong interpersonal skills
Highly organized, attention to detail and focus on quality
Able to balance qualitative and quantitative performance of the team
Able to motivate and communicate clearly
Able to meet expectations and project deadlines
Obtain and refresh the most current version of various data elements using standard methods of research such as verification through internet and outgoing phone calls
Apply new verified data elements to core database records
Assure that new data elements are not duplications of existing core data elements for Healthcare providers (HCP’s) and Healthcare Organisations (HCO’s)
Proactive maintenance of existing data and handling customer requests
Removal of incorrect data elements from core databases

Nice-to-have

Experience working with MDM (master data management applications)
Local Health Care market understanding
Knowledge of medical terminology and data quality standards within the life sciences industry
Previous experience or interest in data, databases
","['Coaching', 'Data Sharing', 'Agile Project Management', 'Process Improvement', 'Interpersonal Skills', 'People and Performance Management', 'Medical Terminology', 'Problem Solving', 'Data Quality', 'Stewardship', 'Project Timeline', 'Team Leadership', 'Attention to Detail', 'Time Management', 'Office Software', 'Life Sciences', 'Master Data Management', 'Databases', 'Ability To Learn', 'Tagalog']"
Data Steward,"ECON INDUSTRIAL BUILDING, 2 ANG MO KIO STREET 64 569084",Full Time,Executive,4 years exp,Information Technology,Monthly,"$6,000to$8,000","Job Description & Requirements
Responsibilities
• Provide technical advisory and support to Data Steward in the execution of data management activities to comply with data governance policies and guidelines.
• Create and maintain technical data documentation.
• Provide the technical expertise around source systems, extract, transform, and load (ETL) processes, data stores, data warehouses, and Business intelligence tools.
• Explain how a system or process works/doesn’t work.
• Check code, SQL, internal database structures, and other programming constructs in search of how the information is structured, how the data moves, and how the data transforms within Data Lake or between systems.
• Assist in identifying where business data elements are physically implemented in a system.
Experience / Skills
• Bachelors degree in IT/ Computer science or equivalent.
• Highly organised, adaptable, meticulous with a strong sense of responsibility and ability to followthrough.
• At least 4 years hands-on experience in data management.
• Strong in Business Needs Analysis.
• Hands-on in Data Strategy.
• Stakeholder Management.
• Data Engineering – familiar to write SQL scripts and stored procedure
• Insurance domain knowledge or/and, experience in Impala/HUE and Data Governance is added
advantage","['Requirements Gathering', 'Data Sharing', 'Agile Project Management', 'TIBCO', 'Information Management', 'Data Management', 'Technical Advisory', 'Data Governance', 'Business Needs Analysis', 'Data Engineering', 'SQL', 'Business Intelligence Tools', 'Stakeholder Management', 'Master Data Management', 'Data Strategy']"
"Data Steward Supervisor, OpenData (Indonesia)","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Senior Executive,1 year exp,"Education and Training, Information Technology, Others",Monthly,"$3,500to$6,500","Directly reporting to the OpenData Research Center Manager, we are looking for a Data Steward Supervisor who will be responsible for the direct supervision of data stewardship team members for the data offering in Indonesia.
You will also be responsible and retain all the responsibilities of a Data Steward, such as updating the attributes of records to improve core data, calling Group Practices, and updating provider affiliation information.
If you have a passion for data and quality – this is a great opportunity for you! Your role will be based in the Veeva Office in Singapore.

What You'll Do

Recruit, coach, motivate, appraise and retain team members
Deliver all necessary training to Data Stewards
Monitor, improve and give feedback on individual and team performance
Allocate work and resources to meet project deadlines
Design, document and optimise processes to ensure best-in-class delivery of data quality
Audit the data quality of Data Stewards
Ensure the team meets and exceeds productivity and quality standards
Run the daily operations in the Data Stewardship team
Report progress to direct line manager
Execute other duties and ad-hoc tasks related to data stewardship as assigned by the management

Requirements

BA/MA or equivalent degree
Bahasa Indonesia is required for facilitating phone / web research validation to both build and maintain the product. (The data sources need to be either phone or web validated with the respective hospitals, clinics or pharmacies to ensure the data is accurate. The product being built for Indonesia will be built in Bahasa and English.)
Ability to learn quickly and independently
Problem solving and efficient time management skills
Proficiency in Windows, Google apps, MS Office and other office software
People and result oriented
Strong interpersonal skills
Highly organized, attention to detail and focus on quality
Able to balance qualitative and quantitative performance of the team
Able to motivate and communicate clearly
Able to meet expectations and project deadlines
Obtain and refresh the most current version of various data elements using standard methods of research such as verification through internet and outgoing phone calls
Apply new verified data elements to core database records
Assure that new data elements are not duplications of existing core data elements for Healthcare providers (HCP’s) and Healthcare Organisations (HCO’s)
Proactive maintenance of existing data and handling customer requests
Removal of incorrect data elements from core databases

Nice-to-have

Experience working with MDM (master data management applications)
Local Health Care market understanding
Knowledge of medical terminology and data quality standards within the life sciences industry
Previous experience or interest in data, databases
","['Coaching', 'Data Sharing', 'Agile Project Management', 'Process Improvement', 'Interpersonal Skills', 'People and Performance Management', 'Medical Terminology', 'Problem Solving', 'Data Quality', 'Stewardship', 'Project Timeline', 'Team Leadership', 'Attention to Detail', 'Time Management', 'Office Software', 'Life Sciences', 'Master Data Management', 'Databases', 'Ability To Learn']"
 , , , , , , , , , 
 , , , , , , , , , 
Tech Lead Manager - Data Platform,1 RAFFLES QUAY 048583,Permanent,Manager,10 years exp,Information Technology,Monthly,$12to$24,"About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
This role is a member of our Data Platform team focusing on Data products and solutions to enterprise services, leveraging TikTok's cutting-edge data infrastructure and data application. You will be helping enterprise customers to build their next generation data warehouse and data analytics, enabling them to do things that were not possible before.

What you will be doing:
We are looking for an innovative Tech Lead Manager to join the team. As the Tech Lead Manager, you will oversee the company’s technical team and all projects they undertake, analyze briefs, write progress reports, identify risks, and develop work schedules. You should be able to work with your team and inspire them to reach their goals.

Responsibilities
• Align with the Tiktok business teams on the values & goals & strategy & roadmaps, empower the Tiktok business with data and data engineering capabiilties
• Lead and manage Data engineering teams, plan for the goal and roadmap for the team
• Lead and establish development guidelines, standards and best practices
• Ensure the data platform & pipeline & solution's high stability & high scalability & high efficiency & high security & low latency
• Define standards and guidelines for data engineering development and operations
• Promote engineering culture through promoting technology innovations, pushing for engineering execellences
• Lead the team with vision on the emerging technologies and digital trends that are most relevant to the company's goals and evolving needs
• Hire, develop, evaluate, reward, and retain a highly productive & innovated team
Requirements
• Bachelor and above Degree in Computer Science, Mathematics, Computer Engineering or relevant disciplines;
• At least 10 years of experience in big data industry, with at least 5 years of experience in managing the data engineering team with 50+ members in internet companies or comparable high-paced businesses
• At least 8 years of experiences of PB above scale level data platform, excellent knowledge and experiences of big data tech stacks, such as Hadoop/HDFS/Kafka/MapRedcue/Spark/Flink/Storm/StructuredStreaming/Clickhouse/Presto/Impala/Doris/Druid/Kylin/Hudi/Delta/Iceberg/Kudo/...
• Expert in data warehousing and data lake theory & methodology
• Expert in data management, data governance, data architecture design
• Strong technical knowledge of data integrations, ETL, data warehouse, data lake, data modelling
• Strong coding skills in SQL/Python/Java/Scala/...
• Good communication skills, with excellent technical and business combination ability
• Rich experiences of leading and driving large-scale project/initiatives - which require complex cross-team collaborations over 3 months
• Good knowledge of BI & Analytical & DevOps methodologies and related products
• Business value oriented
• 0-1 big data platform & data engineering team establishment experience is highly preferred
• Experiences of leading global multicultural team is highly preferred

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Application Architecture', 'Scalability', 'Big Data', 'Mathematics', 'Data Management', 'ETL', 'Data Governance', 'Strategy', 'Data Engineering', 'Good Communication Skills', 'Architecture Design', 'Data Architecture', 'API', 'Data Analytics', 'Data Warehousing']"
 , , , , , , , , , 
 , , , , , , , , , 
Reference Data Specialist  /  Operations  /  Data Management,"THE OCTAGON, 105 CECIL STREET 069534",Full Time,Professional,3 years exp,Banking and Finance,Monthly,"$4,500to$6,000","Our client, a leading financial services firm is looking to hire a Reference Data Specialist. The incumbent must be good at Excel skills and have experience of operational workflows and how data      is used and maintained through the trade lifecycle.

Responsibilities: 


Maintaining high quality, clean data by adhering to a strict governance and controls framework
Support Data Integration projects/ change initiatives/ process enhancement
Extensive liaison with relevant stakeholders to resolve issues faced
Maintain procedures, system controls, identify key processes and improvements
Where assigned by manager, to support other functions within APAC Operations inclusive of:

o Client Onboarding Team (KYC/AML, periodic client review, remediation, etc)
o Trade Management Team (Remediate trade issues with stakeholders)

Requirements:


Degree/ Diploma holder. 
MS Office - Intermediate skills in MS Excel, MS Word and PowerPoint.
Automation and coding skills will be a plus
Sound understanding of the financial markets and financial regulation affecting client lifecycle management.

If you or anyone within your network is keen to discuss it further then please share your resume with manisha@kstalentsolutions.com","['Tableau', 'Sustainability', 'Remediation', 'Ability To Work Independently', 'Data Management', 'Data Integration', 'Data Quality', 'Data Governance', 'Financial Markets', 'MS Office', 'PowerPoint', 'SAP', 'MS Word', 'Excel', 'Financial Regulation', 'Financial Services', 'Reference Data']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Engineer - TikTok,1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$10,000to$20,000","Responsibilities

About TikTok
TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com.

Team Introduction
The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics & dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you!

- Translate business requirements & end to end designs into technical implementations and responsible for building batch and real-time data warehouse
- Manage data modeling design, writing, and optimizing ETL jobs
- Collaborate with the business team to building data metrics based on data warehouse
- Responsible for building and maintaining data products 
- Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices

Qualifications
- At least 5 years in software engineering and 2 years of relevant experience in data engineering
- Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security
- Familiar with data warehouse concept and have production experience in modeling design
- Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink)
- Familiar with at least 1 NoSQL database is a plus (e.g. HBase)
- Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority 
- Strong collaboration skills with the ability to build rapport across teams and stakeholders","['iOS', 'Modeling', 'Big Data', 'Data Modeling', 'Pipelines', 'Hadoop', 'Software Engineering', 'ETL', 'Reliability', 'Data Engineering', 'Design Writing', 'SQL', 'Databases', 'Business Requirements']"
Reference Data Operations,"THE OCTAGON, 105 CECIL STREET 069534",Contract,Middle Management,8 years exp,Professional Services,Monthly,"$9,000to$11,000","My asset management client is looking to fill the below position. If keen please send your details to malvika@kstalentsolutions.com

ROLE
The Data Operations team ensures that our data assets and “data products” are fit for purpose, both now and in the future. Working with Head of Data Operations, the analyst will partake in multiple transformation projects to transition the team to data domains driven specialists, with scalable operating model.

KEY ACCOUNTABILITIES
 This is a new role in the data operations function reporting to the Head of Data Operations. The Operations Project Analyst is responsible for supporting the Project leads in leading a key program to transform my clientinto a data driven organization. The role will partake in driving new data masters for operational data, the implementation of a new Data Management platform to validate data and streamlining data operations activities centrally into Singapore. The department comprises of key data domains expertise in Securities and Index Data, Pricing and Valuation and Portfolio/Fund Data.

The Operations Project Analyst key accountabilities will include:
 Participate in the various workstreams as a Project SME to provide support in key transformation program
 Collaborate with key stakeholders including the Data BAs to map out detailed current as-in and future to-be for all workstreams for Data Operations
 Provide input to requirement documents, use cases and other papers as required
 Redesign current processes to ensure future business scalability and operating model
 Identify Business risks and ability to implement processes for risk mitigation
 Work with BRS, BAs and Developers in the development of data masters, data management platform and any changes required
 Work with Project Lead and project members to prioritize deliverables
 Work with BAU team to support provision of UAT test scripts
 Support UAT testing
 Provide Training to BAU team for future processes
 Ensure all new procedures are documented and agreed

EXPERIENCE / QUALIFICATIONS
 At least 10 years of experience working in Data Management/Operations in the Asset Management industry
 Prior Experience in Data Masters and Data Management Platform project implementation
 Degree in Business/Finance or related disciplines
 An excellent understanding of a wide range of tradable instruments
 Strong analytical and communication skills
 Prior experience using Aladdin and Data Masters like GoldenSource, Fundipedia or other platforms is desirable
 Good understanding of Front Office, Trade Lifecycle and Operations processes
 Understanding data management governance frameworks
 Working knowledge of data vendor systems such as Bloomberg, Refinitiv, S&P, etc.
 Excellent customer focus and high level of accuracy, and attention to detail
 Demonstrated ability to work collaboratively as part of the small team","['UAT', 'Asset Management', 'Bloomberg', 'large datasets', 'Data Analysis', 'Analytical Skills', 'Valuation', 'Data Management', 'Securities', 'Project Management', 'Pricing', 'Reference Data']"
 , , , , , , , , , 
Data Strategist,"CROSS STREET EXCHANGE, 18 CROSS STREET 048423","Permanent, Full Time",Professional,8 years exp,Information Technology,Monthly,"$10,000to$19,000","Job Responsibilities

At Thoughtworks, a Data Strategist is responsible for creating winning data-driven solutions that meet our client’s business and technical objectives.
We value collaboration with multiple stakeholders both on the client-side and internally. Ability to relate with the client's leaders in data, infra, tech and governance stakeholders is important to this role. Internal aspects of the role include creation and continuous improvement of Thoughtworks Data Offerings, Value Propositions, Points of View, etc in collaboration with various stakeholders and the industry at large.
In SEA, you’ll be pioneering the AI practice from scratch, growing the capability and expertise in this space. At Thoughtworks, we expect everyone to be curious and constantly learning. This role will be no exception and people who are successful in this role tend to be voracious readers and open-minded listeners in addition to being able to develop and defend their own opinions on a wide range of matters concerning data, business, society and technology.

Job qualifications
Technical skills

A broad understanding of the data landscape, especially Data Science, Data Engineering, Data Analytics and Data Governance is required as is depth in one of those areas.

Professional skills

A successful candidate will demonstrate the ability to understand the business side as well as the data side and communicate effectively with different stakeholders - especially the technical stakeholders.
A leadership mindset is valuable in working with clients to create and drive strategic data initiatives as well as internally to grow the next generation of data leaders.
Presence in the external tech community: you willingly share your expertise with others via speaking engagements, contributions to open source, blogs and more
","['Excellent Communication Skills', 'Strategic Planning', 'Management Skills', 'Leadership', 'Modeling', 'Working With Clients', 'Quantitative Analysis', 'Data Governance', 'Open Source', 'Strategy', 'Data Engineering', 'Thought Leadership', 'Data Science', 'Storytelling', 'Data Analytics']"
Data Executive (Maxwell),"SINGAPORE SHOPPING CENTRE, 190 CLEMENCEAU AVENUE 239924",Contract,Executive,1 year exp,"Admin / Secretarial, Information Technology",Monthly,$1to$1,"Job Description:

Interpreting existing legacy datasets relating to development Gross Floor Area (GFA) and land use and converting them to follow a new schema. 
Required to understand and interpret planning and development records by synthesizing various data sources including data attributes in excel, and approved plans in various formats (e.g., CAD, PDF, Bentley)
Performing manual and/or scripted quality checks to ensure the accuracy of assembled data. 
Work closely with urban planners and architects to ensure that the data entry is done accurately.  

Job Requirements:

Minimum GCE ‘O’ Level with some administrative & work experience  
Familiarity with Singapore building development application process  
Good proficiency with excel   
Ability to work meticulously and accurately with data and numbers, adhering to standard operating processes to ensure integrity of data 
Ability to work in accordance with project schedule and ensure data accuracy 
Ability to work independently  
Ability to work well in a team and collaborative environment 
Prior experience in drafting work for architectural / interior design industry 
Basic understanding of GIS platforms (e.g. ArcGIS Pro, QGIS) 
Experience with Python for basic data processing 

Working Arrangement:
Contract Duration: From April 2023 (11 months)
Mon to Fri: 8:30am – 6pm
Sat/Sun: Off
Location: Maxwell Road
Salary: TBA","['Ability To Work Independently', 'Architectural', 'Architects', 'GIS', 'Land Use', 'Data Entry', 'Interpreting', 'ArcGIS', 'Python', 'Interior Design', 'Excel', 'CAD']"
Data Manager (Maxwell),"SINGAPORE SHOPPING CENTRE, 190 CLEMENCEAU AVENUE 239924",Contract,Manager,3 years exp,Information Technology,Monthly,$1to$1,"Job Description:

Assembling 3D models of buildings in different BIM formats (e.g. RVT, IFC, GIS) through a suite of CAD/BIM authoring software to support the organization of planning data. 
Understand and interpret planning and development records by synthesizing various data sources including approved plans in various formats (e.g. CAD, PDF, Bentley), as well as performing manual or scripted quality check to ensure the accuracy of assembled data. 
Extract and evaluate information from building floor plans in digital formats, before updating cohesive information from these sources into relevant data repositories, both in tabular form as well as a spatial data model using GIS software (ArcGIS). 
Explore new modelling technologies and recommend further streamlining to the modelling processes. 

Job Requirements:

Minimally a Diploma in Architecture / Interior design or equivalent 
Familiarity with Singapore building development application process and ability to read and interpret submission drawings in both CAD and BIM formats (Revit, ArchiCAD, Bentley Aecosim, IFC) 
Adequate proficiency with Autodesk Revit and AutoCAD Modelling software  
Adequate proficiency with BIM and CAD viewing and navigation software (e.g. Revit Viewer, 
DWG TrueView, Autodesk Design Review) 
Adequate proficiency in Microsoft Office Suite (e.g. Excel, Word) 
Ability to work meticulously and accurately with data and numbers, adhering to standard operating processes to ensure integrity of data 
Ability to work in accordance with project schedule and ensure modelling accuracy 
Ability to work well in a team and collaborative environment 


Working Arrangement:
Contract Duration: From April 2023 (11 months)
Mon to Fri: 8:30am – 6pm
Sat/Sun: Off
Location: Maxwell Road
Salary: TBA","['Revit', 'Autodesk Revit', 'Microsoft Office', 'BIM', 'Floor Plans', 'GIS', '3D', 'ArcGIS', 'Assembling', 'Interior Design', 'ArchiCAD', 'Excel', 'AutoCAD', 'CAD']"
Data Analyst (Banking / Contract / SAS / SQL),"CITY HOUSE, 36 ROBINSON ROAD 068877","Contract, Full Time",Professional,3 years exp,"Banking and Finance, Information Technology",Monthly,"$5,000to$7,900","Our client is looking for a Data Analyst
Key Responsibilities:

This function is responsible for various data activities, which include data mining, database management and maintenance, data quality and data analysis
Data request & data merging – Key data required across analyses include SG Granular Data only accessible to country DM. Dedicated country DM will allow for a quicker turnaround of reports generated in country and summary tables sent to Regional DM
Collaborate and Work closely with internal and external business partners in building, implementing, tracking and improving decision strategies
While this is business functional role, requires collaboration with marketing team, technology team and various systems for execution and launches

Expected analyses include (but not limited to):

Campaigns & initiatives analysis – Analytics work required from target selection to campaign performance. Country DM support vital even as number of initiatives is expected to increase in 2023
MC conversion opt out data analytics – Analytics for MC opt out customers require SG DM support. Dedicated country DM personnel will allow for a quicker turnaround for such MIS request.
MC eligible customer study – SG DM personnel support required for study of MC eligibility scrubbing process, which will translate to future targeted initiatives, refinement scrubbing process

Qualifications:
·      3 years relevant experience in data with basic SQL knowledge.
·      Ability to understand system integration and logical thinking.
·      Preferred hands-on experience on any analytic tools (Ex.SAS, Knowledge Seeker, SPSS etc.)
·      Minimum 3 years of experience in data analytics / project management.
Interested candidates may apply through the application system. We regret to inform only Shortlisted candidates will be notified.
EA License No. 01C4394 • RCB No. 200007268E •Derrick Tiew Yong Han EA Registration No. R1877971
By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with the Privacy Policy.","['SAS Programming', 'Data Analysis', 'System Integration', 'SPSS', 'Data Quality', 'Marketing', 'Data Mining', 'SQL', 'Project Management', 'Python', 'Data Analytics', 'MIS']"
Portfolio Accounting Systems and Data Analyst,"ONE MARINA BOULEVARD, 1 MARINA BOULEVARD 018989",Permanent,Professional,8 years exp,Banking and Finance,Monthly,"$10,000to$14,000","Job Description
This is a blended role across Technology and Business Operations as part of the Portfolio Operations – Client & Portfolio Technology & Operations Team within InvesTech. InvesTech provides each of Wellington’s investment teams with the data, controls, and support they need to ensure that their investment intent is accurately reflected in accordance with client regulatory and operational requirements. This is a great opportunity for an experienced Analyst to join a strong, collaborative, global, and blended technology and operations team in a role with leadership and advancement opportunities. The individual will be responsible for supporting the portfolio accounting technology application suite as well as day-to-day activities associated with managing and processing of portfolio accounting activity with a specific focus on those in Asia Pacific.

Our Portfolio Accounting Technologies serve complex requirements on multiple fronts including:

A high-volume environment with substantial daily transaction activity
A wide variety of asset classes across equity, fixed income, and derivatives
A large number of markets in which we invest around the world
A global team of investors and relationship managers who require timely data
A complex technology environment providing real-time integration with many of our investment applications

The Technology responsibilities will include supporting the portfolio accounting technology application suite and associated batch processes. These applications relate to supporting integration with the vendor portfolio accounting application, Geneva (SS&C/Advent), and its integration with our reference data, investor, and client reporting applications around the firm to generate timely and accurate information to our investment teams and clients.

The Operational responsibilities will include data analysis, validation, and adjustment of portfolio accounting transactions processed through the portfolio accounting systems as a part of a global team.  Expect to communicate regularly with other groups within InvesTech, and across the firm including Trading, Portfolio Management, Legal, Performance, Derivative Operations, Private Equity, and Global Relationship Management. You will also serve as a resource to other members of the Portfolio Operations team in Asia Pacific for portfolio accounting knowledge, escalations, and guidance.

Due to the many consumers of portfolio accounting data throughout the firm, this position requires excellent analysis and communication skills. You must be a self-starter with the ability to multi-task and work on a variety of assignments with people at all levels of the organization.

This position requires some early, late and weekend shift coverage.

A day in the life of a Portfolio Accounting Data & Systems Analyst

Act as the APAC regional escalation point for all portfolio accounting data and technical issues that require detailed analysis and management
Execute daily processing/validation procedures during portfolio accounting batch processing, ensuring the integrity and consistency of data across multiple platforms
Identify and implement process improvements and system enhancements that increase efficiencies and/or reduce risk for the team and firm
Represent Portfolio Accounting at interdepartmental and external meetings
Interact directly with business and technology partners at all levels of the organization to define, analyze and document requirements, as well as set priorities. Act as a champion for the needs of the business partners and a trusted advisor
Develop a strong partnership with the delivery team to ensure on time, scalable and high-quality business solutions


QUALIFICATIONS

Experience with Geneva (SSC/Advent) or similar vendor portfolio accounting system
Experience with writing, optimizing and executing complex SQL queries with relational database technology to perform data and systems analysis
Experience with batch scheduling technologies like IBM TWS or similar
Willingness to work across both technology and business functions in a fast-paced, and team-oriented environment while managing conflicting priorities
Excellent written and verbal communication skills
Strong analytical and problem-solving skills, with high attention to detail
Strong client relationship skills and proven ability to build consensus.  Experience working directly with business partners to understand their needs and deliver solutions that meet those needs.
Change agent, creative, innovative, self-motivated and able to work with minimal supervision
Bachelor’s degree is required
","['Creative', 'Ability to Multitask', 'Excellent Communication Skills', 'Data Analysis', 'Analytical Skills', 'Interpersonal Skills', 'Problem Solving', 'Systems Analysis', 'SQL', 'Attention to Detail', 'Portfolio Management', 'Teamoriented', 'Writing', 'Team Player', 'Technology Application']"
"Associate Engineer, Product Data Control","VDL BUILDING, 259 JALAN AHMAD IBRAHIM 629148",Permanent,Executive,3 years exp,Engineering,Monthly,"$3,500to$4,500","Responsibilities:

You will be responsible to check the correctness and completeness of product package, such as Technical Product Data (TPD) and Bill of Materials (BOM), from customers. You will create and control item part numbers and BOM in BaaN ERP system, as well as, maintain and control the TPD documentation in the Document Management Control system. You will also create projects in BaaN ERP system, for fulfilment of customer Sales Order. In addition, you will analyze the impact of Engineering Change Orders (ECOs) and/or configuration changes, in BaaN ERP, and implement and co-ordinate the changes, with various departments, such as planner, purchaser, production and Sales & Program Department.

Requirements:

Degree/Diploma in Engineering/Science
Minimum 1 year of relevant experience
Knowledge of ERP system
Knowledge in Microsoft Excel and Macro will be      advantageous
","['Document Management', 'Front Office', 'Preventive Maintenance', 'Microsoft Excel', 'Derivatives', 'Reserves', 'Valuation', 'Tax', 'Change Orders', 'ERP', 'JavaScript', 'Planner', 'Team Player', 'Product Development', 'Electronics', 'Africa']"
Business Data Analyst - MNC | Consumer Electronics,"SHAW CENTRE, 1 SCOTTS ROAD 228208",Contract,Junior Executive,2 years exp,"Consulting, Information Technology",Monthly,"$4,000to$5,500","Roles & Responsibilities:
· Engage with internal stakeholders for SFDC administrative support and facilitate / assign lead/business opportunity within B2B businesses.
· Conduct regular checks on data accuracy and perform data clean-up and de-duping procedures
· Produce Daily, Weekly, Monthly business reports with an alert system.
·  Understand, interpret data and provide business insight in order to support management to develop strategy / plan to support new business opportunity.
· Work closely with business owners to identify opportunities and serve as an ambassador for data analyst/data science.
· Present insights to key stakeholders to drive strategic improvement.
·  Performs other duties as assigned by management /direct supervisor.

Requirements:
· Bachelor’s or Master’s Degree in Finance, Business Management, Economics, Statistic, Computer Science, Engineering or related field.
· 1-2 years working experience in related field
· Good Analytical and problem-solving skill.
· Knowledge of business intelligence tools (Power pivot, Power Query, Power BI) is a plus.
· Good knowledge of computer literacy especially MS Excel and PowerPoint.
· Excellent command of English and presentation skill.
·  Ability to work under strict deadline and develop alternative solutions in compliance with relevant policies and must be very detail-oriented and process driven.","['Tableau', 'Microsoft Excel', 'Data Analysis', 'Data Quality', 'Economics', 'PowerPoint', 'B2B', 'SQL', 'Python', 'Business Intelligence Tools', 'Administrative Support', 'Data Analytics', 'Power BI', 'Databases', 'Business Requirements']"
Assistant Professor in Instructional Design  /  Learning Analytics & Data Visualization,"NATIONAL INSTITUTE OF EDUCATION, 1 NANYANG WALK 637616",Full Time,Professional,3 years exp,Education and Training,Monthly,"$6,000to$10,150","The Learning Sciences & Assessment Academic Group (LSA) invites applications with an earned doctorate and research portfolio in Instructional Design / Learning analytics & Data Visualization, for a tenure-track Assistant/Associate Professor position. This is an excellent opportunity for outstanding scholars to engage in a dynamic department to advance our education and research goals.

LSA is an interdisciplinary academic group that focuses on understanding learning and assessment from multiple perspectives with the ultimate goal of enhancing and ensuring educative outcomes for all learners. Our mission is to enable educational practitioners to become designers of learning experiences and environments and active contributors in a reflective community of practice. The academic group is concerned with the relationship between theory and practice, and adopts a variety of methodologies, including but not limited to experimental studies, reflection-in-action, action research, design experiments and ethnography for the advancement of its research and teaching. We grapple with the tensions and the nexus between learning, assessment and instructional design, by mediating the design process as both a science and an art. Currently, we offer courses for initial teacher education, as well as graduate programmes such as the Master of Arts (Instructional Design and Technologies), Master of Education (Learning Sciences and Technologies), Master of Arts in Professional Education (Training and Development), Master of Teaching, Master of Science in Science of Learning and Design, Doctor of Education (Technologies and Technology-Mediated Learning Environments) and Doctor of Philosophy (Education).
The candidate would play an active role in some or all of these programmes. Applicants who are prepared to support and work with colleagues on learning and assessment issues in common or new expertise areas are valued. Working across disciplinary interests is encouraged.

Requirements
Successful candidates must have:

For assistant professor
· A PhD or equivalent qualifications or will be acquiring the qualifications at the time of application in the area of Instructional Design / Learning Analytics and Data Visualization
· A keen and updated awareness of technological/social/global effects on Instructional Design / learning analytics and data visualization
· Indicators of ability to secure and manage competitive grants
· An emerging record of associated scientific research, presentations and publications in the area of Instructional designs / learning analytics and data visualization
· Evidence of excellence in teaching, and understanding of school practice
· A developing international network of scholarly collaborators
· Excellent communication (verbal and written English)
· Willingness to understand and support the work of colleagues beyond one’s niche expertise

Responsibilities

Successful candidates will be expected:
● To initiate and/or participate in research examining a wide range of issues related to Instructional Design / Learning Analytics and Data Visualization, both within and beyond the Singapore educational system
● To teach existing and new courses in initial teacher education, executive, undergraduate and graduate programmes
● To work with a team of faculty to develop and teach courses, and pioneer changes in practices in schools
● To supervise initial teacher education and/or graduate students
● To publish research in reputable journals or other outlets as is customary in his/her field
● To establish professional connections with local and international researchers and practitioners in the specific expertise area
● To share expertise with NIE colleagues through various platforms
● To contribute to services at the departmental, institutional, university, national and international levels

Application
Please submit your application together with the following documents to us : 

A cover letter addressing how you meet the requirements of this position
A research statement
A teaching statement
Course outline or teaching plan of courses you may be interested in teaching
A resume including a publication list, names of three referees and your desired starting date of employment
Your best publications
Any other documents beyond those listed here or requested on the application form that demonstrate your qualifications and credentials

Closing Date
This position will remain open until filled.

Other Information
More information on LSA can be found at https://www.nie.edu.sg/our-people/academic- groups/learning-sciences-assessment

Note to applicants
Please note that only shortlisted candidates will be notified (via email).","['Written English', 'Teaching', 'Grants', 'Publications', 'Evidence', 'Instructional Design', 'Ethnography', 'Action Research', 'Research Design', 'Data Visualization']"
DATA PROCESSOR / DRAUGHTSPERSON / DRAFTSMAN,1092 LOWER DELTA ROAD 169203,Full Time,Junior Executive,1 year exp,Others,Monthly,"$1,600to$3,000","Land and hydrographic survey computations & computer-aided draughting

Requirements:
Diploma in related field; or
GCE 'O' Level with relevant experience in engineering& cadastral drafting
Knowledge in GIS, ESRI, Autocad & Micro-Station an advantage
CAD Skills
Attention to details
Efficient in time management
Results oriented
Technical knowledge and competences
Quick learner and eager to develop and improve
Attentive and able to focus
Able to perform well without close supervision

","['Revit', 'Construction', 'Asbuilt Drawings', 'BIM', 'Architectural', 'Drawing', 'Electrical', 'GIS', 'Data Processing', '3D', 'Microstation', 'Attentive', 'ESRI', 'Attention to Details', 'Time Management', 'AutoCAD', 'CAD']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Head Of Operations (Data Center),"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616",Permanent,Manager,8 years exp,Engineering,Monthly,"$5,000to$15,000","about the company
My client is a hybrid, hyperscale and edge solutions provider in Pan Asia. With providing multiple hybrid ecosystem solutions and mission-critical infrastructure for IT workloads, this is a great brand to join at an exciting time in their development.
about the job

Responsible for all critical environments within the data centre.
Maintain and implement policies, processes and procedures for all aspects of operations.
Ensure the compliance of all day-to-day operations to the legislation.
Monitor and keep track against KPIs, SLAs, and metrics (incl. performance, capacity, availability, budget)
Oversee on the ground incident response, problem resolution, and change management to support high-quality customer experience as a Single Point of Contact for customers.

skills & experience required

Degree in Electrical / Mechanical Engineering.
Min 5 years’ of data center operations management at the Senior Leadership.
Pocces with a deep understanding of the Data Centre Market will be an added advantage.
Familiar with up-to-date data centre industry practice will be an added advantage.

If you are interested in the position , kindly send your CVs in to amy.leo(@)randstad.com.sg
Please include your availability, expected salary and reason for leaving your current job.
We regret that only shortlisted candidates will be contacted.
EA: 94C3609 / Reg: R22105802
Applicants must be fully vaccinated or have a valid exemption in accordance with MOM’s regulations to allow them to enter the workplace. Applicants may be required to share verifiable COVID-19 vaccination documents or proof of a valid exemption at the point of offer. Randstad Pte. Limited and/or the Client reserves the right to withdraw an offer if the applicant fails to provide verifiable COVID-19 vaccination and/or proof of exemption documents","['Leadership', '24/7 operations', 'Legislation', 'Data Centre environments', 'EHS Audits', 'Data Centre Facilities Management', 'SLA management', 'Team Leadership', 'EHS Management Systems', 'Metrics']"
Data Engineer | Up to SGD$7k / month – J.T.,"CENTRAL PLAZA, 298 TIONG BAHRU ROAD 168730","Contract, Full Time",Junior Executive,3 years exp,Information Technology,Monthly,"$5,000to$7,000","What you’ll be doing:

Work closely as part of the agile product team to design, develop, test and deploy data integration products under the guidance of the DSTA Product Manager
Provide monthly progress reporting and status updates to Authority.
Deliver all required documentations (in compliance to Authority’s QMS processes and standards) including but not limited to design specifications, data specifications, user requirements, mapping documents and unit test plan.
Responsible for complying with data integration development processes and standards defined by Authority.
Develop and manage the data integration programs with Authority’s furnished software that include Informatica PowerCenter and Talend.
Maintain and perform continuous enhancements of data pipeline to ensure smooth data ingestion and good performance. This scope requires personnel to work with Oracle Database, Big Data Platform and tools such as Informatica PowerCenter and Talend.
Conduct and support requirement gathering with the Authority’s project team for new data integration program development.
Perform all required testing to ensure quality of deliverables i.e. User Acceptance Test (UAT), System Integration Test (SIT), Operational System Acceptance Test (OSAT).
Review system, application activities and database logs to detect abnormalities based on provided criteria.
Develop extractors for data in source systems including but not limited to SAP BW OpenHub, Oracle database, SQL Server database and flat file.

What you’ll need:

Degree/Diploma in Computer Science, Computing, Electrical Engineering, or IT equivalent
Experience in building and optimising data pipelines, architecture and datasets using DI/ETL technology (e.g. Informatica, Talend).
Shall have experience in supporting data transformation, data structures, metadata, dependency and workload management.
Experience in multiple data source support (e.g. flat files, SQL database, SAP database, PostgreSQL database, unstructured data not limited to text, documents, images, digitalised video, digitalised audio, sensor data) would be advantageous.

Benefits:

AL: 18 days
ML: 14 days
Medical benefit
Bonuses

Interested applicants: kindly submit your resume to joelle.tam@bgc-group.com","['PostgreSQL', 'Data Structures', 'Informatica', 'Data Transformation', 'System Integration', 'analyze datasets', 'ETL', 'SQL', 'SAP', 'Data Architecture', 'Metadata']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Engineer,"SINGAPORE POST CENTRE, 10 EUNOS ROAD 8 408600",Permanent,Senior Executive,3 years exp,Information Technology,Monthly,"$6,000to$7,500","- Design and development experience on Azure Logic Apps, Azure Functions – Function Apps, Azure API Management and Azure Service Bus

- High-level knowledge of how Azure private networks work and what are related aspects involved related to subnets, firewall and routing tables etc.

- Programming experience on Java preferably (Python can be an alternative)

- Experience in using Azure monitoring and logs

- Working knowledge with SQL Server or Oracle DB

- Having exposure to application support process

- Ability to prepare technical documentation

- 3 to 5 years of IT experience preferred","['Technical Documentation', 'Oracle', 'Azure', 'Routing', 'SQL', 'Application Support', 'SQL Server', 'Python', 'Java', 'API']"
Contract Senior Research Assistant  /  Assistant Manager Data Science,"TOURISM COURT, 1 ORCHARD SPRING LANE 247729","Contract, Full Time",Senior Executive,2 years exp,"Information Technology, Travel / Tourism",Monthly,"$3,000to$5,000","What the role is:
To implement, manage, monitor and assemble surveys through the use of a survey platform to collect data and use data analytics to generate insights that help STB to make data driven decisions, that will drive growth of Singapore tourism.

Main responsibilities:

Support the project manager in implementation and execution of data collection through surveys by managing the end-to-end survey processes, such as capturing survey requirements, development,      deployment and monitoring of surveys for the purpose of data collection from our tourists.  Responsible for various aspects of vendor and contract management.
Manage survey data collection operational work (e.g., weekly status reporting, survey campaign monitoring and management).
Lead and execute the training and upskilling of business units in using the survey platform to build and launch their own surveys.
Support test planning and test execution of enhancements to existing surveys.
Develop software codes / scripts to automate and build data processing pipelines for survey data integration.
Contribute to the development of new data models that integrate survey data with STB’s internal datasets.
Apply data mining techniques, perform statistical analysis and build prototype analysis pipelines iteratively to provide insights from data at scale.
Distil and present coherent insights using business intelligence tools (e.g. QlikSense) and carry out data      storytelling to answer business questions. This may require building new dashboards from scratch based on user input and setting up the associated ETL workstreams.


Competency requirements:

Achieving results with others
Analytical thinking
Change management
Project management
Stakeholder management & relationship building
Data Analytics – perform analysis on data using data analysis tools (e.g. R, SQL) and statistical techniques to obtain insights, patterns or relationships
Data Visualisation – Ability to set up new QlikSense dashboard and communicate insights through visualisation

Job requirements:

Working knowledge of R and SQL
Minimum 2 years experience with developing surveys on survey platforms (e.g. Qualtrics, Forsta)
Minimum 2 years relevant experience in data analysis, data story telling, quantitative market research projects
Survey project management, involving survey development, data quality, data mapping & integration, user acceptance testing
Proven track record in engaging relevant stakeholders (within and outside of the organization)
Experience in using visualisation tools & creating new dashboards (e.g. QlikSense)
Strong presentation and communication skills with ability to express complex ideas in an easy-to-understand manner
Strong command of written and spoken English


Application Status: Shortlisted candidates will be contacted within 2 weeks from the closing date of this job posting. We regret to inform that only shortlisted candidates will be notified.","['QlikSense', 'Market Research', 'Data Analysis', 'Biomarkers', 'Cognition', 'Wayfinding', 'ETL', 'Data Mining', 'Data Collection', 'Business Intelligence Tools', 'Data Science', 'Data Analytics', 'Test Execution', 'Upper Extremity', 'Rehabilitation', 'Acute Care', 'Test Planning', 'Data Visualisation']"
Data Operations Executive,"KATONG SHOPPING CENTRE, 865 MOUNTBATTEN ROAD 437844",Full Time,Executive,2 years exp,Sales / Retail,Monthly,"$2,000to$3,500","Key Performance Areas

Respond to telephone calls for Sales enquiry and support in a timely manner and have the ability to close and answer sales technical questions
Precisely document the sales quotation and issues, and discuss on pricing and issues related to System sales
Identify and resolve technical issues by escalate issues to other support teams when necessary.
Work in a fast-paced environment, able to adapt to frequent change and be able to work a flexible schedule
Work with diverse groups and individuals to meet goals, establish priorities, and solve complex sales issues

Requirement

GCE ‘O’ Level / Diploma
Excellent communication skills both written and verbal
Self-motivated, and possess a high level of personal accountability
Attention to detail, Ability to multi-task and work independently
Strong problem solving/analytical abilities
With Basic SQL knowledge
","['Ability to Multitask', 'Excellent Communication Skills', 'Sales', 'Microsoft Office', 'Microsoft Excel', 'Aftersales', 'Inventory', 'Administration', 'Attention to Detail', 'Accountability', 'Team Player', 'Microsoft Word', 'Customer Service', 'Pricing', 'Shipping']"
Data Analyst (JIRA / Agile / $7200),"CT HUB, 2 KALLANG AVENUE 339407",Full Time,Professional,5 years exp,Information Technology,Monthly,"$4,000to$7,500","
Key Responsibilities:

Lead grooming sessions with the appropriate subject matter experts to finalize the features needed to deliver the campaign and finalize the functional specifications together with technology team
Data request and Data Merging 
Work with the data engine build team to fit any development
Actively monitor campaign performance and actively recommend and facilitate improvements via experimentation, iterations of the app etc.
Partner with data scientists to improve the performance of the applications
Requirements
Bachelors/University degree, Master’s degree preferred
Min 3 – 5 years experience on campaign management/ data analytics and Project Management 

Skills - Basic Programming Agile , Basic SQL, 
Hands on experience on analytic tools -(SAS , SPSS etc...)

Send your contact to my email- Linda@forteemp.com.sg
OR WhatsApp’s FULL CV to 92273438 (DO NOT CALL)","['Web Services', 'Experimentation', 'Agile', 'Application Development', 'SQL', 'JIRA', 'Websphere Application Server', 'Docker', 'Java', 'API', 'Data Analytics', 'Software Development']"
Assistant Manager – Strategy / Data Analyst,"MAPLETREE BUSINESS CITY, 10 PASIR PANJANG ROAD 117438",Full Time,Executive,1 year exp,Information Technology,Monthly,"$4,000to$6,500","As part of the Sectoral Transformation Group in IMDA, the SMEs Go Digital Division aims to make going digital simple for SMEs.

As part of the Programme Office, you will be using data to provide actionable insights and targeted proposals in order to enhance the impact of Government support given to SMEs. You will also be working on key strategic initiatives such as reviewing current programmes and processes, as well as developing strategic communications for key stakeholders.

You will be presented with the opportunity to analyse data, develop strategic business insights, propose implementation approaches, and engage with key stakeholders.

Responsibilities:

Analyse data to identify gaps and areas of improvement for programme planning and execution.
Work within in team to undertake strategic reviews of programmes and initiatives.
Co-develop a stakeholder map and strategic communications strategy for various SMEs Go Digital products and services.
Design, plan and execute data analytics projects that help to optimise the SMEs Go Digital programme.
Understand the operational requirements needs within the SMEs Go Digital team (e.g. governance) as well as the business challenges faced by external parties (e.g. vendors, SMEs).
Develop actionable, data-based proposals and present key findings to senior management and/or other stakeholders.
Use Business Intelligence Tools to design analytics dashboards.

Requirements

Background (either academic or working experience) in Statistics, Information Technology, Business Analytics, Data Science, Computing or related quantitative discipline.
Good knowledge and experience with visualisation tools such as Qliksense, Power BI and Tableau.
1-3 years of relevant working experience, preferably in business intelligence & analytics, finance, business consulting or trade industry.
Methodical, process oriented, organised and proactive self-starter.
Good written and spoken communication, presentation and negotiation skills


Only shortlisted candidates will be notified. ","['QlikSense', 'Negotiation', 'Tableau', 'Business Intelligence', 'Strategic Communications', 'Information Technology', 'Strategy', 'Business Analytics', 'Business Intelligence Tools', 'Statistics', 'Data Science', 'Consulting', 'Data Analytics', 'Power BI', 'Data Visualization']"
Information Technology Master Data Management Head,"THE METROPOLIS, 9 NORTH BUONA VISTA DRIVE 138588",Contract,Middle Management,15 years exp,Information Technology,Monthly,"$9,000to$13,500","This is a 1-year contract role.

What is the role
The Information Technology Master Data Management Head/ Data Platform Manager for Electric Mobility (E-Mobility) is responsible for unlocking value for the business through secure, reliable, sustainable data operations. Able to identify, mature and deliver opportunities through the value funnel that demonstrate benefits. Strong understanding of the digital and data revolution and its current and future impact on business. Able to translate business strategy into data operations-specific actions and interventions, to assess the benefits of new technologies and trends, and have deep understanding of digitalisation and data & analytics. Strong stakeholder and change management skills and ability to partner and influence across the organisational ecosystem.
The Data Platform Manager sets the strategic vision for the use, governance and value creation of data platform operations within the company. The Data Platform Manager understands and can explain how to align data analysis with business needs and lay out the roadmap of how to proceed. The Data Platform Manager pro-actively identifies data operations opportunities creating new & additional insights to further accelerate the Value from Data journey.

Accountabilities:
- Value Funnel Support: IT Operations focal point to drive the Value from Data (VfD) agenda. Develop future opportunities with the respective business/function by understanding the business goals and drivers, leveraging the ITM D&A toolkit, to identify the top VfD opportunity areas, and ensure the top Value from Data ‘Asks’ are embedded into the IT strategic plan.
- Working Delivery Engine: Leverage the agreed cross-functional governance and Target DnA Operating Model, ensure E-Mobility has a robust and well-working operating engine for the opportunities in each funnel across all opportunity types (Data Management, Information Management, Compliance Management, Data Governance, Management Information and Analytics.)
- Establish Data Foundations: Support the Platform, Market Standard and digitalisation strategies. Ensure data foundations (Data Governance, Data Models & Flows, Data Quality, Data Architecture) are strategically considered to ensure the implications are reviewed and positioned as part of the IT roadmap.
- Adopt the Enabling Technologies: Ensure technology plan for Operations is embedded and investments holistically support the Value from Data Funnel
- People & Skills: Create and lead an E-Mobility Data Operations team within the segment and link it into the enterprise forums. Support the capability and capacity development across the DnA delivery engine.
- Stakeholder Management: Work with a wide variety of senior IT and Business stakeholders to bring alignment for the strategic direction of the segment and drive the delivery of the DnA Natural Team.

What we need from you
- Significant experience (+10 years) in developing and managing Data and Analytics strategies and initiatives in complex international organisations in the sectors of Retailing, Energy, or distributed site Operations.
- Track record in delivering value, from opportunity identification to delivery, dealing with unknowns and making decisions with incomplete set of information.
- Expertise in developing and architecting solutions in a collaborative environment, as well as significant experience in multiple hardware/software computing and cloud environments.
- Experience in managing and working with enterprise architecture repositories and modeling tools.
- Significant experience managing solution delivery and managing third parties.
- Experiences in creating a data-driven culture and enabling behavioural change.

Skills & Competencies
- 15+ years of professional experience in the IT field, at least 10 years in a data related role, and at least 3 years in a senior IT leadership role.
- Bachelor or Master degree in Information Technology, Computer Science, Data Management, or a related discipline.
- Strategic thinker, able to develop and articulate a vision and direction in complex organisational and (IT) technical situations.
- Strong stakeholder management and influencing skills. Able to articulate a vision and build support for that vision in the wider team and organisation.
- Ability to self-start and direct efforts based on high-level business objectives.
- Strong collaboration and leadership skills with the ability to coach and develop teams to meet new challenges.
- Strong interpersonal, communication, facilitation and presentation skills.
- Ability and experience to work through complex interfaces across organisational and geographic boundaries.
- Excellent analytical, planning and problem solving skills
- Strong data modeling, design, warehousing and business intelligence knowledge.
- Strong, current technical proficiency with applications architecture, frameworks and enterprise solutions delivery.","['Management Skills', 'Warehousing', 'Business Intelligence', 'Data Analysis', 'Modeling', 'Change Management', 'Data Management', 'Information Technology', 'Data Quality', 'Data Governance', 'Business Strategy', 'IT Operations', 'Data Architecture', 'Stakeholder Management', 'Facilitation', 'Master Data Management']"
"Data Engineer  /  Technology  / Up to $8,000 / month!","HAVELOCK2, 2 HAVELOCK ROAD 059763","Permanent, Full Time",Senior Executive,3 years exp,Information Technology,Monthly,"$7,000to$8,000","My client, an established company is looking out for a data Engineer and the incumbent to join needs to have such attributes.

Job roles:

Manage data lake API calls from 3rd party application and access controls.
Participate in designing the architecture of the data lake platform for new use cases.
Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment.
Identify, design, and implement continuous
Able to understand business requirements and translate to design document from data ingestion to data modelling.
Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications.

Job requirements:

Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse).
Knowledge of data modelling and understanding of different data structures and their benefits and limitations.
Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL.
A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL).

How to Apply:

Interested applicants may apply by sending in your updated résumé (in MS Word format) to my email or apply directly:
Consultant: Tan Jun Jie
EA personnel reg. no.R1878852
EA License No. 17C8502","['Microsoft Azure', 'Factory', 'Azure', 'Pipelines', 'T-SQL', 'Data Structures', 'Data Engineering', 'SQL', 'MS Word', 'Writing', 'Data Architecture', 'API', 'Business Requirements']"
"Data Engineer  /  Technology  / Up to $8,000 / month!","HAVELOCK2, 2 HAVELOCK ROAD 059763","Permanent, Full Time",Senior Executive,3 years exp,Information Technology,Monthly,"$7,000to$8,000","My client, an established company is looking out for a data Engineer and the incumbent to join needs to have such attributes.

Job roles:

Manage data lake API calls from 3rd party application and access controls.
Participate in designing the architecture of the data lake platform for new use cases.
Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment.
Identify, design, and implement continuous
Able to understand business requirements and translate to design document from data ingestion to data modelling.
Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications.

Job requirements:

Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse).
Knowledge of data modelling and understanding of different data structures and their benefits and limitations.
Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL.
A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL).

How to Apply:

Interested applicants may apply by sending in your updated résumé (in MS Word format) to my email or apply directly:
Consultant: Tan Jun Jie
EA personnel reg. no.R1878852
EA License No. 17C8502","['Microsoft Azure', 'Factory', 'Azure', 'Pipelines', 'T-SQL', 'Data Structures', 'Data Engineering', 'SQL', 'MS Word', 'Writing', 'Data Architecture', 'API', 'Business Requirements']"
"Data Engineer  /  Technology  / Up to $8,000 / month!","HAVELOCK2, 2 HAVELOCK ROAD 059763","Permanent, Full Time",Senior Executive,3 years exp,Information Technology,Monthly,"$7,000to$8,000","My client, an established company is looking out for a data Engineer and the incumbent to join needs to have such attributes.

Job roles:

Manage data lake API calls from 3rd party application and access controls.
Participate in designing the architecture of the data lake platform for new use cases.
Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment.
Identify, design, and implement continuous
Able to understand business requirements and translate to design document from data ingestion to data modelling.
Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications.

Job requirements:

Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse).
Knowledge of data modelling and understanding of different data structures and their benefits and limitations.
Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL.
A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL).

How to Apply:

Interested applicants may apply by sending in your updated résumé (in MS Word format) to my email or apply directly:
Consultant: Tan Jun Jie
EA personnel reg. no.R1878852
EA License No. 17C8502","['Microsoft Azure', 'Factory', 'Azure', 'Pipelines', 'T-SQL', 'Data Structures', 'Data Engineering', 'SQL', 'MS Word', 'Writing', 'Data Architecture', 'API', 'Business Requirements']"
 , , , , , , , , , 
 , , , , , , , , , 
Senior Project Manager (Data Engineering),"GUOCO TOWER, 1 WALLICH STREET 078881","Contract, Full Time",Manager,5 years exp,Information Technology,Monthly,"$8,000to$13,000","Job Description:

Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget and scope
Translate business requirements to technical specifications, provide high level solution design
Drive engineering teams in building to the roadmap, managing project delivery, dependencies and risks, track deliverables, and overcome roadblocks
Handle regular stakeholder communication and project updates

Requirements:

5+ years of experience inmanaging engineering or data related projects
Work with the business users to understand business requirements and translate that to high level technical specifications
Manage and coordinate test plan, user sign off and go-live plan
Work on defining high level architecture and appreciate technical complexities required
Strong communication skills to coordinate with project team, stakeholders and management
Comfortable working with both waterfall and agile methodologies
Knowledge of one or more database technologies (Snowflake, Oracle, Hadoop) and experienced in Cloud Technologies
Proficiency in writing Advanced SQLs, experience with business analytics products like Tableau

Nice to have:

Experience with data science and machine learning tools and technologies is a plus
Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus.
","['Snowflake Cloud Data Warehouse', 'Machine Learning', 'Oracle', 'Big Data', 'Oracle SQL', 'Hadoop', 'Agile Methodologies', 'ETL', 'Data Engineering', 'SQL', 'Python', 'Snowflake Computing', 'Data Architecture', 'Data Science', 'Java', 'Project Delivery']"
Data Center Inventory & Asset Technician,"UOB PLAZA, 80 RAFFLES PLACE 048624",Permanent,Professional,2 years exp,Information Technology,Monthly,"$4,000to$7,000","In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day and we need you as a Data Center Inventory & Asset Technician (DIAT).
Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers trainings and opportunities including Career Rotation Programs, Diversity & Inclusion trainings and events, and professional certifications.
Our infrastructure is comprised of a large global portfolio of more than 100 datacenters and 1 million servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide.
With environmental sustainability and optimization at the forefront of our datacenter design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider.
Do you want to empower billions across the world? Come and join us in CO+I and be at the forefront of the action!
Responsiblities
Safety Practices

Complies with security and data management policies.
Escalates any security or safety incidents. Coordinates with security escorts for third-party vendors.

Tactical Shift Management

Performs assigned tasks and escalates issues during high-volume work activity or escalation-based situations.
Leverages process knowledge and best judgment to complete next task without direct supervision.

Inbound and Outbound Logistics

Coordinates, prepares, and executes incoming/outgoing deliveries (e.g. purchase order [PO] receiving, Rack Movement Supervisor [RMS] activities).
Applies appropriate customs documentations and standards for outbound packages.
Ensures complete and detailed physical inventory tracking and staging.

Customer Service

Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks.
Ensures IAM tasks are completed accurately as requested, as well as meet company and industry standards and policies.
Builds strong working relationships with customers.

Inventory Management

Maintains and stewards up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories).
Performs inventory cycle audits, data corrections, and various Data Center regulatory compliance or certification control audit activity.
Performs material movement, including shipping/receiving and inventory management per standard process.
Ensures detailed physical inventory tracking and staging.

Warranty Process Management

Engages supplier to initiate warranty claim when automation is not available and processes the orders.
Processes failed vendor hardware devices using online/other tools, including information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices.
Follows all Service Level Agreements (SLAs) related to RMA warranty process.

Data Bearing Device (DBD) Destruction

Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary.
Ensures DBD serial number matches with database.
Coordinates with and oversees any third-party vendors who perform DBD destruction as necessary.

Procurement

Notifies management about ordering stock shortages. Escalates any issues to management.

Operational Excellence

Follows procedures to contribute to plans to develop, build, and run methodologies. Ensures execution according to accepted procedures for consistency, accuracy, and timeliness of delivery.

Other

Embody our culture and values

Responsiblities 
For this role, you are welcome to apply if you meet the following Required Qualifications:

High School Diploma AND 1+ year(s) experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related fieldOR equivalent experience.


While not required, we also look for the following Preferred Qualifications:

2+ year(s) experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience.


Background Check Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:

Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.

#COICareers
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.  We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.
Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","['Microsoft Azure', 'Sustainability', 'Asset Management', 'Warehouse Management', 'Hardware', 'Data Center', 'Inventory', 'Information Technology', 'Inventory Management', 'Authorization', 'Process Management', 'Warranty', 'Screening']"
Data Center Inventory & Asset Technician,"UOB PLAZA, 80 RAFFLES PLACE 048624",Permanent,Professional,2 years exp,Information Technology,Monthly,"$4,000to$7,000","In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day and we need you as a Data Center Inventory & Asset Technician (DIAT).
Microsoft’s Cloud Operations & Innovation (CO+I) is the engine that powers our cloud services. As a CO+I DIAT, you will perform a key role in delivering the core infrastructure and foundational technologies for Microsoft's online services including Bing, Office 365, Xbox, OneDrive, and the Microsoft Azure platform. As a group, CO+I is focused on the personal and professional development of all employees and offers trainings and opportunities including Career Rotation Programs, Diversity & Inclusion trainings and events, and professional certifications.
Our infrastructure is comprised of a large global portfolio of more than 100 datacenters and 1 million servers. Our foundation is built upon and managed by a team of subject matter experts working to support services for more than 1 billion customers and 20 million businesses in over 90 countries worldwide.
With environmental sustainability and optimization at the forefront of our datacenter design and operations, we continue to grow and evolve as we meet the ever-changing business demands that hold Microsoft as a world-class cloud provider.
Do you want to empower billions across the world? Come and join us in CO+I and be at the forefront of the action!
Responsiblities
Safety Practices

Complies with security and data management policies.
Escalates any security or safety incidents. Coordinates with security escorts for third-party vendors.

Tactical Shift Management

Performs assigned tasks and escalates issues during high-volume work activity or escalation-based situations.
Leverages process knowledge and best judgment to complete next task without direct supervision.

Inbound and Outbound Logistics

Coordinates, prepares, and executes incoming/outgoing deliveries (e.g. purchase order [PO] receiving, Rack Movement Supervisor [RMS] activities).
Applies appropriate customs documentations and standards for outbound packages.
Ensures complete and detailed physical inventory tracking and staging.

Customer Service

Maintains a strong focus to understand the impact of their work when completing tickets and assigned Inventory and Asset Management (IAM) tasks.
Ensures IAM tasks are completed accurately as requested, as well as meet company and industry standards and policies.
Builds strong working relationships with customers.

Inventory Management

Maintains and stewards up-to-date and accurate logical information within various inventory management systems (e.g., configuration management databases, asset management repositories).
Performs inventory cycle audits, data corrections, and various Data Center regulatory compliance or certification control audit activity.
Performs material movement, including shipping/receiving and inventory management per standard process.
Ensures detailed physical inventory tracking and staging.

Warranty Process Management

Engages supplier to initiate warranty claim when automation is not available and processes the orders.
Processes failed vendor hardware devices using online/other tools, including information processing, packaging, shipment, and receipt of return for Return Merchandise Authorization (RMA) devices.
Follows all Service Level Agreements (SLAs) related to RMA warranty process.

Data Bearing Device (DBD) Destruction

Performs destruction of data bearing devices (DBD) following all Service Level Agreements (SLAs) and Microsoft policies as necessary.
Ensures DBD serial number matches with database.
Coordinates with and oversees any third-party vendors who perform DBD destruction as necessary.

Procurement

Notifies management about ordering stock shortages. Escalates any issues to management.

Operational Excellence

Follows procedures to contribute to plans to develop, build, and run methodologies. Ensures execution according to accepted procedures for consistency, accuracy, and timeliness of delivery.

Other

Embody our culture and values

Responsiblities 
For this role, you are welcome to apply if you meet the following Required Qualifications:

High School Diploma AND 1+ year(s) experience warehouse/supply chain in an information technology (IT) environment, inventory management, retail, warehouse management, or a related fieldOR equivalent experience.


While not required, we also look for the following Preferred Qualifications:

2+ year(s) experience in warehouse/supply chain in an information technology (IT) environment, IT, and/or logistics, operating heavy-load movement equipment (e.g., forklift, pallet jacks, chassis lifts) for a large corporationOR equivalent experience.


Background Check Requirements:
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:

Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.

#COICareers
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.  We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.
Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","['Microsoft Azure', 'Sustainability', 'Asset Management', 'Warehouse Management', 'Hardware', 'Data Center', 'Inventory', 'Information Technology', 'Inventory Management', 'Authorization', 'Process Management', 'Warranty', 'Screening']"
Accounting Data Entry Clerk (Temporary 3-4months),"PARKWAY PARADE, 80 MARINE PARADE ROAD 449269",Temporary,Junior Executive,3 years exp,"Accounting / Auditing / Taxation, Building and Construction",Monthly,"$2,800to$3,000","Job Role:

An Accounting Data Entry Clerk is a professional who is responsible for maintaining financial records, running reports, and recording a wide range of transactions. Their duties include providing administrative assistance to accountants as well as preparing statements that confirm the accuracy of database information.
A successful accounting assistant should be familiar with all accounting procedures and have a flair for numbers.

Job Descriptions:

Coordinate and collect data from Finance Executives
Transfer of data from Sun System Excel template to Acumatica Excel template
Providing accounting and clerical assistance to the accounting department
Preparing bank deposits, general ledger postings, and statements
Ensure the correctness and accuracy of data before importing and processing in Acumatica.
Assist finance in scanning and attaching pdf files on transactions processed in Acumatica.

Job Requirements:

LCCI, CAT, ITE, and Diploma in Accounting or equivalent
Minimum 3 years of accounting experience, preferably as an Accounts Receivable Clerk or Accounts Payable Clerk
Knowledge in using MS Word/Excel and accounting systems (Candidates with knowledge of SunSystems or Acumatica   Systems an added advantage, nevertheless, training will be provided)
Familiarity with bookkeeping and basic accounting procedures
Competency in MS Office, databases, and  accounting software
Hands-on experience with spreadsheets and   financial reports
Ability to perform filing and record-keeping tasks
Data entry and word processing skills

Desired attributes

Analytical: enjoy analysing things from all angles and thinking of ways to make things better
Inquisitive: Always staying on top of developments in the industry and keeping abreast of new research and ideas
Safety conscious: Recognise hazards, safety risks, and unsafe practices at the workplace in relation to products/services, placing safety as a top   priority for self and others
Structured and Systematic: Work in an orderly manner and in compliance with procedures, regulatory and safety requirements
Team player: Understand that each person is part of a larger team working together to bring about the success of any project.
","['Accounts Payable', 'Job Descriptions', 'Data Entry', 'MS Office', 'Accounts Receivable', 'Word Processing', 'General Ledger', 'Accounting', 'Compliance', 'Deposits', 'Bookkeeping', 'Spreadsheets', 'Excel', 'Team Player', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"MGR / AVP, Business Analyst, Finance Data Management, GFCA",63 CHULIA STREET 049514,Permanent,Executive,3 years exp,Banking and Finance,Monthly,"$6,000to$12,000","
OCBC Bank is the longest established Singapore bank, formed in 1932 from the merger of three local banks, the oldest of which was founded in 1912. It is now the second largest financial services group in Southeast Asia by assets and one of the world’s most highly-rated banks, with an Aa1 rating from Moody’s. Recognised for its financial strength and stability, OCBC Bank is consistently ranked among the World’s Top 50 Safest Banks by Global Finance and has been named Best Managed Bank in Singapore by The Asian Banker.

Division Description
Group Finance looks beyond providing numbers. We add value in the decision-making process and facilitate the formulation of effective business strategies. We uphold the integrity of our financial records and ensure that the highest standards are applied in our reports. We provide financial analyses and insights to management and businesses to make informed decisions. We engage our stakeholders regularly to keep them abreast of the Bank's financial performance and development.
As a guardian of the Bank's financial resources, we facilitate efficient allocation of scarce resources to guide and steer business growth. We evaluate new business opportunities to strengthen the Bank's position and competitiveness.
We are a fun, dynamic, diverse and nurturing group and we believe that people are key in building a forward-looking finance team.
As a team member of the Finance Data Management, you are required to provide data stewardship oversight on GFRDM (Group Financial Reporting Datamart) through understanding the use of finance information in support of various reporting and analytical needs within GFCA.

Key Responsibilities:
As a team member of the Finance Data Management, you are required to provide data stewardship oversight on GFRDM (Group Financial Reporting Datamart) through understanding the use of finance information in support of various reporting and analytical needs within GFCA.  Your key responsibilities would include:

GFRDM maintenanceEnsure data integrity and accuracy of GFRDM through reconciliation against source applications and GL.
Ensure that the Layer 1 xmaps are updated timely and acts as central coordinator with the various teams in GFCA in ensuring consistent data application between Layer 1 and respective Layer 2s’ specialised applications.

Project management and participationAssess impact of new products and upstream system enhancements to GFRDM
Liaise between IT and GFCA finance users on data and information requirements and ensure appropriate data are mapped into GFRDM.
Perform user acceptance testing; working alongside other finance teams in supporting their specialised applications.
Participate in the investigation, data flow discussions resulting from ERP 2.0 on downstream GFCA datamarts, define change specifications to support use – reconciliation and analysis.

OthersSupport GFCA finance users on data queries and data needs.
Participate in finance related projects as assigned; contribute in thought process on the appropriate use of data for information analysis.


The ideal Candidate would meet the following requirements:

Professional qualification in Finance and/or Computer/Information Science or equivalent.
Knowledge of SQL and finance applications would be an advantage.
Have a good understanding of project management, finance processes and banking products to help drive process and data usage efficiency and change.
Good oral/written communication and presentation skills.
Proactive team player with good interpersonal skills and the ability to foster collaboration with internal and external parties.

At OCBC, we recognise your drive, passion and talent. We will bring out the best in you and empower you to excel. Fulfil your life goals and career ambitions with us.

*We regret that only shortlisted Candidates will be notified.","['ERP', 'Data Management', 'Formulation', 'SQL', 'Project Management', 'Banking', 'User Acceptance Testing', 'Team Player', 'Financial Services', 'Financial Reporting']"
 , , , , , , , , , 
Data Operations Project Analyst (18mth contract),"MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983","Contract, Full Time",Senior Executive,10 years exp,Banking and Finance,Monthly,"$5,000to$10,000","ROLE

Data is a critical enabler of our business, from our investment professionals and clients to our distribution and operations team. The Data Operations team ensures that our data assets and “data products” are fit for purpose, both now and in the future. Working with Head of Data Operations, the analyst will partake in multiple transformation projects to transition the team to data domains driven specialists, with scalable operating model.

KEY ACCOUNTABILITIES

This is a new role in the data operations function reporting to the Head of Data Operations. The Operations Project Analyst is responsible for supporting the Project leads in leading a key program to transform Eastspring into a data driven organization. The role will partake in driving new data masters for operational data, the implementation of a new Data Management platform to validate data and streamlining data operations activities centrally into Singapore. The department comprises of key data domains expertise in Securities and Index Data, Pricing and Valuation and Portfolio/Fund Data.

The Operations Project Analyst key accountabilities will include:

Participate in the various workstreams as a Project SME to provide support in key transformation program
Collaborate with key stakeholders including the Data BAs to map out detailed current as-in and future to-be for all workstreams for Data Operations
Provide input to requirement documents, use cases and other papers as required
Redesign current processes to ensure future business scalability and operating model
Identify Business risks and ability to implement processes for risk mitigation
Work with BRS, BAs and Developers in the development of data masters, data management platform and any changes required
Work with Project Lead and project members to prioritize deliverables
Work with BAU team to support provision of UAT test scripts
Support UAT testing
Provide Training to BAU team for future processes
Ensure all new procedures are documented and agreed

EXPERIENCE / QUALIFICATIONS

At least 10 years of experience working in Data Management/Operations in the Asset Management industry
Prior Experience in Data Masters and Data Management Platform project implementation
Degree in Business/Finance or related disciplines
An excellent understanding of a wide range of tradable instruments
Strong analytical and communication skills
Prior experience using Aladdin and Data Masters like GoldenSource, Fundipedia or other platforms is desirable
Good understanding of Front Office, Trade Lifecycle and Operations processes
Understanding data management governance frameworks
Working knowledge of data vendor systems such as Bloomberg, Refinitiv, S&P, etc.
Excellent customer focus and high level of accuracy, and attention to detail
Demonstrated ability to work collaboratively as part of the small team

GENERAL CANDIDATE ATTRIBUTES

A deep understanding of asset management enterprise data, its associated processes, systems, controls, and deliverables.
A strong ability to be hands on yet has a holistic strategic vision on data management
An Independent and performance driven individual
Strong relationship management skills
","['Front Office', 'UAT', 'Asset Management', 'Relationship Management Skills', 'Bloomberg', 'Scalability', 'Valuation', 'Data Management', 'Securities', 'Attention to Detail', 'Communication Skills', 'Customer Focus', 'Pricing']"
Data Analyst Manager 数据分析师经理,"SOLARIS, 1 FUSIONOPOLIS WALK 138628",Permanent,Manager,3 years exp,Information Technology,Monthly,"$15,000to$30,000","About UP Devlabs:
We are seeking a team of highly motivated who can jointly develop innovative solutions and enjoy the process of continuous learning of trending and modern technologies. If you are looking to collaborate with highly motivated peers, and immerse in best industrial practices, or if you have a deep passion for new creation and innovation ideas, this is the right opportunity for you.
Responsibilities:
1.Collecting and interpreting data Analysing results.
2.Reporting the results back to the relevant members of the business.
3.Identifying patterns and trends in data sets.
4.Working alongside teams within the business or the management team to establish business needs.
5.Defining new data collection and analysis processes.
Skill and Qualifications:
1.Minimum 3 years of native Data Analyst experience/Internet company experience is preferred/gaming company is required.
2.Candidate must possess at least a Bachelor’s Degree in Computer Science, mathematics, statistics, economics.
3.Experience in data models and reporting packages
4.Ability to analyse large datasets
5.Ability to write comprehensive reports
6.Strong verbal and written communications skills as Data Analyst do communicate with the wider business.
7.An analytical mind and inclination for problem-solving
8.Attention to details as data analysis and reporting must be precise.
关于 UP Devlabs：
我们正在寻找一支积极进取的团队，他们可以共同开发创新解决方案并享受不断学习趋势和现代技术的过程。 如果您希望与积极进取的同行合作，并沉浸在最佳行业实践中，或者如果您对新的创造和创新理念有着浓厚的热情，那么这就是您的最佳机会。
职责：
1.收集和解释数据分析结果。
2.将结果反馈给业务相关成员。
3.识别数据集中的模式和趋势。
4.与企业内部团队或管理团队合作，确定业务需求。
5.定义新的数据收集和分析过程。
技能和资格：
1.至少3年原生Data Analyst经验/有互联网公司经验者优先/有游戏公司经验者优先。
2.候选人必须至少拥有计算机科学、数学、统计学、经济学学士学位。
3.数据模型和报告包的经验
4.分析大型数据集的能力
5.综合报告撰写能力
6. 强大的口头和书面沟通技巧，作为数据分析师与更广泛的业务进行沟通。
7.分析思维和解决问题的倾向
8.注重细节，数据分析和报告必须准确。
Job Code: UP-SGDS-DAM-20230209","['Data Analysis', 'Mathematics', 'Data Management', 'Economics', 'Interpreting', 'Data Collection and Analysis', 'SQL', 'Written Communications', 'Statistics', 'Data Analytics']"
Infra Support Engineer,80 BENDEMEER ROAD 339949,"Contract, Full Time",Senior Executive,5 years exp,Information Technology,Monthly,"$7,200to$9,200","Overview:
The Infrastructure Engineer is responsible for IT system infrastructure design and implementation projects for Japanese bank customers.
Responsibilities
· Responsible for the design, installation & configuration, testing and other customer support in IT system implementation projects, mainly with Microsoft Windows and Linux environment to the specifications of client’s requirements
· Understanding the customers’ system architecture and design
· Perform on-site and remote support for OS / middleware / network troubleshooting
· Perform regular maintenance to maintain the infrastructure including mission critical systems
· Manage project documentations (e.g. architecture design, parameter design, test spec plan/result, operation procedure manual etc) for new IT system implementation & its change.
· Any other ad-hoc duties as required or assigned

Requirements:
· Bachelor Degree in Information Technology/Information Systems/Computer Science, Business IT or its equivalent
· At least 3 years of working experience in Windows/Linux server environments.
· Good understanding and work experience on ITSM standards, processes, guidelines and provide the best practices.
· Experience in middleware software configuration design & installation in any mission critical system implementation projects or strong will to expand the capability for system designing area
· Experience in Installing, configuring, troubleshooting and testing in Operating systems.
· Knowledge in Windows / Linux clustering setup and troubleshooting.
· Knowledge in Storage system, network system (TCP/IP, load balancer and firewall)
· Knowledge in Enterprise backup systems (eg. Arcserve)
· Scripting experience (e.g. Powershell/VBS/Python/Shell) for BAU tasks automation
· Good-to-have skills:
- Linux and Middleware (IBM MQ / Connect:Direct / Veritas cluster ) experience
- Job management software and system monitoring software knowledge
- VMware knowledge is added advantage
- SQL / Oracle database implementation
· Good Analytical and problem-solving skills
· Proactive personality, Team player/contributor
· Strong verbal, written communication skills
· Strong willingness to learn new technology and skills
· Prior working experience in the Japanese Company is an advantage","['Lead Generation', 'Sustainability', 'Data Modeling', 'Healthcare', 'MySQL', 'Economics', 'Tuning', 'Organizational Development', 'SQL', 'Requirements Analysis', 'SQL Server', 'Written Skills', 'Articulation', 'Visualization', 'Google Analytics', 'Databases']"
 , , , , , , , , , 
Data Center Operator (NOC),19 KALLANG AVENUE 339410,Full Time,Executive,2 years exp,Information Technology,Monthly,"$4,000to$6,000","Have knowledge of and be familiar with:
cable management;
computer components and basic troubleshooting (A+ and N+ certifications);
Linux;
Cisco/Juniper/Arista/Infinera OS; and
Data Center facilities and environments.
Have at least two (2) years of remote hand working experience;
Be able to perform administrative work well, without supervision;
Be able to perform the Services independently, without supervision;
Have experience stacking and racking servers to a battery or other power source;
Be able to work on multiple concurrent projects while meeting deadlines and ensuring up-time; and
Be able to lead projects and work autonomously on servers, routers, and switches.
It is preferred, but not required, that the Metro Techs:

be IITL and CCNA certified;
be able to lift 55lbs (25kg) servers/network equipment;
be organized and excellent with documentation;
have good communication skills; and
have access to a car and be able to drive between sites in the same metro area if needed (hard requirement).
 

","['Switches', 'Work Autonomously', 'Troubleshooting', 'CCNA', 'Administrative Work', 'Data Center', 'NOC', 'Good Communication Skills', 'Data center management', 'Routers', 'Linux', 'knowledge of data center']"
 , , , , , , , , , 
"Backend Engineer (Aeolus), Data Platform",1 RAFFLES QUAY 048583,Full Time,Professional,2 years exp,Information Technology,Monthly,"$6,500to$13,000","About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team:
Aeolus is an in-house analytics platform that is heavily used by more than 130,000 employees globally. It integrates data from various data sources into the platform. It facilitates the cleaning, shaping, and organisation of data in a visualised way before it can be analysed. It stores them in an optimal way so that queries over billions of rows of data can be done within seconds. It organises results on dashboards with powerful charts and tables to drill down so that insights can be revealed in an effective way. We are passionate about building the best data analytics platform in the world and are looking for top-notch software engineers to join the talented team.

What you'll be doing:
1. Design and implement a powerful and easy-to-use data integration system
2. Segment and design system layers to support componentized and layered application development, including business functionality and database access
3. Work with other engineers, managers, Product Management, QA, and Operations teams to develop innovative solutions that meet market needs with respect to functionality, performance, scalability, reliability, realistic implementation schedules, and adherence to development goals and principles
4. Estimate engineering effort, plan implementation, and rollout of system changes
5. Must be able to independently design code and test major features, as well as work jointly with other team members to deliver complex changes
6. Identify technical areas for improvement and make detailed business cases for improvements or new areas of opportunities

Qualifications
What you should have:
1. Bachelor's Degree in Computer Science or related discipline with experience in software engineering, with 2 years of relevant experience.
2. Experience in object-oriented design methodology and strong software development skills and expertise in Java.
3. Experience in requirements analysis, design, coding, and unit testing of scalable, distributed, fault-tolerant applications.
4. Experience with large-scale data-driven systems is highly desired.
5. Good working knowledge of distributed systems and OLAP databases is preferred.
6. Good communication skills to work with global teams. Fluent in English & Mandarin.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Requirements Gathering', 'Scalability', 'Unit Testing', 'Rollout', 'Software Engineering', 'Application Development', 'Data Integration', 'Reliability', 'Requirements Analysis', 'Good Communication Skills', 'Distributed Systems', 'OLAP', 'Java', 'Data Analytics', 'Databases', 'Software Development']"
Backend Engineer (Aeolus) - Data Platform,1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$10,000to$20,000","Responsibilities

About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team:
Aeolus is an in-house analytics platform that is heavily used by more than 130,000 employees globally. It integrates data from various data sources into the platform. It facilitates the cleaning, shaping, and organisation of data in a visualised way before it can be analysed. It stores them in an optimal way so that queries over billions of rows of data can be done within seconds. It organises results on dashboards with powerful charts and tables to drill down so that insights can be revealed in an effective way. We are passionate about building the best data analytics platform in the world and are looking for top-notch software engineers to join the talented team.

What you'll be doing:
1. Design and implement a powerful and easy-to-use data integration system
2. Segment and design system layers to support componentized and layered application development, including business functionality and database access
3. Work with other engineers, managers, Product Management, QA, and Operations teams to develop innovative solutions that meet market needs with respect to functionality, performance, scalability, reliability, realistic implementation schedules, and adherence to development goals and principles
4. Estimate engineering effort, plan implementation, and rollout of system changes
5. Must be able to independently design code and test major features, as well as work jointly with other team members to deliver complex changes
6. Identify technical areas for improvement and make detailed business cases for improvements or new areas of opportunities

Qualifications

What you should have:
1. Bachelor's Degree in Computer Science or related discipline with experience in software engineering, with 5 years of relevant experience.
2. Experience in object-oriented design methodology and strong software development skills and expertise in Java.
3. Experience in requirements analysis, design, coding, and unit testing of scalable, distributed, fault-tolerant applications.
4. Experience with large-scale data-driven systems is highly desired.
5. Good working knowledge of distributed systems and OLAP databases is preferred.
6. Good communication skills to work with global teams. Fluent in English & Mandarin.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Requirements Gathering', 'Scalability', 'Unit Testing', 'Rollout', 'Software Engineering', 'Application Development', 'Data Integration', 'Reliability', 'Requirements Analysis', 'Good Communication Skills', 'Distributed Systems', 'OLAP', 'Java', 'Data Analytics', 'Databases', 'Software Development']"
Data Centre,"FORTUNE CENTRE, 190 MIDDLE ROAD 188979",Contract,Executive,1 year exp,Information Technology,Monthly,"$2,500to$3,200","Role:Data Centre

JD:
Responsibilities
Rack, Build, cable, configure, and provision Intel and AMD Servers
Rack, cable, and deploy Cisco Layer 2 networking equipment
Troubleshoot, test, quality assurance of Server hardware
Professionally resolve hardware issues via trouble ticket
Desired Experience:
Freshers to 3 Years of experience
Experience in PC Hardware and Server Hardware (on Job training provided)
Operating System Installation - Windows Server, Linux, Unix
PC Assembly and HW troubleshooting
Understanding of basic hardware troubleshooting and applying logical methods of resolution
Basic Networking Knowledge
Rack, cable, and deploy Cisco Layer 2 networking equipment a plus
Experience with RAID levels is a plus","['Switches', 'Troubleshooting', 'Hardware', 'Quality Assurance', 'Wiring', 'Data Center', 'Unix', 'Windows Server', 'Networking', 'Windows', 'Routers', 'ITIL', 'Cabling', 'Assembly', 'Disaster Recovery', 'Linux']"
Data Analyst (12 months contract),"UOB PLAZA, 80 RAFFLES PLACE 048624",Contract,Executive,2 years exp,"Banking and Finance, Information Technology",Monthly,"$5,000to$5,200","Your new company
This is a multinational bank with presence all over the globe. With operations across consumer, corporate and institutional banking, this bank prioritises collaboration and a dynamic working environment.

Your new role
You will be responsible for handling the automation and reporting while supporting US and all other markets the team covers. You will also be managing all queries arising from reports while performing analysis on excel file. This is a 1 year renewable contract.

What you'll need to succeed

2 years of working experience with min 1 year of experience in Data Analysis
Competent in Tableau and Alteryx
Dataiku will be nice to have
Advanced Excel skills (Pivot Table, Vlookup etc)

What you'll get in return
This is an excellent opportunity to be part of a global bank. You will be part of a collaborative working environment and you will be remunerated at market competitive rates.

What you need to do now
If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV, or call Shabnam at Hays on +65 63030726 or email Shabnam.Bahar@hays.com.sg [mailto:Shabnam.Bahar@hays.com.sg] for a confidential discussion. Referrals are welcome.

Registration ID No. R1873584 | EA License number: 07C3924 | Company Registration No. 200609504D","['Tableau', 'Data Analysis', 'Advanced Excel', 'VBA', 'VBA Excel', 'VBA Macros', 'Banking', 'Excel', 'VBA Programming', 'Vlookup', 'Excel VBA']"
 , , , , , , , , , 
Data Center Support Specialist,"HONG LEONG BUILDING, 16 RAFFLES QUAY 048581",Full Time,Senior Executive,3 years exp,Information Technology,Monthly,"$4,500to$7,000","Responsibilities :

Coordination with internal teams and external vendors to ensure project milestones are met in a timely manner
Information gathering on requirements from internal teams
Assist structured cabling design in IT rooms and work with vendors on the implementation
Assist to manage purchase requests required for projects, i.e. obtaining and reviewing quotations, obtain approval for purchase, submission of purchase requests through internal system, ensuring timely delivery and payment of purchases
Coordinating various tasks required for the project i.e. site access, delivery, installations, etc.
Provide onsite support for installations and physical inspection to ensure quality of work by vendors (where applicable)
Maintaining of project reports, records, documentations
Update inventory information  
Other tasks as assigned by DCS Project team lead to support the project


Requirements :

Working experience with Data Centers and IT Facilities. Knowledge and prior experience in the following:
Physical racking and un-racking of devices
Equipment placements in IT racks (rack assignment)
Structured cabling design and implementation
Understanding of space, power and cooling
Experience in supporting project work
Attend to various site meetings
Carry out on-site meeting inspections
Report & update work prgoress


Desired Skills & Education :

Minimum Diploma in IT/Engineering or related field
Experience working with IT Service Management tools (e.g Remedy, ServiceNOW)
Experience working with Inventory management and / or DCIM tools","['DCS', 'IT Service Management', 'Data Center', 'Inventory', 'Invoicing', 'Auditing', 'Inventory Management', 'Project Management', 'Landscaping', 'Project Coordination', 'Cabling', 'Facilities Management']"
 , , , , , , , , , 
AWS ETL Cloud Data Engineer (IFRS 17),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,5 years exp,Information Technology,Monthly,"$6,500to$10,500","We are looking to hire a AWS ETL Data Engineer. This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project
Responsibilities:

Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc.
Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync & Glue.
Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture.
Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services.
Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming.
Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud.
Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards.
Work on hybrid Datalake.
Work closely with multiple stakeholders to ensure high standards are maintained.

Mandatory Skill-set

Bachelors Degree in Computer Science, Information Technology or other relevant fields
5+ years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark.
3+ yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL & Spark/Python

Good to have Skill-set

Fundamental of Insurance domain
Functional knowledge on IFRS17
","['IFRS', 'RDS', 'PySpark', 'Big Data', 'AWS', 'ETL', 'Information Technology', 'Tuning', 'Data Engineering', 'SQL', 'S3']"
Lead AWS ETL Cloud Data Engineer (IFRS 17),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,8 years exp,Information Technology,Monthly,"$9,000to$13,500","We are looking to hire a Lead AWS ETL Data Engineer. This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project.
Responsibilities:

Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc.
Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync & Glue.
Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture.
Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services.
Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming.
Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud.
Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards.
Work on hybrid Datalake.
Work closely with multiple stakeholders to ensure high standards are maintained.

Mandatory Skill-set

Bachelors Degree in Computer Science, Information Technology or other relevant fields
8+ years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark.
5+ yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL & Spark/Python

Good to have Skill-set

Fundamental of Insurance domain
Functional knowledge on IFRS17
","['IFRS', 'Apache Spark', 'Big Data', 'Pipelines', 'AWS', 'ETL', 'Information Technology', 'Data Engineering', 'SQL', 'Data Architecture', 'S3']"
"Big Data Engineer (Financial Services) Senior Consultant, Technology Consulting",1 RAFFLES QUAY 048583,"Permanent, Full Time",Senior Executive,3 years exp,"Banking and Finance, Consulting, Information Technology, Insurance",Monthly,"$4,500to$9,000","At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.
We are the only professional services organization who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.
The Opportunity
As part of our Data and Analytics team of Financial Services Consulting practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.
Your Key Responsibilities

Participation in large-scale client engagements.
Contribution towards, or even leading, the delivery of innovative and engaging big data solutions.
Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques.
Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues.
Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines.

Skills and Attributes for Success

Leverage technology to continually learn, improve service delivery and maintain our leading-edge best practices
Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel
Good understanding of financial services industry

To Qualify for the role, you must have

Bachelor or Master’s degree in computer science, Engineering, or other related fields.
Minimally 3 years of relevant experience
Understanding or even practical experience of handling and manipulating semi-structured and unstructured data.
Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available.
Ability to deploy, manage, and administer Hadoop-based components.
Ability to design, build, install, configure and support Hadoop-based applications.
Experience with one of Java, C# or C++.
Hands-on experience with HiveQL.
Familiarity with data ingestion tools such as Kafka, Flume and Sqoop.
Knowledge of hadoop related workflow/scheduling tools such as Oozie.
Understanding of data modeling (ER models) techniques.
Experience with investigating and handling data quality issues.
Minimum 1-3 years hands-on experience in two (2) or more of the above areas.

Ideally, you’ll also have

Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc.
Experience with Business Intelligence or statistical analysis tools and techniques.
Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan.
Strong time management and organizational skills to gather and make use of data (both internal and external).

What we look for
Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.
What we offer

Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.

If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
Apply now.","['Leadership', 'Teradata', 'Data modelling', 'Big Data Framework', 'Big Data', 'Hadoop', 'SQL', 'Banking', 'Hive', 'Presentation Skills', 'Consulting', 'Java', 'Professional Services']"
 , , , , , , , , , 
Field Service Engineer (Data Center & IT Solutions),33 CHANGI SOUTH AVENUE 2 486445,Full Time,Executive,2 years exp,Engineering,Monthly,"$2,800to$3,500","Responsibilities

Installation of Data Center hardware, software applications and network monitoring solutions
Responsible for Post-sales technical support roles
Repair, service, maintenance, troubleshoot and install Environment Tech and Data Center equipment at site
Project coordinators for efficient project execution to meet customer’s requirement and expectation, project schedule and quality standard.
Support on project sizing and consultation
Assist in project implementation
Work with customers, suppliers and internal resources on development of new programs.
Ensuring timely execution and delivery of proto-tools, prototypes and information flow.

Requirements

Minimum ITE/Diploma in Computer, Engineering or equivalent
At least 2 years of Technical Support/ System deployment experience in IT Industry
Knowledge of installation of electrical product such as power meter and maintenance will be an added advantage.
Knowledge of Basic Networking Windows (IP Configuration, Firewall, Remote Access and Topology Drawing) will be an added advantage
Knowledge of Basic Linux Command (CENTOS, RHEL and UBUNTU)
Knowledge of Wiring (RJ45, Dry Contact, RS485)
Experience in Network/ Data Center Infrastructure support
Good communication and interpersonal skill
Passionate and team work environment
Possess Class 3 driving license will be an added advantage
","['Field Service', 'Hardware', 'Ubuntu', 'Wiring', 'Data Center', 'Electrical', 'Networking', 'Class 3 Driving License', 'CentOS', 'Windows', 'Infrastructure Support', 'Technical Support']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Scientist - Image Processing & Computer Vision,"VISION EXCHANGE, 2 VENTURE DRIVE 608526",Full Time,Executive,3 years exp,Sciences / Laboratory / R&D,Monthly,"$4,000to$8,000","Job Summary:
Biofourmis is looking for Data Scientists in the field of image processing and computer vision to join our R&D team. The ideal candidate should have passion in using advanced machine learning techniques to make sense of biosensor data and image data in the medical field. We are building end-to-end services that integrate seamlessly into the lives of patients via multiple touchpoints to improve patients’ quality of life and outcomes.
Responsibilities:

Developing scalable models and algorithms by leveraging state-of-the-art computer vision and machine learning techniques for medical image/video analysis, synthesis, and other related tasks.
Conducting cutting-edge research in image/video related algorithms. Drive innovations by integration with other biosignals processing.
Documenting clearly on how algorithms have been designed, implemented, verified, and validated.

Experience / Training:

Hands on experience with development of image/video data analytics solutions in any of the field: face recognition, eye-movement tracking, emotional analysis, walking-step analysis, posture detection techniques, X-ray/MRI medical image processing etc.
Deep understanding of state-of-the-art computer vision techniques in areas such as object detection, image classification, 3D reconstructin, etc; Familar with transfer learning and able to modify the underlying logics of those architectures.
Experience with healthcare data, human physiology or cardiology is a plus.
Publishing papers in top AI conferences or journals is a plus, including but not limited to CVPR, ICCV, ECCV, ICML, NeurIPS ICLR, KDD, AAAI, IJCAI, etc.

Education:

PhD in Computer Science, Electronic Engineering or related fields with strong computer vison or medical image processing skills. (Masters with related working experience may be considered).

Skills:

Proficient with pattern recognition, image/video analysis, signal processing, anomaly detection, semi-unsupervised learning, and hypothesis testing.
Proficient with programming in Python. Strong Programming in C/C++ is a plus.
Experience with face recognition and emotional auto-analysis techniques.
Familiar with one type of medical image (e.g. X-ray, ultrasound imaging, etc) is a plus.
Good research ability and critical thinking skills.
Excellent written and verbal communication skills
","['Machine Learning', 'Ultrasound', 'Image Processing', 'NLTK', 'Healthcare', 'Critical Thinking', 'Urban Planning', 'Computer Vision', '3D', 'Python', 'Anomaly Detection', 'Pattern Recognition', 'Data Analytics', 'Django', 'Signal Processing', 'Cardiology']"
"Media Manager, Applied Data and Technology","TOURISM COURT, 1 ORCHARD SPRING LANE 247729","Permanent, Full Time",Manager,6 years exp,Marketing / Public Relations,Monthly,"$5,000to$9,000","What the role is:
Digital marketing has always been informed by data to better target and reap effective performance returns. As consumers become increasingly savvy with digital platforms while technology evolves in allowing the identification of individual rather than aggregated data, there is a need for an organization to be equipped with the relevant resource in harnessing an intentional data strategy to meaningfully apply today’s data set with the increasing sophistication of technology and ecosystem. This will not only allow for organisation to stay ahead of data trends but also, future proofing against any inadvertent landscape disruption or consumer shifts.
Against the rising concern on consumer data privacy which in turn resulted in a myriad of data policies and measures for marketers to maneuver, the role of Media Manager (Applied Data and Technology) is therefore critical in guiding our digital marketing work against these pivots with a clear and sustainable data and media strategy.
Role will be working closely across the Marketing Group (MG) in ensuring how our respective platforms and paid media strategies take into consideration how data will impact outcomes while calibrating against contingencies.
The ideal candidate would be skilled in shaping and enhancing STB's data-driven marketing roadmap that include data strategy, solutions architecting of an ad:tech/mar:tech ecosystem, data management & profiling, audience analytics.

Main responsibilities:

Develop and operationalise a marketing data strategy that promotes a proactive approach in continually assessing and calibrating against the prevailing technology ecosystem
    
Manage our current adtech stack (including Data Management Platform) and  recommend any enhancements of the technology stack
Review and implement the recommendations put forth across STB's Cookieless Strategy


Develop and manage an end-to-end data framework that allows for meaningful collection, storage and consumption of data with agility and scale
    
Overseeing MG's existing pool of 1st/2nd/3rd party data and identify gaps and opportunities to maximise existing use of data and harness incremental data


Develop a close working relationship with all relevant data owners, line units, external technology partners and agencies, to fulfil key areas of your deliverables
    
Given that data collection takes place across the entire Board and with our tourism stakeholders, to maintain a proactive watch on potential synergies to develop win-win data activation outcomes




Competency requirements:

Showing good business acumen, analytical thinking and judgement
Working effectively within STB to achieve results
Working effectively with stakeholders outside STB
Serving with heart, commitment and purpose
Being innovative and learning continuously
Background in digital media advertising (include SEM and Social Channels and Programmatic) and/or demonstrate a keen interest and capacity to grow in this area
Strong analytical skills with knowledge on global/regional media landscape and metrics (across paid, owned, and earned)


Job requirements:

Minimum 6-8 years of relevant experience using analytical methodologies to solve business, marketing, and media challenges
    
Experience with a digital agency/ consultancy, martech/ adtech platform service provider, 3rd party data solutions provider, etc. is desirable


Possess prior hands-on experience and capabilities relating to:
    
Digital marketing campaign programs: developing the quantifiable KPIs, objectives, and methodologies for achieving accountable and sustainable digital marketing performance (increased sales and conversions, and improved efficiencies via digital marketing), which can be used to demonstrate the value or ROI of such AdTech capability investments
Cloud marketing solutions: Adobe Experience Cloud, Google Marketing Platform, Salesforce Marketing Cloud, etc..
Buy-side AdTech and processes (DMPs or CDPs, Tagging, Reporting) or equivalent technology for data-based personalized digital marketing (i.e. implementing and/or using systems such as Salesforce Audience Studio, Adobe Audience Manager, Google Marketing Platform, etc.)
Programmatic marketing or paid media experience (running, setting up, launching and performing any ongoing optimizations of paid media campaigns and paid media operations on Google, Facebook, DSPs, Ad Exchanges, SEO, SEM, etc.)
Advanced understanding of data architecture, systems integration, and data flow of interconnected ecosystems such as CRM, data lake, DMP, DSP
Advanced understanding of analytics outputs and configurations: insights and dashboards development, being able to understand and recommend a suitable tagging strategy for collecting customer behavior data across the online journey, and recommend the types of reports and dashboards required to track performance and optimization against the use cases


This should translate to the ability to:
    
Develop strategies to effectively leverage STB's existing data & marketing infrastructure to better audience understanding and marketing effectiveness
Propose strategies to evolve STB's data & marketing practices to stay ahead of technology and media landscape changes
Design and measure data-driven media tests to validate and trial new ways to improve the quality of marketing data


Able to lead complex multi-dimensional stakeholder engagements that include agencies, STB line units and partners, with strong communication and presentation skills.
Able to think strategically and articulate complex challenges and solutions to non-technical audiences clearly and succinctly
Organized, structured and able to work against clear objectives and timelines.


Application Status: Shortlisted candidates will be contacted within 2 weeks from the closing date of this job posting. We regret to inform that only shortlisted candidates will be notified.","['Digital Media', 'SEM', 'Media Strategy', 'Assessing', 'Analytical Skills', 'Social Media', 'Business Acumen', 'Data Management', 'Investments', 'Systems Integration', 'Marketing', 'Data Architecture', 'Presentation Skills', 'Articulate', 'Facebook', 'SEO', 'media agency', 'Data Strategy']"
Infinus Finance Business Analyst for Financial Reporting Data (1 year Contract role),63 CHULIA STREET 049514,Permanent,Executive,5 years exp,Banking and Finance,Monthly,"$7,000to$12,000","OCBC Bank is the longest established Singapore bank, formed in 1932 from the merger of three local banks, the oldest of which was founded in 1912. It is now the second largest financial services group in Southeast Asia by assets and one of the world’s most highly-rated banks, with an Aa1 rating from Moody’s. Recognised for its financial strength and stability, OCBC Bank is consistently ranked among the World’s Top 50 Safest Banks by Global Finance and has been named Best Managed Bank in Singapore by The Asian Banker.

Roles and Responsibilities
A team member of Infinus project covering Finance data from GFRDM (Group Financial Reporting Datamart), EDW and manual sources to support Financial Reporting requirements. Key responsibilities include:

Gather business requirements of Group Financial Reporting
Prepare data requirements for reporting schedules and identify their data sources
Acquire working knowledge of GFRDM data models (L1 and L2), its data profiles and data gaps
Responsible for project tasks assigned and deliver to project timelines
Support and perform functional testing of reports
Liaise with GFRDM and EDW subject matter experts on enhancements needed for reporting data
Assess impact on reporting queries when there are GFRDM changes


The ideal Candidate would meet the following requirements:

At least 5 years of relevant experience
Professional qualification in Finance and/or Computer/Information Science or equivalent.
Has developer SQL coding skills
Has a good understanding of project management, finance processes and banking products
Good oral and written communication
Proactive team player with good interpersonal skills and the ability to foster collaboration with internal and external parties.

At OCBC, we recognise your drive, passion and talent. We will bring out the best in you and empower you to excel. Fulfil your life goals and career ambitions with us.

*We regret that only shortlisted Candidates will be notified.","['Interpersonal Skills', 'Written Communication', 'SQL', 'Project Management', 'Banking', 'Excel', 'Team Player', 'Financial Services', 'Financial Reporting', 'Business Requirements']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
System Data Analyst (Fresh Graduate / Intern),"HOR KEW BUSINESS CENTRE, 66 KALLANG PUDDING ROAD 349324",Internship/Attachment,Fresh/entry level,1 year exp,Engineering,Monthly,"$1,000to$1,500","System Data Analyst (Fresh Graduate/Interns)

Durapower Technology (Singapore) Pte Ltd is a wholly owned subsidiary of Durapower Holdings Pte Ltd. Durapower provides customized lithium-ion battery systems; for energy storage applications ranging from hybrid and pure electric vehicles, specialty vehicles as well as microgrid and smart grid.

Responsibilities

Support Project team, project Engineers on the backend data analysis;
Convert raw data to Dec from Hex, and to Bin and Hex;
Read and decode the raw data (Hex to Dec, Hex to Bin) from project CAN logger;
Prepare data findings, and present to the project team;
Setting up processes and systems to make working with data more efficient
Create and generate a user interface or tool to automatically extract raw data and decode them, to be understandable easily to all peoples;
Developing and maintaining databases, data systems – reorganizing data in a readable format
Preparing final analysis report for the shareholders to understand the data-analysis steps, enabling them to take important decision based on various facts and trends

Requirement

Degree in Electrical, Electronics, Computing science;
Fresh Graduate with 1 year of relevant internship experience previously or interns available for at least minimum 4 to 6 months
Good interpersonal and communication skills;
Possess sound engineering background;
Probelm-solving skills
Strong mathematical skills to help collect, measure, organize and analyse data
Knowledge of how to create and apply the most accurate algorithms to dataset in order to find      root cause and solution
Good in Big data collation and integration;
Professional with SQL, Excel, C/C++, Java, Python, MATLAB, HTML, Power BI or else
","['Data Analysis', 'Big Data', 'HTML', 'Electrical', 'Vehicles', 'User Interface', 'SQL', 'Matlab', 'Python', 'Communication Skills', 'Excel', 'Java', 'Power BI', 'Databases', 'Electronics']"
 , , , , , , , , , 
 , , , , , , , , , 
APAC Real Estate Manager (Data Center),"SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623",Permanent,Manager,10 years exp,Information Technology,Monthly,"$8,000to$14,000","about the role

Supply side mandate for land search and development activities for Data Center Business
Pre-Investment Due-Diligence on land bank and green field brown field projects
Development Planning experience in data center
Statutory Approvals experience
Program Management
Procurement and property lease management
Contract and supplier management which involves negotiating contracts along with supporting supplier activities
Process improvement and project management

skills and experience required

Degree in Engineering with knowledge on Real Estate Management or equivalent 
Min 10 years of relevant real estate operations experience
Successful track record of overseeing the management of a portfolio of properties
Must possess the understand of all the legal steps and due diligence required for land and building leasing & purchasing and the license required etc.

To apply online please use the apply function, alternatively you may contact yitwei kwan at yitwei.kwan(@)randstad.com.sg. (EA: 94C3609 | R1325913)","['Front Office', 'Management Skills', 'Leadership', 'Business Intelligence', 'Oral Communication Skills', 'Dashboard', 'Property Management', 'Technology Scanning', 'Good Interpersonal Communication Skills', 'Rollout', 'Vendor Management', 'Enterprise Architecture', 'PMP', 'Design Thinking', 'Real Estate', 'Facilities Management']"
Data Entry Officer (PM Shift),"STARHUB GREEN, 67 UBI AVENUE 1 408942","Permanent, Full Time",Non-executive,1 year exp,"Admin / Secretarial, Sciences / Laboratory / R&D",Monthly,"$1,500to$2,000","Under general supervision, and in accordance with Company policies, procedures and guidelines, you shall be responsible to:

Enter patient demographic information & orders laboratory tests completely and accurately into the Laboratory Information System (LIS).
Recognize and correct inaccurate or missing information on the laboratory requisitions

Job Requirements

Minimum GCE N or O-Level
Candidates without experience are welcome to apply as on-the-job training will be provided.
Possess basic computer skills, able to type fast & have an eye for details.
Good interpersonal & communication skills
Responsible & hardworking team player with positive work attitude & supportive of the operational needs
","['Typing', 'Microsoft Office', 'Customer Information', 'Data Entry', 'Attention to Detail', 'Communication Skills', 'Administrative Support', 'Team Player', 'Laboratory', 'Able To Work Independently']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Business Coordinator – Data and Analytics,"HSBC BUILDING, 21 COLLYER QUAY 049320",Permanent,Professional,2 years exp,Others,Monthly,"$4,500to$7,500","Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/amplifyhealthexternal/job/Singapore-SG-Amplify-Health/Business-Coordinator---Data-and-Analytics_JR-34093
Where you would add value
The role entails coordinating deliverables from across all the units and ensure knowledge and communication is maintained between the teams and the executive. This includes deep understanding and compiling of key information for key discussions around data and analytics short to long term strategies.
How you would make a difference
Core responsibilities include:

​Coordinate with data and analytic leadership to prepare reports and presentations required for communication to various stakeholders
Prepare meeting agenda’s, analytical and data reports for various leadership committees
Assist with people and operating model with senior and executive stakeholders
Manage team onboarding processes, documentation and general staff support
Recommend and roll out structured template documents for repeatable deliver of standard outputs and processes
Ensure accurate and transparent communication for tracking and management of short to long term strategic goals
Converting data and analytic content to business and marketing content for a broad range of audiences and formats

What you need to be successful
Behavioural skills

Communication skills across a wide range of stakeholders
Ability to work cohesively in a team environment
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude focused on continuous improvement
Ability to take feedback and constructive criticism to drive improved delivery

Technical understanding
An understanding of the technical tools used in healthcare analytics is preferred with respect to the following topics:

Understanding of patient health management, provider profiling, healthcare reporting, and other key healthcare technologies etc.
Understanding of clinical tools including coders, groupers, and classifications
Understanding of data science in the healthcare space
Understanding of healthcare benefit pricing, product pricing and other actuarial calculations (reserving, risk rating, etc.)
Understanding of fraud and operations environment

Additionally, the following technical skills are core to the role:

Understanding of analytical and solution architecture on cloud.
Business/process mapping

Qualifications

Informatics or relevant degree, or similar (Honours degree preferred)
Experience in healthcare technology is preferred
","['Leadership', 'Actuarial', 'Big Data', 'Mergers', 'Healthcare', 'Informatics', 'Attention to Detail', 'Solution Architecture', 'Fraud', 'Data Science', 'Benchmarking', 'Acquisitions', 'Pricing']"
Senior Application Engineer - Data Science,"UBI TECHPARK, 10 UBI CRESCENT 408564","Permanent, Full Time",Senior Executive,7 years exp,"Engineering, Others",Monthly,"$5,000to$7,000","Job Summary
As an Application Engineer, you will collaborate with Sales and Marketing to help customers across a range of industries see how MathWorks products and services can address their needs. You will work with customers to uncover their technical and business challenges, and demonstrate how MATLAB and MathWorks solutions can address their needs. You will demonstrate your technical expertise during sales meetings, conference calls, and public seminars.

This non-commissioned position is based in Singapore. Travel mostly in South East Asia. Travel may be up to 25% of time regionally.
Responsibilities

Provide technical pre-sales support.
Work with prospective customers to understand their workflow and uncover their challenges.
Prepare and deliver presentations, demonstrations, and application-specific examples in customer meetings, seminars, and other public events.
Conduct extended evaluations to promote large-scale adoption of MathWorks tools. This may include multiple engagements with customers, both pre and post sales, to ensure their success.
Work closely with Marketing organizations to identify new application areas, and develop compelling messaging.
Establish rapport and credibility with our customers across multiple hierarchy levels. Build champion users and supporters of our solutions.
Collaborate with Sales to develop strategies for driving the adoption of MathWorks tools.

Minimum Qualifications

A bachelor's degree and 7 years of professional work experience (or a master's degree and 5 years of      professional work experience, or a PhD degree, or equivalent experience) is required.
Experience with MATLAB
Experience with one or more of the following: Big Data Techniques, Advanced Statistics, Machine Learning, Deep Learning, Signal Processing, Image Processing

Additional Qualifications
Required:

Experience with (and enthusiasm for!) MATLAB is essential; experience with a broad set of MathWorks products is a plus.
Exceptional verbal and written communication skills in both a group and individual settings
Excellent presentation skills (or a strong motivation to learn them)
Highly motivated to work directly with customers to help them understand how MATLAB products are used to solve their engineering and business problems
Continuous learner

Pluses:

Experience with other programming languages, e.g. Python, R, Java, C/C++ or .NET
Experience with cloud computing, e.g. AWS, Azure, GCP
","['Machine Learning', 'Image Processing', '.NET', 'Azure', 'Cloud Computing', 'Technical Presales', 'Python', 'Presentation Skills', 'Statistics', 'GCP', 'Java', 'Signal Processing']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Management Officer | Private bank,"THE OCTAGON, 105 CECIL STREET 069534","Contract, Permanent, Full Time",Non-executive,3 years exp,Banking and Finance,Monthly,"$3,000to$3,600","Responsibilities:

Maintain strong relationship with Front Office and provide support with queries and troubleshooting
Ensure accurate and timely execution of account opening, closure client and static modification service requests
Conduct name screening upon request from Compliance team
Ability to understand the business requirements for maintenance of external clients’ records
Participate in user acceptance testing when needed


Job Requirements:

Possess diploma/degree with min 3 years of related working experience
Proficient in Microsoft Excel (Pivot table, V Lookup) will be advantageous
Related working experience in static data maintenance (T24, CRM, EAM/EFA/Finder relationships)
Able to speak to people from all levels
Only Singaporeans


Working hours : Mon – Fri (9am – 6pm)
Working location : Pasir Panjang
1 year contract (Rolling contract) + 1 month completion bonus

To submit your application, please click on the “Apply Button” or send your UPDATED CV in Microsoft Word format OR email to Michael.chee@Tangspac.com Your interest will be treated with strict confidentiality","['CRM', 'Wealth Management', 'Front Office', 'Excellent Communication Skills', 'Troubleshooting', 'Microsoft Excel', 'Wealth', 'Private Banking', 'Transparency', 'Risk Management', 'Compliance', 'User Acceptance Testing', 'Microsoft Word', 'Diplomacy', 'Screening', 'Business Requirements']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
KY11 - Accounts assistant [AR | Data entry | Changi],"SHENTON HOUSE, 3 SHENTON WAY 068805",Permanent,Fresh/entry level,1 year exp,Accounting / Auditing / Taxation,Monthly,"$1,800to$2,000","Position title : Accounts Assistant (AR)
Location: Changi South Street 1
Working days / hours : Monday to Friday (08:30 am to 6:30 pm)
Salary : $1800 - $2000

Responsibilities:

Issue Tax Invoices
Printing of Tax Invoices
Issue Debit & Credit Notes
Sending E-invoices to selected customers
Monthly sending of E-SOA to all customers
Timely Collection of Accounts Receivables
Sort and file Delivery Orders (DO)
Follow up on customers’ requests like sending copies of Tax Invoices, DO’s, etc.
Perform other Administrative Duties like Ordering of Stationeries, Staff Uniforms, etc
Assist in any other ad hoc duties as assigned by department head

Requirements:

At least 1 year experiences.

WhatsApp: https://wa.me/6596112291 (Kyra)
Email: kyra.thesupreme@gmail.com
Voon Yih Boon Reg No: R22106724
The Supreme HR Advisory Pte Ltd EA No: 14C7279","['Cost Accounting', 'Cash accounting', 'Chasing up invoices', 'Tax', 'Data Entry', 'Accounting', 'invoice handling', 'Fund Accounting', 'Accurate Data Entry', 'invoice follow up', 'Invoice Processing']"
"Assistant Manager, Data Protection (Compliance /  Healthcare Industry))","ONE FINLAYSON GREEN, 1 FINLAYSON GREEN 049246",Permanent,Senior Executive,3 years exp,"Accounting / Auditing / Taxation, Healthcare / Pharmaceutical",Monthly,"$4,000to$6,000","Responsbilities

Monitor and track organisation’s compliance with established controls and tools
Manage the company’s data repository for sensitive information
Partner departments and stakeholders on data breach management and follow up
Work with internal and external stakeholders to understand data request needs, strengthen the management of data and implement data protection initiatives
Oversee and conduct regular audits and reviews
Coordinate training requirement with stakeholders
Handle queries or complaints from the public and staff pertaining to data protection matters
Organise and support internal and external meetings for the department
Support administrative matters for the department
Perform any other duties/projects as assigned by supervisor

Requirements

Degree holder
At least 2-3 years of relevant experience in Audit or Advisory or Compliance or Data Management.
A good understanding of medical terminology will be advantageous
Process strong analytical and problem-solving skills
Motivated, proactive, optimistic and thrive when facing challenges
Excellent interpersonal and communication skills, verbal and written
Ability to work in a fast-paced and dynamic environment, multitask and adhere well to timelines
Proficient in MS Office applications such as Word, Excel and Powerpoint

To apply, please visit www.gmprecruit.com and search for Job Reference: 22041.
To learn more about this opportunity, please contact XinYi at xinyi.chai@gmprecruit.com.
We regret to inform that only shortlisted candidates will be notified.
GMP Recruitment Services (S) Pte Ltd   |   EA Licence: 09C3051   |   EA Personnel: XinYi   |   Registration No: R1328898","['Data Management', 'Medical Terminology', 'MS Office', 'PowerPoint', 'Compliance', 'compliance policy', 'compliance issues', 'Audits', 'Communication Skills', 'Excel', 'Audit']"
 , , , , , , , , , 
Quantity Surveyors (Various levels. Data Centre projects),"CENTRAL MALL, 1 MAGAZINE ROAD 059567","Permanent, Full Time",Professional,3 years exp,Professional Services,Monthly,"$5,000to$10,000","Main Purpose of the Job:

To provide quantity surveying/cost management consultancy services covering the full lifecycle of our clients’ projects which encompass multiple industry sectors that includes Data Centres.

The services to be provided may include but may not be limited to cost estimation, benchmarking, BIM take-offs, cost reporting, procurement management/tendering, contract administration, contract management, progress valuations, settlement of final accounts, etc.

Job Description (Key Responsibilities):

Key responsibilities include, but not limited to:

Provide support to the project director in the cost management of projects.
Work collaboratively with the team and stakeholders to manage relevant issues proactively.
Represent the company in a professional and diligent manner.
Control the cost parameters of the projects and take such reasonable measures as may be necessary to maintain approved client budgets
Strive for continuous improvement in service delivery
Understand clients’ requirements and provide sound advice, which may include elements of benchmarking, feasibility studies and the like.
Prepare pre-contract cost estimates, cost plans, budgetary studies and project cash-flow for a variety of developments using Cost X; Cubicost, or similar.
Measure (take off quantities) for all structural and architectural elements.
Manage the procurement process, which may include advising on procurement strategies, shortlisting vendors, preparation of tender and contract documentation, managing the tender process, including tender evaluation/recommendation and checking that tender/contract requirements are being adhered to.
Provide cost information and studies to support value engineering.
Manage contract documentation, valuation of progress payments, variation assessments, cost control and financial reports, including cashflow reporting.
Finalise project final accounts.


Job Requirements & Person Specification (Qualifications, Experience, Skills & Behaviours)

Bachelor’s Degree in Building, Quantity Surveying, Project & Facilities Management, Infrastructure Project Management or equivalent from recognized universities
Minimum of 1 year of QS experience for Data Centre projects
Minimum of 3 years of post-qualification QS experience for Executive Quantity Surveyor roles; Circa 5 years of post-qualification QS experience for Senior Quantity Surveyor roles; Circa 8 years of post-qualification QS experience for Senior Executive Quantity Surveyor roles
Good technical knowledge – Measurement, cost estimating, construction technology, contracts and law
Able to work as a team player and multi-task on few on-going projects/ assignments.
Ability to communicate clearly in both spoken and written English is essential.
Ability to work with digital software (e.g.: CostX; CubiCost) will be essential.
Work experience gained in consultancy firms preferred.
Project experience in the following sectors would also be advantageous: Biopharma / Life Sciences / Healthcare, Corporate Real Estate/Office fit out, Advanced Manufacturing, Logistics, Hotels/Hospitality, Private Developers
Candidate to have clear and analytical approach to problem solving, and strong decision-making abilities.

About Asia Infrastructure Solutions:

Asia Infrastructure Solutions is a leader in delivering project & programme management, cost management, sustainable design, engineering, business advisory and consultancy solutions for the infrastructure, buildings, and environmental sectors. The company was established by Global Infrastructure Solutions Inc. (GISI), the largest privately owned construction manager in the commercial building, industrial and healthcare markets, and a leading project / construction manager in the environmental and public infrastructure sectors. GISI and its founding members have over 90 years of project experience in Asia and currently employs 12,500 employees globally, operating in more than 90 countries.

Asia Infrastructure Solutions has a strong and diversified team of project managers, construction managers, programme managers, cost managers, sustainability consultants and various disciplines of engineering professionals with a long track record in the infrastructure, building and environmental sectors delivering the future for the built and natural environment. Our professional and technical expertise and capabilities are inherited from the Arcadis Design & Engineering / Hyder / Freeman Fox in Hong Kong and Arcadis Consulting / EC Harris / Davis Langdon & Seah businesses in Singapore which span many decades in the Asia region.
Notable projects in Singapore include the Jewel at Changi, CapitaSpring, the North-South Corridor, various hotels, data centers and corporate headquarters for the world’s leading MNCs to name a few.

We empower our employees to succeed and we invest in their professional growth through learning & development programmes as well as membership of professional bodies. Our employees also receive a range of benefits that includes opportunities for hybrid/flexible working, a share-ownership scheme, and private healthcare coverage.

Asia Infrastructure Solutions . Delivering the Future . AsiaInfraSolutions.com

Fair recruitment practices:
Asia Infrastructure Solutions adheres to the Tripartite Standards for Recruitment Practices in Singapore and uses fair, merit-based, and inclusive hiring practices.

Employment agencies:
Candidates referred by employment agencies will not be considered unless the agency has been explicitly instructed to provide candidates for the stated role.","['Analytical Approach', 'Feasibility Studies', 'Written English', 'Valuation', 'Quantity Surveying', 'Cost Management', 'Architectural', 'Value Engineering', 'Construction Technology', 'Administration', 'Estimates', 'Team Player', 'Tendering', 'Cost Control', 'Service Delivery']"
 , , , , , , , , , 
"Data Platform Specialist (DWH, ETL, Azure)",600 North Bridge Road 188778,"Contract, Full Time",Professional,3 years exp,Information Technology,Monthly,"$6,000to$9,000","Job Purpose
The Data Platform Specialist will be given a unique opportunity to work on projects of high impact to our schools and students using cloud technologies and products. You will be responsible for the design, build, maintenance, security and performance of the data and business intelligence platform as well as acting as a trusted consultant to IT management, making recommendations for how to build and scale the business intelligence data platform to serve both internal and external customers.

Key Responsibilities and Accountabilities

1. Technical Design

 Translate business needs to technical specifications
 Analyze business requirements, understand underlying data sources, transformation requirements, data mapping, data modelling and metadata for reporting solutions
 Design EDW data layer with appropriate enterprise considerations like scalability, performance, security, maintainability, automation etc

2. Technical Build

 Build infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.
 Incrementally build client’s enterprise data warehouse
 Evaluate and improve existing BI systems
 Write code, conduct unit testing, documentation and troubleshooting
 Create visualizations and reports for various business units

3. Data Expertise

 Understand the client’s business and captured/generated data
 Understand associated data flows between different enterprise systems

4. Technical Coaching

 Participate in technical sharing and peer review sessions with team members

Knowledge and Experience

BSc/BA in Computer Science, Engineering or relevant field
Building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.
Able to integrate multiple data sources & user-end applications with databases into one system. (to store the data and its retrieval from the databases)
Solid experience in designing and implementing robust data pipelines and ETL framework
Proven experience as a Data Warehouse architect & developer, including full implementation of data warehousing solution.
Good understanding of enterprise design concepts: re-usability, continuous integration, security, scheduling, monitoring, etc

Technical and Soft Skills

In-depth understanding of database management systems, online analytical processing (OLAP), SQL queries (Azure SQL DB)
Expertise with Azure Resource Management and templates is an added advantage
Exposure to cloud technologies (MS Azure, AWS) & desire to learn and deliver new things on a needs-basis. (big data, BI, data science, etc.)
Strong expertise in data warehouse design methodologies and technologies, data modelling(data vault experience is preferable), data quality and metadata
Effective oral, written communication and presentation skills.
Strong interpersonal skills. Self-motivated with a keen attention to detail.

Problem Solving/ Decision Making Level and Freedom

Proven analytical and problem-solving skills, with an ability to effectively prioritize and execute tasks.
","['Microsoft Azure', 'Scalability', 'Azure', 'Big Data', 'ETL Tools', 'Pipelines', 'ETL specification', 'Datawarehousing', 'SQL Azure (Cloud SQL Server)', 'ETL', 'Data Quality', 'SQL', 'Continuous Integration', 'Data Science', 'OLAP', 'Metadata', 'Data Warehousing', 'Databases', 'SQL Azure', 'Technical Design']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"Manager (Data Scientist), AIO Innovation Office (Contract) (JR3637)",1E KENT RIDGE ROAD 119228,Permanent,Manager,4 years exp,Admin / Secretarial,Monthly,"$5,000to$8,000","Join the NUHS Group Chief Technology Office (GCTO) that advocates flexible and innovative working culture. Successful candidate will be part of a team of Data Scientists and Software Developers who partner clinicians to propose, develop, and implement advanced Artificial Intelligence / machine learning models and pipelines to augment clinical workflows in NUHS cluster. The candidate will also ensure the adequacy and effectiveness of the models and tools for NUHS.
You will be responsible for the following:

Research and development of machine learning models in various clinical areas such as clinical notes, medical images, and patients’ data
Research and development of neural network models to analyze free text and identifying, categorizing opinions expressed in a piece of text
Work with the team to design and architect the workflow of the data and algorithms including data input, output and storage between various health IT systems
Work with the team to develop and deploy necessary AI models for NUHS in-house chatbot framework in hybrid cloud environment
Optimize data analysis processes and systems for better efficiency and maintenance
Document clearly explaining how algorithms have been implemented, verified and validated
Lead project team to deliver AI related research and development requirement to meet the business need

Requirements

Minimum Bachelor’s degree in computer science or related fields with strong statistical modelling and machine learning skills. Graduate degree in related fields is preferred
4 years of hands-on experience in the development of end-to-end data analytics solutions and machine learning pipeline including data exploration/extraction/crawling, data processing, and model building
Hands-on experience on development of AI models in NLP
Proficient with programming in Python and AI related frameworks such as Scikit-Learn, TensorFlow, and PyTorch
Knowledge and experience in machine learning platform and services from cloud providers such as AWS, GCP, Azure
Familiarity with healthcare data, medical image is a plus
Experience in leading AI projects and virtual team
Strong problem-solving skills with the ability to work independently and in a team
Excellent written and verbal communication skills, including the ability to communicate technically and non-technically with ability to translate between the two
","['TensorFlow', 'Machine Learning', 'Data Analysis', 'Azure', 'Ability To Work Independently', 'Pipelines', 'Architect', 'Healthcare', 'Artificial Intelligence', 'Research and Development', 'PyTorch', 'Python', 'GCP', 'Data Analytics']"
 , , , , , , , , , 
"Snr Delivery Manager, Data & Analytics","COMCENTRE, 31 EXETER ROAD 239732","Permanent, Full Time",Manager,10 years exp,"Information Technology, Telecommunications",Monthly,"$7,000to$12,000","We’re looking for an experienced Delivery Manager who has experience to deliver enterprise-wide data programs / projects, and ability to manage stakeholders, business, and other IT delivery at different levels.
This role is part of Singtel Group IT – Data & Platform Management, responsible to deliver data programs and projects on time and on budget meeting the business objectives. 

The Delivery Manager will have to manage multiple projects of varying sizes and complexity at any point in time.

The successful candidate must also be able to demonstrate stand-out leadership skills and advocacy of digital transformation using data.

Key Responsibilities:
Stakeholder Management & Communications

The role requires extensive engagement with senior management and hence strong negotiation and influencing skills are a must. The candidate will be required to exhibit evidence of directly influencing and managing the program business ‘outcome’ rather than purely managing the program ‘process’.

Delivery and Resource Management

Manage / deliver programs and projects related to data solutions and own the complete end to end project management accountability
Develop, manage, and improve stakeholder relations – both internal and external
Use of project management artefacts to ensure effective outcomes such as:Accuracy of forecasting
Delivery timelines and schedules are met
Adherence to quality standards

Monitor and control the project progress, budget, cost, resources, schedule and deliverables
Ensure compliance to Singtel Project Management policies and procedures
Lead in the identification of business impacts resulting from project implementation and proactively manage them
Resolving program/project escalated issues and disputes while maintaining constructive working relationships and achieving schedule commitments
Prepare resource plans and manage ongoing resource forecasts
Run Weekly Status Meetings and Steering committee meetings for updates to management.

Financial Management

The role is tasked with meeting both key program/project delivery milestones along with financial and customer centric KPIs.
Prepare monthly financial forecasts and reconciliations against budget to ensure forecasting variance maintained within agreed variance limits.
Deliver financial submissions and updates to sponsors and senior stakeholders in accordance with Singtel capital management processes
Strong financial and commercial management skills are required to ensure financial budgets are managed effectively and program delivers to sponsor’s expectations.

Contract Management

The Senior Delivery Manager will need to manage the entire procurement process leading to successful vendor selection through standard tender processes.
Timely contract negotiations and managing contracts is a vital skill to succeed in this role. The incumbent must ensure that all procurement governance guidelines are strictly adhered to.

Data Domain Expertise

The role requires good understanding of lifecycle and processes related to data projects like Data Warehouse, BI or Big Data platform implementations.
The candidate needs to have good understanding of processes like Data modelling, Data Integration, Data Quality and Governance.

The Ideal candidate should possess:

Bachelor’s degree in Business Management, IT, Computer Science, Computer Engineering or equivalent
PMP or Prince2 is highly preferred
Minimum 10 years of experience in delivering large scale data programs in big data, data warehouse, BI & reporting and / or data management
Experience in delivering projects in agile delivery methodologies
Experience in project tracking; continuously monitors project for potential risks, highlight issues and dependencies and status reporting
Experience in working with cross functional teams comprises of IT, business, data product owners and
vendors
Experience in procurement process – managing tenders and negotiating contracts
Experience in managing Capex of over S$5M
Experience in IT financial management, budgeting and project cost controlling
Experience in senior stakeholder management
","['Management Skills', 'Commercial Management', 'Budgets', 'Big Data', 'Financial Management', 'PRINCE2', 'Contract Management', 'Agile', 'Procurement', 'Project Management', 'PMP', 'Evidence', 'Resource Management', 'Stakeholder Management']"
22591190 VP Portfolio Management - Data Scientist,5 CHANGI BUSINESS PARK CRESCENT 486027,Full Time,Middle Management,6 years exp,Banking and Finance,Monthly,"$11,000to$19,999","The Specialized Analytics Ld Analyst is a strategic professional who stays abreast of developments within own field and contributes to directional strategy by considering their application in own job and the business. Recognized technical authority for an area within the business. Requires basic commercial awareness. There are typically multiple people within the business that provide the same level of subject matter expertise. Developed communication and diplomacy skills are required in order to guide, influence and convince others, in particular colleagues in other areas and occasional external customers. Significant impact on the area through complex deliverables. Provides advice and counsel related to the technology or operations of the business. Work impacts an entire area, which eventually affects the overall performance and effectiveness of the sub-function/job family.

Responsibilities:

Incumbents work with large and complex data sets (both internal and external data) to evaluate, recommend, and support the implementation of business strategies
Identifies and compiles data sets using a variety of tools (e.g. SQL, Access) to help predict, improve, and measure the success of key business to business outcomes
Responsible for documenting data requirements, data collection / processing / cleaning, and exploratory data analysis; which may include utilizing statistical models / algorithms and data visualization techniques
Incumbents in this role may often be referred to as Data Scientists
Specialization in marketing, risk, digital and AML fields possible
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.

Qualifications:

6-10 years of experience
Working experience in a quantitative field, Financial/Credit Card industry
Must have Demonstrated ability in data retrieving and manipulation as well as proficient analytical skills
Excellent analytic ability and problem solving skills
Proficient in Microsoft Office including excellent MS Excel skills to develop analytic presentations
Excellent communication and interpersonal skills, be organized, detail oriented, and adaptive to matrix work environment

Education:

Bachelors/University degree, Master’s degree preferred

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.","['Adaptive', 'Microsoft Office', 'Analytical Skills', 'Interpersonal Skills', 'Transparency', 'Marketing', 'Strategy', 'SQL', 'Compliance', 'AML', 'Excel', 'Diplomacy', 'Data Visualization']"
 , , , , , , , , , 
"Senior Manager, Group Data Centre Operations (Governance)","CENTENNIAL TOWER, 3 TEMASEK AVENUE 039190","Permanent, Full Time",Manager,10 years exp,"Building and Construction, Engineering, Others",Monthly,"$8,000to$12,500","To provide strategic leadership for the delivery of a controlled and structured approach for regional operations in order to achieve ST Telemedia Global Data Centres' business objectives and mission imperatives.
To start-up New 'in-country' DC Operations and provide onsite leadership for training and getting in-country team operational, which includes but not be limited to:
· Represent in country Operations team during start-up, to transition new data centre over to the in-country Operations team;
· Responsible for the planning and oversight of all activities necessary for the transition of new data centre to the in-country Operations team;
· Maintain communication and collaboration during all phases of a new data centre built and handover to in country Operations team;
· Identify all construction related activities which may infringe on any part of a live data centre;
· Attend the design review meetings to highlight operational concerns prior to readiness of in country Operations team;
· Support Engineering team in facilitating inquiries that require input from Operations;
· Share lessons learned elsewhere that have been captured for consideration or mitigation for new builds;
· Support onboarding of the in-country Operations teams for new greenfield sites;
· Build functional knowledge of the site through attendance at key phases of the project, gain in-depth knowledge of the site and documents risk register for transition to in country Operation team;
· Support site acceptance through turnover walks;
· Support review of turnover documentations;
· Participate in turnover issue meetings and provide input on impact to in country Operations;
· Adhere to STT GDC operation methodology in every phase of the project handover;
· Ensure documentation is maintained and kept up to date in line with STT GDC operation standards and policies; and
· Ensure all STT GDC operation Policies, Standards and Standard Operating Procedures (SOPs) are adhered to by new in country Operations team.
To provide strategic leadership for group wide DC Operations, which includes but not be limited to:
· Responsible for global maintenance standards, alignment, costing review and modelling;
· Review, compare and contrast all DC Operational Capex and Opex budget across all regions; and
· Review and align in country Engineering Policies, processes and procedures and define group wide minimal Operations standards (MEP).
To develop group wide minimal operating standards, which includes but not be limited to:
· Support DC Ops Service Assurance in alignment of OT and IT Security Policies;
· Attend all design review meetings to highlight operational concerns; and
· Support Global Change Management.
To be the Subject Matter Expert for engineering matters and develop frameworks for DC Operations, which includes but not be limited to:
· Drive Environmental, Social and Governance initiatives and explore deployable sustainability solutions with in-country DC Operations Heads;
· Lead Global Problem Management; and
· Support customer impacting incident review, recovery and share case study for lesson learnt;
To develop risk management and governance for group wide operations, which includes but not be limited to:
· Support Risk assessment and Management; and
· Lead Capacity Management.
To develop group wide operational performance data and Key Performance Indicators, which includes but not be limited to:
· Collate Environmental, Social and Governance related data points and recommend opportunities for improvement with local DC Operations; and
· Prepare benchmarking across countries and sites and recommend opportunities for improvement.
To conduct internal and external audits for ensuring continued compliance to global standards, which includes but not be limited to:
· Drive technical certification programmes, including TIA-942, Uptime, ISO 50001, ISO 14001, SS564, LEEDS, BCA-IMDA Green Mark for Data Centres, GBCI Greenship, etc.
To conduct physical audit to all facilities annually, which includes but not be limited to:
· Support external and internal site audits organised by DC Ops Audit and DC Ops Service Assurance; and
· Conduct annual Capacity Management review.
Any other duties or projects as assigned by the Management.
Requirements
· Degree in Mechanical Engineering, Electrical Engineering, Building Services, Facilities Management or equivalent.
· Minimum 15 years of relevant work experience with at least 10 years of relevant work experience in design, construction, operations and/or maintenance of mission critical facilities
· Licensed Electrical Worker
· SCEM, GMP, GMFP, GMM, GMFM, LEED GA, LEED AP, GBC GA, GBC GP and equivalent sustainability certifications
· CDFOM, CDFOS, CDCE, CDCS, DCP, DCS, ITIL and other equivalent certifications
· Proven track record in the provision of strategic leadership for the delivery of a controlled and structured approach for regional operations
· Proven track record in the development of policies, standards, procedures, and guidelines for the alignment of facility management programme and mitigation of operational risks
· Subject Matter Expert in building services and other data centre critical infrastructure
· Proficient in AutoCAD & Revit and MS Office - Outlook, Word, Excel, PowerPoint and Project
· Preferred Skillsets
o Risk management, problem management, change management and capacity management
o Project management, program management, contract management and vendor management
o Energy management
o Environmental, health and safety management","['DCS', 'LEED', 'Governance, risk and compliance', 'Regional Planning', 'Data Centre environments', 'GMP', 'Contract Management', 'Building Services', 'Energy Management', 'Data Centre', 'Data Centre Facilities Management', 'Vendor Management', 'Problem Management', 'regional programme', 'LEED AP', 'governance controls', 'Electrical Engineering', 'Mechanical Engineering', 'Facilities Management']"
 , , , , , , , , , 
 , , , , , , , , , 
Internal Auditor /  Senior Internal Auditor  /  AM Internal Audit (IT - Data Analytics),"AIRLINE HOUSE, 25 AIRLINE ROAD 819829","Permanent, Full Time",Professional,2 years exp,Accounting / Auditing / Taxation,Monthly,"$4,200to$9,000","Job Description
The Senior Internal Auditor of Data Analytics will primarily be responsible for developing, assembling, and distributing the analytics needed to support SIA Internal Audit teams for audit fieldwork activities.
The role will also have responsibilities in addressing ad-hoc analytics requests which may come from the Internal Audit Leadership Team.  From time to time, the auditor may also support and participate in Internal Audits focused on financial, operational, IT, or fraud risks.
Key Responsibilities:

Utilizes SAP knowledge and expertise to move towards digitalisation.
Work with audit team and stakeholders in process design, analyze audit requirements and arrive at functional solution (Blueprint) for continuous monitoring of key business/IT processes for anormalies
To design functional specifications for reports, interfaces, dashboard, enhancements, workflow and forms.
Support internal audit to analyze critical issues and investigation if needed.

Requirements

Degree in Computer Science or Computer Engineering with minimum 3 years’ experience as consultant of SAP product.
Experience with development of continuous monitoring capabilities and data analytics related initiatives will be preferred.
Understand SAP backend structure and tables and have technical knowledge of SAP backend tables in key modules: Financial Accounting and Controlling (FICO), Human Capital Management (HCM), Material Management (MM), Plant Maintenance (PM), Production Planning (PP), Quality Management (QM) and Sales Distribution (SD).
Candidates with experience in a similar technical product owner position will also be considered.
Strong analytical skills and having ability to abstract bigger view.
Self-motivated with a strong passion in driving the team and managing the delivery on-time, with quality and cost efficiency.
Experience in data analytics or programming tools such as Tableau, Python, and SQL is a plus
Good communication skills with ability to interact with all levels
","['Tableau', 'Dashboard', 'Data Analysis', 'Analytical Skills', 'Quality Management', 'Data Management', 'Investigation', 'Financial Accounting', 'Auditor', 'SQL', 'SAP', 'Python', 'Fraud', 'Internal Audit', 'Data Analytics', 'Audit', 'Human Capital']"
"Data Platform Specialist (DWH, ETL, Azure)",600 North Bridge Road 188778,"Contract, Full Time",Professional,3 years exp,Information Technology,Monthly,"$6,000to$9,000","Job Purpose
The Data Platform Specialist will be given a unique opportunity to work on projects of high impact to our schools and students using cloud technologies and products. You will be responsible for the design, build, maintenance, security and performance of the data and business intelligence platform as well as acting as a trusted consultant to IT management, making recommendations for how to build and scale the business intelligence data platform to serve both internal and external customers.

Key Responsibilities and Accountabilities

1. Technical Design

 Translate business needs to technical specifications
 Analyze business requirements, understand underlying data sources, transformation requirements, data mapping, data modelling and metadata for reporting solutions
 Design EDW data layer with appropriate enterprise considerations like scalability, performance, security, maintainability, automation etc

2. Technical Build

 Build infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.
 Incrementally build client’s enterprise data warehouse
 Evaluate and improve existing BI systems
 Write code, conduct unit testing, documentation and troubleshooting
 Create visualizations and reports for various business units

3. Data Expertise

 Understand the client’s business and captured/generated data
 Understand associated data flows between different enterprise systems

4. Technical Coaching

 Participate in technical sharing and peer review sessions with team members

Knowledge and Experience

BSc/BA in Computer Science, Engineering or relevant field
Building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources, applications and platforms.
Able to integrate multiple data sources & user-end applications with databases into one system. (to store the data and its retrieval from the databases)
Solid experience in designing and implementing robust data pipelines and ETL framework
Proven experience as a Data Warehouse architect & developer, including full implementation of data warehousing solution.
Good understanding of enterprise design concepts: re-usability, continuous integration, security, scheduling, monitoring, etc

Technical and Soft Skills

In-depth understanding of database management systems, online analytical processing (OLAP), SQL queries (Azure SQL DB)
Expertise with Azure Resource Management and templates is an added advantage
Exposure to cloud technologies (MS Azure, AWS) & desire to learn and deliver new things on a needs-basis. (big data, BI, data science, etc.)
Strong expertise in data warehouse design methodologies and technologies, data modelling(data vault experience is preferable), data quality and metadata
Effective oral, written communication and presentation skills.
Strong interpersonal skills. Self-motivated with a keen attention to detail.

Problem Solving/ Decision Making Level and Freedom

Proven analytical and problem-solving skills, with an ability to effectively prioritize and execute tasks.
","['Microsoft Azure', 'Scalability', 'Azure', 'Big Data', 'ETL Tools', 'Pipelines', 'ETL specification', 'Datawarehousing', 'SQL Azure (Cloud SQL Server)', 'ETL', 'Data Quality', 'SQL', 'Continuous Integration', 'Data Science', 'OLAP', 'Metadata', 'Data Warehousing', 'Databases', 'SQL Azure', 'Technical Design']"
 , , , , , , , , , 
"Lead Data Product Manager, Transformation Office","ONE MARINA BOULEVARD, 1 MARINA BOULEVARD 018989",Permanent,Manager,5 years exp,"Information Technology, Others",Monthly,"$8,000to$10,000","Do you have the capability and drive to develop analytical data products? We are seeking a Lead Data Product Manager to develop new data products such as new data pipelines, data marts, data exchanges and predictive models that will help NTUC better serve our members. Join us if you wish to direct your skills towards enabling workers to earn a better living and live a better life.
This role resides in NTUC’s Transformation Office, which drives digital transformation in NTUC.
You will:

Support the development and execution of NTUC’s data strategy
Develop and project manage data products, including new data pipelines, data marts, data exchanges and predictive models
Manage vendors who maintain and operate NTUC’s analytical data infrastructure
Engage NTUC’s internal users to understand their data needs and develop data products that meet these needs, including descriptive data analytics, predictive modelling
Engage technology partners to explore new ways of applying digital technologies to meet NTUC’s data needs

Requirements

Bachelor’s degree with 5-8 years’ of experience in AI, data modelling, data warehouse and/or related data projects
Good foundation in project management
Good foundation in data modelling and data management
Has a sense of curiosity and enjoys experimentation
Strong analytical and problem-solving skills
Able to explain data concepts simply to the business units
","['Tableau', 'Change Management', 'Experimentation', 'Data Management', 'SQL', 'Project Management', 'Data Science', 'Data Analytics', 'Data Warehousing', 'Data Strategy']"
 , , , , , , , , , 
 , , , , , , , , , 
IT Senior Data Quality Engineer,81 PASIR RIS INDUSTRIAL DRIVE 1 518220,Full Time,Executive,5 years exp,"Information Technology, Manufacturing",Monthly,"$4,500to$6,000","ROLES AND RESPONSIBILITIES
The person will join our Dynamic IT team to support our factory in its ramp up.
Under the responsibility of the Singapore IT HOD, the IT Senior Data Quality Engineer will have to:
- Manage/Support/Enhance the applications used for our data exchanges with suppliers & customers
- Analyze the users requests (changes & projects) and incidents
- Collaborate with the French team on the projects of replacement of the legacy homemade systems by standards products of the market (CQM Camline, etc)
- Standardize the data extractions
- Ensure the Business Relationship Management with Quality Head and his teams
- Follow the activities of a small AMS team based in France and the associated budget
This will require autonomy, good relationship and a strong quality culture as well as the ability to understand the constraints of our environment and the specificities of the semiconductor industry
The job is based in our Semiconductor factory in Pasir Ris (Singapore) and requires close work with people located in our headquarters in France, with 1 or 2 travels to France per year.

SKILLS AND QUALIFICATIONS
• Senior IT engineer
• Recommended technical skills: Oracle/DB2 SQL, Talend, Camline SQM/CQM/Space
• Nice to have: Biztalk orchestration, BO
• Highly organized, practical, analytical and detail oriented
• Ability to multi-task, prioritize tasks, make critical decisions
• Ability to work productively with frequent interruptions
• Flexible schedule","['Ability to Multitask', 'Factory', 'Analytical Skills', 'Autonomy', 'Quality Management', 'Semiconductor Industry', 'ISO', 'Relationship Management', 'VBA', 'Data Quality', 'SQL', 'French', 'Orchestration', 'Manufacturing']"
Associate - Group Data Office – COO Office – People and Communications Associate - Group Data Office,"MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983",Permanent,Manager,3 years exp,Banking and Finance,Monthly,"$7,000to$11,000","Company overview
Nomura is a global financial services group with an integrated network spanning over 30 countries and regions. By connecting markets East & West, Nomura services the needs of individuals, institutions, corporates and governments through its three business divisions: Retail, Wholesale (Global Markets and Investment Banking), and Investment Management. Founded in 1925, the firm is built on a tradition of disciplined entrepreneurship, serving clients with creative solutions and considered thought leadership. For further information about Nomura, visit www.nomura.com.
Aon’s Benefit Index®, Nomura’s benefits rank #1 amongst our competitors
Function Overview
Group Data Office is the Group Central Data and Analytics arm that works closely with the Group Businesses and Group Corporate functions to enable the execution Nomura Group Strategy through Robust Data Standards & Governance, Actionable Performance Metrics & MIS, and High Impact Information and Analytics Products and Solution.
Job Purpose:
Drive the communication, people culture, knowledge management and branding for the Group Data Office.
Job Responsibilities:
1. Communications:

Communication: Develop and deliver communication strategy & plan to drive engagement and change management within the firm, tying together multiple communication touchpoints (e.g., newsletter, townhalls, intranet site, knowledge base, etc.)
Editorial: Propose, plan, and execute the pipeline for campaigns, coordinating with internal stakeholders on activities to ensure that the timeline is adhered to and editorial standards are kept.
Senior Management Communication: Distill key progress, plans and concepts from GDO’s program of work and deliver succinct and on-brand messaging in innovative formats to targeted senior audience.

2. Knowledge and Competency:

Promote, develop and grow GDO’s body of knowledge and make it available and accessible to both GDO and firm wide audience
Design and administer staff competency framework
Organize and host knowledge sharing, training programs and informal networks to address competency gaps


3. People Culture

Rewards & Recognition: Design, implement and operate a rewards and recognition program for our global team
New Joiners Onboarding: Educate new joiners about our data strategy, culture and organization structure, branding and resources and ensure that they are integrated into the global team
Culture Carrier: Design and execute culture initiatives to promote our brand value and collaboration across the global team

4. Branding: Be the storyteller of data as a key digital and business differentiator – Drive current and new initiatives to compliment the team’s existing activities.
Qualification & Core Skills requirement:

Bachelor's degree or equivalent education in Mass Communication
3-5 years of experience in communications, editorial, or professional services. (Preferred)
Excellent MS Powerpoint and multimedia skills
Understanding of FS industry fundamentals, data related challenges in FSI, as well as data-enabled transformation
Comfortable with public speaking and hosting global calls
Able to collaborate / virtually manage multi-cultural, multi-disciplined, globally dispersed teams.
String communication skills to be able to explain highly technical problems in simple layman form.
Innovative and ability to think outside the box

Diversity Statement
Nomura is committed to an employment policy of equal opportunities, and is fundamentally opposed to any less favourable treatment accorded to existing or potential members of staff on the grounds of race, creed, colour, nationality, disability, marital status, pregnancy, gender or sexual orientation. DISCLAIMER: This Job Description is for reference only, and whilst this is intended to be an accurate reflection of the current job, it is not necessarily an exhaustive list of all responsibilities, duties, skills, efforts, requirements or working conditions associated with the job. The management reserves the right to revise the job and may, at his or her discretion, assign or reassign duties and responsibilities to this job at any time.
Nomura is an Equal Opportunity Employer

TSID: 1224304","['Reserves', 'Multimedia', 'Editorial', 'Treatment', 'Public Sector', 'Knowledge Management', 'Data Governance', 'Strategy', 'Entrepreneurship', 'Public Speaking', 'Investment Management', 'Thought Leadership', 'Ms Powerpoint', 'Data Strategy', 'MIS']"
Real Estate Data Analyst (12 Months Contract),"UOB PLAZA, 80 RAFFLES PLACE 048624","Temporary, Contract",Executive,3 years exp,"Information Technology, Real Estate / Property Management, Others",Monthly,"$6,000to$7,400","Your new company

Top Tier Tech company, fast paced and exciting environment for growth.

Your new role

On a daily basis, you will be expected to:

· Gather data from various sources, review and curate into meaningful metrics, insights and create visualizations for analysis, presentations, reports and dashboards
· Identify, track down and resolve data quality and code issues to ensure that databases and dashboards remain error-free and organized
· Prepare data model, regular management reports, analysis and quarterly performance metrics
· Maintain trustworthy and reliable forward-looking forecast data; strong commitment to accuracy and thoroughness in all aspects of data collection and curation
· Define, develop & document business processes and procedures to improve administrative efficiency
· Support Planners on other adhoc requirements such as forecasting and supply planning.

What you'll need to succeed

Candidate must have at least 3 years of experience in data analytics preferably in the commerical real estate industry.
Confident in SQL.
Confident in presenting infront of various level of stakeholders.
Candidate who is available immediate / short notice will be preferred.

What you'll get in return

You will be given the chance to continuously grow in the company due to the expanding business entity, whilst being a part of the team in the growing manufacturing business.

What you need to do now

If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV to denise.lee@hays.com.sg.

If this job isn't quite right for you but you are looking for a new position, please contact us for a confidential discussion on your career.


EA Reg Number: R21103035
EA License Number: 07C3924 | Company Registration No: 200609504D","['Forecasting', 'Microsoft Excel', 'Commercial Real Estate', 'Big Data', 'Data Management', 'Data Quality', 'Data Mining', 'SQL', 'Data Science', 'Real Estate', 'Data Analytics', 'Manufacturing', 'Databases', 'Corporate Real Estate']"
"Senior Manager, Data Analysis & Insights","SINGAPORE ZOOLOGICAL GARDENS, 80 MANDAI LAKE ROAD 729826",Permanent,Manager,8 years exp,"Travel / Tourism, Others",Monthly,"$6,000to$8,800","Job Duties and Responsibilities
·  Leverage data to drive the larger commercial team’s performance goals tied to incremental revenue generation and customer delight.
·  Transform and Analyze data from various digital sources and dashboards (CRM, Web/App analytics tool, Paid Media) to generate actionable insights aligned with stakeholders and data owners.
·  Follow-up with stakeholders on the results to ensure insights are used and learnings are consolidated across time. Work towards being the ‘data champion’ and ‘go-to-person’ for insights.
·  Proactively look for new innovative ways to better understand our customers needs and behaviours to drive actionable insights.
·  Regularly fine-tune analysis model to improve revenue, retention and media investment efficiency.
·  Other relevant duties as assigned.

Job Requirements
·  Degree in Business Management, Information Technology, Computer Science, Data Analytics or the equivalent.
·  At least 8 years of experience as a hands-on data analyst with a demonstrable record of driving growth via actionable data insights.
·  Well versed in industry-standard Digital analytics data definitions (Web/App/Paid Media).
·  Have used advanced analytics techniques and models to drive business decisions and impact.

Strongly Advantageous
·  Prior experience in website/app analytics implementation/analysis.
·  Prior experience in creating dashboards in PowerBI.

Personal Qualities
·  Work around challenges/roadblocks instead of focusing on them.
·  Strong communication skills to convey ideas, challenges and solutions addressing both technical and non-technical audiences.
·  Willing to learn and adapt to various working styles.
·  Demonstrated ability to effectively work in teams and collaborate towards common goals.","['Microsoft Excel', 'Data Analysis', 'Analytical Skills', 'Information Technology', 'PowerBI', 'Communication Skills', 'Presentation Skills', 'Data Science', 'Decision Making', 'Data Analytics', 'Data Visualization']"
Senior Data Analyst (Banking|Up to $8.5k),"SHAW CENTRE, 1 SCOTTS ROAD 228208",Contract,Non-executive,1 year exp,Banking and Finance,Monthly,"$6,500to$8,500","The Opportunity

This is an exciting opportunity to work for one of the leading banks in Singapore
It is an opportunity for an experienced Senior Data Analyst to join their team
Office Location: CBD


The Job

Be a key member of the data analysis team breaking down data problems into smaller parts that can be resolved in a targeted way
Identify, analyze, and interpret trends or patterns in complex data sets
Work with a team of analysts, comprising of businesses, business analysts, process subject matter experts, technology leads to deliver current state analysis, process re-engineering, establish and facilitate resolution to data quality issues
Leverage technical capabilities to drive the development, evolution, and implementation of data enhancements, that will enable self-service by data consumers
Evaluate data management, data quality and data access processes for gaps, inefficiencies, and opportunities; provide recommendations for improvement
Implement solutions and processes for management and governance across data quality metrics, metadata, lineage, data access rights and business definitions
Establish effective and adaptable stakeholder working group
Provide support to users and assist business unit controllers in translating data requirements into deliverables
Ensure technical solutions provided are appropriate and support process changes
Ensure successful delivery of resolutions and enhancements from analysis and specification of users' requirements, solutioning, test planning, facilitation of simulation, preparation for implementation, live verification, and documentation
Maintain a robust communication between all the stakeholders to ensure coordination and delivery of task and activities, proper engagement and drive effective management decision making on relevant issues escalation


The Talent

3-5 years of experience with exposure to Financial Services, Consulting, Fintech/Technology with minimum 1-2 years of data analytics experience.
Experience analyzing large datasets; applying mathematical, statistical and quantitative analysis techniques to perform complex analyses and data mining
R / Python / Data Analytics Certification is an added advantage
Experience in using Big Data platforms and software, e.g. R, Python, Hive, Pig etc. is desirable
Demonstrated passion for numbers, strategic planning skills, financial products / emerging big data technology and how they will impact the consumer experience
Team player and highly collaborative
Strong oral & written communication


Next Steps

Drop your resume and contact us to follow-up, or send your resume to cecilia.sim@adecco.com
Email Topic: Apply Senior Data Analyst
Only shortlisted candidates will be contacted



Cecilia Sim Xin Yang
Personnel Registration No. R22105099
EA Licence No.91C2918","['Tableau', 'Forecasting', 'Strategic Planning', 'Microsoft Excel', 'Data Analysis', 'Big Data', 'Customer Experience', 'Cost Management', 'Quantitative Analysis', 'Accruals', 'Data Mining', 'Python', 'Budgeting', 'Consulting', 'Data Analytics', 'Financial Services']"
"Sr Delivery Manager, Data & Analytics","CT HUB, 2 KALLANG AVENUE 339407",Permanent,Manager,10 years exp,Information Technology,Monthly,"$11,000to$14,000","We’re looking for an experienced Delivery Manager who has experience to deliver enterprise-wide data programs / projects, and ability to manage stakeholders, business, and other IT delivery at different levels.
The Delivery Manager will have to manage multiple projects of varying sizes and complexity at any point in time.
The successful candidate must also be able to demonstrate stand-out leadership skills and advocacy of digital transformation using data.

Key Responsibilities:

Stakeholder Management & Communications

The role requires extensive engagement with senior management and hence strong negotiation and influencing skills are a must. The candidate will be required to exhibit evidence of directly influencing and managing the program business ‘outcome’ rather than purely managing the program ‘process’.

Delivery and Resource Management

Manage / deliver programs and projects related to data solutions and own the complete end to end project management accountability
Develop, manage, and improve stakeholder relations – both internal and external
Use of project management artefacts to ensure effective outcomes such as:

- Accuracy of forecasting
- Delivery timelines and schedules are met
- Adherence to quality standards


Monitor and control the project progress, budget, cost, resources, schedule and deliverables
Ensure compliance to company's Project Management policies and procedures
Lead in the identification of business impacts resulting from project implementation and proactively manage them
Resolving program/project escalated issues and disputes while maintaining constructive working relationships and achieving schedule commitments
Prepare resource plans and manage ongoing resource forecasts
Run Weekly Status Meetings and Steering committee meetings for updates to management.

Financial Management

The role is tasked with meeting both key program/project delivery milestones along with financial and customer centric KPIs.
Prepare monthly financial forecasts and reconciliations against budget to ensure forecasting variance maintained within agreed variance limits.
Deliver financial submissions and updates to sponsors and senior stakeholders in accordance with comany's capital management processes
Strong financial and commercial management skills are required to ensure financial budgets are managed effectively and program delivers to sponsor’s expectations.

Contract Management

The Senior Delivery Manager will need to manage the entire procurement process leading to successful vendor selection through standard tender processes.
Timely contract negotiations and managing contracts is a vital skill to succeed in this role. The incumbent must ensure that all procurement governance guidelines are strictly adhered to.

Data Domain Expertise

The role requires good understanding of lifecycle and processes related to data projects like Data Warehouse, BI or Big Data platform implementations.
The candidate needs to have good understanding of processes like Data modelling, Data Integration, Data Quality and Governance.

The Ideal candidate should possess:

Bachelor’s degree in Business Management, IT, Computer Science, Computer Engineering or equivalent
PMP or Prince2 is highly preferred
Minimum 10 years of experience in delivering large scale data programs in big data, data warehouse, BI & reporting and / or data management
Experience in delivering projects in agile delivery methodologies
Experience in project tracking; continuously monitors project for potential risks, highlight issues and dependencies and status reporting
Experience in working with cross functional teams comprises of IT, business, data product owners and vendors
Experience in procurement process – managing tenders and negotiating contracts
Experience in managing Capex of over S$5M
Experience in IT financial management, budgeting and project cost controlling
Experience in senior stakeholder management
","['Management Skills', 'Commercial Management', 'Budgets', 'Business Intelligence', 'Data Analysis', 'Big Data', 'Financial Management', 'PRINCE2', 'Data Management', 'Contract Management', 'Agile', 'Data Governance', 'Procurement', 'Project Management', 'PMP', 'Data Architecture', 'Evidence', 'Resource Management', 'Stakeholder Management', 'Data Analytics']"
 , , , , , , , , , 
Junior Data Analyst 初级数据分析师,"SOLARIS, 1 FUSIONOPOLIS WALK 138628",Permanent,Junior Executive,1 year exp,Information Technology,Monthly,"$6,000to$12,000","About UP Devlabs:
We are seeking a team of highly motivated who can jointly develop innovative solutions and enjoy the process of continuous learning of trending and modern technologies. If you are looking to collaborate with highly motivated peers, and immerse in best industrial practices, or if you have a deep passion for new creation and innovation ideas, this is the right opportunity for you.

Responsibilities:
1.Collecting and interpreting data Analysing results.
2.Reporting the results back to the relevant members of the business.
3.Identifying patterns and trends in data sets.
4.Working alongside teams within the business or the management team to establish business needs.
5.Defining new data collection and analysis processes.

Skill and Qualifications:
1.Minimum 1 years of native Data Analyst experience/Internet company experience is preferred/gaming company is required.
2.Candidate must possess at least a Bachelor’s Degree in Computer Science, mathematics, statistics, economics.
3.Experience in data models and reporting packages
4.Ability to analyse large datasets
5.Ability to write comprehensive reports
6.Strong verbal and written communications skills as Data Analyst do communicate with the wider business.
7.An analytical mind and inclination for problem-solving
8.Attention to details as data analysis and reporting must be precise.

关于 UP Devlabs：
我们正在寻找一支积极进取的团队，他们可以共同开发创新解决方案并享受不断学习趋势和现代技术的过程。 如果您希望与积极进取的同行合作，并沉浸在最佳行业实践中，或者如果您对新的创造和创新理念有着浓厚的热情，那么这就是您的最佳机会。

职责：
1.收集和解释数据分析结果。
2.将结果反馈给业务相关成员。
3.识别数据集中的模式和趋势。
4.与企业内部团队或管理团队合作，确定业务需求。
5.定义新的数据收集和分析过程。

技能和资格：
1.至少1年原生Data Analyst经验/有互联网公司经验者优先/有游戏公司经验者优先。
2.候选人必须至少拥有计算机科学、数学、统计学、经济学学士学位。
3.数据模型和报告包的经验
4.分析大型数据集的能力
5.综合报告撰写能力
6. 强大的口头和书面沟通技巧，作为数据分析师与更广泛的业务进行沟通。
7.分析思维和解决问题的倾向
8.注重细节，数据分析和报告必须准确。

Job Code: UP-SGDS-JDA-20230210","['Tableau', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Big Data', 'Labels', 'Mathematics', 'Economics', 'Interpreting', 'Data Collection and Analysis', 'SQL', 'Written Communications', 'Python', 'Statistics', 'Visualization', 'Data Analytics']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Risk Data Mark Business Analyst,"VISION EXCHANGE, 2 VENTURE DRIVE 608526","Contract, Full Time",Professional,5 years exp,Information Technology,Monthly,"$5,000to$7,500","Role   is a Risk Analyst to perform BAU support for a risk data mart that is   providing data to Basel III LCR reporting, Basel Credit Risk management   reporting, Credit Risk management reporting.
Primary   role is performed daily and month end checks on the risk data with the focus   on:

Daily reconciliation / completeness checks and        highlighting and following up on reconciliation breaks
Apart from daily BAU, support to upstream projects        which impacts data mart and support to downstream reporting queries and        enhancements will be required.

In   some instances, Risk Analyst may be required to write simple users   specifications.
1. Perform   daily and month end checks on data in Risk Data Mart including updates of   reconciliation reports.
2. Followup   and resolve reconciliation breaks.
3. Perform   impact assessment and UAT on both upstream projects and downstream   enhancement changes.
4. Support   end users queries of Risk Mart and Risk Mart projects related configuration   changes.
5. Write   simple users specifications for Risk Mart.

1. Work   with Risk Mart BAU lead to perform and resolve daily and month end   reconciliation checks and issues. Update reconciliation documents.
2. Perform   UAT and documentation, raise and resolve UAT issues independently.
3. Provide   support to end users queries and Risk Mart related projects configuration   changes.
4. Assist   in Risk Mart specifications write-up.","['UAT', 'Credit Risk Management', 'Microsoft Excel', 'Analytical Skills', 'User Stories', 'Business Analysis', 'Agile', 'Upstream', 'Test Cases', 'SQL', 'Project Management', 'Banking', 'Team Player', 'Business Process', 'Business Analyst', 'Business Requirements']"
Project Manager with data migration experience,60 Anson Road 079914,"Contract, Full Time",Professional,6 years exp,"Information Technology, Insurance",Monthly,"$6,000to$9,000","Required skills and experience must include:
• Proven management of data migration projects
• Experience with ETL tools (such as Talend)
• Experience of working in a complex, multi-priority organization, preferably experience on Hortonworks Data Platform, Cloudera and MariaDB
• Experience of working within delivery teams from multiple teams (including vendor product teams)
Key responsibilities of the Data Migration Project Manager will include:
• To be responsible for overall project management in ensuring the quality, cost, risk and compliance and project scheduling requirements are met
• To develop project plan based on business case or agreed scope for approval by Project Sponsor / Project Steering Committee (PSC), supported by establishment of the overall success criteria for the project
• To maintain effective project governance, processes and systems to be utilised throughout project
• To actively manage project risk in mitigating all identified risks and change control process
• Identifying the data migration impact of all proposed changes
• Reviewing gaps and proposing a solution for data migration during the solution design phase
• Devise and get approval for the data migration strategy for the implementation
• Oversee and ensure the production of a mapping matrix for all data
• Oversee and ensure a gap analysis for any missing or archive data
• Reviewing as is data quality and putting in place plans to address any required data quality improvements
• Oversee and ensure the building of intermediate database creation scripts
• Oversee and ensure the building of data validation scripts
• Ensure the accurate filling of intermediate data tables during data load

Mode: 1 Year Contract, potentially convertible into Permanent","['Project Risk', 'Agile Project Management', 'ETL Tools', 'Data Migration services', 'Project Management Tools', 'Agile', 'ETL', 'Data Quality', 'data migration strategy', 'Data Migration', 'Project Management', 'Project Delivery', 'Data Warehousing', 'Project Management review']"
 , , , , , , , , , 
Asst Director (IT Data Ops Engineer),"MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983","Permanent, Full Time",Manager,10 years exp,Banking and Finance,Monthly,"$10,000to$19,000","ROLE
The DataOps Engineer will design, develop and maintain data solutions in Eastspring.

KEY ACCOUNTABILITIES

Build and support transformation of Eastspring’s strategic data platform, focusing on robustness, scalability, performance, flexibility, and security throughout the data lifecycle (ingest, store, process and consume).
Collaborate with business analysts to develop a good understanding of business use cases, and design / document / develop / test / deploy / administer data pipelines (batch and real-time streaming) and data models that meet both functional and non-functional requirements.
Conduct analysis / evaluation and proof-of-concept for technical solution designs to facilitate management decision.
Create detailed design from architecture solution to ensure that the solution meets business requirements and are aligned to Eastspring’s data architecture principles and technology stack.
Support SIT, UAT, release, and production operations of the data platform.
Ensure quality, integrity and accuracy of datasets through tracked, secured and auditable controls.
Collaborate with and train our business partners to create analytics dashboards.
Understand and apply security standards / guidelines / tools to adhere to the required data controls for the data platform, data pipelines, applications and access end points.
Drive data platform operations using Data Ops, ensure data quality, and monitor data system.
Drive DevOps (CI/CD) continuous improvements to automate development and release management.

QUALIFICATIONS / EXPERIENCE

Recognized degree or higher in Computer Science or related Engineering fields.
At least 5 years of demonstrated experience in designing and building high performance / resilient data platform using Azure (Azure Data Factory, Azure Data Lake, Azure Synapse Analytics, Cosmos DB, Functions, Azure DevOps, etc), traditional data technologies (ODS, ELT / ETL, data warehouse), micro-service architecture, API, Python, Java and / or .NET development.
In-depth knowledge and experience in designing and implementing commercial cloud(s) solutions (including use of DevOps practices, containerization / k8s, API, microservices, log management), integrating SaaS solutions, security frameworks (e.g. OIDC, encryption), SDLC (both agile and iterative waterfall), use of development support tools (e.g. JIRA, GitHub) and infrastructure operations.
Good knowledge on CDC, data as a product, data fabric and data mesh.
Good understanding of asset and/or wealth management businesses, including trade lifecycle and operational processes.
Certifications are encouraged and demonstrate continuous learning of technologies essential for this role e.g. Azure (data & analytics, infrastructure & security) certifications.

OTHER TRAITS

Positive attitude and collaborative mindset.
Highly motivated to keep abreast with the latest development in technology and to acquire deep technical knowledge and skills.
Excellent communication, presentation and interpersonal skills.
","['UAT', 'Factory', 'Scalability', '.NET', 'Azure', 'Pipelines', 'Release Management', 'ETL', 'SDLC', 'Data Quality', 'JIRA', 'Data Architecture', 'Encryption']"
 , , , , , , , , , 
"Data Analyst (ETL, Python, SQL) - CL","GUOCO TOWER, 1 WALLICH STREET 078881","Contract, Full Time",Fresh/entry level,1 year exp,"Entertainment, Information Technology",Monthly,"$3,500to$5,500","Our client is a multinational technology conglomerate holding company in looking for Data Analyst Engineer to join the team.

Responsibility：

Work with business users and data platform team for requirement gathering and process collaboration
Develop data processing pipelines for data modelling, analysis, and reporting from large and complex transaction datasets
Build BI dashboards with Tableau and internal BI tools for data insights and business support


Requirements:

Degree in Computer Science or related technical field
1 year of working experience in data analysis/data warehouse/mart development and BI reporting
Good understanding of Python, SQL, HiveQL/SparkSQL and the relevant best practices/techniques for perf tuning
Working experience in building BI dashboards with Tableau and other BI tools
Good analytical and technical skills in building batch/streaming data pipelines for big data



Charles, Lau Ngie Hao License No. 02C3423 Personnel Registration No. R1656741

Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https://www.manpower.com.sg/privacy-policy","['Tableau', 'Microsoft Excel', 'Tolerance', 'Big Data', 'Pipelines', 'Working With Clients', 'Software Engineering', 'MySQL', 'ETL', 'Tuning', 'PowerBI', 'Web Developers', 'SQL', 'Python', 'Infrastructure Architecture', 'Screening', 'Data Analytics', 'Power BI', 'Silicon']"
"22599721 AVP - Data, Reporting and Analytics - Citi Private Bank (Hybrid)",5 CHANGI BUSINESS PARK CRESCENT 486027,Full Time,Manager,5 years exp,Banking and Finance,Monthly,"$6,300to$12,300","Wealth Credit Management (WCM) at Citi is a newly formed business line to provide integrated end to end credit underwriting, transaction and portfolio management in partnership with all the origination businesses of the Private Bank and Wealth Management of Citi.  Data Reporting & Analytics (DRA) team is a critical team responsible for preparing various Management & control Reports, perform deep dive analysis on the data to arrive at key trends at portfolio level. The team will service as the primary contact for all internal and external audit queries, data tracing as well as play a critical role in representing LPTM team in various control forum.
We are looking to hire an experienced professional to perform Reporting & Analytics role within Loan Product and Transaction Management in WCM covering Americas.
Key Responsibilities:

Analyze and prepare key control reports and portfolio Monitoring reports for WCM managed Products
Prepare regular / time-sensitive on-demand deliverables by closely working with Product / Portfolio heads.
Identify and implement automation, data improvement, and consolidation opportunities to continually streamline and standardize key reports
Satisfy reporting requirements based on regional needs
Coordinate and work with Underwriters and team leads to ensure key portfolio metrics are not breached
Contribute to the creation of processes, standards, procedures, controls & training for the function
Implement various KRIs and KPIs to enhance data quality, and construct dashboards using BI reporting tools
Identify trends / gaps in large data sets and arrive at sustainable solutions to resolve the gaps
Collaborate with Underwriters, Team leads and other stakeholders and constructively work towards sustainable solutions
Work with Business Risk and Control team to provide business feedback for MCA results
Work with Infrastructure / Technology teams to ensure system enhancements are aligned with the needs of management reporting
Assist with relevant audits both internal and external
Coordinate regulatory related and other adhoc requests as needed

Knowledge, Experience and Skills:

Ability to work with Large Data Sets
Good understanding of Lending product
Understanding of data governance and management
Proven ability to collaborate with team members and senior management both within the lines of business and across multiple stakeholders
Highly developed analytical and decision-making capabilities including the ability to identify, escalate, and propose and execute solutions to complex problems
Ability to multi-task through the practice of strong organizational and time management skills with experience in continuously following-up with various stakeholders
Strong influencing skills and ability to work in an environment where priorities are frequently changing

Qualifications:

5+ years of experience in large financial institution is a must
Advance skill in Excel / VBA / Python /Access / Power Point & Word is a MUST
Advance skill in BI visualization tools (e.g. Tableau, Power BI) and BI reporting tools (e.g. Business Objects, COGNOS) is a MUST
Understanding of lending rules and regulation is a plus
Attention to detail
Excellent oral and written communication capability
Ability to take initiative and self-motivate
Developed analytical and problem-solving abilities
Ability to turn around deliverables quickly and under tight timing constraints and deadlines will be critical
","['External Audit', 'Cognos', 'Credit Management', 'VBA', 'Data Quality', 'Data Governance', 'Business Objects', 'Underwriting', 'Portfolio Management', 'Transaction Management', 'Visualization', 'WCM', 'Power BI']"
Data Analyst (Clinical Quality & Performance Management),"Singapore General Hospital Pte Ltd, 1 Hospital Drive 169608",Contract,Junior Executive,1 year exp,Healthcare / Pharmaceutical,Monthly,"$3,300to$5,000","You will be collaborating with a dynamic team who works closely with their stakeholders to improve the quality of patient care. Your role includes building and managing clinical databases for easy data extraction, analysis, automation, visualisation, report and dashboard building. You are required to ensure high level of data quality through data cleaning, wrangling and validation. In addition, you will also set and monitor targets for performance indicators, as well as participate in quality improvement projects.

Requirement

Degree in Data Science/ Computer Science/ Mathematics/ Statistics/ Economics/ Health Informatics or related disciplines
Strong critical thinking and analytical skills, problem solving skills and attention to details
Proficient in programming languages (R, Python, Visual Basic, SQL and/or XML)
Proficient in data analysis tools (SPSS, Microsoft Excel)
Proficient in data visualisation tools (Tableau, Qlik, Power BI
Good communication (written and spoken) and presentation skills
Good team player

","['Tableau', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Analytical Skills', 'Data Quality', 'Informatics', 'Economics', 'SQL', 'Attention to Details', 'Presentation Skills', 'Statistics', 'Team Player', 'Power BI', 'Databases']"
"Data Architect (Financial Services) Senior Consultant, Technology Consulting",1 RAFFLES QUAY 048583,"Permanent, Full Time",Senior Executive,3 years exp,"Banking and Finance, Consulting, Information Technology, Insurance",Monthly,"$4,500to$9,000","At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.
We are the only professional services organisation who has a separate business dedicated exclusively to the financial services marketplace.
Join Financial Services (FSO) and you will work with multi-disciplinary
teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.
The Opportunity
EY’s Data & Analytics Consulting professionals bring a wealth of experience in working with major financial institutions to align their operating model and infrastructure to their business’ strategic objectives. We assemble the right multi-disciplinary teams, use consistent and proven global methodologies and tools, and draw on the full breadth of EY’s global network, to deliver value and trusted advice to the clients. The key service offerings cover finance function transformation, customer and distribution effectiveness, operations, shared services / outsourcing support, performance management, program advisory, enterprise intelligence, risk management and regulatory change.
Your Key Responsibilities
As markets rapidly change and develop, finance functions must demonstrate real added value to their business. As a finance advisor, you’ll use your experience and knowledge to help deliver greater insight – delivering functional efficiencies as well as transforming the role of finance in our clients’ businesses.
You’ll be developing innovative, sustainable ways to improve the management of people, processes and systems, working alongside other finance professionals in high-performing teams.
Skills and Attributes for Success
• Good understanding of economic or market issues and the ability to interpret their impact on clients
• Strong analytical, problem-solving and communication skills
• Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices
• Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel
To Qualify for the Role, you must have
• Minimum 3 years of financial services experience, along with Enterprise Master Data Management (MDM) tool experience (SAS and IBM MDM tool experience is preferred), Data Modeling, Data Governance, Meta Data Management, and Data Architecture preferably
• Experience in Master Data Management (MDM): business process design for managing master data throughout the lifecycle
• Experience in playing the role of a MDM Architect and leading large MDM Implementation for a full SDLC lifecycle.
• Good understanding on the conceptual/logical data model for insurance/banking sectors across Finance, Retail Bank, Cards, and Marketing.
• Architected solution to enable 360 degree customer view and have data quality concept understanding
Ideally, you’ll also have
• Strong people management skills and able to work/ manage multiple client engagements
• Track record dealing with senior stakeholders and adapting to demanding environments
• Understanding of Enterprise Data Warehouse
What we look for
Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player
that collaborates with people from various teams while looking develop your career in a dynamic organization.
What we offer
• Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
• Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
• Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
• Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
Apply now.","['Coaching', 'Management Skills', 'Data modelling', 'Outsourcing', 'Tax', 'Architect', 'Assurance', 'Wealth', 'SDLC', 'Data Governance', 'Capital Markets', 'Presentation Skills', 'Consulting', 'Professional Services', 'Performance Management', 'Service Delivery', 'Ability to Prioritize']"
 , , , , , , , , , 
GO12573550 - Data Management Analyst (12 months contract),"REPUBLIC PLAZA, 9 RAFFLES PLACE 048619","Temporary, Full Time",Non-executive,5 years exp,Information Technology,Monthly,"$6,000to$8,000","The Company
We are looking for a Data Management Analyst to support our client in the consulting sector. Our client is a global consulting firm, and we are looking for candidate to support them on 12 months rolling.
The Data Management Analyst is a pivotal role in a new divisional analytics organization supporting all APAC functions and markets in the areas of Business Intelligence, Data Management, Data Analytics, and Data Science.
This is a challenging role that supports APAC business functions and processes with the management and maintenance of databases, master-and metadata solutions and data management processes, for the purpose of self-service data exploration, reporting and analysis. You will also be supporting user groups in APAX with understanding and finding data, user training and adoption.
The Role
Data Management and Governance:

Understand business requirements for data and analysis.
With the Data Architect Advisor, design and develop conceptual and logical database schemata, data models, and data integration processes.
Maintain information architectures; manage data design, content, and definitions.
Perform day to day MDM implementation and maintenance activities for core transactional and analytics systems.
Support data stewardship and data quality management processes across APAC business functions.
Support the adoption and embedding of data stewardship in regular business processes.
Conduct or support training sessions and provide coaching to key user groups in APAC.

Project Support - Support key APAC business strategies with analytics solutions:

Provide functional and technical expertise and advice on design and deployment of analytics solutions needed to support main business strategies and initiatives.
Work with peers in Business Analytics, and Data Science to develop and provide solutions.
Build plans; ensure work progress; identify and report success measures.
Prepare and present progress reports and outcomes to stakeholders.

Your Profile

Bachelor’s degree or equivalent in Computer Science, MIS, or similar discipline.
2-7 years of practical data management experience in any industry (4-7 years for Senior).
Expert knowledge of designing, developing and implementing database solutions in one or more leading platforms.
CBIP, CIMP or equivalent accreditation, and SAFe Agile certification are a plus.
Proven experience in master- and metadata management
Up to date knowledge of developments in the business intelligence & analytics space, including emerging big data technologies.
A good understanding of fundamental business principles and problems
Willingness to learn to work with new tools and technologies.
A good understanding of fundamental business principles and problems.
Professional skills: planning & organizing. Project management certification is a plus.

Apply Today
Please send your resume, in WORD format only and quote reference number GO12573550, by clicking the apply button. Please note that only short-listed candidates will be contacted.
Robert Half International Pte Ltd | Co. Registration: 200612189E | EA Licence No: 07C5595 | EA Registration No: R1989404","['Business Intelligence', 'Big Data', 'Quality Management', 'Architect', 'Data Management', 'Data Integration', 'Data Quality', 'Data Design', 'Computer Science', 'Project Management', 'Business Analytics', 'Data Science', 'Data Analytics', 'MIS']"
Lead Data Enigneer (AWS and Spark),"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,8 years exp,Information Technology,Monthly,"$7,500to$12,500","We are looking to hire a Lead Data Engineer. This is an exciting opportunity join Income and lead the data engineering ETL team to build/maintain hybrid Datalake for BAU projects.
Responsibilities
· Lead the team in maintaining ETL data pipelines from ingestion to consumption within a big data architecture.
· Work on Change data capture from Source DBs to Datalake.
· Work on ETL jobs development through Informatica BDM/SPARK on “On-Prem Cloudera Hadoop & AWS Cloud data lakes”.
· Implementing data lineage and other data governance related artefacts within Datalake.
· Maintain ETL data pipelines from ingestion to consumption within a big data architecture.
· Establish, maintain, and enforce ETL architecture design principles, techniques, standards and best practices
· Drive the technical design of ETL reference architecture to ensure high data quality, data integration performance and error recovery/handling
· Review and assess existing ETL applications to support new features, performance improvements, upgrades, and ongoing sustainability
· Conduct design reviews, code reviews, performance tuning and perform an active, leading role in shaping and enhancing overall Informatica architecture, including standards, patterns and best practices
Experience / Skills
· Good verbal and written communication skills.
· At least 8+ years of experience on Informatica BigData ETL, On-Prem Cloudera(Hive, Spark & kafka) & Cloud(preferably AWS).
· Experience in Data Engineering Technologies – MySQL, Oracle, MS SQL Server, JSON, Hadoop platform (HDFS/Hive/Impala/Kudu), AWS (Glue, DMS, S3, Athena, RDS-PostgreSQL, Lambda, Code Commit, Code Pipeline, Code build, etc), Airflow
· Able to do scripting – SQL, bash and Python/PySpark.
· Insurance domain knowledge is added advantage.
Qualification
• Minimum Degree in computer science related areas.","['Apache Spark', 'Oracle', 'AWS', 'Hadoop', 'Informatica', 'MySQL', 'ETL', 'SQL Server', 'Hive', 'AWS Lambda']"
Administrator - Data Protection Office and Technology Risk & Quality,"MARINA ONE EAST TOWER, 7 STRAITS VIEW 018936","Permanent, Full Time",Executive,3 years exp,Admin / Secretarial,Monthly,"$2,600to$5,500","A career at PwC is more than “just” a job. It’s about being part of a culture that is committed to making a difference for each other, our clients, and our community — by empowering you to be the best version of yourself and investing in your growth. You’ll be able to develop as a leader, be well-connected, work in a great environment, explore our benefits and make a positive contribution.

We are currently seeking a suitable candidate to join the team as an administrator to provide support to the Data Protection Office and Technology Risk & Quality team. You will work closely to support the day-to-day operations and will get a chance to fully immerse yourself in the initiatives.

How will you value-add?

Arrange and coordinate meetings, including venues
Manage the Director’s diary
Assist with raising bills and claims and cost monitoring
Assist with formatting and updating of documents and monthly reporting slides
Provide administrative support relating to relevant technical databases and tools
Provide general administrative and operational support to the Data Protection Office and Technology Risk & Quality teams


About you

At least an 'O' level qualification; candidates with a Private Secretarial Diploma preferred
At least 3 years of administrative and/or secretarial experience at a Big 4 accounting firm, multinational company or large organisation
Has the confidence and maturity to deal with all levels of staff
Be meticulous, organised and possess excellent project management skills
Possess a strong people oriented attitude
Good working knowledge of Microsoft Office, in particular with Word, Excel and Powerpoint.
Knowledge of how to use other Microsoft applications is a plus, but not essential.
","['Negotiation', 'Management Skills', 'Microsoft Office', 'Legislation', 'Interpersonal Skills', 'WIP', 'Risk Management', 'Administration', 'Accounting', 'Compliance', 'Project Management', 'Employee Training', 'Audits', 'Communication Skills', 'Administrative Support', 'Big 4', 'Team Player', 'Legal Compliance', 'Data Protection Management', 'Databases']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Solutions /  Project Engineer(Data Centre),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098","Permanent, Full Time",Senior Executive,3 years exp,"Banking and Finance, Engineering, Information Technology, Telecommunications",Monthly,"$3,500to$4,800","
Responsibilities
· Understand scope of project, invite vendor quotations, collate and evaluate vendor quotes
· If required, conduct site survey and data gathering at site
· Review costing for project, prepare sales proposals and provide pre-sales support in clients' requirement analysis
· Draft tender and project documents to assist in the preparation of technical and commercial bids for company projects
· Interpret and review system drawings to identify any difference to tender requirements and raise queries against specification
· Build relationships and liaise with internal customers and external suppliers / vendors and manage daily correspondence for quantities, costs and specifications

Requirements
· Degree in Electrical/Mechanical Engineering
· Possess strong technical knowledge
· A team player with strong individual drive, sense of responsibility and task ownership, ability to plan and organize, willing and capable of multi-tasking functions.
· Excellent presentation, communication and interpersonal skill with ability to interact with people at different levels
· Proactive, resourceful, independent with good problem solving and analytical skills
· Excellent presentation, communication and interpersonal skill with ability to interact with people at different levels
· Proficient in Microsoft Office


Please submit resumes to john@oaktree.com.sg with the following

details in MS Word format:
- Position applying for
- Current remuneration
- Expected remuneration
- Notice period
John Goh Meng Chye

EA License No : 06C4642
EA Reg No : R1102621","['Information Security', 'Technical Analysis', 'Network Administration', 'Industrial control systems', 'SCADA', 'Waste Water Treatment', 'Control', 'Information Security Management', 'Network Forensics', 'Acquisitions', 'Vulnerability Assessment', 'Programming', 'environment', 'Network Security', 'Data', 'Malware Analysis', 'Firewalls']"
Solutions /  Project Engineer(Data Centre),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098","Permanent, Full Time",Senior Executive,3 years exp,"Banking and Finance, Engineering, Information Technology, Telecommunications",Monthly,"$3,500to$4,800","
Responsibilities
· Understand scope of project, invite vendor quotations, collate and evaluate vendor quotes
· If required, conduct site survey and data gathering at site
· Review costing for project, prepare sales proposals and provide pre-sales support in clients' requirement analysis
· Draft tender and project documents to assist in the preparation of technical and commercial bids for company projects
· Interpret and review system drawings to identify any difference to tender requirements and raise queries against specification
· Build relationships and liaise with internal customers and external suppliers / vendors and manage daily correspondence for quantities, costs and specifications

Requirements
· Degree in Electrical/Mechanical Engineering
· Possess strong technical knowledge
· A team player with strong individual drive, sense of responsibility and task ownership, ability to plan and organize, willing and capable of multi-tasking functions.
· Excellent presentation, communication and interpersonal skill with ability to interact with people at different levels
· Proactive, resourceful, independent with good problem solving and analytical skills
· Excellent presentation, communication and interpersonal skill with ability to interact with people at different levels
· Proficient in Microsoft Office


Please submit resumes to john@oaktree.com.sg with the following

details in MS Word format:
- Position applying for
- Current remuneration
- Expected remuneration
- Notice period
John Goh Meng Chye

EA License No : 06C4642
EA Reg No : R1102621","['Information Security', 'Technical Analysis', 'Network Administration', 'Industrial control systems', 'SCADA', 'Waste Water Treatment', 'Control', 'Information Security Management', 'Network Forensics', 'Acquisitions', 'Vulnerability Assessment', 'Programming', 'environment', 'Network Security', 'Data', 'Malware Analysis', 'Firewalls']"
 , , , , , , , , , 
HUMAN RESOURCE ASST  /  HR ASST  /  (PAYROLL) @ Jurong East (5Days / $2800-$3200 / +AWS / +Bonus / Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,800to$3,200","HR ASST (PAYROLL)

5 Days

Monday to Friday

8:30am - 5:30pm

$2800-$3200*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :

Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for HR Asst at Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
HUMAN RESOURCE ASST  /  HR ASST  /  (PAYROLL) @ Jurong East (5Days / $2800-$3200 / +AWS / +Bonus / Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,800to$3,200","HR ASST (PAYROLL)

5 Days

Monday to Friday

8:30am - 5:30pm

$2800-$3200*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :

Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for HR Asst at Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"Business Analyst  /  Scrum Master (Data Programs, Banking Domain)",1 Ang Mo Kio Street 64 569083,"Contract, Full Time",Professional,4 years exp,"Banking and Finance, Information Technology",Monthly,"$6,000to$9,500","Scrum Master / Business Analyst (BA)

Job Description:  
The Data Governance Office (DGO) oversees strategic data transformation initiatives, spear-heading the adoption of data within the bank and enabling a data-driven organization.
As part of the Group’s strategy, you will contribute to the building of an enterprise business glossary, establishment of data lineage and data quality rules to enable self- service analytics for the bank. The candidate will help to ensure that the Agile methodology is understood and used effectively by the relevant stakeholders (e.g. development team including vendor and SMEs). With good business analyst background, the candidate will be able to better understand the mechanics of data management and transit into the Data Governance team to perform data management BAU functions after the project. This includes analysing data requirements from relevant stakeholders, and translate/document them into functional requirements for the Enterprise Metadata Management (EMM) solution which hosts the enterprise business glossary, data lineages and data quality rules.

Responsibilities:
• Ensure that the Agile methodology is understood and used effectively.
• Facilitate meetings, helps to remove impediments to the team's progress
• Organise and lead daily scrum and follow up on any identified obstacles
• Manage the backlog and help the product owner ensure sprint goals are delivered
• Coordinating with relevant stakeholders to gather user requirements, data dictionaries / business glossaries from Data Warehouse, source systems and reporting systems.
• Review new business definitions across similar data elements to ensure consistency and standardisation of business definitions
• Work with data consumers to prioritise data elements to enhance their metadata (e.g. data definitions)
• Assist in the uploading and testing of data dictionaries and/or business glossaries into the Enterprise Metadata Management solution
• Work with the Data Stewards and Data Custodians to ensure business glossaries, lineage models, and Data Quality rules are set up and verified.
• Oversee the EMM solution as the DGO is the business owner of the EMM solution

Requirements:
· 4 to 6 years’ experience in managing Agile projects in Banks
· Prior experience in business analytics work that includes data mapping and preparing functional requirements for business.
· Proven analytical background
· Bachelor’s degree in a related field
· Prior experience in Data programs like BCBS 239 or Enterprise Data Warehouse preferred
· Advanced Excel skills
· Experience in the set-up and usage of Jira to manage project
· Experience in Business Intelligence tools (e.g. Power BI or OBIEE)
· Proficiency in reading and writing SQL queries
· Self-motivated, takes ownership with ability to prioritise, juggle among projects and follow through
· Strong communication/interpersonal skills","['OBIEE', 'Basel II', 'Data Analysis', 'Scrum', 'Business Analysis', 'Data Transformation', 'Financials', 'Agile', 'Data Governance', 'Compliance', 'Project Management', 'Basel regulations', 'Agile Scrum', 'Metadata', 'Business Process', 'Business Analyst', 'Power BI', 'Certified Scrum Master CSM', 'Business Requirements', 'Certified Scrum Master']"
Solution Architect (Data Analytics / AI),"THE OCTAGON, 105 CECIL STREET 069534",Permanent,Professional,5 years exp,"Engineering, Information Technology",Monthly,"$6,000to$8,000","We are representing our client (A Software Engineering Firm) to look for Solution Architect (Data Analytics / Artificial Intelligence)  to complement their existing team.


Responsibilities:

Analyses, designs and develops digitalisation roadmaps and implementation plans based on a current versus future state solutions architecture
Analyses the current architecture to identify weaknesses and identifies opportunities for improvement, and performs ongoing architecture quality review activities.
Leads and facilitates the solutions architecture governance processes by aligning to the enterprise architecture and manages exceptions to architectural standards at a solutions level
Assesses near-term needs to establish business priorities, analyses and develop solutions architectural requirements, and ensures alignment of architectural requirements with the IT strategy.
Work with customers to identify, design and develop AI/ML solutions to address their requirements, challenges and pain points.
Engage solution vendors to determine appropriate products that will meet customer DA/AI requirements
Support data analytics solutions response to RFQ and tenders, proposal development and provide post-sales support.
Lead and guide project team to develop and implement the solution
Exercise and continually develop leadership, management and technical skills

Requirements:

Bachelor’s degree in Data Science, Artificial Intelligence, Computer Science, Engineering or related disciplines.
Strong technical knowledge in software architecture, have breadth across technology stacks with deep hands on skills, and passionate about working with customers to help build applications at scale.
Knowledge of Continuous Integration/Continuous Delivery environment with change/version control process and methodologies.
Knowledge of networking, computing platform, storage, database, security, middleware, network and systems management, and related infrastructure technologies and practices.
Experience in designing and building DA/AI solutions (eg cloud native, microservices architecture using containers/Kubernetes), integrated with machine learning pipeline.
Experience in all stages of the project lifecycle, e.g. planning, requirements gathering, design documentation, testing, rollout and transition to Ops.
Experience in technical presentation, technical documentation.
Experience in delivering projects for the defence sector will be a plus.
","['Machine Learning', 'Technical Documentation', 'Defence', 'Requirements Gathering', 'Architect', 'Architectural', 'Continuous Integration and Continuous Deployment', 'Artificial Intelligence', 'Software Engineering', 'Technical Presentation', 'Information Technology', 'Enterprise Architecture', 'Networking', 'Data Science', 'Data Analytics', 'IT Strategy', 'Software Development']"
 , , , , , , , , , 
Data Analyst (12 months contract),"UOB PLAZA, 80 RAFFLES PLACE 048624",Contract,Executive,2 years exp,"Banking and Finance, Information Technology",Monthly,"$5,500to$6,000","Your new company
This is a multinational bank with presence all over the globe. With operations across consumer, corporate and institutional banking, this bank prioritises collaboration and a dynamic working environment.

Your new role
You will be responsible for handling the automation and reporting while supporting US and all other markets the team covers. You will also be managing all queries arising from reports while performing analysis on excel file. This is a 1 year renewable contract.

What you'll need to succeed

2 years of working experience with min 1 year of experience in Data Analysis
Hands-on experience in Tableau and Alteryx
Dataiku will be nice to have
Advanced Excel skills (Pivot Table, Vlookup etc)
Non-banking/financial services candidates are open to apply!

What you'll get in return
This is an excellent opportunity to be part of a global bank. You will be part of a collaborative working environment and you will be remunerated at market competitive rates.

What you need to do now
If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV, or call Shabnam at Hays on +65 63030726 or email Shabnam.Bahar@hays.com.sg [mailto:Shabnam.Bahar@hays.com.sg] for a confidential discussion. Referrals are welcome.

Registration ID No. R1873584 | EA License number: 07C3924 | Company Registration No. 200609504D","['Tableau', 'Referrals', 'Microsoft Excel', 'Data Analysis', 'Advanced Excel', 'SQL', 'Attention to Detail', 'Python', 'Banking', 'Excel', 'Data Science', 'Visualization', 'Vlookup', 'Data Analytics', 'Data Visualization']"
Enterprise Data Management Consultant / Developer,1 DEPOT CLOSE 109841,"Permanent, Full Time",Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$10,000","Project Description:Leading bank in the Asia headquartered at Singapore looking to implement enterprise wise market data management system. this system will replace banks' existing legacy application and interface with several other downstream systems to provide real time market data feed and interfaces.
Responsibilities:
- Participate in the configuration of EMDMS software solutions based on Bank's requirement.
- Responsible for their configuration and unit testing within Bank's EMDMS implementation project.
- Provide best practice guidance and technical expertise of existing Bank's ecosystem and industry experience to NeoXam PM and consultants.
- Participate in the test support activities - including support of Bank's test team to reproduce and potentially fix bugs and provide feedback to the test team.
- Identify and resolve any implementation issues post-EMDMS go-live.

Mandatory Skills Description:
- Engineering, Computing & Information System - Master's degree / Bachelor's degree or equivalent.
- 3+ years of experience with software implementation and IT Projects in the banking / financial industry within APAC region. Preferably of a financial technology vendor solution
- Strong knowledge of Banking technology ecosystems, especially for systems in scope within the EMDMS project, such as Neoxam / Murex / T24
- Capable of writing rules in scripting language comparable to VBA.
- Experience with RDBMS (SQL language), Data Modeling (conceptual/object oriented thinking).
- Understanding of Enterprise Data Management and ETL techniques and processes.
- Experience of financial data provider feeds such as Bloomberg, Refinitiv, ICE and others.
- Knowledge of financial instruments such as Equities, Fixed Income and Derivatives and rates (FX/MM).
- Project experience with involvement in multiple stages of the project development life cycle.
- Operates independently, takes initiative, good interpersonal skills and ""feels accountable"".
- Proactive and a real team player.

Nice-to-Have Skills:
Understanding of Murex/T24 or Neoxam applications","['Management Consulting', 'Bloomberg', 'Derivatives', 'Data Modeling', 'Interpersonal Skills', 'Unit Testing', 'Data Management', 'Scripting', 'ETL', 'Data Governance', 'Writing', 'Banking', 'Team Player', 'Fixed Income', 'FEED', 'Equities']"
"Team Lead (AVP), Client Static Data & Credit Limit Maintenance (Foreign Corporate Bank) [ALT]","BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908","Permanent, Full Time",Manager,6 years exp,Banking and Finance,Monthly,"$6,000to$9,000","RESPONSIBILITIES:
You will be leading a team of 5 which is responsible for the following:
· New client account setup
· Monitor and timely update of client account / credit limit instructions from the internal stakeholders (front office, operations etc)
· Day end reconciliation of these instructions to ensure accuracy and completeness of these customer static data
· Preparation of periodic reports for the management

As the Team Lead, you will:
· Mentor & train junior or new team members
· Review and implement changes to the work process & systems with the aim to achieve efficiency, robust control, mitigate risks and enhance Clients’ experience
· Investigate and report discrepancies arising from transactions or system failure
· Conduct regular review on the Bank’s Business Continuity Plan (BCP) drill test scripts to maintain operations resiliency

REQUIREMENTS:
· Minimum Degree with at least 6 years of work experience in client static setup or credit limit setup of a Bank
· Able to handle high work volume and multi-task
· Demonstrated leadership experience in managing a team
· Proficient in Microsoft Office Applications; Candidates with advanced Excel or Macro skills will be advantageous
· Strong communication & interpersonal skills

Please contact Alicia Tuang at 9150 6479 or AliciaT@charterhouse.com.sg for a confidential discussion

EA License no: 16S8066 | Reg no.: R1104694

Only successful candidates will be notified.","['Leadership', 'Microsoft Office', 'Microsoft Excel', 'Business Continuity', 'Interpersonal Skills', 'Data Management', 'Advanced Excel', 'Data set', 'Project Management', 'Communication Skills', 'Team Lead', 'Banking', 'Team Leader', 'Databases', 'Financial Services', 'Data']"
 , , , , , , , , , 
"Computer Vision Algorithm Expert, Data Monetization Technology",1 RAFFLES QUAY 048583,Full Time,Professional,3 years exp,Others,Monthly,"$8,000to$16,000","Responsibilities
1. Be responsible for business content understanding of ads, e-commerce, short video, live streaming, and other related content understanding, including images, text, video, audio, etc.
2. Be responsible for data mining, feature engineering, and building machine learning models to build monetization ecology.
3. Optimize model computation efficiency and improve model stability when facing tens of millions of business data and restricted resources.
4. Based on billion scale business data, explore and implement various cutting-edge technologies, such as pre-training, self-supervised learning, few-shot learning, etc.

Qualifications
1. Bachelor's degree or above, majoring in Computer Science, Computer Engineering, Electrical Engineering, or other related fields.
2. Have at least 3 years of working experience in relevant fields.
3. Have a solid foundation with common machine learning and deep learning related techniques and algorithms (e.g. classification, clustering, regression, etc.). Be proficient with at least one deep learning framework (e.g. PyTorch, TensorFlow).
4. Be familiar with computer vision related tasks. Have rich experience in at least one aspect, such as image/video classification, object detection, image/video retrieval, OCR, image segmentation, etc.
5. Related experience in at least one of the following areas is a plus:
  1. Be familiar with NLP-related tasks. Have experience in at least one aspect, such as text classification, semantic analysis, sentiment analysis, NER, etc.
  2. Be familiar with audio-related tasks. Have experience in at least one aspect, such as ASR, AED, LID, etc.
  3. Be familiar with multimodal machine learning, large-scale pre-training, etc.
  4. Be familiar with the theory and application of graph neural networks, knowledge graphs, and have relevant experience; 
  5. Be familiar with model acceleration techniques such as pruning, quantization, distillation, etc.; Have relevant experience in deploying models using frameworks such as TensorRT.
6. Solid programming foundation. Be familiar with basic data structures and algorithms.
7. Have excellent analytical and problem-solving skills, logical thinking skills, communication and collaboration skills. Maintain curiosity about new things, and have a strong sense of responsibility, integrity and reliability.
8. Having published papers in top AI conferences or journals is a plus.","['TensorFlow', 'Machine Learning', 'AED', 'Data Structures', 'Segmentation', 'Sentiment Analysis', 'Computer Vision', 'Reliability', 'Ecology', 'Text Classification', 'Data Mining', 'PyTorch', 'Monetization', 'Electrical Engineering', 'OCR']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Information Technology - Principal Technologist Data Engineering & Analytics,"TechSQ, 722 Upper Changi Road East 486854","Permanent, Full Time",Professional,7 years exp,Information Technology,Monthly,"$8,000to$16,000","Job Description

This position requires a seasoned senior software developer with advanced software engineering and distributed system development skills. He/she is comfortable in architecting and implementing custom open-source-based big-data platforms, such as those for data ingestion (both batch and near-real-time) and MLOps in AWS cloud.

Key responsibilities include:

Provide technical leadership in data engineering for guiding SIA’s data engineering and analytics team. Drive the overall technical vision and roadmap for evolving SIA’s distributed data management systems and data analytics.
Be an effective implementer, and a technical mentor for the team which will involve the following core activities:


Design and develop new systems architecture for data engineering services and their ecosystem, spanning distributed databases (relational, columnar, graph, in-memory); MLOps; orchestration (Apache Airflow); distributed stream/batch data processing or other big data technologies. Maintenance and evolution of existing on-premises and AWS cloud data warehouse/data lake systems.
Design data models for mission-critical and high-volume near-real-time and batch data; build idempotent/atomic production data pipelines to make data ingestion more robust and fault tolerant.
Develop a highly automated self-service data platform for business users.


Assist in stakeholder management and resolve resource conflicts within or between agile teams. Lead projects involving high levels of coordination among departments and business areas.
Any relevant ad-hoc duties.

Requirements

BS in Computer Science or other related discipline is required. Advanced degrees in Computer Science (PhD, MS) are highly desirable.
7 years or more of relevant industry experience in the following technical areas:


Advanced programming skills in Python. Conversant with data structures, algorithm design, and software design patterns.
Experience in building data pipelines (such as data collection, warehousing, processing, analysis, monitoring, and governance) using open-source data ingestion platforms.
At least intermediate-level knowledge and hands-on experience with AWS cloud components and best practices (serverless services like Lambda, Step Function, Glue; managed services like EMR, MSK). Solid understanding in deploying data stores such as S3, RedShift, ElastiCache, PostgreSQL, and ClickHouse; Athena/Presto SQL analytics engine.
Prior experience in modern software development is required (such as web frontend UI, backend API microservices, understanding of CI/CD and Scrum/Kanban agile development). Strong grasp on object-oriented or functional programming (using e.g. Python, Java, Scala, or C#).
Experience with commercial or open-source data ingestion platforms, including an in-depth understanding of modern ETL methodologies.


Proven experience in technical leadership. Capable of mentoring a data engineering team in delivering on multiple competing priorities with little supervision. Seasoned resource estimation, planning, and negotiation skills to work with diverse stakeholders.
Prior tech lead experience in a software development team using Agile/Scrum/Kanban methodology is a big plus.
","['ClickHouse', 'Agile', 'Data Engineering', 'EMR', 'SQL', 'Python', 'Algorithm Design', 'Java', 'Technical Leadership', 'API', 'Stakeholder Management', 'Data Analytics', 'Databases', 'Software Development', 'Agile Development']"
"Principal Specialist, Planning, Strategy & Data Analysis",80 JURONG EAST ST 21 609607,Permanent,Senior Executive,3 years exp,"Admin / Secretarial, General Management, Human Resources, Information Technology",Monthly,"$7,510to$8,600","Job Description
As Principal Specialist for Planning, Strategy & Data Analysis (PSDA), you will contribute individually as well as assist your Deputy Director to manage a small team to work on facilitating discussions and develop measures and strategies for the organisation’s needs. You should excel at communicating, engaging multiple stakeholders including government agencies, conducting evidence-based studies and analysis, and moving strategies into implementation.

Job Responsibilities

Negotiate, coordinate, and liaise with internal and external stakeholders, including the Ministry of Manpower (MOM) and Workforce Singapore (WSG).
Conduct studies of industry groups, worker segments, overall employment and employability landscape, and/or ad hoc studies as requested, to identify trends, threats, and opportunities. Craft compelling stories and data-driven recommendations from findings or insights to be presented to various stakeholders.
Support senior management with new matters that arise by making sense of emerging issues and gaps that do not fit neatly into clear categories, as well as corporate and strategy matters, including monitoring and tracking KPIs; preparation for external meetings with government agencies; analysing developments that impact the organisation.
Organise and support annual corporate planning sessions and seminars (and ad hoc brainstorming sessions) to conceptualise overall workplan and communicate corporate strategy, provide analysis and insights to support and guide management in decision-making.
Prepare and present regular reports and topical presentations to senior management, including NTUC senior management.
Oversee, plan for, maintain, and track clean data to be used for data analysis.

Job Requirements

Good interpersonal and negotiation skills
Excellent analytical, writing, and communication skills
Project management, problem-solving, and leadership skills
Meticulous, self-driven, and able to multi-task
At least 3 years’ experience in planning/policy, consultancy, or strategy formulation
","['Negotiation', 'Microsoft PowerPoint', 'Able To Multitask', 'Analytical Writing', 'Data Analysis', 'Business Analysis', 'Formulation', 'Strategy', 'Project Management', 'Communication Skills', 'Excel', 'Team Player', 'Data Visualization']"
Technical Project Manager - Data Engineering - RSM,"GUOCO TOWER, 1 WALLICH STREET 078881",Contract,Manager,5 years exp,Engineering,Monthly,"$8,000to$10,000","Role:

Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget, and scope
Translate business requirements to technical specifications, provide high-levell solution design
Drive engineering teams in building to the roadmap, managing project delivery, dependencies and risks, track deliverables, and overcome roadblocks
Handle regular stakeholder communication and project updates

Required:

5+ years of experience of managing engineering or data related projects
Work with the business users to understand business requirements and translate that to high level technical specifications
Manage and coordinate test plan, user sign off and go-live plan
Work on defining high level architecture and appreciate technical complexities required
Work with development team on effort assessment, and manage task assignments and deliverables
Comfortable working with both waterfall and agile methodologies
An understanding of data in a sophisticated enterprise system landscape, including data governance, security, quality, and standardization
Knowledge of one or more database technologies (Snowflake, Oracle, Hadoop) and experienced in Cloud Technologies
Proficiency in writing Advanced SQLs, experience with business analytics products like Tableau

Nice to have:

Experience with data science and machine learning tools and technologies is a plus
Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus.

Interested candidates, please share your updated resume with shirley.rajasekar@experis.com.sg or click the ""Apply now"" function.
We regret to inform you that only shortlisted candidates will be notified.

Shirley Monisha
Personnel Reg No: R22106767
Manpower Staffing Services (S) Pte Ltd
EA License No: 02C3423","['Tableau', 'Machine Learning', 'Oracle', 'Staffing Services', 'Hadoop', 'Agile Methodologies', 'ETL', 'Data Governance', 'Data Engineering', 'Python', 'Writing', 'Business Analytics', 'Data Science', 'Java', 'Project Delivery', 'Business Requirements']"
 , , , , , , , , , 
 , , , , , , , , , 
Assistant Manager - Electrical Design (Data Centre),0 Kallang Place 339213,Permanent,Middle Management,5 years exp,Engineering,Monthly,"$5,200to$6,200","Industry: Data Centre
Competitive remuneration package
Permanent role

Responsibilities:

Responsible for developing technical solutions for data centre projects, from inception to completion stage. The incumbent will be working with internal and external stakeholders to ensure projects are delivered within budget and time      requirements, and will be expected to travel for work if assigned to      overseas projects.
Execute technical qualification, planning and development of technical solutions for      pre-deals, as the Technical Solutions Manager and/or Head of Department      may direct
Manage and generate technical solutions, project cost and planning structure for prospective deal engagements and investment approvals
Obtain proposals and carry out assessment, selection, appointment, and management of consultants for the development of design and cost estimation
Support project team during the whole course of project execution, such as executing projects’ quotation and tendering process for various packages, such as main contractors, sub-contractors, vendors, suppliers etc., in accordance with      the approved procurement process
Organize and conduct meetings with stakeholders, such as clients, asset owners, consultants, contractors, vendors, suppliers etc., to address all technical related      matters during the whole course of project execution and client’s engagement
Perform tracking on the progress of solutions development and project cost, against the approved schedule during pre-project investment approval stage, for timely handover to client, asset owners and operations team respectively
Perform assessment on technical solutions, such as potential risks and mitigation measures, compliance to the requirements and standards etc.

Requirements:

Bachelor’s Degree, preferably in Electrical Engineering
Minimum 4 years of working experience in mission critical environment
Ability to carry out high level review of design drawings & documentations
Familiar with design and procurement processes
Ability to manage internal and external stakeholders, technical & non-technical

Job ID: L5YRV793

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Kindly email your resume in a detailed Word format to carlo@peopleprofilers.com

We regret that only shortlisted candidates will be notified


People Profilers Pte Ltd
20 Cecil Street, #08-09 PLUS Building Singapore 049705
+65 6950 9747

EA Licence Number: 02C4944
Registration Number: R1100011
EA Personnel: Carlo Antonio Dela Cruz","['Feasibility Studies', 'Cecil', 'Construction', 'Lighting', 'Electrical Design', 'Data Centre environments', 'Electrical', 'Building Services', 'PLC', 'Data Centre', 'Procurement', 'Data Centre Facilities Management', 'Compliance', 'AutoCAD', 'Tendering', 'Electrical Engineering', 'Layout', 'Project Cost', 'Commissioning']"
 , , , , , , , , , 
Data Administrator (6 months contract),"SINGAPORE LAND TOWER, 50 RAFFLES PLACE 048623","Contract, Full Time",Fresh/entry level,1 year exp,"Admin / Secretarial, Insurance",Monthly,"$3,000to$3,600","about the company
Our client, one of the top leading international insurance company globally.

about the job
In this position as a Data Administrator, you will be responsible for the researching, collating and updating of Insurance providers’ data so as to maintain the network providers’ data accuracy in the new provider’s database. The ideal incumbent is expected to validates provider's agreed rates, follow by uploading onto the new provider’s database and coordinate with internal stakeholders in APAC and other region to ensure signed contracts and agreed preferred rates are uploaded accurately and timely.

skills and experience required

1+ years of experience in corporate environment - Financial or Insurance industry preferred
Strong data or excel skills
Good communication & interpersonal skills
Eye for detail and proactive
Highly independent and fast learner

If the above position interest you, kindly click on the appropriate link to apply for this role.

EA: 94C3609/R132534

Applicants must be fully vaccinated or have a valid exemption in accordance with MOM’s regulations to allow them to enter the workplace. Applicants may be required to share verifiable COVID-19 vaccination documents or proof of a valid exemption at the point of offer. Randstad Pte. Limited and/or the Client reserves the right to withdraw an offer if the applicant fails to provide verifiable COVID-19 vaccination and/or proof of exemption documents.","['Microsoft Excel', 'Reserves', 'Oracle', 'Data Analysis', 'Interpersonal Skills', 'Data Management', 'Administration', 'Attention to Detail', 'Life Insurance', 'System Administration', 'Excel', 'Authentication', 'Databases', 'Insurance', 'Data', 'Insurance Portal']"
"Information Technology - Principal Technologist, Data Engineering & Analytics (Scoot)","TechSQ, 722 Upper Changi Road East 486854","Permanent, Full Time",Professional,7 years exp,Information Technology,Monthly,"$8,000to$16,000","Job Description

The successful candidate will play a lead role within the Data Engineering and Analytics team within Scoot’s Information Technology Division.

Key responsibilities include:

• Provide technical leadership in data engineering for guiding Scoot’s data engineering and analytics team. Drive the overall technical vision and roadmap for evolving Scoot’s distributed data management systems and data analytics.
• Be an effective implementer and a technical mentor for the team in the following core activities:
- Design and develop new systems architecture for data engineering services and their ecosystem, spanning distributed databases (relational, columnar, graph, in-memory); DataOps; and other big data technologies.
- Maintenance and evolution of existing GCP cloud data warehouse/data lake system.
- Design data models for mission-critical and high-volume near-real-time and batch data; build idempotent/atomic production data pipelines to make data ingestion more robust and fault tolerant.
• Assist in the stakeholder management and resolve resource conflicts within or between agile teams. Lead projects involving high level of coordination among departments and business areas.
• Any relevant ad-hoc duties.


Requirements

• BS in Computer Science or other related discipline is required. Advanced degrees in Computer Science (PhD, MS) are highly desirable.
• 7 years or more relevant industry experience in the following technical areas:
- Advanced programming skills in Python. Conversant with data structures and algorithm design.
- Experience in building data pipelines (including data collection, warehousing, processing, analysis, monitoring, and governance) using data ingestion platforms.
- At least intermediate-level knowledge and experience with  GCP cloud components and best practices.
- Good understanding in deploying data stores such as S3, GCS and BigQuery.
- Prior experience in modern software development is required (such as web frontend UI, backend API microservices, understanding of CI/CD and Scrum/Kanban agile development). 
- Experience with data ingestion platforms, including an in-depth understanding of modern ETL methodologies.
• Proven experience in technical leadership. Capable of mentoring a team in delivering on multiple competing priorities with little supervision. Seasoned resource estimation, planning, and negotiation skills to work with diverse stakeholders.
• Prior experience with managing software development teams using Agile/Scrum/Kanban methodology is a big plus.","['Warehousing', 'Data Structures', 'Agile', 'Information Technology', 'Data Engineering', 'Python', 'Algorithm Design', 'GCP', 'Technical Leadership', 'API', 'Stakeholder Management', 'Data Analytics', 'S3', 'Databases', 'Software Development', 'Agile Development']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
9866 - Regional Project Manager ( DCIM and BMS  /  Data Centre ),"SHENTON HOUSE, 3 SHENTON WAY 068805",Full Time,Manager,7 years exp,Engineering,Monthly,"$7,000to$10,000","Regional Project Manager

Working day / time: Monday to Friday | 9am to 6pm
Salary: $7k to $10k
Location: Ubi

Job Description:

The Regional Project Manager is responsible for leading and delivering data center
infrastructure management (DCIM) and building management system (BMS) projects across multiple locations in the region. This includes overseeing the design, implementation, and maintenance of systems and processes that support the day-to-day operations of the data center and the building.

Responsibilities:

• Lead cross-functional project teams to ensure successful delivery of DCIM and BMS projects across multiple locations in the region
• Develop project schedules, budgets, and resource plans, and monitor progress to ensure that projects are delivered on time and within budget
• Coordinate with stakeholders across different locations to gather requirements and develop project plans that meet their needs
• Oversee the implementation and integration of DCIM and BMS technologies, including monitoring, power management, and asset management systems, HVAC, lighting, and security systems
• Develop and maintain project documentation, including project plans, status reports, and change requests
• Monitor project risks and issues, and develop mitigation plans to address any challenges that arise
• Ensure that all projects are delivered in accordance with IT policies, standards, and procedures
• Provide regular project updates to senior management, stakeholders, and project teams
• Stay up-to-date with the latest industry trends and best practices, and identify opportunities to improve the DCIM and BMS project management process across the region.

Requirements:

• Bachelor's degree in Computer Science, Engineering, Business Administration, or equivalent.
• At least 7 years of experience in project management, with a focus on data center infrastructure management (DCIM) and building management system (BMS) projects, and experience managing projects across multiple locations
• PMP, Prince2, or other project management certification preferred
• Strong knowledge of DCIM and BMS technologies, including monitoring, power management, asset management, HVAC, lighting, and security systems
• Experience with project management methodologies, such as Agile and Waterfall

Karen Lee Kai En    Reg No: R22108159 
The Supreme Hr Advisory Pte Ltd   EA No: 14C7279","['Budgets', 'Asset Management', 'Lighting', 'Data Center', 'PRINCE2', 'Agile', 'HVAC', 'Administration', 'Power Management', 'Project Management', 'PMP']"
1 Year Senior Data Analyst (Local Bank) #BBZ,"NGEE ANN CITY, 391A ORCHARD ROAD 238873","Contract, Full Time",Senior Executive,5 years exp,Banking and Finance,Monthly,"$5,500to$7,000","Job Responsibilities

Identify and extract key data insights to address business pain points
Support data transformation initiatives to establish scope, timelines, ownership, and dependencies for each data analytic stream, track and report the progress
Coordinate with various internal and external business stakeholders to ensure smooth data-to-insights conversion


Requirements: 

Work experience of more than 5  years as a Data Analyst with proven track record of running data projects with different stakeholders
A good understanding of data management and analytics, know programming like SQL, Python, with general financial industry knowledge
Good communication and interpersonal skills to effectively interact with internal and external stakeholders of all levels



CEI no.: Jerlin Aw Bi Zhi (R1218675)
Recruit Express Pte Ltd
EA Licence no.: 99C4599","['HTML + CSS', 'Excel Macro', 'Dashboard', 'Interpersonal Skills', 'HTML', 'Data Transformation', 'Data Management', 'Advanced Excel', 'SQL', 'Python', 'Excel VBA', 'metrics dashboard']"
Snr Consultant (Data Engineer  /  ETL  /  BI),"MIDVIEW CITY, 24 SIN MING LANE 573970",Permanent,Senior Executive,3 years exp,"Consulting, Customer Service, Information Technology",Monthly,"$5,000to$12,000","Job Highlights

Work Life Balance, Hybrid Work From Home
Fun Working Environment & Attractive Benefits Package
Career Development Within a MNC Company

Job Description
As the leading analytics provider in APAC and part of our Company's growth, we are looking for dynamic, motivated, and dedicated individuals to be part of our team in Singapore. If you have the right skill set, driven, willing to learn and demonstrates a can-do attitude, come join us ! We welcome candidates of all levels.

Responsibilities
· Deliver end-to-end Business Intelligence, Analytics and Data Management solutions to customer
· Work with the larger team in technical design sessions to define data definition, data and analytics solution requirements and specifications
· Analyse business requirements, designing, developing, testing & supporting application and Data warehouses from build to production (including proof-of-concept)
· Ability to develop test plans and lead testing cycles
· Provide product and application support and maintenance when needed
· Actively participates in defining solution options and selecting the appropriate BI, Analytics and Data Management solution
· Development of ETL pipelines, data management and BI platform
· Ensures appropriate documentation, customer involvement and sign-off
· Develop development framework and assign development effort to team members
· Actively leads and manages team members to a successful project

Requirements
· Diploma/Degree in Computer Science / Computer Engineering / Information Technology related field or IT equivalent
· Have 3 - 5 years’ experience in Business Intelligence/Data Warehouse/Analytics / Big Data Projects involving in requirements gathering designing, development, deployment, conducting knowledge transfer and post deployment support
· Have 3 - 5 years’ experience with ETL, Business Intelligence and Visualization Tools
· Have experience with Data Modelling using dimensional modelling techniques and designing the metadata layer for self-service analytics
· Have experience actively leading and managing a team of 3 to 5 members
· Independent with ability to work effectively in a team and who takes initiative and engages their colleagues
· Excellent communication and interpersonal skills with ability to communicate with clarity and confidence with colleagues and customers
· Likes technology, taking initiative to learn more and share knowledge with juniors and within the team
· Proven abilities to take initiative, innovative and the ability to develop creative solutions for challenging client needs

Additional knowledge it would be great to have:
· SAP related skillsets S/4 HANA, SAP Analytics Cloud, SAP BW
· Cloud and network concepts
· Databases such as MariaDB, MySQL, PostgreSQL
· Programming languages such as Java, Python, ASP.Net with C#.Net or VB.Net
· AWS, Azure or Google Cloud Platform services and products","['Leadership', 'Business Intelligence', 'Data modelling', 'PostgreSQL', 'Azure', 'Big Data', 'AWS', 'MySQL', 'ETL', 'MariaDB', 'SAP HANA', 'SAP', 'ASP.NET', 'Analytics', 'Data Warehouse Architecture', 'VB.NET', 'Communications', 'Java', 'API', 'Databases']"
Business Analyst (Data Migration) | Insurance | Contract,"GUOCO TOWER, 1 WALLICH STREET 078881",Contract,Professional,5 years exp,Information Technology,Monthly,"$12,000to$15,000","Principal responsibilities

Using storyboarding, task analysis, user research tasks and whatever appropriate to capture and develop user requirements
Support and engage with cross functional/business and multi-channel teams with minimum to no direct line responsibility for those individuals
Assisting with the creation and design of process flows, journey maps, etc. that can facilitate the understanding of sales customer journey
Liaising with relevant business teams, technology teams, digital teams, legal, risk and compliance teams, to document requirements, provide design options and recommendations
Identifying opportunities & drive requirement gathering/delivery for approval processing through data automation and workflow automation
Collaborate with developers and subject matter experts in ensuring user stories are developed correctly and meet acceptance criteria
Identify and document scenarios and user acceptance criteria and assist the test manager for the User Acceptance Test completion
Assist the business parties with the change management activities to ensure successful project implementation

Job Requirements

Bachelor's degree in Computer Science or any related discipline
Minimum 5 years of hands-on experience working as BA in either Data migration projects (for Life Insurance)
Hands-on experience working on Life Insurance Policy Admin, good understanding of policy lifecycle & various business processes involved.
Agile methodology and ways of working experience
Ability to build good relationships with stakeholders based on a good understanding of their objectives and the services they require to meet those objectives
Ability to think innovatively to find creative solutions, with a proactive approach to problem solving
Excellent analytical skills and the ability to operate effectively with ambiguous and incomplete data
Experience in developing business case, business requirements, and impact assessments
Awareness of the testing process and experience of performing testing
Experience of process improvement and LEAN thinking methodologies

Interested candidates may send in their resume and cover letter directly to gem.cabria@manpower.com.sg (R1434374), stating the position as the subject title in the email.
Jireli Gem Mejia Cabria | EA License No. 02C3423 | Personnel Registration No. R1434374

Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https://www.manpower.com.sg/privacy-policy

","['Analytical Skills', 'Change Management', 'Process Improvement', 'User Stories', 'Problem Solving', 'Agile Methodology', 'Data Migration', 'Compliance', 'Life Insurance', 'User Research', 'Task Analysis', 'Testing Process', 'Storyboarding', 'Business Requirements']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Scientist - Natural Language Processing,"VISION EXCHANGE, 2 VENTURE DRIVE 608526",Full Time,Executive,3 years exp,Sciences / Laboratory / R&D,Monthly,"$4,000to$8,000","Job Summary:
Biofourmis is looking for Data Scientists in the field of natural language processing (NLP) to join our Data Science team. The ideal candidate should have passion to use healthcare data and advanced machine learning techniques to build services for patients and caregivers. At Biofourmis, we are building end-to-end services that integrate seamlessly into the lives of patients via multiple touchpoints to improve patients’ quality of life and outcomes.
Responsibilities:

Conducting cutting-edge research on NLP algorithms, especially the application in the medical context.
Developing state-of-the-art NLP algorithms in the medical context. Algorithms are designed to extract/categorise/understand key information including doctor’s diagnosis, recommendations, outcome, endpoints from free-form clinical texts (or electronic medical records) which contains acronyms, abbreviations and typing errors.
Documenting clearly on how algorithms have been designed, implemented, verified and validated.

Experience / Training:

Hands on experience in building natural language processing models and tools, including machine learning / deep learning models such as BERT, Transformer-XL, etc.
Knowledge in medical semantic technology; background in or exposure to healthcare data, human physiology or cardiology is preferred.
Publishing papers in top AI conferences or journals is a plus, including but not limited to ACL, NAACL, EMNLP, EACL, ICML, ICLR, NeurIPS, KDD, AAAI, IJCAI, etc.

Education:

PhD in Computer Science, or related fields with strong coding skills.

Skills:

Hands on experience with development of natural language processing solutions including but not limited to semantic analysis, intention recognition, human-machine dialogue, named entity recognition, clustering, etc.
Proficient with natural language processing deep learning architectures, such as BERT, Transformer-XL, GPT2, etc.; Familar with transfer learning and able to modify the underlying logics of those architectures.
Experience with medical NLP in any type of clinical texts (such as electronic medical records) is a plus.
Good research ability and critical thinking skills.
Excellent written and verbal communication skills
","['Machine Learning', 'Product Innovation', 'Natural Language Processing', 'NLTK', 'Healthcare', 'Critical Thinking', 'FMCG', 'Publishing', 'Python', 'Algorithm Design', 'Statistics', 'Data Science', 'Medical Records', 'Django', 'Cardiology']"
Quality Control Engineer (Data Center) (PRIT),"CITY HOUSE, 36 ROBINSON ROAD 068877",Permanent,Senior Executive,4 years exp,Information Technology,Monthly,"$5,000to$7,000","Job Description:
The DC Ops Project QA&QC Engineer will work closely with the implementation and Facilities Engineering team to ensure that all quality assurance/quality control documents for the engineering fit out (EFO) project are handed over smoothly, including drawings, certificates, calibration tests, inspection reports, non-compliance reports, site instructions and observations, asset lists delivered, and other quality assurance/quality control documents.

Establish quality control checklists and procedures for each project to ensure all work is performed in accordance with facility standards.
Maintain a quality program that meets the DC Operations stringent quality requirements.
Review, Witness testing and commissioning of all project with the implementation, operations team and consultant before handing over to the individual site teams.
Ensure that all types of EFO work are carried out according to the approved method statement.
Coordinating, Review, Approve the MOP, RA of all works related to Implementation & Operations team and ensure that all requirements are met, all tasks are completed on time and to the required standards.
Ensure that assessment and related inspections/works are planned, coordinated, conducted, controlled, and liaised with implementation manager.
Establish a regular meeting schedule with individual site DC operations and implementation team to track all project deliverables.
Conduct physical verification of the installed components (Rack ID, Breaker ID, Cee form ID, Power Whips ID, etc.) together with the vendor, implementation team, and DC operations team.
Work closely with implementation team to ensure that DCIM points are enabled for each project, and to ensure that all integrations and DCIM alerts are received at BMS/Email.
Prepare and submit weekly report to Manager Facilities engineering and DCM.

Qualifications:
Bachelor’s degree preferred subjects Electrical or Mechanical Engineering.

Minimum Requirements:

At least 3 - 5years in Data Center building facility operations or data center project or fit out work related experience.
Data center Consultant or Project background will be value added advantage
Knowledge in ACMV and other M&E related systems.
Knowledge on statutory requirements (BCA/ SCDF/ green mark)


Interested candidates, who wish to apply for the above position, please send in your resume to priyanka_tewari@persolkelly.com

We regret to inform that only shortlisted candidates will be contacted.

PERSOLKELLY Singapore Pte Ltd
EA License No. 01C4394
EA Reg No: R1875348 (Tewari Priyanka)
**********************************

By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy available at https://www.persolkelly.com.sg/policies. You acknowledge that you have read, understood, and agree with the Privacy Policy.**********************************","['Construction', 'Quality Control', 'Quality Management', 'Quality Assurance', 'Data Center', 'ISO', 'Assurance', 'Project Quality', 'Electrical', 'Raw Materials', 'Audits', 'Manufacturing', 'Audit', 'Commissioning', 'Mechanical Engineering', 'Calibration']"
"Assistant Laboratory Officer, Laboratory of Systems Biology & Data Analytics, GIS",60 Biopolis 138672,"Contract, Full Time",Professional,1 year exp,Sciences / Laboratory / R&D,Monthly,"$1,900to$3,800","Good communication (verbal and written) and presentation skills
Description:We are a team headed by Dr Matias I Autio, Research Scientist in the Laboratory of Systems Biology & Data Analytics.We are embarking  on a proof-of-concept project to establish a method for generating genome-engineered induced pluripotent stem cells for use in cell therapy. The  project is closely linked with industrial partners and the aim is to translate  the results eventually into the clinic. We are looking for an Assistant Laboratory Officer to support the research activities for the  duration of the project.

Responsibilities:·        
Provide technical and wet-lab support  to the team’s research activities.     
Assist with hands-on experiments and operations to engineer  mammalian cells.
 Follow analytical procedures  and instrumental operation guidelines.       
Perform data collection and manage research data and notes.      
Assist the team with the maintenance of smooth and safe operation in the working environment.        
Ensure project deliverables are met in  a timely manner and to the highest standard.

Requirements: 
Polytechnic diploma in Biological Sciences or Life  Sciences-related discipline.      
Working  knowledge of laboratory-based methodologies such as nucleic acid extraction and basic molecular cloning.      
Experience  with mammalian cell culture and genome  editing is preferred.       
Good organizational skills and ability to multitask.      
Highly motivated, keen to learn and committed to laboratory work.      
Able to work independently and as part of a team.","['Ability to Multitask', 'Systems Biology', 'Molecular Cloning', 'Strong technical skills', 'Cell Culture', 'Biological sciences', 'Presentation Skills', 'Mammalian Cell Culture', 'Laboratory', 'Able To Work Independently']"
 , , , , , , , , , 
Data Management Centre Officer (1-Year Contract),"CERTIS CISCO CENTRE, 20 JALAN AFIFI 409179",Contract,Executive,2 years exp,Admin / Secretarial,Monthly,"$1,800to$2,500","About Certis
We are a leading security services organisation. We put technology to work in making the world a safer place. Our mission is that as trusted partners, we protect lives and assets, and deliver integrated critical services. By empowering our people, our goal is to enable our communities to stay safe and thriving. We offer a broad range of opportunities and career pathways for our people to grow and explore their potential. We believe that people, equipped with innovative thinking and technological capabilities will make the world safer, smarter and better.

Life at Certis
If you are a passionate individual looking for opportunities to expand your skills, and purposeful work instead of just a ‘job’, we would love to hear from you. At Certis, no two days look alike. Our work calendars are filled with chances to collaborate with others, and bring new initiatives to life. Whether you’re looking to improve a process, or have an innovative idea awaiting a technology solve, we want you to bring your ideas to the table. We are a close-knit team that looks out for each other, works hard to get the job done, and encourages each other to grow – the perfect place for you to grow your career!

Responsibilities we will trust you with:

Maintains accurate and updated employees' records in a high volume and fast moving environment of at least 18000 personnel, while in compliance with Service Level Agreement mutually agreed with Business Partners
Maintains the HR system and along with IS, to participate in upgrades of the system
Supports the automation efforts in areas of service design, process improvement and user acceptance testing
Work closely with the Compensation & Benefits Team and as well, IS Team on updates / service request arising from HR Policy changes
Prepare monthly / ad-hoc reports for HR, Business Units and Management Team
Attend to and resolve queries and requests while maintaining a confidential work environment
Liaise with internal and external auditors on employee data and headcount matters
Perform any other tasks as assigned


Your areas of knowledge and expertise that matter most for this role:

A Diploma or equivalent, preferably in Human Resource Management or Information Technology
Preferably with 2 –3 years of HR or business administrative experience in a Shared Service environment
Ability to work under pressure in a fast paced environment
Matured and independent team player, self-motivated and creative with problem-solving skills
Service –oriented mindset coupled with strong communication and interpersonal skills
Knowledge of SAP will be an advantage


What you can expect from us:

Work on projects for world-class security projects renowned for their safety, reliability and efficiency
Commitment to your ongoing development, including on-the-job opportunities, formal programs and assistance with further education
Community volunteering opportunities
A competitive remuneration package, featuring performance-based incentives and a medical insurance and dental allowance
","['Service Design', 'Microsoft Excel', 'Process Improvement', 'Interpersonal Skills', 'Risk Management', 'Information Technology', 'Reliability', 'SAP', 'Human Resource', 'Administrative Support', 'User Acceptance Testing', 'Resource Management', 'Team Player', 'Human Resources']"
Project Admin Executive - Data Science (Permanent),"Peninsula Plaza, 111 North Bridge Road 179098","Permanent, Full Time",Executive,3 years exp,"Admin / Secretarial, Information Technology",Monthly,"$3,500to$5,000","Presently we have a Job Opportunity for a Project Admin Executive position with one of our leading clients in Singapore.

Govt Security Clearance is required for this role: Cat 2A

Location: Depot Road

Job Responsibilities:

Providing support to various projects teams in administrative matters
Asset and budget tracking
Collation of inputs
Providing assistance in procurement matters
Assisting project managers in coordinating project management activities
Any other duties as and when assigned

Job requirements:

Minimum GCE O/ N Level with an NCC Education Diploma in Computer Studies
At least 1 year of relevant experience
Proficient with MS Office Productivity tools like Word, Excel, Powerpoint
Ability to carry out simple reporting and data analysis
Enjoy meeting people and a team player
Has a strong sense of purpose to bring an enjoyable and positive work environment experience to the Office premises
Knowledge and interest in Data Science/Data Analytics platform will be an advantage


Interested candidates, kindly email your updated CV/resume in Word format to vanessa@zenithinfotech.com.sg, indicating your expected salary and notice period. Only shortlisted applicants will be notified.","['Strategic Planning', 'Microsoft PowerPoint', 'Budgets', 'Microsoft Office', 'Microsoft Excel', 'Data Analysis', 'Positive Team Player', 'Procurement', 'Collate data', 'PowerPoint', 'Office Administration', 'Project Management', 'Reporting', 'Project Coordination', 'Microsoft Word', 'Scheduling', 'Oral & Written Communication Skills']"
Vice President / Assistant Vice President - Data Analytics,"ASIA SQUARE TOWER 2, 12 MARINA VIEW 018961",Permanent,Professional,10 years exp,Banking and Finance,Monthly,"$6,500to$11,000","Job Description:
1. Lead Business Analytics team for Transaction Banking in Asia Oceania region in line with business strategies & KPI
2. Application of transaction banking business knowledge and experience on formulating data driven actionable insights for Sales promotion
3. Ensuring discovery, consolidation and distribution of data from internal & external sources for meaningful business insights to pursue.
4. Timely preparation and delivery of relevant reports, visualisation & dashboards by country, product, sub product etc.
5. Continuous effort on review of existing reports/data for management and for country teams in automating them to increase efficiency & productivity
6. Work closely with management, internal stakeholders & others on market or event driven insights

Job Requirements:
1. Experience in working with huge dataset
2. Knowledge of database structures and tools such as SAS, Tableau, Power BI, SQL & Python
3. Good understanding and experience in Transaction Banking business in the region
4. Understanding of data related to transaction banking business, including common data taxonomies/terminologies
5. Ability to coach & mentor junior staff on Analytics, Tableau & Python etc.","['Tableau', 'Microsoft Excel', 'Consolidation', 'Risk Management', 'Transaction Banking', 'SQL', 'Python', 'Business Analytics', 'Integrated Marketing', 'Scheduling', 'Hotel Management', 'Power BI', 'Financial Services', 'Brand Awareness']"
"Associate, Data Operations (Investment firm)","TWENTY ANSON, 20 ANSON ROAD 079912","Contract, Full Time",Non-executive,2 years exp,Banking and Finance,Monthly,"$5,000to$7,500","
Rare opportunity
Established investment firm
Opportunity for growth

An opportunity has come up with a reputable investment firm for an Associate, Data Operations (2-year contract).
The successful candidate will support the public markets function in business data operations. You will be a key person to enhance the Standard Settlement Instructions for the firm – static data setup, work with key business stakeholders to act as a data steward for SSI services and participate in the implantation of SSI and product roadmap.
The ideal candidate comes with at least 2 years experience in asset management/fund management/financial services background, with experience in settlements/payments. Candidates with experience in DTSS OC and SWIFT will be highly considered. Good knowledge of financial instruments and strong communication skills a pre-requisite as you will need to liaise with key business stakeholders.

Applicants who are keen please send across your updated CV to Rachel.ljy@ethosbc.com or click on the link to apply. Thank you and look forward to speaking with you!
Reg No. R1987809 
BeathChapman Pte Ltd 
Licence no. 16S8112
","['Account Management', 'Microsoft Excel', 'Operations', 'Investments', 'Investment Banking', 'Account Banking', 'Funding', 'investment strategy', 'Communication Skills', 'Data']"
IT Senior Data Mgt Engineer,81 PASIR RIS INDUSTRIAL DRIVE 1 518220,Full Time,Executive,5 years exp,"Information Technology, Manufacturing",Monthly,"$5,000to$5,800","The person will join our Dynamic IT team to support our factory in its ramp up.

Under the responsibility of the Singapore IT HOD, the IT Senior Data Mgt Engineer will have to:
- Analyze the users requests (changes & projects) and incidents
- Define the best solution (JMP, PowerBI, etc) and implement it
- Manage the obsolescence of the legacy reports/solutions
- Interact with the rest of Singapore IT team (CIM, Business Apps) and the teams in France (functional and technical alignment, experience sharing, common corporate projects like the AWS datalake design)
- Study and implement innovative solutions with our experts and/or external partners around Machine learning, AI and image recognition
This will require autonomy, good relationship and a strong quality culture as well as the ability to understand the constraints of our environment and the specificities of the semiconductor industry.
The job is based in our Semiconductor factory in Pasir Ris (Singapore) and requires close work with people located in our headquarters in France.

SKILLS AND QUALIFICATIONS
• Senior IT engineer
• Recommended technical skills: Oracle/DB2 SQL, JMP, PowerBI, Talend, Python
• Nice to have: experience in Machine learning, AI and image recognition, AWS Cloud solutions (SageMaker, etc), Delphi, ASP, BO
• Highly organized, practical, analytical and detail oriented
• Ability to multi-task, prioritize tasks, make critical decisions
• Ability to work productively with frequent interruptions
• Flexible schedule","['Machine Learning', 'JMP', 'Factory', 'Clinical Research', 'Autonomy', 'Pipelines', 'Data Center', 'Delphi', 'Semiconductor Industry', 'SageMaker', 'Clinical Data Management', 'PowerBI', 'SQL', 'ASP', 'Python']"
CMI / DATA / DRR - Senior Developer 2387,20 Pasir Panjang Road 117439,Contract,Executive,6 years exp,"Banking and Finance, Information Technology",Monthly,"$6,000to$10,000","Mission Context: Data Framework Project
The Data Framework provides a central data store for all the Front Office Orders, RFQs, Transactions and Collateral information.  It also provides Market Data sourcing, Data distribution, client, instrument and referential data and is driven by an electronic Data Dictionary application : Collibra.It acts as a source of data for different regulatory reportings (MIFID 2 , SFTR , MAR etc). The Data Framework team is looking for a development expert on big data technologies to evolve the platform to ingest market data, RFQ (Cross Asset) and distribute data via APIs. The project milestones are   ambitious and challenging. The position is ideal for someone with a strong interest in data processing and data science.

Qualifications and Profile
An ideal Candidate should have

At least 6 years of software development experience with at least 4 years’ experience working with Java
A strong understanding of recent Java language features.
Good knowledge of algorithms and data structures, with strong fundamentals in complexity analysis
Strong ability to analyze code – understand execution flow & debug even without access to a        debugger
Experience with Maven, Git, writing and maintaining unit/integration tests
At least 5 years of experience with Sql Server or any other RDBM
Experience in database performance tuning and optimizations

The candidate would need to possess the below skills/expertise

Java 8 development with multi-threading principles, good knowledge of Java data structure and objects.
Apache Storm/Flink/Spark
Knowledge on AWS is good to have.
Parrallel processing of the message transformation pipeline to fPML, Json and key/value
Experience of working with large scale Sql Server database
Kafka publishing/distribution primarily + MQ (optional)
Microservices based technology. Defining APIs and registering APIs in the service catalogue.
Systematic dictionarization of services in Collibra good to have.
APIs and functions, taxonomy of attributes in intefaces (Swagger)
Experence in Performance Tuning and optimizations
Experience with Jira/other issue tracking system.
Agile methodology(Scrum/Kanban)

Other Professional Skills and Mind-set

Excellent communication (wriiten and verbal) and interpersonal skills across all levels with        demonstrated ability to influence different stakeholders.
Strong analytical and problem solving skills
Proficient in software development life cycle
Autonomy to include implicit deliverables in assignment based on best practices
Appetite to participate to technical market trends and communities
Strong sense of confidentiality

Interested applicants, please email your resume to Shaun Quek Yew Meng
Email: shaunquek@recruitexpress.com.sg
CEI Reg No: R1660732
EA Licence No: 99C4599","['Apache Storm', 'Git', 'JSON', 'Apache Spark', 'Kanban', 'AWS', 'Agile Methodologies', 'Software Development Life Cycle', 'Maven', 'SQL Server', 'RDBMS', 'Performance Tuning', 'Software Development']"
Director - Portfolio Management (Data Centre Fund),"SAMSUNG HUB, 3 CHURCH STREET 049483","Permanent, Full Time",Senior Management,10 years exp,"Banking and Finance, Real Estate / Property Management",Monthly,"$12,000to$14,000","We are recruiting for a Director – Portfolio management with a dedicated Data Centre (DC) fund.
You will be responsible for (1) reporting, (2) asset management and (3) portfolio management.
These will include:

Providing annual and quarterly updates and reports on fund performance, investment and divestment opportunities, organize and present supporting materials for investment analysis. You will liaise with various business teams across the group to ensure coordinated initiatives and messaging, prepare written reports and make presentations to the relevant management levels for approval as well as assisting in the annual budget and annual business planning process, including formulating asset level strategies to maximize returns to the fund.

You will also assist in overseeing performance of assets by analyzing asset performance vs. market benchmarks, managing partner relationships which involves the regular review of tenancy mix, asset positioning and implementation of effective marketing plans and control of operating expenses to maximize net operating income from assets, prepare monthly/ quarterly /annual portfolio reports. This covers financial performance, leasing/sales status etc.

You will be monitoring existing investments and perform regular reporting functions including understanding of annual business plans for assets under management as well as monthly asset management reports to investors.

Requirements

Degree in Real Estate / Finance / Accountancy / Commerce / Business Administration from leading university, preferably with good quantitative skills and a foundation in finance and financial analysis.
At least 10 years of work experience in the Private Equity, Investor Relations or Portfolio Management related function
Possess excellent verbal, written communication and proofreading skills
Strong attention to detail, excellent organisational skills and the ability to handle multiple assignments and deadlines

All applications will be treated in the strictest confidence. Personal data provided will be used for recruitment purposes only.

Please apply with your CV in word document format. We regret to inform that only shortlisted candidates will be notified. For other positions related to real estate, please go to https://careers.tri-cap.com.sg/.

EA Licence: 17C8777
​EA Personnel: R1109270","['Asset Management', 'Microsoft Excel', 'Strong Attention To Detail', 'Investment Analysis', 'Recruiting', 'Investments', 'Private Equity', 'Risk Management', 'Administration', 'Written Communication', 'Business Planning', 'Portfolio Management', 'Investor Relations', 'Financial Analysis', 'Real Estate', 'Proofreading']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"Executive  /  Senior Executive, ESM Data Coordinator - 1-year agency contract","Pacific Tech Centre, 1  Jalan Kilang Timor 159303","Temporary, Contract",Junior Executive,2 years exp,Information Technology,Monthly,"$4,000to$4,500","Office Location: Pacific Tech Centre, 1 Jalan Kilang Timor, Singapore 159303

You will be required to perform the below job responsibilities, depending on which functional areas you will be allocated to (but not limited to) - 

Responsibilities:
Data Migration

Experience with data migration (from source legacy system to target system)
Understands data objects/structures (master data, transaction data) in the relevant functional area
Coach and explain to users on the data, the dependencies and impact on transactions and operations when relevant
Guide users in cleansing, preparing and enriching data in designated data templates. Getting data ready for uploads.
Guide users in validating migrated data

Project Implementation (required for Dynamics 365 and a plus for other functional areas)

Implementation of Dynamics 365 CRM (SAP & Anacle a plus)
Understand business requirements, design process blueprint, configure system and execute testing, deployment

Other job responsibilities

Coordinates data preparation (master and transaction data) for on-boarding and divestment of properties
Facilitates end-user training sessions to improve staff performance capability
Assists in the updating of Process blueprints, Technical & Functional specs and Training Materials
Generation of process KPIs and performance reports
Monitor and report progress
Assist with other project implementation activities where required


Requirements:

Candidate should possess a Diploma/Bachelor Degree in IT, ERP or Accountancy or other Business-IT disciplines.
Candidate should have at least 2 - 3 years of hands-on, working experience in implementing or supporting applications. 
Prior experience in SAP/Anacle/Dynamics 365 project implementation/rollout/SNP CrystalBridge will be advantageous. 
Candidate should have good analytical and interpersonal skills.
Good with Excel, macros, SQL queries and formulas.


Closing Statement:
At CapitaLand, we advocate fair employment practices, and recruit talents based on merit and fit with our Corporate values. We provide equal opportunity for all qualified persons and build an inclusive workplace regardless of race, gender, age, religious belief or nationality.

Only shortlisted candidates will be notified.","['CRM', 'Microsoft Office', 'Microsoft Excel', 'Analytical Skills', 'Dynamics', 'Interpersonal Skills', 'ERP', 'Administration', 'SQL', 'Data Migration', 'Project Management', 'Advocate', 'Team Player', 'Able To Work Independently', 'Business Requirements']"
 , , , , , , , , , 
"Data Strategy and Transformation (Financial Services) Senior Consultant, Tech Consulting",1 RAFFLES QUAY 048583,"Permanent, Full Time",Senior Executive,3 years exp,"Banking and Finance, Consulting, Insurance",Monthly,"$6,000to$12,000","We are the only professional services organization who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.

The opportunity
With our Data & Analytics team in FSO experiencing rapid growth, now is an exciting time to join us on this journey. We are looking for talent with a passion for data and the know-how to partner with our to clients to disrupt and transform Financial Services organisations. Whether you are a Consultant at the start of your career or a Manager looking for the next opportunity, if you want to make a difference by developing leading data and technology strategies and helping to solve our clients’ most pressing data challenges, we would love to hear from you.

Your key responsibilities
· Design the execution of our clients’ transformation programs to support their transition towards a data-driven organisation, with data and people at the heart of change.
· Bring to life a seamless data and analytics strategy that solve our clients’ most complex business challenges to enable the making of better-informed decisions.
· Design and implement data and technology operating models that encompass people, process, technology, and data.
· Leverage data platforms and solutions to help our clients visualise and better understand their data.
· Provide thought leadership on how our clients can innovate with traditional or emerging technology tools and disrupt their current ways of working to extract greater value from their input.
· Lead and support the creation of client proposals and business development initiatives.

Skills and attributes for success
· Understand how data strategies are created and implemented.
· Passion for designing large, multi-year data transformations with people at the centre of change.
· Passion for solving big complex problems using data and technology
· Working with diverse and inclusive teams of talented people solving client issues.
· Build strong, meaningful relationships with client stakeholders.
· Work as a team player to support other team members by sharing your knowledge, experience, and skillsets.

To qualify for the role, you must have
· Minimum 3 years’ experience in Financial Services (either industry or consulting and appropriate to your level). Preferably a year of consulting experience in any of the Big 4 or consulting firms.
· Experience in data and analytics approaches such as data mesh.

What we look for
Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.

What we offer
· Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
· Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way
· Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
· Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.

If you can demonstrate that you meet the criteria above, please contact us as soon as possible.

The exceptional EY experience. It’s yours to build.

Apply now.","['Management Consulting', 'Asset Management', 'Data Analysis', 'Big Data', 'Emerging Technology', 'Tax', 'Data Management', 'Private Equity', 'Capital Markets', 'Project Management', 'Banking', 'Data Science', 'Consulting', 'Big 4', 'Business Development', 'Data Analytics', 'Professional Services', 'Insurance', 'Financial Services']"
1 Year Data Analyst (Local Bank) #BBZ,"NGEE ANN CITY, 391A ORCHARD ROAD 238873","Contract, Full Time",Executive,2 years exp,Banking and Finance,Monthly,"$3,800to$5,000","Job Scope:

Data transformation and integration from diverse data sources
Translate data into insights to be able to answer business questions
Build predictive models to extrapolate missing information of data and exploit various data mining opportunity
Coordinate with various internal and external business stakeholders across multiple key business sectors to ensure delivery of projects
Assist in any work or/and projects as assigned

Job Requirements:

Good data skills such as Excel is compulsory. Programming skills (eg. Python) and Machine Learning capability is a plus.
Good slides / PPT skills is ideal.
Meticulous, inquisitive, proactive and able to initiate and bring along extra values beyond BAU
Independent worker with good communication and interpersonal skills to effectively interact with colleagues and external parties of all levels
Desktop/online research capacity and experience



Interested applicant, kindly send your detailed resume to jerlinaw@recruitexpress.com.sg


CEI no.: Jerlin Aw Bi Zhi (R1218675)
Recruit Express Pte Ltd
EA Licence no.: 99C4599","['Tableau', 'Machine Learning', 'Data Analysis', 'Big Data', 'Interpersonal Skills', 'Data Transformation', 'Data Quality', 'Data Mining', 'SQL', 'Python', 'Excel', 'Ms Powerpoint', 'Statistics', 'Data Science', 'Power BI']"
 , , , , , , , , , 
 , , , , , , , , , 
PAYROLL ASST @ Jurong East (5Days / $3000 / +AWS / +Bonus / Payroll Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,500to$3,000","PAYROLL ASST

5 Days

Monday to Friday

8:30am - 5:30pm

$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :
Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for Payroll Asst @ Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
PAYROLL ASST @ Jurong East (5Days / $3000 / +AWS / +Bonus / Payroll Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,500to$3,000","PAYROLL ASST

5 Days

Monday to Friday

8:30am - 5:30pm

$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :
Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for Payroll Asst @ Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
PAYROLL ASST @ Jurong East (5Days / $3000 / +AWS / +Bonus / Payroll Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,500to$3,000","PAYROLL ASST

5 Days

Monday to Friday

8:30am - 5:30pm

$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :
Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for Payroll Asst @ Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
 , , , , , , , , , 
ACCOUNTS ASST (PAYROLL) @ Jurong East (5Days / $3000 / +AWS / +Bonus / Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,500to$3,000","ACCOUNTS ASST (Doing Payroll)

5 Days

Monday to Friday

8:30am - 5:30pm

$2500-$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences or Accounts Asst experience

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other basic hr duties

For Application :

Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for Accounts Asst (Payroll) @ Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
ACCOUNTS ASST (PAYROLL) @ Jurong East (5Days / $3000 / +AWS / +Bonus / Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,700to$3,000","ACCOUNTS ASST (Doing Payroll)

5 Days

Monday to Friday

8:30am - 5:30pm

$2500-$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences or Accounts Asst experience

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other basic hr duties

For Application :

Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for Accounts Asst (Payroll) @ Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
HUMAN RESOURCE ASST (PAYROLL) @ Jurong East (5Days / $3000 / +AWS / +Bonus / Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,500to$3,000","HR ASST (PAYROLL)

5 Days

Monday to Friday

8:30am - 5:30pm

$2500-$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :

Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for HR Asst at Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
HUMAN RESOURCE ASST (PAYROLL) @ Jurong East (5Days / $3000 / +AWS / +Bonus / Data Entry),"PENINSULA PLAZA, 111 NORTH BRIDGE ROAD 179098",Permanent,Junior Executive,1 year exp,Human Resources,Monthly,"$2,500to$3,000","HR ASST (PAYROLL)

5 Days

Monday to Friday

8:30am - 5:30pm

$2500-$3000*

AWS

Variable Bonus

Jurong East

Tradehub 21

Nearest MRT : Jurong East MRT

Paymaster

Pleasant personality

Able to work in a team

Looking for candidates with minimum 6 mths Payroll data entry experiences

Mature candidates welcome

Jobscope :
Data entry of 700 payroll details and other general hr duties

For Application :

Pls apply here or email to diana@aahr.com.sg

Pls indicate inside the resume :
1.Personal Particulars
2.Last Drawn Salary
3.Expected Salary
4.Notice Period
5.Reasons for leaving
6.Photo/Selfie

Email Subject : Apply for HR Asst at Jurong East","['Microsoft Excel', 'Administration', 'Payroll', 'Data Entry', 'Accounting', 'Attention to Detail', 'Communication Skills', 'HRIS', 'Team Player', 'Microsoft Word']"
Community Researcher (CRM & Data Analyst),"STAMFORD COURT, 61 STAMFORD ROAD 178892",Full Time,Professional,3 years exp,Professional Services,Monthly,"$4,000to$7,000","My Community is a non-profit organisation which conducts community-based participatory research and heritage assessments; establishes community museums, archives and libraries; organises participatory programmes and guided tours; and cocreate community architecture and urban spaces. We seek to preserve our social memories, celebrate our shared culture and heritage and champion greater community involvement in cultural management and urban governance.

Before we were formally registered as a society on 26 August 2010, we started engaging the Queenstown community through befriending in 2006, organising guided tours in 2008 and blogging in 2009. On 12 December 2015, My Community was registered as a charity under the Charities Act. We were then recognised as an Institution of Public Character on 13 December 2016.

Today, My Community boasts almost 500 volunteers. Our first community museum in Queenstown was opened on 31 December 2018.

Job Description

A passionate and meticulous community researcher who is keen to work with community stakeholders to develop a community-based participatory research model based on integrating quantitative and qualitative data
Develop, administer and maintain My Community's Customer Relationship Management (CRM) system (Salesforce) and GIS resources (ArcGIS)
Conceptualise, coordinate and execute mixed method research (MMR) including surveys, oral history interviews, community mapping, focus group discussion.
Gather and intepret information 
Administer Salesforce and volunteer management system
Digitise, create, maintain and update GIS databases and produce accurate maps and other representation of data for public use and field work activity.
Use geoprocessing tools and spatial data analysis to document, explore and investigate the relationship between people and places.
Conceptualise, coordinate and prepare community-based research reports and documentation projects.
Communicate the research findings and recommendations to community stakeholders.

Requirements

Keen interest in interacting with the community (residents, shopkeepers, students, diverse stakeholders and partners) on arts, culture and heritage.
Bachelor’s or Master’s Degree in Quantitative and Qualitatively Research Methods, Arts/Cultural Management, Urban Planning, Urban Science/Policy or equivalent.
Minimum 3 to 5 years of relevant work experience in the urban planning/policy, heritage, construction industry or equivalent.
Proficient with Salesforce.
Familiar with spatial and statistical analysis and interactive data visualisation.
Familiar with ArcGIS with extensions Network Analyst, 3D Analyst and Spatial Analyst or open-source software including AutoDesk, AutoCAD, QGIS, Grass and PCI
Proficient with data collection and programming tools  for both quantitative and qualitative research including R, Python, SPSS, Excel or equivalent.
Ability to use data collection devices including tile, audio recorder, camcorder and GPS-enabled applications.
Ability to conceptualise, organise and conduct oral history interviews, focus group discussions, cultural mapping and other community-based research methodologies.
Excellent interpersonal, leadership and time-management skills
Proficient in English and a national language (Chinese, Tamil or Malay). Ability to communicate in dialects is an advantage.
Ability to work independently as well as in a team and effectively under pressure in multiple projects to meet tight deadlines.
","['Ability to Multitask', 'Community Outreach', 'Museum Education', 'Archives', 'Change Management', 'Information Management', 'Urban Planning', 'Customer Relationship Management', 'Vendor Management', 'ArcGIS', 'Museum Collections', 'Oral History', 'Excel', 'Volunteer Management', 'Design Education', 'Salesforce Administrator', 'Cultural Heritage']"
 , , , , , , , , , 
 , , , , , , , , , 
"Senior Manager (Data Scientist), AIO Biomedical Informatics Office (JR3636)",1E KENT RIDGE ROAD 119228,Contract,Manager,6 years exp,Others,Monthly,"$5,800to$9,500","Join the NUHS Group Chief Technology Office (GCTO) that advocates flexible and innovative working culture. Successful candidate will be part of a team of Data Scientists and Software Developers who partner clinicians to propose, develop, and implement advanced Artificial Intelligence / machine learning models and pipelines to augment clinical workflows in NUHS cluster. The candidate will also ensure the adequacy and effectiveness of the models and tools for NUHS.
You will be responsible for the following:

Research and development of machine learning models in various clinical areas such as clinical notes, medical images, and patients’ data
Research and development of neural network models to analyze free text and identifying, categorizing opinions expressed in a piece of text
Work with the team to design and architect the workflow of the data and algorithms including data input, output and storage between various health IT systems
Work with the team to develop and deploy necessary AI models for NUHS in-house chatbot framework in hybrid cloud environment
Optimize data analysis processes and systems for better efficiency and maintenance
Document clearly explaining how algorithms have been implemented, verified and validated
Lead project team to deliver AI related research and development requirement to meet the business need

Requirements

Minimum Bachelor’s degree in computer science or related fields with strong statistical modelling and machine learning skills. Graduate degree in related fields is preferred
6 years of hands-on experience in the development of end-to-end data analytics solutions and machine learning pipeline including data exploration/extraction/crawling, data processing, and model building
Hands-on experience on development of AI models in NLP
Proficient with programming in Python and AI related frameworks such as Scikit-Learn, TensorFlow, and PyTorch
Knowledge and experience in machine learning platform and services from cloud providers such as AWS, GCP, Azure
Familiarity with healthcare data, medical image is a plus
Experience in leading AI projects and virtual team
Strong problem-solving skills with the ability to work independently and in a team
Excellent written and verbal communication skills, including the ability to communicate technically and non-technically with ability to translate between the two
","['TensorFlow', 'Machine Learning', 'Data Analysis', 'Azure', 'Ability To Work Independently', 'Pipelines', 'Architect', 'Healthcare', 'Artificial Intelligence', 'Research and Development', 'PyTorch', 'Python', 'GCP', 'Data Analytics']"
IT Senior Data Mgt Engineer,81 PASIR RIS INDUSTRIAL DRIVE 1 518220,Full Time,Executive,5 years exp,"Information Technology, Manufacturing",Monthly,"$5,000to$5,800","The person will join our Dynamic IT team to support our factory in its ramp up.

Under the responsibility of the Singapore IT HOD, the IT Senior Data Mgt Engineer will have to:
- Analyze the users requests (changes & projects) and incidents
- Define the best solution (JMP, PowerBI, etc) and implement it
- Manage the obsolescence of the legacy reports/solutions
- Interact with the rest of Singapore IT team (CIM, Business Apps) and the teams in France (functional and technical alignment, experience sharing, common corporate projects like the AWS datalake design)
- Study and implement innovative solutions with our experts and/or external partners around Machine learning, AI and image recognition
This will require autonomy, good relationship and a strong quality culture as well as the ability to understand the constraints of our environment and the specificities of the semiconductor industry.
The job is based in our Semiconductor factory in Pasir Ris (Singapore) and requires close work with people located in our headquarters in France.

SKILLS AND QUALIFICATIONS
• Senior IT engineer
• Recommended technical skills: Oracle/DB2 SQL, JMP, PowerBI, Talend, Python
• Nice to have: experience in Machine learning, AI and image recognition, AWS Cloud solutions (SageMaker, etc), Delphi, ASP, BO
• Highly organized, practical, analytical and detail oriented
• Ability to multi-task, prioritize tasks, make critical decisions
• Ability to work productively with frequent interruptions
• Flexible schedule","['Machine Learning', 'JMP', 'Factory', 'Autonomy', 'Data Center', 'Delphi', 'Semiconductor Industry', 'SageMaker', 'Clinical Data Management', 'PowerBI', 'SQL', 'ASP', 'Python']"
Data Processing Clerk in Geotechnical Instrumentation & Monitoring,"WIN 5, 15 YISHUN INDUSTRIAL STREET 1 768091",Full Time,Executive,1 year exp,Admin / Secretarial,Monthly,"$1,600to$1,800","- Assisting instrumentation engineer in daily data entry
- Data processing via software
- Report preparation and submission
- Documentation and filing of hardcopy records; 
- Preparation of daily, weekly and monthly data reports
- Proper maintenance of databases
- Computer data backup; and coordinating among colleagues to ensure that data are available and to validate error data
- Must be proficient in Microsoft Excel
- Good organization skill
","['organisation skills', 'Microsoft Office', 'Microsoft Excel', 'Quality Control', 'Information Technology', 'Data Entry', 'Accountability', 'Communication Skills', 'Administrative Support', 'Microsoft Word', 'Customer Service', 'Scheduling', 'Databases']"
"ELV Manager (Security, PA, AV & IT / DATA)","WOODLANDS BIZHUB, 190 WOODLANDS INDUSTRIAL PARK E5 757516","Permanent, Full Time",Manager,5 years exp,"Building and Construction, Engineering",Monthly,"$5,000to$9,000","Responsibilities:
·      Assist the Project Manager to plan, control, co-ordinate and oversee the construction of factory and infra-structure associated.
·      Lead role in managing the sub-contractors for the task at the project site.
·      Involve in the thorough review of method statements and risk assessment and technical submissions for Client’s approval.
·      Responsible for the safety, quality, progress and environment impact of the works.
·      Site project management.
·      Daily site activities planning, preparing work breakdown, daily site operations, site coordination, monitoring and reporting work progress.
·      Work closely with project the project team on the progress and ensure timely work arrangements
·      Ensure that all the works are executed in accordance with approved Method Statement, Safety Procedure and Quality Methods.
·      Liaise with the client and carry out site inspection.
·      Attend weekly or monthly meeting with main-con on work progression and prepare monthly meeting progression report.
·      In charge of the inspection of works and necessary approval by client side if required.
·      Ensure site safety & compliance to authorities’ requirements.
Requirements:
·      Minimum Bachelor degree in Civil Engineering or related field
·      Minimum 5 years in the M&E or ELV industry
·      Understanding of all aspects of the construction process including building products, construction details and relevant rules, regulations, and quality standards
·      Competent in conflict and crisis management
·      Leadership and people management skills
·      Excellent time and project management skills
·      Proficient in MS Office, or etc","['Management Skills', 'Factory', 'Leadership', 'Construction', 'Risk Assessment', 'MS Office', 'Compliance', 'Project Management', 'Crisis Management', 'Civil Engineering', 'Conflict', 'People Management']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Information Technology - Senior Data Sciences & Analytics Engineer (Analytics Engineering Track),"TechSQ, 722 Upper Changi Road East 486854","Permanent, Full Time",Professional,3 years exp,Information Technology,Monthly,"$5,500to$11,000","Job Description

We have multiple senior data engineering positions available. The Data Analytics Engineer is responsible for designing and developing robust, scalable data pipelines, data marts and business intelligence dashboards to be used across Singapore Airlines Group.

Key Responsibilities:

Understand business processes, applications and how data is created, stored and gathered in Singapore Airlines.
Use big data tools and platforms to create and maintain data pipelines, making sure pipelines are robust, scalable, and reliable. Troubleshoot and rectify issues with data pipelines as necessary.
Build expertise and domain knowledge on the data. Establish and own the data quality and SLA for various data flows.
Explore, analyse, and aggregate various types of data to provide business insights to the data team stakeholders. Create compelling story and visualisation to convey these insights. Ask right and inquisitive questions of the data to deliver analytics solution to the business.
Design, build and manage data marts to satisfy our growing data needs.
Any other ad-hoc duties.
This is an individual contributor role.
Note: You could be posted to any subsidiary in SIA Group.

Requirements

BS degree in Computer Science or a related technical field. MS or PhD degree is a plus.
Python development experience in production environment is required.
More than 2 years of SQL (such as PostgreSQL, Oracle, AWS Redshift, GCP Big Query, or Hive) experience is required. NoSQL experience is a plus.
More than 2 years working with Linux OS. Knowledge of networks and cybersecurity is a plus.
Experience working with infrastructure-as-code systems like AWS CloudFormation. DevOps, AWS and GCP experience is a plus.
Experience in working with a commercial ETL tools like Ab Initio and Talend would be a plus.
Experience in ETL pipeline design, implementation and maintenance.
Experience working with visualization tools (specifically Tableau would be preferred).
Ability in analysing data to identify deliverables, gaps and inconsistencies.
Ability in managing and communicating data mart plans to internal customers.
","['Tableau', 'Business Intelligence', 'Oracle', 'PostgreSQL', 'Big Data', 'Pipelines', 'ETL', 'Data Quality', 'Data Engineering', 'SQL', 'Python', 'GCP', 'Visualization', 'Data Analytics', 'Linux']"
MT10720 - Data Center Project Engineer,"20 COLLYER QUAY, 20 COLLYER QUAY 049319",Full Time,Professional,1 year exp,Information Technology,Monthly,"$3,500to$5,500","Data Center Project Engineer

ITCS Group is an IT Managed Services, Outsourcing and Talent-Sourcing company. We provide customised IT Consulting Solutions, Project Management, IT resourcing and on/off-shore Application Development Services across the Asia Pacific region. With offices strategically located in Hong Kong, Tokyo, Singapore, Sydney, and Mumbai. ITCS Group is the preferred technology partner for leading MNCs, including Global Investment Banks, Fortune 500 companies, across Asia Pacific. 
 
We are currently looking for a Data Center Project Engineer to join our banking and financial team in Singapore to support Data Center Services end-to-end project team.

Responsibilities:
- Coordination with internal teams and external vendors
- Assist structured cabling design in IT rooms and work with vendors on the implementation
- Manage purchase requests required for projects i.e., obtain and review quotations, approval for purchase, submission of purchase requests
- Coordinating tasks required for the project i.e., site access, delivery, installations
- Provide onsite support for installations and physical inspection to ensure quality of work
- Maintaining of project reports, records, documentations

Requirements:
- Knowledge in Data Center operations or implementations, or related experience
- Formal project management training or certifications is a plus

Additional Information:
- Location: HarbourFront
- Working hours: Regular working hours","['Managed Services', 'Outsourcing', 'Data Center', 'Purchasing', 'Application Development', 'Procurement', 'Project Management', 'Banking', 'Consulting', 'Cabling']"
 , , , , , , , , , 
"Director Sales / Business Development - Data, Valuations & Analytics","MARINA BAY FINANCIAL CENTRE, 12 MARINA BOULEVARD 018982",Permanent,Middle Management,6 years exp,Information Technology,Monthly,"$16,000to$22,000","Job Description
Department overview:
Sales specialist is a key function within S&P Global Market Intelligent with responsibility for client-facing activity including all aspects of business development for its specialist product line and region. The primary focus is placed on new business sales, renewing of existing business and enabling the roll-out of new products and services.
Position summary
This role will have responsibility for promoting the S&P Global Data, Valuations and Analytics product - fixed income pricing, OTC derivatives, valuations, Security Finance, Research Signals, Dividends Forecasting, Trade Cost Analysis, Indices & ETF benchmarking solutions suite of services across Singapore and other parts of South East Asia (SEA). This role will partner with S&P Global account management teams to leverage distribution partnerships to win new business from financial institutions
Duties & accountabilities
The candidate will work as the main driver of revenue acquisition across assigned accounts and product lines and will ensure that the business goals are achieved. The candidate will work within the Fixed income pricing and valuation sales team and work closely with other sales & account managers, business development teams and data support teams. Specifically duties & responsibilities include:

Generation of lead pipeline for new business and existing clients
Renewal of existing business within defined accounts
Reporting of actual vs. budgeted sales on a regular basis and accurate forecasting
Maintaining communication with accounts by being in regular contact with key users and building a position of trust, respect and openness with the view to generating new business
Listen and identify the client’s needs and highlight any cross selling opportunities to relevant Sales specialist team. For multi-product opportunities, coordinate the relevant sales specialists to deliver the client solution
Proactively seek sales referrals from existing accounts
Take ownership of client issues with the assistance of the data and business development teams
Maintain pipeline and generate management reports (cold calls list, user list etc.) from Salesforce
Delegate non-revenue opportunity related activities (billing, initial and on-going client set up and training, contractual administration duties etc.) to relevant support teams
Take responsibility for keeping IHS Markit products knowledge to a high standard for defined product area and to a referral standard for IHS Markit’s other product lines, remaining aware of developments
Act as a point person for allocated products providing support to clients, technical information, product characteristics, coaching sales peers in terms of sales USPs and pre sales questioning
Actively participate and drive activities such as sales conferences and special events, sales collateral production, client entertainment, association memberships to maximize sales revenue and retention

Education and experience

Candidates are likely to be degree educated
Candidates will have significant proven sales experience which will ideally have been gained from a data, financial software or banking background
Recent experience selling in to SEA financial institutions
Fixed income and/or OTC derivative knowledge is strongly desired
Understanding of the Security Finance eco system would be an advantage
Strong inter-personal and influencing skills
Strong organisational skills with the ability to manage multiple sales in parallel whilst maintaining excellent attention to detail
Proven track record in generating own pipeline from cold calls
Ability to meet internal/external deadlines
Ability to listen, learn quickly and demonstrate initiative
Ability to present and negotiate with senior level management and manage complex sales process
Willingness to cover accounts within SEA region
Advanced working knowledge of Microsoft Office programmes; Outlook / Word / Excel / Powerpoint
Knowledge of Salesforce is beneficial

Commercial Awareness

Able understand the end to end sales process and be comfortable and experienced in dealing with senior level negotiations
Able to demonstrate interest in staying abreast of industry developments and regulatory developments

Personal Competencies

Must be credible and confident in a high pressure environment and be able to manage senior level meetings
Displays a resilient and adaptable style, track record of remaining calm in demanding circumstances, adjusting comfortably to changing conditions / priorities

Communication

Good communication skills both written and verbal required for complex commercial and business discussions
Fluency in English essential. Fluency in another SEA language preferred

Teamwork

Works collaboratively with others to achieve group goals and objectives.
Team player and willing to progress in a rapidly  changing environment
","['Outlook', 'Account Management', 'Forecasting', 'Referrals', 'Microsoft Office', 'Derivatives', 'Entertainment', 'Valuation', 'USPS', 'Selling', 'Sales Process', 'Cross Selling', 'Fixed Income', 'Benchmarking', 'Business Development']"
 , , , , , , , , , 
Data Scientist cum Engineer (Contract),111 North Bridge Road 179098,Contract,Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$8,000","Zenith Infotech  has been in the business since 1997, providing tech recruitment services to our clients from government bodies and reputable corporate clients.

Currently, one of our client is looking out for Data Scientist cum Software Engineer, 1 year contract role. 

Requirement : 

You have a minimum of 5 years software experiences, where you would have understood the process of negotiating and unraveling the nitty gritty details of your customer or user’s datasets
You should have a good repertoire of software tools and programming languages to which you can apply to building an MVP or enterprise ready product
You have experience setting up Spark and using it for batch processing, and possibly streaming experience with Flink or Kafka.
Good to have experience with natural language processing
You should have good working knowledge about Machine Learning and or Deep Learning algorithms in the realm of supervised, unsupervised, reinforcement not limited to ANN, CNN, RNN, GAN
You should have good working knowledge in statistical classification domain eg. Logistic Regression, K-nn, Kernel SVM, Naïve Bayes, Decision Tree, Random Forest, Clustering domain e.g. K-means clustering, hierarchical clustering
You should have a good understanding of applying gradient boosting in regression and classification problems. E.g. XGBoost and in anomaly detection and outlier detection techniques e.g. DBSCAN, Gaussian Mixture Models
You would have working knowledge of Java & Python and you should be able to explain the underlying mechanics in addition to the theoretical Machine/Deep Learning model
You would have good working knowledge of the Machine Learning and Deep Learning toolkits available in OSS, commercial software
Worked in a squad or guild team setup and understand the agile processes, ceremonies and appreciates them
You are an open, strong communicator who communicates effectively across teams, locations and cultures, in-person and virtually
You are autonomous and know how to adapt quickly and drive change for the better
You bloom in a team and like working in a collaborative environment
You agree that data over opinion is a healthy and an important mentality
","['Machine Learning', 'Logistic Regression', 'Big Data', 'Natural Language Processing', 'Hadoop', 'Mathematics', 'XGBoost', 'Agile', 'Spark', 'Data Mining', 'SQL', 'Python', 'Anomaly Detection', 'Statistics', 'Data Science', 'Java', 'Data Analytics']"
Sr Mechanical Design Engineer (Data Centre),0 Kallang Place 339213,Permanent,Senior Executive,2 years exp,Engineering,Monthly,"$4,500to$5,500","Industry: Data Centre
Competitive remuneration package
Permanent role

Responsibilities:

Execute technical qualification, planning and development of technical solutions for      pre-deals, as the Technical Solutions Manager and/or Head of Department may direct
Manage and generate technical solutions, project cost and planning structure for prospective deal engagements and investment approvals
Obtain proposals and carry out assessment, selection, appointment, and management of consultants for the development of design and cost estimation
Support project team during the whole course of project execution, such as executing projects’ quotation and tendering process for various packages, such as main contractors, sub-contractors, vendors, suppliers etc., in accordance with      the approved procurement process
Organize and conduct meetings with stakeholders, such as clients, asset owners, consultants, contractors, vendors, suppliers etc., to address all technical related      matters during the whole course of project execution and client’s engagement
Perform tracking on the progress of solutions development and project cost, against the approved schedule during pre-project investment approval stage, for timely handover to client, asset owners and operations team respectively
Perform assessment on technical solutions, such as potential risks and mitigation measures, compliance to the requirements and standards etc.

Requirements:

Bachelor’s Degree, preferably in Mechanical Engineering
Minimum 1-2 years of working experience in mission critical environment or M&E QS background
Ability to carry out high level review of design drawings & documentations
Familiar with design and procurement processes
Ability to manage internal and external stakeholders, technical & non-technical
Genuine interest in problem-solving and proactive in exploring solutions
Strong critical thinking skills with good communication skills, both spoken and written

Job ID: QW65X999

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Kindly email your resume in a detailed Word format to carlo@peopleprofilers.com

We regret that only shortlisted candidates will be notified


People Profilers Pte Ltd
20 Cecil Street, #08-09 PLUS Building Singapore 049705
+65 6950 9747

EA Licence Number: 02C4944
Registration Number: R1100011
EA Personnel: Carlo Antonio Dela Cruz","['Cecil', 'Tolerance', 'Data Centre environments', 'Critical Thinking', 'Solidworks', 'Electrical', '3D', 'Fabrication', 'Data Centre', 'Procurement', 'Data Centre Facilities Management', 'Good Communication Skills', 'AutoCAD', 'Assembly', 'Tendering', 'Manufacturing', 'CAD', 'Project Cost', 'Mechanical Engineering']"
"Senior Vice President, Data Engineering",78 AMOY STREET 069897,"Permanent, Full Time",Manager,8 years exp,"Banking and Finance, Consulting",Monthly,"$10,000to$20,000","Responsibilities:

Manage projects under one or more accounts
Oversee the implementation and quality control of projects with regards to both budget, timeline and quality delivery
Identify opportunities, articulate Synpulse value, and facilitate sales and contract negotiations for new and existing clients
Independently drive the success of client projects by managing a team of consultants, directing activities, ensuring high quality deliverables and timely submission
Effectively interpret and communicate results from analysis to the business and our client’s stakeholders
Drive and develop the Data Engineering practise within Synpulse by providing guidance to your juniors

What we’re looking for:

At least 8 years of experience working in the Financial Services sector on big data project implementations
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines
Strong coding experience in the likes of Scala or Java
Coding experience using Python
Client facing experience, good communication and presentation skills
Bachelor’s Degree in Computer Science, Physics, Mathematics, or similar degree or equivalent
Enthusiasm to learn and develop emerging technologies and techniques
Strong technical communication skills with demonstrable experience of working in rapidly changing client environments
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies

It’s a bonus if you have:

A background in AML, KYC, screening, regulatory compliance or fraud is highly advantageous
Have worked on a variety of complex data orientated projects for financial services clients
Have a good understanding of computer science and preferable come from a software engineering background or other scientific degree incorporating IT modules (e.g., Math/Physics)
Have exposure to Agile, especially SCRUM
Ability and willingness to travel
Experience working with a variety of modern development tooling (e.g., Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g., Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting)
Have an excellent appreciation of what makes a high quality, operationally stable system and how to streamline all areas of development, release and operations to achieve this

Benefits

Snacks & Drinks
Health Insurance
Robust Career Path
Academy Program with Buddy-Mentor

WE

Want to transform what banking means with you!
Are inclusive and diverse
Are committed to creating a flexible, supportive work environment that helps you effectively manage your work and family commitments
Embrace innovate-thinking and entrepreneurship in everything we do
Are award winning and known for our commitment to outcomes
Apply the latest tech and new ways of working
Support your personal growth

Apply by sending us CV and a short summary of you.","['Puppet', 'Grocery', 'Public Policy', 'Capacity Building', 'Data Engineering', 'Fraud', 'Technical Architecture', 'Technical Communication', 'Banking', 'AML', 'Presentation Skills', 'Articulate', 'Health Insurance', 'Directing', 'Financial Services']"
 , , , , , , , , , 
Medical Data Associate (Clinical / Research),"211 HENDERSON, 211 HENDERSON ROAD 159552",Full Time,Executive,1 year exp,Others,Monthly,"$3,800to$4,500","Key responsibilities:
· Based on an in-depth understanding of Lucence's technology and product portfolio and medical science, interpreting genomic alterations in appropriate clinical contexts and reporting (for both clinical and research samples) results accurately and timely following established procedures.
· Working closely with the Medical Data Science team in the curation and maintenance of database - evaluating scientific publications/clinical studies and integrating functional effects of genomic variants and their associated diseases using standard terminologies and established guidelines.
· Writing, maintaining, and updating workflows and protocols for clinical reporting pipeline.
· Participating in research-oriented projects for clinical validation of tests (in collaboration with external organizations).
· Participating in internal and external quality assurance programs.
· Performing other relevant duties as assigned.

To be a good fit for this role, you would have:
• ﻿At least a degree in Biomedical Science, Life Sciences or its equivalent.
• Familiarity/good understanding in molecular techniques, genetics and NGS applications. Prior experience in research/clinical, in the field of cancer biology/genetics is a plus.
• Good communication and presentation skills and an ability to write short summary reports.
• The ability to work independently as well as in a team.
• Exceptional attention to detail.
• Flexibility in working on weekends, public holidays, from 8 am to 6 pm, based on staff rosters.
• Strong self-motivation, resilience, adaptability, and a keen interest in learning.
• COVID-19 Vaccination Requirement: Fully Vaccinated.

The following will also be a plus:
• Knowledge in genomic medicine and liquid biopsy; and
• Fluency in variant annotation and interpretation and use of genome databases such as COSMIC, ClinVar, Varsome, Ensembl and OncoKB; and
• Ability to interpret genomic data in patient- and treatment-specific contexts following established procedures.","['Clinical Research', 'Ability To Work Independently', 'Site Management', 'Medicine', 'Alterations', 'Interpreting', 'Protocol', 'Adaptability', 'Attention to Detail', 'Writing', 'GCP', 'Data Science', 'Life Sciences', 'Genetics', 'Databases', 'Clinical Monitoring']"
 , , , , , , , , , 
Senior Analyst / Associate (Data Centre),"SAMSUNG HUB, 3 CHURCH STREET 049483","Permanent, Full Time",Senior Executive,2 years exp,"Banking and Finance, Real Estate / Property Management",Monthly,"$5,000to$6,500","We are recruiting for a Senior Analyst/Associate for an upcoming Data Centre Fund and you will be part of an inaugural team with a APAC mandate.

Reporting to the Director and Managing Director, you will be assisting in cash flow modelling such as building and running cash flow models for investment/asset/portfolio management. You will be reviewing monthly property report and update the cash flow model of each asset as well as integrating the asset level cash flow models into fund model for returns forecasting and run asset sensitivities & hold/sell analysis.

You will also organise and present supporting materials for investment analysis, prepare written reports and make presentations levels for approval, you will also be looking at returns calculation, sensitivities and all analytics. You will also assist in overseeing performance of assets by analyzing asset performance vs. market benchmarks, managing partner relationships which involves the regular review of tenancy mix, asset positioning and implementation of effective marketing plans and control of operating expenses to maximize net operating income from assets. You  will assist in asset annual budget and annual business planning process, including formulating asset level strategies to maximize returns to the fund.

You will also support deal closing, due diligence and seeing through the entire process till completion of deals. You will support closing of acquisition/disposition including the coordinating and obtaining of all required internal approvals; setting up and maintaining of all data/transaction files.

You will be assisting in portfolio monitoring of existing investments and perform regular reporting functions including understanding of annual business plans for assets under management as well as monthly asset management reports to investors.

Requirements

You are Degree qualified in Real Estate / Finance / Accountancy / Commerce / Business Administration from leading university, preferably with good quantitative skills and a foundation in finance and financial analysis. You have at least 2 years of professional experience in a real estate fund/financial institutions/developer/financial advisory firms, particularly in corporate finance/fund raising/investments.

You are highly competent in financial modelling, research, quantitative as well as sharp analytical, research, problem solving skills and communication skills.

All applications will be treated in the strictest confidence. Personal data provided will be used for recruitment purposes only.

Please apply with your CV in word document format. We regret to inform that only shortlisted candidates will be notified. For other positions related to real estate, please go to https://careers.tri-cap.com.sg/.

EA Licence: 17C8777
​EA Personnel: R1109270","['Forecasting', 'Asset Management', 'Due Diligence', 'Investment Analysis', 'Recruiting', 'Investments', 'Property', 'Administration', 'Marketing', 'Business Planning', 'Financial Modelling', 'Financial Analysis', 'Communication Skills', 'Real Estate', 'Cash Flow']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Entry Clerk - Part Time,"8 @ TRADEHUB 21, 8 BOON LAY WAY 609964",Part Time,Non-executive,1 year exp,"Admin / Secretarial, Building and Construction",Monthly,$12to$15,"Job Descriptions

Perform all data entry and general administrative tasks, such as answering phones and responding to emails. 
Update, maintain workers data records and information.
Scanning and filing.
Salary Range: $12 - $15 / hr

Job Requirements:

1 - 2 years of relevant work experience in Singapore.
Prior administrative experience in an advantage.
Excellent written and verbal communication skills.
Strong organizational and effective time management skills.
Proficient in Microsoft Office.
Possess strong attention to detail and accuracy in data entry submission.
Able to multitask and work under pressure.
Able to prioritize tasks and meet tight deadlines, in a fast paced environment.
Able to work independently and as part of a team.
Able to work immediately or with short notice.
","['Able To Multitask', 'Microsoft Office', 'Ability To Work Under Pressure', 'Verbal Communication', 'Strong Attention To Detail', 'database accuracy', 'ensuring data accuracy', 'accuracy of data', 'Written Communication', 'Data Entry', 'Excellent Written Communication Skills', 'Time Management', 'Time Management skills', 'Written & Verbal Communication Abilities', 'Work in a Fast Paced Environment', 'Oral & Written Communication Skills', 'Able To Work Independently', 'Accuracy and precision']"
Senior Data Scientist I (NLP expert),71 AYER RAJAH CRESCENT 139951,Full Time,Senior Executive,3 years exp,"Engineering, Healthcare / Pharmaceutical, Professional Services",Monthly,"$6,500to$9,000","Who we are
Holmusk is building the largest Real-World Evidence platform, starting with behavioral health. Combining a leading behavioral health database with AI-powered analytics and digital solutions, we are advancing the frontier of evidence generation and fueling innovation.

At Holmusk, we have the privilege of collaborating with internationally renowned psychiatrists/ specialists in behavioral health. We collaborate with established pharmaceutical companies and clinical institutions primarily on behavioral health. We take pride in our diverse workforce and inclusive culture. We believe it takes all kinds of people to build the best products and bring real change to the healthcare space.

Whom are we looking for
We are looking for a NLP expert for the Senior Data Scientist-I (NLP) position based in Singapore. The SDS-I will serve as the in-house expert for NLP algorithms applied to healthcare problems and would be responsible for driving the custom NLP projects/ solutions for enrichment of Holmusk’s real world behavioral health database. If this description excites you, come join a diverse and collaborative team of engineers, designers, data scientists, health and business professionals who are passionate about improving healthcare.

If this description excites you, come join a diverse and collaborative team of engineers, designers, data scientists, health and business professionals who are passionate about improving healthcare.

What is in it for you

Opportunity to collaborate with leading SME-s from Mental Health space globally including the US, UK, SG and PRC
Opportunity to work in a collaborative environment that encourages creativity
Publish research findings in international peer reviewed journals
Make major impact on the behavioral health space globally
Flexible work schedules

Responsibilities

Comprehend requirements for extraction of specific data from unstructured clinician’s notes for the development, training & validation of NLP models
Conduct literature survey on NLP and decide on appropriate NLP frameworks to meet specific end goals
Understand the underlying biology/etiology of mental health disorders, care delivery patterns etc. to facilitate annotations for NLP and model development
Work on developing NLP models in collaboration with junior data scientists which encompasses code review, maintenance of code repositories and code/ model versioning
Develop strategies for interpreting model insights
Ensure scientific rigor in model development
Oversee project development and communicate project updates effectively to managers
Creation of material including model insights and use cases as required by managers
Acquire domain knowledge on behavioral health to be able to communicate with subject matter experts confidently

Requirements

PhD in Computer Science, Engineering, Statistics, Applied Mathematics, Bioengineering or related fields
Prior experience in driving NLP based projects
Have deep knowledge of NLP concepts including but not limited to: Language models like BERT, XLNet, StructBERT etc.; Recurrent Networks, LSTM/ GRU-s, Attention Mechanisms, Transformers, Encoder-Decoder architectures, Siamese Networks; NLP metrics e.g., the BLEU score, Rouge scores, Triplet loss etc.; New models like Reformers, Longformers; Probabilistic NLP algorithms
Experience in model development and analysis using Scikit-learn, Pandas, Numpy, Tensorflow 2.0 and PyTorch
Knowledge of relational databases and SQL
Have familiarity with AWS facilities
Excellent communication, interpersonal relationship skills and a strong team player

Other skillsets that will be an added advantage

Publications on projects using NLP
Prior experience in information extraction using language modeling
Prior experience in ML model deployment / containerization / MLOps on AWS
Automatic hyperparameter optimization (Keras Tuner/ Hyperopt etc)
","['TensorFlow', 'Pandas', 'Modeling', 'Natural Language Processing', 'Healthcare', 'Behavioral Health', 'Keras', 'Computer Science', 'Information Extraction', 'Interpreting', 'PyTorch', 'SQL', 'Mental Health', 'Statistics', 'Evidence', 'language models', 'Databases', 'Applied Mathematics']"
Network Data Professional - Routing and Switching,"BHARAT BUILDING, 3 RAFFLES PLACE 048617",Permanent,Professional,4 years exp,Information Technology,Monthly,"$5,500to$8,000","Below is the Job Description -
a) Manage network infrastructure such as internet links, traffic shapers, routers, and switches
b) Support in daily operations on incident management, problem(s) / issue(s) remediation, and service(s) restoration
c) Fulfilling of service request(s) following the Change Management procedure.
d) Track and assess all announcements and/or advisories (from device principal, IT Security Team, Government IT Security Incident Response (GITSIR) Team, etc. on patches on vulnerabilities, software bugs and firmware upgrades for network devices.
e) Planning and applying of devices’ security patches and firmware upgrades in accordance with the severity.
f) Preparation of monthly reports on operational issues, link performance, patch status for all DMZ network equipment.
g) Create and maintain documentations of network configuration, network diagram, mapping, processes, and service records.
h) Any other tasks assigned by the Institute
Qualification and Skills for Network Data Engineer:
i) Relevant Diploma or bachelor’s degree in Computer Engineering (or equivalent).
j) Candidate must have minimum CCNP certification (routing & switching).
k) At least 3 years of strong experience supporting a campus network infrastructure, with in-depth hands-on experience on network devices such as Cisco Nexus switches, Catalyst switches, ASR Routers, Networking Monitoring Tools, etc.
l) Knowledge on network compliance is an added advantage.
m) Excellent problem-solving skills in a multi-tasking, fast-paced and complex work
environment.
n) Good communication skill and written skills in English, positive attitude, team player, resourceful and resolve problems independently.","['Switches', 'Remediation', 'Announcements', 'Change Management', 'CCNP', 'Routing', 'Compliance', 'Networking', 'Written Skills', 'Firmware', 'Routers', 'Team Player', 'Incident Management']"
 , , , , , , , , , 
"Senior Manager, Data Science & Business Intelligence","STARHUB GREEN, 67 UBI AVENUE 1 408942","Permanent, Full Time",Manager,10 years exp,"Engineering, Telecommunications",Monthly,"$12,000to$15,000","Job Title: Senior Manager, Data Science & Business Intelligence
Job purpose
You will lead the Data Science and BI function and to manage the governance, collection, measurement, and visualisation of data, build and enhance data science models to drive business objectives and identify opportunities to improve processes and strategies with technology solutions for Data Science and BI.
Responsibilities
Analytics:
* Conduct monthly deep dives on consumer segment performance (Sub-base, ARPU, Revenue and margins) with a second level insights on product performance by consumer segments.
* Define, measure, and communicate key performance indicators for consumer segment.
* Perform complex analysis and modeling for segment by multiple products for GTM activities, with the goal of maximizing revenue, market share and minimizing risk.
* Assist in segment GTM by identifying key drivers for business case/sponsorship and post mortem evaluation, effectiveness of campaigns
* Provide actionable recommendations for opportunities that support business objectives identified through ongoing program and customer measurement.
Data Science
* Use advanced analytics techniques and models to drive business decisions and impact
* Proactively look for new innovative ways to better understand our customers needs and behaviours to drive actionable insights
* Regularly measure existing model performance to improve churn, upsell and cross sell KPI’s
* Continuously look at how we can enrich our data to create new segments and potential target groups
Data & Business Intelligence :
* Provide data and regular reports to the business teams to enhance current strategy for churn, retention, cross and up sell to meet business objectives.
* Manage and continuously improve the performance dashboards and look for opportunities to improve efficiency across the business through new interactive deep dive dashboards
* Oversee the deployment of data to the data warehouse and continuously update and enhance it to keep up with changing business needs.
* Explore and include new data sources in the data warehouse for data science, analytics, digital rewards and campaign management
* Define, measure, and communicate key performance indicators for consumer segment.
Team Leadership
* Manages a small team across data science, data engineering and data visualisation
* Coach, retain and grow the team’s capability and skillsets with an emphasis on empowering the team
* Create an environment of continuous business improvement and a culture of innovation
* Form part of the CLM leadership team and add value across Customer Insights, Campaign Strategy and Digital Rewards
* Manage and continuously evaluate the existing BI and Data Science tools for optimal performance
Requirements
* Degree in Statistics, Mathematics, Economics Engineering or similar field with at least 10 years of data science and analytical work experience in a related role, ideally 3+ in the telco industry
* Prior experience using Python, R, SAS, SQL, Data Robot or a similar tool
* Experience utilising Visualisation tools – Tableau, PowerBI or similar tool
* Quantitative and comfortable working with large amounts of data
* A self-starter with analytical curiosity and strong business acumen
* Strong analytical skills with an eye for an insight and the ability to make data driven recommendations
*We regret that only shortlisted candidates will be notified.","['Tableau', 'Business Intelligence', 'Analytical Skills', 'Modeling', 'Mathematics', 'Business Acumen', 'Technology Solutions', 'Economics', 'Data Engineering', 'PowerBI', 'SQL', 'Team Leadership', 'Python', 'Statistics', 'Data Science', 'Data Visualisation']"
 , , , , , , , , , 
Backend Software Engineer (Time Series Data Warehouse) - Cloud Infrastructure,1 RAFFLES QUAY 048583,Full Time,Professional,3 years exp,Information Technology,Monthly,"$10,000to$20,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The time series data warehouse team is committed to creating high-performance enterprise warehouse products that empowers our users to make efficient data-driven decisions. You will be part of a talented team which will be responsible for building the next-generation, cloud-native and high-performance data warehouse while facing unique, exciting and unprecedented challenges.

Responsibilities
- Participate in the design and implementation of timeseries data warehouse platforms and tools;
- Deeply exploring business-oriented scenarios and providing practical solutions;
- Build and develop batch and streaming data warehouses to support business growth;
- Develop time series data warehouse platforms to serve multiple tenants.

Qualifications
- Bachelor's or higher degree in computer science, software engineering, or related fields;
- More than 3 years of experience with C++ or Java program development (at least one), pursue high-quality code and focus on code engineering quality;
- Solid knowledge of Linux system, proficient in multi-threading, network programming, and distributed development in any programming language;
- In-depth understanding of the implementation principles surrounding distributed systems, proficient in key technologies of distributed storage and computing with practical experience;
- Good at independent thinking, able to proactively identify problems, and have systematic problem analysis and problem solving skills.

Preferred Qualifications
- Experience in the development or optimization of TSDB such as OpenTSDB, Influxdb, M3, Prometheus or Karios;
- Experience in data warehouses technique and related production experience;
- Experience in SQL and Hadoop eco-system (e.g. Hive, HDFS, Yarn, MapReduce);
- Experience with Storm/Spark/Flink is a plus;
- Contributor/Committer of the open-source community is a plus.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Program Development', 'Kubernetes', 'Multithreading', 'Azure', 'Hadoop', 'Software Engineering', 'MapReduce', 'Distributed Systems', 'Docker', 'ITIL', 'Ansible', 'S3', 'Virtualization', 'Linux', 'C++']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Protection Office – Senior Associate,"MARINA ONE EAST TOWER, 7 STRAITS VIEW 018936","Permanent, Full Time",Senior Executive,3 years exp,"Consulting, Information Technology, Risk Management",Monthly,"$3,000to$6,500","We believe that challenges are better solved together. That's why you'll join a diverse, global community of solvers - an unexpected mix of people that come together to build trust in society and solve important problems. With us, you are encouraged to lead with your heart and values, and where your unique skills are developed and put to work in unexpected and exciting ways, superpowered by technology.

How will you value-add?
Facilitating compliance through accountability, building clients’ trust and safeguarding the firm’s data and reputation are at the heart of the Data Protection Office. A career in the Data Protection Office provides you with a great opportunity to drive continuous data protection improvements and promote a positive data culture.
We are currently seeking a suitable candidate to join the team as an Assistant Manager to provide support to the DPO team in developing guidance and monitoring compliance with applicable laws and regulations, contractual obligations as well as internal policies and procedures.

Key responsibilities:

Assist with implementing global policies and developing local policies and guidance in the areas of data protection and privacy, with a view for efficiency through the use of technology
Assist with reviews to ensure privacy and data protection compliance and proactively address potential privacy and data protection issues
Assist with investigations and advise on security incidents or privacy complaints and undertake reporting and remedial actions as necessary
Assist with data protection control reviews as part of technology risk assessments
Support the incident management process
Support Legal and Risk Management processes around privacy and data protection issues in contract negotiations and client relationships
Assist with developing training material on data protection and privacy
Assist with periodic internal and external reporting
Assist with developing and maintaining content on internal data protection portals
Assist with ad-hoc projects

About you

At least 3+ years of experience in any of these areas - IT security, IT audit, data security, data risk and compliance
Be well spoken, resourceful and a team player who has the confidence and maturity to interact effectively with all levels of staff within the firm.
Strong analytical and problem-solving skills with an eye for detail and accuracy
Possess a high level of resilience and positive work attitude
Willingness to learn and deliver timely and quality results to internal stakeholders
Good writing skills (English) is a plus
","['Information Security', 'Governance, risk and compliance', 'Microsoft Excel', 'Data Security', 'Risk Management', 'Compliance', 'Employee Training', 'IT Audit', 'Communication Skills', 'Incident Management']"
DATA ENGINEER /  ANALYST (PART TIME),"TRADEHUB 21, 18 BOON LAY WAY 609966",Part Time,Fresh/entry level,1 year exp,Others,Monthly,"$1,500to$1,800","Includes but is not limited to the following.
- Carry out data preparation (extract data from company systems & cleanse data).
- Analyse data and derive insights by using Power BI that derive productivity, quality, and safety improvements. Produce meaningful reports and present to Company management for recommendations and call to action.
- Propose and implement changes to the company website, which may include User Interface and Design (UI/UX).
- Assist senior management in integration and digitalisation initiatives.
- Assist management team with methodically archiving signature project works based on an internally aligned framework. Present showcase projects in engaging graphical detail.
- Assist management for the preparation of various certification processes, audits and award submissions.

Skills
- Proficient in MS Office, especially PowerPoint and Excel
- SQL
- Microsoft PowerBI
- Quick and Adaptable

Qualifications
- Local Polytechnic Diploma, Advanced Diploma in IT or equivalent
- Student pursuing an undergraduate degree in IT or equivalent are welcome.
- Experience in Data Analytics is welcome but not necessary.
- Demonstrated ability to self-learn, is a team player and task oriented.
- Singaporeans and PRs only","['Microsoft Excel', 'Archiving', 'Teaching', 'MS Office', 'PowerPoint', 'Adaptable', 'PowerBI', 'User Interface', 'SQL', 'Audits', 'Excel', 'Microsoft Power BI', 'Team Player', 'Customer Service', 'Facebook', 'Data Analytics', 'Data Visualisation']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Lead AWS Data Infrastructure Engineer,"INCOME CENTRE, 75 BRAS BASAH ROAD 189557",Permanent,Professional,6 years exp,Information Technology,Monthly,"$8,500to$13,500","Income is looking for Lead Data Infrastructure Engineer to join our Data Engineering team in Singapore. Our team owns and runs the Enterprise Datalake used by thousands of users and hosted across AWS, GCP and On-Premises servers.
As a Data Infrastructure Engineer, you will design, build, maintain and improve our data infrastructure on Cloud, which enables us to make Income data driven organisation. In this role, you would also get the opportunity to work with world-class big data and cloud services, such as: AWS/GCP, Glue, Spark, DBT, Airflow, Tableau and PowerBI.
Responsibilities

Work with data engineering and machine learning teams to improve our data infrastructure for increased reliability, maintainability, and scalability.
Architect and design solutions to improve our data delivery capabilities, data quality monitoring, and data pipeline lifecycle.
Architect and administer our cloud applications such as AWS Glue, Sagemaker, LakeFormation, Iceberg Lakehouse, etc.
Managing Regression Testing Suite, Continuous Integration and Continuous deployment Pipelines.

Qualifications

Bachelors Degree in Computer Science, Information Technology or other relevant fields
6-7 years of designing and building Large Scale Infrastructure and ETL deployment and management pipelines using Terraform, Jenkins, AWS CodePipeline and AWS CodeBuild.
At least 1-2 years of team leading experience
Broad experience in SQL and Python.
Hands-on experience of writing, building and deploying Containerised applications using ECS or EKS or GKE.
Experience in cloud application architecture & administration in AWS with the stacks such as: EC2 instances, Glue, Terraform (build & manage script), Jenkins, CodePipeline, CodeBuild, RDS (PostGres) instances, S3, Airflow
Experience in Deployment and implementation of AWS Glue with basic knowledge of SQL and Python - able to read and understand.
Hands-on experience designing, building, and operationalizing large-scale enterprise data solutions and applications.
Background in in custom ETL design, implementation, and maintenance.
Hands-on experience with strong exposure to AWS CLI and BOTO3 Python libraries.
","['Big Data', 'Pipelines', 'Architect', 'SageMaker', 'Information Technology', 'Team Leading', 'EC2', 'Reliability', 'Data Engineering', 'SQL', 'Python', 'Data Visualization']"
Research Fellow  /  Research Associate (Signal Processing & Data Analytics),"NANYANG TECHNOLOGICAL UNIVERSITY, 50 NANYANG AVENUE 639798","Contract, Full Time",Professional,2 years exp,Sciences / Laboratory / R&D,Monthly,"$4,000to$8,000","The Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE@NTU) invites applications for the position of Research Fellow/ Research Associate.
We are looking for a Radar Signal Processing and Data Scientist with solid knowledge and experience on design, implementation, integrate and test algorithm for radar system and AI/ML algorithms and strong interest in joining an interactive interdisciplinary team
Key Responsibilities:

Responsible for developing, integrate and implement advance radar signal processing algorithms
Develop and implement ML algorithms and tools to build machine learning and analytics platform.
Contribute in AI/ML projects from design, data processing, development, implementation, documentation, validation and optimization.
Explore new technologies for data implementation & AI adoption.
Develop visualization, dashboards and report formats according to project requirements.
Generate IP/Patents and publish high quality papers in journal and conferences

Job Requirements:

PhD/Master’s degree in electrical/electronics/computer engineering or related fields.
Prior experience of radar signal processing and beamforming techniques.
At least 2-5 years of relevant experience with machine learning algorithms, platforms and APIs
Strong foundation in mathematics, as well as familiarity with signal analysis and estimation.
Programming skills in Python, R, C++, and Matlab
Strong background in handling data and programming
Independent analytical problem-solving skills
Highly motivated, independent and able to work as a team
Willingness and ability to develop new skills
Good communication, interpersonal and critical skill.

We regret that only shortlisted candidates will be notified.","['Machine Learning', 'Biomechanics', 'Physics', 'Mathematics', 'Process Simulation', 'Artificial Intelligence', 'Chemistry', 'Characterization', 'Python', 'Publications', 'Visualization', 'Laboratory', 'C++', 'Signal Processing']"
"Senior Vice President, Data Scientist",78 AMOY STREET 069897,"Permanent, Full Time",Manager,8 years exp,"Banking and Finance, Consulting",Monthly,"$10,000to$20,000","Responsibilities:

Manage projects under one or more accounts
Oversee the implementation and quality control of projects with regards to both budget, timeline and quality delivery
Identify opportunities, articulate Synpulse value, and facilitate sales and contract negotiations for new and existing clients
Independently drive the success of client projects by managing a team of consultants, directing activities, ensuring high quality deliverables and timely submission
Effectively interpret and communicate results from analysis to the business and our client’s stakeholders
Drive and develop the Data Science practise within Synpulse by providing guidance to your juniors

Requirements:

Demonstrated at least 8 years of relevant experience in the Financial Services industry.
Experience in building up a practise – including recruiting, leading, and organising the team.
Uncanny ability to remove the complexities from complex data science methods and theories
Seasoned consulting professional who is comfortable operating in a client-facing role
Fluency of at least one scripting language (e.g. Python) and its related frameworks and libraries
Strong domain experience in one of the following areas: Fraud Risk Management, Transaction Monitoring, AML, KYC, Trade Surveillance, or Market Conduct
Deep experience and knowledge of data processing, machine-learning, and data analytics techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Identify patterns in data. This includes having a keen sense of pattern detection and anomaly detection.
Critical thinking and problem-solving skills are essential for interpreting data.
","['Public Policy', 'Capacity Building', 'Critical Thinking', 'Scripting', 'Artificial Neural Networks', 'Interpreting', 'Surveillance', 'Python', 'Anomaly Detection', 'AML', 'Data Science', 'Articulate', 'Data Analytics', 'Fraud Risk Management', 'Directing', 'Financial Services']"
 , , , , , , , , , 
"Assistant Manager, Data Protection (Compliance /  Healthcare Industry))","ONE FINLAYSON GREEN, 1 FINLAYSON GREEN 049246",Permanent,Senior Executive,3 years exp,"Accounting / Auditing / Taxation, Healthcare / Pharmaceutical",Monthly,"$4,000to$6,000","Responsbilities

Monitor and track organisation’s compliance with established controls and tools
Manage the company’s data repository for sensitive information
Partner departments and stakeholders on data breach management and follow up
Work with internal and external stakeholders to understand data request needs, strengthen the management of data and implement data protection initiatives
Oversee and conduct regular audits and reviews
Coordinate training requirement with stakeholders
Handle queries or complaints from the public and staff pertaining to data protection matters
Organise and support internal and external meetings for the department
Support administrative matters for the department
Perform any other duties/projects as assigned by supervisor

Requirements

Degree holder
At least 2-3 years of relevant experience in Audit or Advisory or Compliance or Data Management.
A good understanding of medical terminology will be advantageous
Process strong analytical and problem-solving skills
Motivated, proactive, optimistic and thrive when facing challenges
Excellent interpersonal and communication skills, verbal and written
Ability to work in a fast-paced and dynamic environment, multitask and adhere well to timelines
Proficient in MS Office applications such as Word, Excel and Powerpoint

To apply, please visit www.gmprecruit.com and search for Job Reference: 22041.
To learn more about this opportunity, please contact XinYi at xinyi.chai@gmprecruit.com.
We regret to inform that only shortlisted candidates will be notified.
GMP Recruitment Services (S) Pte Ltd   |   EA Licence: 09C3051   |   EA Personnel: XinYi   |   Registration No: R1328898","['Data Management', 'Medical Terminology', 'MS Office', 'PowerPoint', 'Compliance', 'compliance policy', 'compliance issues', 'Audits', 'Communication Skills', 'Excel', 'Audit']"
"Assistant Manager, Data Protection (Compliance /  Healthcare Industry))","ONE FINLAYSON GREEN, 1 FINLAYSON GREEN 049246",Permanent,Senior Executive,2 years exp,"Accounting / Auditing / Taxation, Healthcare / Pharmaceutical",Monthly,"$4,000to$6,000","Responsbilities

Monitor and track organisation’s compliance with established controls and tools
Manage the company’s data repository for sensitive information
Partner departments and stakeholders on data breach management and follow up
Work with internal and external stakeholders to understand data request needs, strengthen the management of data and implement data protection initiatives
Oversee and conduct regular audits and reviews
Coordinate training requirement with stakeholders
Handle queries or complaints from the public and staff pertaining to data protection matters
Organise and support internal and external meetings for the department
Support administrative matters for the department
Perform any other duties/projects as assigned by supervisor

Requirements

Degree holder
At least 2-3 years of relevant experience in Audit or Advisory or Compliance or Data Management.
A good understanding of medical terminology will be advantageous
Process strong analytical and problem-solving skills
Motivated, proactive, optimistic and thrive when facing challenges
Excellent interpersonal and communication skills, verbal and written
Ability to work in a fast-paced and dynamic environment, multitask and adhere well to timelines
Proficient in MS Office applications such as Word, Excel and Powerpoint

To apply, please visit www.gmprecruit.com and search for Job Reference: 22041.
To learn more about this opportunity, please contact XinYi at xinyi.chai@gmprecruit.com.
We regret to inform that only shortlisted candidates will be notified.
GMP Recruitment Services (S) Pte Ltd   |   EA Licence: 09C3051   |   EA Personnel: XinYi   |   Registration No: R1328898","['Data Management', 'Medical Terminology', 'MS Office', 'PowerPoint', 'Compliance', 'compliance policy', 'compliance issues', 'Audits', 'Communication Skills', 'Excel', 'Audit']"
"Assistant Manager, Data Protection (Compliance /  Healthcare Industry)","ONE FINLAYSON GREEN, 1 FINLAYSON GREEN 049246",Permanent,Senior Executive,3 years exp,"Accounting / Auditing / Taxation, Healthcare / Pharmaceutical",Monthly,"$4,000to$6,000","Responsbilities

Monitor and track organisation’s compliance with established controls and tools
Manage the company’s data repository for sensitive information
Partner departments and stakeholders on data breach management and follow up
Work with internal and external stakeholders to understand data request needs, strengthen the management of data and implement data protection initiatives
Oversee and conduct regular audits and reviews
Coordinate training requirement with stakeholders
Handle queries or complaints from the public and staff pertaining to data protection matters
Organise and support internal and external meetings for the department
Support administrative matters for the department
Perform any other duties/projects as assigned by supervisor

Requirements

Degree holder
At least 2-3 years of relevant experience in Audit or Advisory or Compliance or Data Management.
A good understanding of medical terminology will be advantageous
Process strong analytical and problem-solving skills
Motivated, proactive, optimistic and thrive when facing challenges
Excellent interpersonal and communication skills, verbal and written
Ability to work in a fast-paced and dynamic environment, multitask and adhere well to timelines
Proficient in MS Office applications such as Word, Excel and Powerpoint

To apply, please visit www.gmprecruit.com and search for Job Reference: 22041.
To learn more about this opportunity, please contact XinYi at xinyi.chai@gmprecruit.com.
We regret to inform that only shortlisted candidates will be notified.
GMP Recruitment Services (S) Pte Ltd   |   EA Licence: 09C3051   |   EA Personnel: XinYi   |   Registration No: R1328898","['Data Management', 'Medical Terminology', 'MS Office', 'PowerPoint', 'Compliance', 'compliance policy', 'compliance issues', 'Audits', 'Communication Skills', 'Excel', 'Audit']"
 , , , , , , , , , 
9866 - Finance & HR Manager ( Data Centre  /  Engineering & Building Services Industry ),"SHENTON HOUSE, 3 SHENTON WAY 068805",Full Time,Manager,15 years exp,Accounting / Auditing / Taxation,Monthly,"$4,500to$5,500","Finance & HR Manager

Working Hours: 5 Days [9am - 6pm]
Salary: $4500 - $5,500
Location: Neat Potong Pasir

Requirements:

With Diploma/Degree in Finance/Accountancy/Banking or other equivalent
At least 15Year(s) of working experience in the related field is required for this position.
Excellent Finance & Accounts Knowledge and Office management skills
With relevant HR experience

Responsibilities: 
1) Finance & Accounting

Manage the overall accounting and financial reporting
Maintain the accounting system;
Coordinate & facilitate internal & external Audits to effectively communicate and ensure that requirements are adhered to;
Liaise with Auditor for Expatriate Taxation

2) Human Resource

Liaise with recruitment agency
Recruitment & Selection
Payroll
New employee onboarding & orientation
Performance Management
Employee Exit
Employee Data Management (Personnel Data and leaves records)
Employee Benefits Administration (Insurance, medical claims
HR policies & procedures
","['Taxation', 'Management Skills', 'Data Management', 'Office Management', 'Administration', 'Payroll', 'Accounting System', 'Auditor', 'Accounting', 'Employee Benefits', 'HR Policies', 'Audits', 'Human Resource', 'Benefits Administration', 'Performance Management', 'Financial Reporting']"
9866 - Finance & HR Manager ( Data Centre  /  Engineering & Building Services Industry ),"SHENTON HOUSE, 3 SHENTON WAY 068805",Full Time,Manager,15 years exp,Accounting / Auditing / Taxation,Monthly,"$4,500to$5,500","Finance & HR Manager

Working Hours: 5 Days [9am - 6pm]
Salary: $4500 - $5,500
Location: Neat Potong Pasir

Requirements:

With Diploma/Degree in Finance/Accountancy/Banking or other equivalent
At least 15Year(s) of working experience in the related field is required for this position.
Excellent Finance & Accounts Knowledge and Office management skills
With relevant HR experience

Responsibilities:

This role is work under Operations Department, need to liaise with project team on the progress for claims, AR, payments, invoice etc. + oversee finance team + 1 hr admin under this role + liaise with recruitment agency + liaise with hiring manager + ad hoc duties.

1) Finance & Accounting

Manage the overall accounting and financial reporting
Maintain the accounting system;
Coordinate & facilitate internal & external Audits to effectively communicate and ensure that requirements are adhered to;
Liaise with Auditor for Expatriate Taxation

2) Human Resource

Liaise with recruitment agency
Recruitment & Selection
Payroll
New employee onboarding & orientation
Performance Management
Employee Exit
Employee Data Management (Personnel Data and leaves records)
Employee Benefits Administration (Insurance, medical claims
HR policies & procedures
","['Taxation', 'Management Skills', 'Data Management', 'Office Management', 'Administration', 'Payroll', 'Accounting System', 'Auditor', 'Accounting', 'Employee Benefits', 'HR Policies', 'Audits', 'Human Resource', 'Benefits Administration', 'Performance Management', 'Financial Reporting']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Centre Engineer (12 hours Shift),"PLUS, 20 CECIL STREET 049705","Permanent, Full Time",Junior Executive,1 year exp,Information Technology,Monthly,"$4,500to$6,000","· Location: Woodlands or Chai Chee
· Remuneration: Basic (up to $6000) + AWS
· 12 hours Shift

Responsibilities
· Manage the maintenance and daily operations of the DC facilities with the objective of achieving uninterrupted availability at all times and to ensure the fulfillment of our service commitment to customers.
· Support service delivery to ensure contracted service level agreements and key performance indicators are met or exceeded.
· Perform routine facilities activities including inventory control. Critical systems checks and functional testing. Able to respond and take action in response to facilities crisis management activities including: power outages, fire alarms, HVAC outages. Analyze data and identify trends with facility issues to determine root cause and take appropriate action.
· Respond to BMS/EMS alerts, investigate and feedback on any outstanding issues or events and respond to emergency situations and be on standby duty as required.
· Provide technical support to all aspects of data center operations including the operation, maintenance and repair of all mission critical equipment and systems supporting a 24x7 data center operation to achieve 100% uptime and 100% compliance with all customer SLAs.
· Assist in all site construction activities and installations, in coordination with external contractors to ensure system design, installation and testing adhere to operational standards. Witness testing of all equipment during commissioning and validate sequence of operations and receipt of all operational documentation.
· Support for customer installations, in coordination with the design & construction as well as operations requirements to coordinate customer move-in and turn-on, and other service request & deliveries.
· Maintain compliance with local workplace safety & health (WHS) standards and local electrical and building codes.
· Ensure adherence to all standard operating procedures (SOP), method of procedures (MOP), and emergency response procedures (ERP) established for the critical environments, as well as the formal change control process.
· Participate in the scheduling, coordination and completion all significant planned and emergency maintenance events for the facility and ensure these activities are executed in a controlled and proven method to ensure the reliability of the critical loads supported by these systems.
· Support various accreditation, certification and compliance initiatives such as BCA-IDA Green Mark DC/QMS/ISMS/BCMS/PCIDSS/OSPAR, etc as may be required.

Requirements
· Preferably with minimum 1 year experience in Data Center Facilities Management & Operations environment and service delivery.
· ITE/Diploma in Electrical or Mechanical engineering or equivalent qualification
· 24x7 rotating shift duty
· Able to comprehend, analyse and interpret complex project documents, including AutoCAD, Visio and PDF documents
· General technical and functional knowledge of data center infrastructure to include electrical and mechanical systems, fire detection and protection systems, building management systems, equipment maintenance, space planning, construction of critical facilities environment
· Working location : 1-Net (East) at Chai Chee / 1-Net (North) Woodlands

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Alternatively, you may wish to email your resume in a detailed Word format to debbie@peopleprofilers.com

We regret that only shortlisted candidates will be notified
People Profilers Pte Ltd, 50 Raffles Place, #19-12, Singapore Land Tower, Singapore 048623
Tel: 6950 9748
http://www.peopleprofilers.com
debbie@peopleprofilers.com

Consultant in charge: So Boon Shyen, Debbie
EA Licence Number: 02C4944
Registration Number: R1111376

ID: L5YRY453","['Facilities Operations', 'Data Center', 'Visio', 'HVAC', 'Facilities & Maintenance', 'Inventory Control', 'Data Centre Facilities Management', 'Equipment Maintenance', 'Facilities Shut-Down and Re-Start', 'Space Planning', 'Change Control', 'Routers', 'Crisis Management', 'Cabling', 'Facilities Engineering', 'Commissioning', 'Facilities Management', 'Building Management Systems', 'Technical Support']"
Store Cum Data Entry Asst,"WOODLANDS BIZHUB, 224 WOODLANDS INDUSTRIAL PARK E5 757294",Full Time,Junior Executive,2 years exp,Wholesale Trade,Monthly,"$1,800to$2,200","Job Description

Industry/ Organization Type: Industrial Hardware shop
Position Title: Store Assistant/ Data Entry Assistant
Working Location: Woodlands Industrial Park
Working Hours: 5½days (Monday to Friday, 8.00 am – 5.00 pm, Sat 8.00am - 12.00noon)
Duration: Permanent

Key Responsibilities

Collating and processing order for incoming and outgoing goods
Responsible for stock inventory in store
Perform housekeeping for store 
Ensuring the accuracy and quality of all goods 
Picking and packing
Making sure all stock is labeled and stored correctly
Ensure stock/warehouse are organized, packed, stacked, labeled, cleaned, and maintain in a good working and storage environment
Issuing of DO/INV with all Order 
Data entry for goods purchased and delivery respectively

APPLY NOW!!

Minimum Secondary education
At least 1 year of relevant work experience 
Able to use Microsoft Office
Comfortable handling and processing order for incoming and outgoing goods
Ensuring the accuracy and quality of all goods 
","['Microsoft Office', 'Microsoft Excel', 'Secondary Education', 'Hardware', 'Housekeeping', 'Inventory', 'Customer Information', 'Administration', 'Data Quality', 'Data Entry', 'Attention to Detail', 'Spreadsheets', 'Team Player', 'Microsoft Word']"
 , , , , , , , , , 
Project Manager with data migration experience -SD,"ONE RAFFLES PLACE, 1 RAFFLES PLACE 048616","Permanent, Full Time",Manager,5 years exp,Information Technology,Monthly,"$8,000to$9,500","Role : Project   Manager with data migration experience

Required skills and experience must include:
• Proven management of data migration projects
• Experience with ETL tools (such as Talend)
• Experience of working in a complex, multi-priority organization, preferably experience on Hortonworks Data Platform, Cloudera and MariaDB
• Experience of working within delivery teams from multiple teams (including vendor product teams)
Key responsibilities of the Data Migration Project Manager will include:
• To be responsible for overall project management in ensuring the quality, cost, risk and compliance and project scheduling requirements are met
• To develop project plan based on business case or agreed scope for approval by Project Sponsor / Project Steering Committee (PSC), supported by establishment of the overall success criteria for the project
• To maintain effective project governance, processes and systems to be utilised throughout project
• To actively manage project risk in mitigating all identified risks and change control process
• Identifying the data migration impact of all proposed changes
• Reviewing gaps and proposing a solution for data migration during the solution design phase
• Devise and get approval for the data migration strategy for the implementation
• Oversee and ensure the production of a mapping matrix for all data
• Oversee and ensure a gap analysis for any missing or archive data
• Reviewing as is data quality and putting in place plans to address any required data quality improvements
• Oversee and ensure the building of intermediate database creation scripts
• Oversee and ensure the building of data validation scripts
• Ensure the accurate filling of intermediate data tables during data load","['Project Risk', 'ETL', 'Data Quality', 'MariaDB', 'Strategy', 'Data Migration', 'Compliance', 'Project Management', 'Change Control', 'Scheduling']"
Specialist Sales - Enterprise Data Sales Development Representative (SDR) - Singapore,"CAPITAL SQUARE, 23 CHURCH STREET 049481",Full Time,Professional,2 years exp,Banking and Finance,Monthly,"$10,000to$16,000","Data professionals - on both the buy and sell sides - are under mounting pressure to do more with less, even as demands to reduce operational risk and increase operational efficiency have never been greater. While firms acknowledge the need for enterprise-wide data consistency, ensuring its timeliness, quality, delivery, reliability, and distribution remains a pervasive challenge. Firms that commit to utilizing only highest-quality data can eliminate the data inconsistencies inherent to working with multiple vendors and lower their costs overall. A partnership with Bloomberg Enterprise Sales allows just this, giving them strategic advantage.
What's the role?
Bloomberg Enterprise Data Sales (EDS) is experiencing a prolonged period of unprecedented growth. Our Data and Technology solutions focus on the acquisition, organisation and distribution of content around Financial firms. With the help of groundbreaking product innovation at Bloomberg, we work in partnership with our clients, taking out the heavy lifting, enabling them to do more with less.
We are looking for a Sales Development professional to join our Sales team in Singapore. The successful candidate will be responsible for lead generation, new business strategies and marketing, managing the day to day relationship of large accounts as well as hunting for growth opportunities.
We'll trust you to:

Generate leads across ASEAN accounts for the Enterprise Data Sales team
Engage in frequent prospecting calls to existing accounts and new business to develop sales opportunities
Build the sales pipeline and identify new opportunities to grow revenue within existing accounts
Stay informed about the evolving Enterprise Sales business and the financial markets in order to spot trends, look for new opportunities and establish credibility with our clients by understanding their business
Establish and maintain efficient processes to assist in the smooth day to day operations of sales administration
Be responsible for administrative duties associated with Account Management

You'll need to demonstrate a depth of understanding in the following areas:

The Customer's business (who their customers are, how they make money)
The Customer's technology stack, workflows, and internal structure (org chart, how decisions are made, competing products)
Features and benefits of Bloomberg solutions

You'll also leverage this knowledge to build and maintain credibility with clients, identify gaps and recommend solutions, and deliver on revenue-generating and adoption/usage goals.
You'll need to have:

2 to 5 years of client facing experience in Financial services or Financial technology organisations
Experience selling technology solutions to major financial institutions in the past 5 years
Hands on experience with financial data technology solutions
Outstanding client service experience, relationship management skills and sales aptitude
Experience in managing technical and data content sales deals within an account until close and maintain an ongoing relationship with the client
Working knowledge of the financial community landscape and data needs
Consultative and solution sales skills
Demonstrated continuous career growth within an organisation
Strong presentation and communication skills in English

We'd love to see:

Fluency in Mandarin or an additional, South East Asian language, for servicing our clients across the region.

If this sounds like you:
Apply if you think we're a good match. We'll get in touch to let you know what the next steps are, but in the meantime feel free to have a look at this: https://www.bloomberg.com/professional/solution/data-and-content/
Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law. 

Bloomberg is a disability inclusive employer. Please let us know if you require any reasonable adjustments to be made for the recruitment process. If you would prefer to discuss this confidentially, please email apac_recruit@bloomberg.net.","['consultative selling skills', 'Lead Generation', 'Collaboration', 'Technology Solutions', 'Business Strategy', 'Client Service', 'Communication Skills', 'Financial Technology', 'Stakeholder Management', 'Financial Services']"
Project Manager (Data Science),6 SERANGOON NORTH AVENUE 5 554910,Permanent,Middle Management,8 years exp,Information Technology,Monthly,"$9,000to$14,000","Responsibilities:

Define strategy and implement the plan to coordinate and aggregate demand across all Public Healthcare Institution (PHI) through internal and external forums.
Scan industry and landscape for promising new areas in AI solutions based on MOH’s defined strategic objectives & thematic areas
Engage users on new tech & pilot explorations, and manage the pilot lifecycle.
Work with multiple stakeholders to identify, scope and support the implementation of POC, POV, pilot innovation projects, and manage and track life-cycle of innovation projects at each of the Explore, MVP, POC, POV and Scaling stage.
Share knowledge and information on use cases and work with the funding agencies to identify and evaluate collaborators/providers that offer potential solutions that best suit the needs of users.
Coordinate and communicate with the funding agencies (if applicable) whose investment and grant objectives are relevant to the potential solution at the POC or MVP stages.
Participate as internal review and/or evaluation panelists during the screening and selection process as deemed appropriate by department/division.
Manage AI and tech programmes, track and report to senior management / programme office and retain engagement with the stakeholders throughout the innovation life cycle.

Requirements / Qualifications


Preferably 10 years’ experience and have hands-on experience in project management, client management of medium to large-scale projects, including innovation projects.
Strong interpersonal skills with the ability to work with different groups of stakeholders.
Possess leadership qualities.
Experience in the healthcare industry or experience in developing different types of incubation programs for startups would also be an added advantage.
Degree in Computer Science, Computer Engineering, Data Science or equivalent.
","['Statistical Programming', 'Machine Learning', 'Healthcare Industry', 'PySpark', 'Leadership', 'Interpersonal Skills', 'Healthcare', 'Open Source', 'Strategy', 'SQL', 'Project Management', 'Python', 'Statistics', 'Data Science', 'Screening', 'Data Analytics']"
Data Center Facility Engineer (Junior),2 KAKI BUKIT AVENUE 1 417938,Full Time,Junior Executive,1 year exp,Engineering,Monthly,"$2,000to$2,800","- Responsible for critical facility operation of Alibaba data centers.
- Responding the emergent failure and tracking preventative maintenance.
- Responsible for capacity management of facility systems including power and cooling, etc.
- Manage availability risk of facility systems and drive the resolution.
- Support IT manager (IT) on their project and operations.
- Support design and project teams on new site/data-hall construction and commissioning.

Minimum Qualifications:
- Diploma in engineering of electrical, mech or related field.
- 1 year of critical facility management or operation experience in large scale data center or 2+ years large scale production facility management experience in large scale plant.
- Experience and knowledge of MEP equipment such as UPS, generator, Chiller, Pump, cooling tower, etc.
- Good sense of building and maintain a safety and high efficiency working environment in daily work.
- Strong written and verbal communication skill in English.
- High attention to details to identify the risk and drive to resolve them.","['Preventive Maintenance', 'Troubleshooting', 'Water', 'Verbal Communication', 'Construction', 'Fire Protection', 'Data Center', 'Electrical', 'Attention to Details', 'Audits', 'Manufacturing', 'Electrical Engineering', 'Commissioning', 'Mechanical Engineering', 'Facilities Management', 'EHS']"
"JOB: Senior Business Analyst (Qlik, Power BI & Data Analytics)","REPUBLIC PLAZA, 9 RAFFLES PLACE 048619",Contract,Professional,4 years exp,Information Technology,Monthly,"$6,500to$9,500","We are a top 8 global IT services company with operations in 50+ countries. We offer an advanced portfolio of application, business process, cloud, and infrastructure services to businesses and governments worldwide.
NTT DATA Singapore PTE Ltd is a wholly owned subsidiary of NTT DATA Corp, a part of NTT Group, the world’s 65th Largest Company according to Fortune Magazine.

At NTT DATA SINGAPORE, we pride ourselves on being an inclusive and equal opportunity employer that puts our people and clients first. We welcome different ideas, backgrounds and passionate individuals to join us in our inclusive environment to achieve stronger and better results through teamwork, foresight, and innovation. We pledge to create a harmonious and nurturing culture, where all individuals feel a sense of pride and belonging, regardless of age, gender identity, race, sexual orientation, physical or mental ability, ethnicity

COLLECTION, USE AND DISCLOSURE OF PERSONAL DATA - NTT DATA will be assessing and evaluating your suitability for employment/appointment or continued employment/appointment in any position within our organisation

📧 EMAIL ID : Interested candidates, please email your resume to sandeep.sringeripai@nttdata.com


Interested in working with a top 10 global IT services provider?

Must have Qlik, Power BI and data analytics Experience 

Job Descriptions:
1. Arrange and discuss with users to understand the reporting requirement, and document down the requirements into technical specification or mappings for development team to deliver
2. Identify the source data required for creation of the reports and dashboards, interpret the data to understand the relationship of different datasets
3. Facilitate the computerization of analytics and data collection processes
4. Collaborate with source system PICs to establish the data connection and data feeding automation
5. Work closely with existing Data Warehouse team to bring the data into DWH system for reporting and dashboarding
6. Carry out complex analysis of datasets and conduct appropriate data validation

Key skillset:

At least 3 to 5 years experience in BA, interfacing  with Technical team and Business team
Knowledge of Qlik, Power BI and data analytics. Powershell  ( MUST HAVE )
Banking knowledge and able to understand the corporate banking, trade finance

📧 EMAIL ID : Interested candidates, please email your resume to sandeep.sringeripai@nttdata.com


","['QlikSense', 'Business Intelligence and Data Analytics', 'Dashboard', 'Powershell', 'Trade Finance', 'QlikView', 'Data Warehouse Architecture', 'Design of data warehouse', 'Banking', 'Microsoft Power BI', 'Data Analytics', 'Power BI', 'data warehouse solution']"
Research Associate (Clinical Data Engineer),21 LOWER KENT RIDGE ROAD 119077,Full Time,Professional,3 years exp,Sciences / Laboratory / R&D,Monthly,"$4,250to$6,375","Job Description
Roles & Responsibilities
The National University of Singapore invites applications for a Research Associate (Clinical Data Engineer) position, in the Healthy Longevity Translational Research Program, Yong Loo Lin School of Medicine, with an affiliation with the National University Health System (NUHS) Centre for Healthy Longevity.
The Centre for Healthy Longevity (CHL), one of 6 Centres of Excellence of the National University Health System (NUHS), aims to be a leading institute for geroscience research and translation globally, renowned for translating research into practice to improve healthspan.
The CHL is seeking a research associate (Clinical Data Engineer) develop comprehensive human research databases for its clinical research projects. The candidate will be working with large amounts of highly complex electronic health data from multiple sources, including biomedical health records, clinical and molecular readouts etc. One major thrust is to develop the technical infrastructure to support a growing database.
The position requires experience in managing large datasets, data linkage, quantitative analysis of large observational, cross-sectional and longitudinal cohort datasets and intervention trials. The candidate will work closely with the research team from the Healthy Longevity Translational Research Program and the CHL to design the data collection and management strategy for research studies.
Appointments will be on a 2-year contract in the first instance, with the possibility of extension.
Duties & Responsibilities

Work with management team, and research team to develop a clinical research management system in line with NUS/ NUHS data policy guidelines
Formulate techniques for quality data collection to ensure adequacy, accuracy and legitimacy of data
Establish rules and procedures for data sharing, curation, management
Identify, manage and track issues, risks and dependencies that affect the delivery of the project outcome
Support research team in the daily use of data systems and ensure adherence to legal and company standards
Assist with reports and data extraction when needed
Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (new technologies, upgrades etc.)
Ensure clinical databases and archives are protected from security breaches and data losses
Develop data visualization framework, models for CHL

Qualifications
MSc/MA in computing, data analytics, healthcare statistics or relevant field

Candidate should possess at least 3 years of experience with demonstrated competency at the junior managerial level
Excellent communication skills to facilitate cross-disciplinary work
Excellent understanding of data administration and management functions (collection, analysis, distribution etc)
Familiar with modern database information system technologies (REDCAP is a plus)
Proficient in statistical software (SPSS, SAS, Graphpad etc.)
An analytical mindset with problem-solving skills

Formal Application
Interested applicants are invited to apply directly at our NUS Career Portal.
Please include current/expected salary, supported by a detailed CV (including personal particulars, academic and employment history, complete list of publications/oral presentations and full contacts of 3 referees). Finally, a detailed cover letter indicating why the applicant wishes to join the Centre for Healthy Longevity is required.
Remuneration will be commensurate with the candidate’s qualifications and experience. We regret that only shortlisted candidates will be notified.
COVID-19 Message
At NUS, the health and safety of our staff and students are one of our utmost priorities, and COVID-vaccination supports our commitment to ensure the safety of our community and to make NUS as safe and welcoming as possible. Many of our roles require a significant amount of physical interactions with students/staff/public members. Even for job roles that may be performed remotely, there will be instances where on-campus presence is required.
Taking into consideration the health and well-being of our staff and students and to better protect everyone in the campus, applicants are strongly encouraged to have themselves fully COVID-19 vaccinated to secure successful employment with NUS.","['Translational Research', 'Archives', 'Analyze Information', 'Data Sharing', 'Clinical Research', 'Healthcare', 'Medicine', 'Quantitative Analysis', 'Translation', 'SPSS', 'Trials', 'Statistics', 'Data Analytics', 'Databases']"
Permanent Data & Reporting Executive #BBZ,"NGEE ANN CITY, 391A ORCHARD ROAD 238873","Permanent, Full Time",Professional,1 year exp,"Banking and Finance, Insurance",Monthly,"$3,800to$4,500","Main Duties: 

Prepare regular management reports on key performance drivers of the sales channels. (eg: Monthly MI reporting, Daily Sales Report)
Collate various manufacturer sales data and upload into agent portal.
Prepare and monitor Tactical Incentive results, provide periodic progress reports required by the stakeholders.
Validate on yearly basis for Promotions/Demotions of Wealth Managers.
Support the Manager on Yearly basis FA Questionnaire to MAS.
Support the Manager to identify and implement automated processes for department. conducting user acceptance testing to ensure changes are in accordance with business needs.
Attend to various reporting or ad hoc projects


Requirements

Minimum 1 year of relevant working experience, preferably with business performance reporting/analyst experience
Diploma in Accounting/ Business studies/Data Sciences or related disciplines
Advanced proficiency in Microsoft Excel (Pivot Table, Advanced Formulas: Xlookup, Nested Ifs, SUMIF, COUNTIF)
Able to create a report template from scratch with Excel.
Proficiency in database query languages like SQL, VBA Macros or other programming skills like Phyton is a plus



Interested applicant, kindly send your detailed resume to jerlinaw@recruitexpress.com.sg



CEI no.: Jerlin Aw Bi Zhi (R1218675)
Recruit Express Pte Ltd
EA Licence no.: 99C4599","['Sales', 'Microsoft Excel', 'Wealth', 'VBA', 'SQL', 'Scratch', 'Python', 'User Acceptance Testing', 'Excel', 'Automated Processes', 'Python Programming']"
0430 - Regional Project Manager [ Data Centre Management Solutions ],"SHENTON HOUSE, 3 SHENTON WAY 068805",Full Time,Manager,6 years exp,Information Technology,Monthly,"$5,000to$8,000","
Ubi
5 Days
Data Centre Management Solutions
Company Benefits & Incentives
Career Progression Opportunities!

Responsibilities:

Lead cross-functional project teams to ensure successful delivery of DCIM and BMS projects across multiple locations in the region
Develop project schedules, budgets, and resource plans, and monitor progress to ensure that projects are delivered on time and within budget
Coordinate with stakeholders across different locations to gather requirements and develop project plans that meet their needs
Oversee the implementation and integration of DCIM and BMS technologies, including monitoring, power management, and asset management systems, HVAC, lighting, and security systems
Develop and maintain project documentation, including project plans, status reports, and change requests
Monitor project risks and issues, and developmitigation plans to address any challenges that arise
Ensure that all projects are delivered in accordance with IT policies, standards, and procedures
Provide regular project updates to senior management, stakeholders, and project teams
Stay up-to-date with the latest industry trends and best practices, and identify opportunities to improve the DCIM and BMS project management process across the region.

Requirements:

Relevant experiences
At least Degree Holder in Computer Science, Engineering, Business Administration, or equivalent.
","['Negotiation', 'Microsoft PowerPoint', 'Budgets', 'Asset Management', 'Microsoft Excel', 'Lighting', 'Change Management', 'Agile', 'HVAC', 'Administration', 'Power Management', 'Project Management', 'PMP', 'Accountability']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Account Assistant cum Data Entry,"REPUBLIC PLAZA, 9 RAFFLES PLACE 048619",Full Time,Fresh/entry level,1 year exp,Accounting / Auditing / Taxation,Monthly,"$2,500to$4,500","Job Description & Duties:
Responsible for key in all the supplier invoices to system
Check all incoming emails for invoices
Handling of incoming correspondences related to accounts
Perform any other duties delegated by Accountant/MD
Handle the daily function/operation of accounts department
Ensure completeness, accuracy and timeliness of sales invoicing.

Requirement:
- Min LCCI higher diploma
- Mature and meticulous individuals, self motivated, independent & hardworking
- Good with excel and careful with numbers.
- Flair with understanding processes and dataflows and streamlining processes.

Others :
Career advancement prospects
Good working environment
Salaries will commensurate with qualifications and experience
Location: Central

Qualified or interested candidates, please stating the following:-
1) Availability
2) Current/ last drawn salaries
3) Reason for leaving previous employment
4) Expected Salary","['Accounts Payable', 'Microsoft Office', 'Microsoft Excel', 'Tax', 'Invoicing', 'Data Quality', 'Payroll', 'Data Entry', 'Bank Reconciliation', 'Accounts Receivable', 'Accounting', 'Excel', 'Team Player', 'Microsoft Word']"
Data Modeling SQL Database (Contract),"PLAZA 8 @ CBP, 1 CHANGI BUSINESS PARK CRESCENT 486025",Contract,Manager,4 years exp,Information Technology,Monthly,"$7,000to$11,000","Job Description & Requirements
Contract position: 12 months contract
Located in Bayfront Ave/Harbourfront Centre

Job Description:
Business data analyst will assist to build and maintain end to end  datamart solution for the data platform initiative to address business  requirements. This role will require usage various tools such as  Microsoft SQL Server data tools, Windows batch scripting, Powershell,  APIs, Structured Query Language (SQL) for development, automation and  maintenance of database solution in gaming and hospitality management  domain. They will also work with other development teams for validation  of the data.
. Experience with financial analysis, trend analysis, with background in Hospitality and/or Gaming would
be a plus.","['Scripting', 'Information Technology', 'Hospitality Management', 'Microsoft SQL Server', 'Trend Analysis', 'SQL', 'SQL Server', 'Financial Analysis', 'Windows Batch', 'Hospitality', 'Business Requirements']"
2812 - Account Assistant [ AP  /  AR  /  Business Central  /  Data Entry ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,000to$2,500","Accounts Assistant
5 Days
Near to Bedok MRT
$2000 - $2500

Job Scopes:
Assist with AP and AR activities.
Handle customer enquiries.
Creating and posting of AP and AR transactions in Accounting software.
Other ad-hoc duties as assigned by superiors.
Any experience with Microsoft Business Central will be advantageous.
Comfortable with data-entry work.","['Account Service', 'email accounts', 'Account plans', 'Account Banking', 'manage accounts', 'Account Balance', 'client accounts', 'Fund Accounting', 'Bank Accounts', 'account system', 'account opening']"
2812 - Account Assistant [ AP  /  AR  /  Business Central  /  Data Entry ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,000to$2,500","Accounts Assistant
5 Days
Near to Bedok MRT
$2000 - $2500

Job Scopes:
Assist with AP and AR activities.
Handle customer enquiries.
Creating and posting of AP and AR transactions in Accounting software.
Other ad-hoc duties as assigned by superiors.
Any experience with Microsoft Business Central will be advantageous.
Comfortable with data-entry work.","['Account Service', 'email accounts', 'Account plans', 'Account Banking', 'manage accounts', 'Account Balance', 'client accounts', 'Fund Accounting', 'Bank Accounts', 'account system', 'account opening']"
 , , , , , , , , , 
6606 - Buyer [ Data Centre  /  Construction  /  Engineering  /  Infrastructure  /  Procurement  /  Purchasing  /  Sourcing  /  Supply Chain ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Executive,3 years exp,Purchasing / Merchandising,Monthly,"$3,000to$5,000","(Data Centre / Engineering & Building Services Industry)
Buyer

Working Hours: 5 Days [9am - 6pm]
Salary: Up To $5,000 (Based on Experience & Last Drawn)
Location: Lor Bakar Batu, Potong Pasir 

Requirements:

Diploma / Degree holder in Supply Chain Management
1 - 2 years of relevant working experience / relevant industries

Jobs Scope:

Handles full set of purchasing process (Sourcing, RFQ, shipping and follow up on
deliveries)
Prepare Purchase Orders to suppliers ensure all deliveries are in time to meet site schedules
Ensures timely PO execution and address supplier’s capacity, materials issues that may affect supply
Works closely with vendors to schedule delivery and pick-up of equipment
Coordination with vendors on scheduling & expediting of deliveries or resolution of purchase discrepancies if any
Analyses and maintained an accurate cost per site (equipment and labour)
Supports all Engineering programs in identifying and qualifying Suppliers, auditing new Vendors using both
Technical and commercial knowledge to support company requirements
Maintain procurements database
Works closely with Finance to resolve invoice discrepancies and verified correct shipment/purchase orders on packing lists
Exercise good vendor management and monitor performance of suppliers to meet objectives in the area of quality, inventory control and actively engages suppliers
To perform any other duties that may be assigned by the immediate supervisor from time to time.

If you are interested to apply, kindly WhatsApp me your updated resume in DOC file and allow our Consultant to match you with our Clients.
Whatsapp: +65 8204 7336
✉liki_wong@thesupremehr.com","['Negotiation', 'ERP', 'Supply Chain', 'Purchasing', 'Building Services', 'Auditing', 'Inventory Control', 'Procurement', 'Assortment', 'Vendor Management', 'Supply Chain Management', 'Scheduling', 'Pricing', 'Sourcing', 'Shipping']"
 , , , , , , , , , 
 , , , , , , , , , 
"6 Months Junior Data Analyst (Up to 2,500 /  NO EXP OK!)","SHAW CENTRE, 1 SCOTTS ROAD 228208",Contract,Fresh/entry level,1 year exp,Admin / Secretarial,Monthly,"$2,000to$2,500","The opportunity

Duration: 6 month contract, IMMEDIATE
Salary: $2,200-2,500/month
Location: Raffles
Working days & hours: Monday – Friday: 9am – 6pm
Work in a Singaporean multinational real estate operating organization

Job Description

Clean and gather data to create dashboard
Gathering requirement
Preparation of LMS, CRM & Ops system
Manage various vendors and data streams coming into Tableau

Requirements

With intermediate knowledge in excel (Pivot Table/Vlookup)
Prior study background or internship experience in data analysis is a plus

Next step

Prepare your updated resume (please include your current salary package with full breakdown such as base, incentives, annual wage supplement, etc.) and expected package.
Interested candidates please click on 'Apply here' or email: angeline.low@adecco.com
All shortlisted candidates will be contacted
","['CRM', 'Tableau', 'Microsoft Excel', 'Dashboard', 'Data Analysis', 'Data Management', 'Pivot Table', 'Data Entry', 'Attention to Detail', 'Excel', 'Statistics', 'Real Estate', 'Vlookup']"
SERVICE TECHNICIAN / ENGINEER (DATA CENTRE INDUSTRY),10 KAKI BUKIT AVENUE 1 417942,Full Time,Non-executive,3 years exp,Engineering,Monthly,"$2,500to$3,000","JOB DESCRIPTION:
1. Carry out preventive maintenance for electrical power system – UPS System and computer room/data centre equipment.
2. Attending to service calls, perform trouble shooting and resolve technical problems at customer site.
3. Hands-on field service work for installation, testing and  commissioning of UPS, batteries and electrical power system equipment.
4. Coordinate site logistics and arrangement.
5. Preparation and submission of relevant technical and safety documentation.
6. Any other duties as deemed necessary from time to time

JOB REQUIREMENTS:
1. NITEC/Diploma/Degree in Electrical, Electronics Engineering or equivalent
2. Minimum 3 years of hands-on working experience in electrical power systems.
3. Familiar with electrical, mechanical and WSH guidelines and procedures
4. Possess Class 2B and/or Class 3 license
5. Good communication skills, customer oriented and able to work as a team
6. Able to perform rostered 24/7 on call standby.

OTHERS:
1. Positive working environment
2. Training will be provided
3. Immediate vacancies available","['Class 3 License', 'Field Service', 'Preventive Maintenance', 'Electrical', 'Good Communication Skills', 'Customer Oriented', 'Power Systems', 'Electronics', 'Commissioning', 'Technical Support']"
 , , , , , , , , , 
Lecturer / Senior Lecturer (AI & Data Science) - School of Maths & Science,500 DOVER ROAD 139651,Contract,Middle Management,2 years exp,Education and Training,Monthly,"$3,000to$8,550","The job of an academic is challenging but meaningful. Not only will s/he have both the knowledge and working experience, s/he must also possess a passion for working with youths, nurturing and moulding their characters. There will be opportunities to develop curriculum, introduce new courses as well as be involved in consultancy and other applied research projects. Administrative work related to teaching and School/Institutional strategic initiatives will also be an important part of the job.  The successful candidates will be expected to be resourceful and innovative with initiative and good communication skills.
The appointee must be competent to teach at diploma and higher levels in any one of the following areas:

Artificial Intelligence (AI)
Computer Vision (CV)
Data Science (DS)
Data Analytics (DA)
Natural Language Processing      (NLP)

The appointee should also be able to teach in any one of the following areas:

Engineering Mathematics
Statistics
Computing

The appointee will also be required to teach at least one of the following broad-based, foundational modules under the common core curriculum to enable our students to have the necessary emerging digital skills and human skills.

Data Fluency
Artificial Intelligence and Its Impact
Persuasive Communication with Data Storytelling
Problem Solving with Creative and Computational Thinking

Responsibilities:-

Conduct lessons, create teaching and assessment materials and mentoring of students
Develop and maintain new/existing teaching curriculum for modules stated above
Undertake projects/consultancy work with both internal and external stakeholders, possibly in area of AI and DS

Requirements:-

Passionate about education and possess good values
Team player with the ability to work independently
Possess good communication skills, both written and verbal
Relevant qualifications in the field of Artificial Intelligence, Data Science, Computer Science,      Engineering, Mathematics or Statistics, preferably with a postgraduate qualification in a relevant field
Experience in cloud computing or software engineering, particularly in the deployment of AI/DS models into production is preferred though not mandatory

Successful candidate will be offered a 2-year contract in the first instance.
Closing Date: 23 February 2023
If you are shortlisted for the position(s), you should hear from us within 30 days of the closing date of the advertisement.","['Engineering Mathematics', 'Teaching', 'Applied Research', 'Ability To Work Independently', 'Cloud Computing', 'Administrative Work', 'Natural Language Processing', 'Computational Thinking', 'Artificial Intelligence', 'Software Engineering', 'Computer Vision', 'Characters', 'Good Communication Skills', 'Data Science', 'Storytelling']"
Information Technology - Senior Data Sciences & Analytics Engineer (Machine Learning Track),"TechSQ, 722 Upper Changi Road East 486854","Permanent, Full Time",Professional,3 years exp,Information Technology,Monthly,"$5,500to$11,000","Job Description
SIA has multiple positions for machine learning/deep learning experts to drive our AI and data science initiatives.

Key Responsibilities:

Member of the in-house AI Center-of-Excellence team that works on challenging problems in machine learning (including areas on NLP, computer vision, recommender system, transfer learning and reinforcement learning), mathematical optimization, game theory, and experimental design.
Research and develop statistical machine learning and deep learning algorithms to meet complex product requirements. The scope includes defining hypotheses, executing necessary tests and experiments; evaluating, tuning and optimizing algorithms and methods; and having an eye towards cloud implementation ease, scalability, and robustness in a live customer-facing production environment.
Provide technical direction and guidance to a small and highly skilled team of junior and senior data scientists embedded in Kanban data squads. These squads deliver products/services in AI, data science and data analytics to stakeholders in a large number of business units. Serve as a go-to expert in your area of ML/DL expertise.
Work closely with business stakeholders to create impactful and intelligent features/products. Collaborate with other team members including data scientists, data engineers and data strategists. Strategic ownership of all critical end-to-end AI processes.
Administer/maintain performant cloud and on-premises GPU compute resources that train large ML models and provide inference microservices in production.

Requirements

PhD degree related to computer science, advanced machine learning or other AI disciplines is required. Consideration will be given to exceptional candidates without advanced degrees.
Advanced programming skills in Python. Strong technical skills in algorithm design/analysis, data structure and SQL. Intermediate-level mastery of functional/object-oriented software development using modern programming languages such as Scala, JavaScript, Java and C#.
At least 3 years of relevant industry experience in two or more of the following areas:Expert-level hands-on skills in shallow and deep machine learning. Highly conversant with GPU-accelerated deep learning frameworks (such as TensorFlow and PyTorch).
Demonstrated ability in rapidly adapting, training and deploying state-of-the-art AI models in production based on the latest published research papers and code.
Knowledge and working experience in workflow, map-reduce or stream processing systems such as Spark and Kafka.
Strong skills in Bayesian statistics and inference. Comfortable with the application of Bayesian and causal networks for probabilistic reasoning.

Significant hands-on experience with AWS, GCP or similar public cloud environment.
Excellent mentoring, interpersonal and communication skills for working with both technical staff and non-technical business users.
Demonstrated intellectual firepower as a rapid problem-solver and tech lead.
Experience with Agile/Scrum/Kanban methodologies is a plus.
","['TensorFlow', 'Scalability', 'Scala', 'Kanban', 'Customerfacing', 'Technical Direction', 'Computer Vision', 'Tuning', 'PyTorch', 'Experimental Design', 'GCP', 'Data Science']"
2812 - Accounts Assistant [ AP  /  Invoice  /  Payment  /  Data Entry  /  GST  /  Bank Reconciliation ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,200to$2,500","Accounts Assistant ( Accounts Payable )
Address: Kallang
Salary: $ 2200 - $ 2500
Working Hour: 5 days, 9am - 6pm

Job Requirements:

Min qualification Diploma in Accounting  or CAT or equivalent
Min 1 year of experience in AP function
Willing to work after office hours if needed especially during month end closing

Job Scope:

Accounts payable and expenses management
Liaising with suppliers on invoices and payments
Prepare journals and data entry
Check, verify and process invoices, expense claims & reimbursements
Ensure accurate and timely closing of accounts
Check and key in accounting codes and GST into system
Assist to prepare GST reports and filing of GST
Accounts reconciliation
Bank reconciliation
Update and maintain the inventory record
Submission of monthly inventory report
Other accounting related duties as required
Assist AR functions if needed
","['Accounts Payable', 'Inventory', 'Financial Transactions', 'Accounting System', 'Data Entry', 'Bank Reconciliation', 'Accounts Receivable', 'Accounting', 'Bookkeeping', 'Able To Work Independently']"
 , , , , , , , , , 
Data Center Electrical Engineer  /  Solution Architect,"Interlocal Centre , 100G  Pasir Panjang Road  118523",Full Time,Middle Management,7 years exp,Engineering,Monthly,"$6,000to$13,000","1) Lead Eaton technical sales engagement with clients in APAC for outcomes, consultative and solution selling opportunities. Be able to articulate the solution to Consultants, Facilities and Operations teams as well as Procurement teams for clients.
2) Provide pre-sales technical support for clients: work with internal Eaton teams and third-party technology providers to identify client business problems, facilitate requirements design thinking sessions, architecture presentations, product feature descriptions and value propositions, and solution demos and presentations.
3) Work with the sales teams, Bid Management Team and Key Account Managers within the region and globally to develop value propositions for key stakeholders: executives, operators, finance leaders and IT leaders, and be able to put together compelling proposals for Eaton solutions
4) Assist Bid Management Team respond to RFP documents, put together solution requirements and design, system customization and configuration, align service offerings and ultimately be the client’s point of contact for maintaining the solution roadmap.
5) Collaborate and coordinate with Eaton factories and regional technical stakeholders to ensure alignment in solution and technical offering to global clients
6) Develop templates and best practices for solution deployment into data center client accounts, working with the regional professional services/delivery team.
7) Help with existing and new account planning and strategy, to bring in Eaton hardware and software content and grow hardware and software revenue in the region. Provides technical and sales consulting, support for major account opportunities.
8) Develop a broad network of industry technology contacts, stay current with latest technologies in the data center space, including detailed understanding of competitive solutions.
9) Position Eaton value through our hardware and software content: position appropriate Eaton products, services, third party technologies as part of a solution that fits the client needs.
10) To be committed & responsible for Quality Management System;
Implement the process approach and risk-based thinking
Provide the necessary support to fully implement and sustain the QMS
Communicating to the organization the importance of conforming to QMS requirements
Ensuring the QMS meets its goals
Engage, direct, and support individuals contributing to the QMS
Create a culture of continuous improvement
Qualifications:
7+ years of deep domain expertise with the data center industry, designing and deploying hardware and software for data centers.
5+ years of technical sales experience with UPS, Switchgear, and software technologies like DCIM, or EPMS, or cloud/SaaS, or AI/ML, or edge computing solutions, or analytics software packages and cybersecurity.
5+ years of consultative engagement with executive and technical teams in developing and translating business use cases to solution requirements and architecture documentation.
Bachelor’s degree in computer science/electrical or mechanical engineering
CAD and Visio
TCP/IP, Linux O/S MS SQL Server, Relational Database
Scada systems, industrial automations or BMS systems","['Account Planning', 'Quality Management', 'Data Center', 'Visio', 'SCADA', 'Solution Selling', 'SQL', 'SQL Server', 'Design Thinking', 'Consulting', 'Articulate', 'Technical Sales', 'CAD', 'Linux', 'Technical Support']"
 , , , , , , , , , 
 , , , , , , , , , 
"Data Analyst, (Oracle  /  SQL  /  PL)","PLAZA 8 @ CBP, 1 CHANGI BUSINESS PARK CRESCENT 486025",Full Time,Non-executive,3 years exp,Information Technology,Monthly,"$5,000to$7,800","Responsibilities:


Experience in data analysis.
Able to manage data reconciliation/quality checks (implementation, monitoring and troubleshooting).
Experience in Oracle PL/SQL.
Able to perform UAT.
Able to manage SLA and queries from end users.
Able to provide documentation support e.g. in technical/functional specifications.

Requirements:


Have at least 2 years of experience in data analysis.
Able to manage data reconciliation/quality checks      (implementation, monitoring and troubleshooting).
Experience in Oracle PL/SQL.
","['UAT', 'PL/SQL', 'Troubleshooting', 'Microsoft Excel', 'Oracle', 'Data Analysis', 'Data Management', 'Data Quality', 'Data Analytics', 'Data Visualization']"
"Senior Assistant Manager / Manager, Data Analytics (Finance) (JR4173)",1E KENT RIDGE ROAD 119228,Permanent,Manager,5 years exp,Accounting / Auditing / Taxation,Monthly,"$4,500to$7,000","The incumbent will support the Data Analytics (Finance) for Regional Health System (RHS) Office towards achieving Population Health goals under Healthier SG. He/she will provide the linkage between financial and clinical related data requirements and business partner with the Population Health Finance and RHS Leads teams to form meaningful analysis for decision making. This would require the personnel to establish a good understanding and knowledge of the existing processes, a strong background of healthcare processes and systems and have knowledge and skills of data analytics. In analysis, both qualitative and quantitative techniques are applied to turn data into insights and recommend actionable for implementation.

Job Description
Integrate financial data with clinical outcomes and Key Performance Indicators

Liaise and work closely with various stakeholders (RHS Leads, PopHealth/Institution Finance and data owners) in integrating financial data with the clinical outcomes achieved
Map and design financial data requirements against the Key Performance Indicators.
Consolidate and maintain relevant databases relating to projects requiring financial information.
Design and produce dashboards and value adding reports to facilitate updates to senior management and aids in decision making.
Rationalise clinical outcomes against financials spending.
Perform regular refresh of up to date financial information to databases and dashboards.
Partner with RHS Leads and PopHealth Finance to identify areas of focus on cost recovery and pricing structure.

Others

Be a financial resource – able to provide sound financial and practical advice to internal and external stakeholders.
Collaborate with stakeholders to identify available and relevant datasets and make strategic recommendations on such collection, integration and usage.
Able to work well with multi stakeholders internally and externally.
Any ad-hoc projects/tasks assigned by the Reporting Officer and Head of Department.

Requirements

At least Bachelor of Accountancy, Business, Business Analytics, Statistics or Economics; or a related field;
At least 5 years of relevant working experience
Strong sense of business acumen and stakeholders' engagement to understand the organisational issues and challenges
Numerate, meticulous and possesses analytical aptitudes to make sense of complex data from multiple sources to translate into financially viable recommendations in a succinct and graphical way
Good quantitative skills and data literacy, with knowledge of Excel, SAP and Microsoft Office suite, SQL, Python, STATA, R or similar languages.
Proficient in data visualisation tools, like Tableau, to transform quantitative analysis into compelling visuals a plus
Adaptable, creative, have a bias towards action, and able to work well with multi teams and stakeholders’ environment
Exhibits high degree of initiative and independence: Demonstrates the ability to acquire and develop in depth knowledge require for to function effectively and proficiently. Inquisitive, meticulous and possess good logical, analytical and process flow skills.
Team player with effective and clear communication skills.
","['Tableau', 'Literacy', 'Healthcare', 'Business Acumen', 'Financials', 'Quantitative Analysis', 'Economics', 'Information Design', 'Adaptable', 'Business Analytics', 'Statistics', 'Decision Making', 'Data Analytics', 'Databases', 'Data Visualisation']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Admin cum Accounts [ Invoice  /  Data Entry  /  5 Days  /  Tuas],"THE INDEX, 110 TUAS SOUTH AVENUE 3 637369","Full Time, Flexi-work",Junior Executive,1 year exp,"Admin / Secretarial, Customer Service, General Work, Manufacturing, Purchasing / Merchandising",Monthly,"$1,800to$2,100","5 days work week: 9am to 5pm
Work Flexible: 3 days in office, 2 days work from home
Work Location: Tuas
Transportation to and from: Jurong Point
Salary Range: S$1,800-S$2,100  + Variable Bonus

Job Description

Processing full cycle of Customers' purchase orders till shipment fulfilment (ERP system)
Handle basic purchasing activities with approved vendor list
Promptly respond on customer's weekly order report
Attend to customer enquiries on orders related matters

Candidates Profile

Diploma with business studies background
Proficient in MS Office applications, in particular MS Excel
Able to communicate effectively in English
Willingess to gain new knowledge and skillset
Interests in exposing to other functional role within the organization

","['Microsoft Office', 'Microsoft Excel', 'Administrative Work', 'Interpersonal Skills', 'Purchasing', 'Invoicing', 'Administration', 'Data Entry', 'MS Office', 'Accounting', 'Transportation', 'Administrative Support', 'Excel', 'Team Player', 'Microsoft Word', 'Customer Service', 'Scheduling', 'Able To Work Independently']"
2812 - Management Analyst [ MRO  /  P&L  /  Balance Sheet  /  Business Partner  /  Analyse Data,"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Senior Executive,3 years exp,Accounting / Auditing / Taxation,Monthly,"$4,000to$5,300","Position : Management Analyst
Working Day : 5 Days
Working Timing :  9AM - 5:30PM
Working Location :  [ HQ @ Eunos ]
Salary : $4000 - $5300 + AWS

Job Description

Extract, interrogate and analyse data to support business decision making.
Provide valuable insight into the implementation of major projects.
Evaluate the company’s current assets and investments and gauge the company’s overall financial health through key financial ratios.
Analyze and determine profitability of existing products.
Assist with business planning and budgeting process, including the delivery of appropriate consolidation
models and related documentation.
Create and maintain financial models and detailed forecasts of the company’s future operations.
Utilize historical and exisitng data to analyze performance and suggest improvements.
Consider expansion or growth opportunities, map out growth plans, including capital expenditures and investments.
Prepare middle to long-term financial forecasts.
Support the development and implementation of Finance policies and procedures.
Prepare reports for the leadership team and support any other ad-hoc business reporting.

Job Requirement

Bachelor’s degree in Finance or related disciplines
A minium of 3-5 years of relevant analytical experience
","['Asset Management', 'Leadership', 'Microsoft Office', 'Risk Assessment', 'Data Analysis', 'Analytical Skills', 'Consolidation', 'Investments', 'Risk Management', 'Administration', 'Business Planning', 'Project Management', 'Banking', 'Budgeting', 'Capital', 'Decision Making', 'Financial Services']"
"Executive, Healthcare Information (Data Stakeholder Success)","CONNECTION ONE, 167 JALAN BUKIT MERAH 150167",Full Time,Executive,2 years exp,"Healthcare / Pharmaceutical, Sciences / Laboratory / R&D",Monthly,"$4,000to$5,500","The SingHealth Polyclinic’s (SHP) Healthcare Information (HI) team’s Vision takes after that of SHP’s Data Administration Group (DAG), which is “A data-driven approach to better and safer care, with seamless access to data and analysis”. HI consists of 4 sub-teams – Data Management, Healthcare Intelligence, Machine Learning and Data Stakeholder Success.
To achieve our Vision, the Executive of HI’s Data Stakeholder Success team will ensure all relevant teams within SHP have the capabilities and know-how to create a data-driven culture by:

working with stakeholders to understand their data-related needs, then planning the curriculum and implementing training sessions to address their needs, driving towards data democratisation and self-help
providing internal team technical support on data/technical products during design phase
conceptualising and creating a steady pipeline of training material, whether for training sessions, online videos or electronic direct mailers
providing technical support to users on existing data/technical products, including troubleshooting
working with relevant stakeholders to understand any changes to data-related platforms or processes, and coming up with appropriate change management plans/materials to ensure smooth transitions

You will also assist in managing some general administrative duties.

Job Requirements:

Bachelor’s degree with at least 2 years of relevant experience in a training/change management setting; experience in the data analytics/healthcare industry is preferred
Able to conceptualise and implement a strategy to ‘get everyone on the same page’, whether it is to learn a skill or to be proficient in a new/amended process
An ability to quickly understand the training needs of users; prior understanding of platforms/software like Oracle Business Intelligence (OBIEE), Tableau, R/Python is a plus
Relevant skillsets to create training/change management material as required; e.g. Microsoft PowerPoint/Adobe Illustrator skills are a plus
Strategic mindset in working out what needs to be done, then planning the best way to move forward with stakeholders independently


Interested applicants may apply at https://careers.singhealth.com.sg/job-invite/1540/","['Tableau', 'Machine Learning', 'OBIEE', 'Troubleshooting', 'Change Management', 'Healthcare', 'Data Management', 'Strategy', 'Illustrator', 'Oracle Business Intelligence', 'Technical Support']"
"Assistant Manager, Data Protection Office (Healthcare | West Coast)","ONE FINLAYSON GREEN, 1 FINLAYSON GREEN 049246",Permanent,Professional,3 years exp,Accounting / Auditing / Taxation,Monthly,"$4,500to$6,000","Job Description
The role will provide support in developing, implementing and continual strengthening the hospital’s data protection framework to ensure the organisation is in full compliance with the legislations and organisational policies.

Monitor and track organisation’s compliance with established controls and tools
Manage the hospital’s data repository for sensitive health information
Partner departments and stakeholders on data breach management and follow up
Work with internal and external stakeholders to understand data request needs, strengthen the management of data and implement data protection initiatives
Oversee and conduct regular audits and reviews
Coordinate training requirement with stakeholders
Handle queries or complaints from the public and staff pertaining to data protection matters
Organise and support internal and external meetings for the department
Support administrative matters for the department
Perform any other duties/projects as assigned by supervisor

Job Requirements

Degree holder
A minimum of 2-3 years of relevant experience in Audit or Advisory or Compliance or Data Management.
A good understanding of medical terminology will be advantageous
Process strong analytical and problem-solving skills
Motivated, proactive, optimistic and thrive when facing challenges
Excellent interpersonal and communication skills, verbal and written
Ability to work in a fast-paced and dynamic environment, multitask and adhere well to timelines

Only shortlisted candidate will be notified.
To apply, please visit to www.gmprecruit.com and search for Job Reference: 21680
GMP Recruitment Services (S) Pte Ltd | EA Licence: 09C3051 | EA Personnel: Jaremy Ong | Registration No: R1876766","['data protection', 'data protection regulation', 'Data Management', 'GMP', 'data protection legislation', 'Medical Terminology', 'Compliance', 'privacy and data protection', 'Audits', 'Communication Skills', 'Data Protection Management', 'Audit']"
 , , , , , , , , , 
"Machine Learning Engineer, Risk Data Mining - Singapore",1 RAFFLES QUAY 048583,Permanent,Professional,3 years exp,Information Technology,Monthly,"$10,000to$20,000","TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Business Risk Integrated Control (BRIC) team is missioned to:
- Protect ByteDance users, including and beyond content consumers, creators, advertisers;
- Secure platform health and community experience authenticity;
- Build infrastructures, platforms and technologies, as well as to collaborate with many cross-functional teams and stakeholders.

The BRIC team works to minimize the damage of inauthentic behaviors on ByteDance platforms (e.g. TikTok, CapCut, Resso, Lark), covering multiple classical and novel community and business risk areas such as account integrity, engagement authenticity, anti spam, API abuse, growth fraud, live streaming security and financial safety (ads or e-commerce), etc.
In this team you'll have a unique opportunity to have first-hand exposure to the strategy of the company in key security initiatives, especially in building scalable and robust, intelligent and privacy-safe, secure and product-friendly systems and solutions. Our challenges are not some regular day-to-day technical puzzles -- You'll be part of a team that's developing novel solutions to first-seen challenges of a non-stop evolvement of a phenomenal product eco-system. The work needs to be fast, transferrable, while still down to the ground to making quick and solid differences.

Responsibilities
- Build machine learning solutions to respond to and mitigate business risks in ByteDance products/platforms. Such risks include and are not limited to abusive accounts, fake engagements, spammy redirection, scraping, fraud, etc.
- Improve modeling infrastructures, labels, features and algorithms towards robustness, automation and generalization, reduce modeling and operational load on risk adversaries and new product/risk ramping-ups.
- Uplevel risk machine learning excellence on privacy/compliance, interpretability, risk perception and analysis.

Qualifications
- Master or above degree in computer science, statistics, or other relevant, machine-learning-heavy majors.
- Solid engineering skills. Proficiency in at least two of: Linux, Hadoop, Hive, Spark, Storm.
- Strong machine learning background. Proficiency or publications in modern machine learning theories and applications such as deep neural nets, transfer/multi-task learning, reinforcement learning, time series or graph unsupervised learning.
- Ability to think critically, objectively, rationally. Reason and communicate in result-oriented, data-driven manner. High autonomy.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['TensorFlow', 'Machine Learning', 'Classical', 'Autonomy', 'Modeling', 'Labels', 'Hadoop', 'Python', 'Fraud', 'Statistics', 'Publications', 'Data Science', 'Scientific Computing', 'API', 'Linux']"
"Data & AI Solution Lead, Public Sector","IBM PLACE, 7 CHANGI BUSINESS PARK CENTRAL 1 486072",Full Time,Professional,10 years exp,"Consulting, Information Technology",Monthly,"$12,000to$20,000","Job Description

To lead Data and AI solution development, client presentation and provide delivery oversight on large scale data analytics and AI engagements
Lead the solution development and pre-sales process, including visioning, development of PoCs and manage delivery.
Work closely with the practiced leaders in recruiting and developing capabilities required.
Work closely with IBM teams to respond to and manage RFI/ RFP.
Responsible for running client workshops, pitches and presentations.
Working closely with clients to identify, understand, define their requirements and solve business problems.
Identify opportunities for innovation in solution and delivery, bringing to bear new technologies and methodology best practices.

Job Requirements

Relevant work experience in solutioning and delivering Data AI engagements on cloud (Azure or AWS or GCP) platform based Data/AI solutions.
Minimum 10 years of relevant work experience in building data and advanced analytics solutions using tech like Hadoop, Tableau, Qlik, Kafka, Informatica, Talend, etc.
Proficient with major data analytics software (ETL, Dashboard, Data modelling) and methodologies (i.e. Agile)
Exposure in predictive analytics, modelling and business intelligence with high performance computing techniques based on statistical software, open source platforms and BI tools.
Familiar with data management and data governance, data engineering, architecture design, systems integration and security
Excellent analytical, communication and presentation skills with the ability to engage business stakeholders and multidisciplinary teams and communicate complex quantitative analysis in a clear, precise and actionable manner
Determined and results-driven personality, with a high level of enthusiasm, energy and confidence
Keen learner who is able to adapt to evolving situations and a dynamic business landscape.
Prior work experience in a Consulting/Architecture position
Prior work experience in Singapore public sector with required security clearance.
","['Security Clearance', 'Tableau', 'Business Intelligence', 'Dashboard', 'Solutioning', 'Hadoop', 'Informatica', 'Public Sector', 'Quantitative Analysis', 'Systems Integration', 'Predictive Analytics', 'Data Governance', 'Open Source', 'Data Engineering', 'High Performance Computing', 'Architecture Design']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"Transition and Data Catch-up Lead (IFRS 17) (2 years, Direct contract)","INCOME CENTRE, 75 BRAS BASAH ROAD 189557","Contract, Full Time",Senior Management,8 years exp,"Banking and Finance, Information Technology",Monthly,"$8,000to$15,000","This role is to oversee the  planning and implementation of supporting accounting systems, processes and controls to produce IFRS 17 compliant financial reporting for the company. You will drive the catch-up closing process planning and catch-up runs under the new IFRS 17 standard.

This role will report to the IFRS 17 Program Director and contribute to the successful completion and implementation of the IFRS 17 Program.

Key responsibilities
Before project go-live

Work on the successful implementation of the IFRS 17 catch- up reporting system working closely with finance, actuarial and IT teams.
Planning and monitoring system implementation activities
Developing appropriate governance over the IFRS catch-up closing process, technical accounting results & disclosures.
Working with the team on the production of disclosure requirements, identifying and ensuring data sources are ready for catch-up runs, and supporting the testing of future processes to meet those disclosure, especially for historical comparative figures
Taking ownership of IFRS 17 catch-up reporting system & process development, to deliver a robust and reliable platform for IFRS 17 compliant results.
Leading the coordination and planning with stakeholders on the design and planning of the new end-to-end closing process for IFRS17 comparative figures
Designing error-handling procedures and processes to support generation of comparative figures post project go-live

Post project go-live

Monitoring the team in executing parallel runs and supporting the generation of comparative figures; testing and refining the operating model to ensure full readiness for the go-live date for IFRS 17 financial reporting.
Guiding the team in performing financial year-end closing, reporting and prepare financial statements
Supervising the team to handle issues (technical, data or financial) occurring during the generation of IFRS17 comparative figures
Guiding the team to reconcile and perform adjustments, where necessary to ensure compliance for IFRS17 comparative figures
Overseeing preparation and review of prior period financial analysis on the technical results.
Coordinating closely with reporting teams to support the production of IFRS 17 results and financial statements
Supporting and championing continual enhancements to reporting capabilities within the Risk Integrity system and related reporting processes as required.
Supervising the working day timetable for IFRS17 catch-up reporting


Qualifications 

Bachelor of Accountancy or Actuarial Science
At least 8 years’ working experience; good to have at least 3~4 years in the Insurance industry
Good understanding of the IFRS17 accounting standard
Experience in the implementation of IFRS 17; in either the PMO, Finance or Actuarial workstreams
Experience in financial reporting and month end closing
Strong interpersonal skills and ability to connect and influence various stakeholders
Experience of creating and maintaining a project plan
Proven track record of successfully managing their own work and that of others where required, including the ability to plan, prioritise and organise work to meet tight deadlines
Excellent written and verbal communication skills, including the ability to relate effectively to users at all levels and careful attention to detail
Excellent analysis and problem-solving skills
","['IFRS', 'Management Skills', 'Change Management', 'Interpersonal Skills', 'Business Acumen', 'Project Planning', 'PMO', 'Project Management', 'Financial Statements', 'Planning and Implementation', 'Communication Skills', 'Financial Reporting']"
 , , , , , , , , , 
"Data Analyst, HERA Partner (18-month contract)","MARINA BAY FINANCIAL CENTRE, 10 MARINA BOULEVARD 018983","Contract, Full Time",Manager,5 years exp,Banking and Finance,Monthly,"$7,000to$10,000","ROLE
The Data Analyst works closely with Finance SMEs to gather requirements, assess solutions, and support change management and implementation related to data migration and finance transformation.

KEY ACCOUNTABILITIES
A core team member of Data & AI, responsible for the collective success of the team and the company. The Data & AI team consist of various domain experts including Data Engineers, Data Developers and Data Analysts to perform multi-disciplinary, interrelated activities

Gather requirements:
· Elicit data migration requirements from stakeholders, applying effective elicitation methods. Ensure requirements are complete
· Document requirements and processes using industry-standard notations
· Work with Finance SMEs and third-party vendors to define the scope of data extraction from various source systems
· Work with Finance SMEs and system integration partner to define the scope of data requirements for the target applications
· Perform data analysis to cleanse and standardize data, and ensure data consistency and quality
· Work with Finance SMEs to transform the extracted data and prepare data migration templates for business sign-off
· Work with system integration partner on error resolution and facilitate data reconciliation and sign-off from Finance SMEs post migration
· Perform gaps and resolutions analysis

Assess and validate solutions:
· Facilitate workshops with internal and external stakeholders to drive out solution options and works closely with them to complete solution design documents
· Support functional and integration testing

Support change management and implementation:
· Provide information as required to facilitate effective communications
Provide project support to the impacted teams during implementation phases, including answering queries, trouble shooting, liaison with service provider, and providing regular reporting
· Contribute to project management processes, including status reporting, risk, issue, change, and compliance management
· For smaller projects, act as the project manager as well as business analyst to deliver the project

EXPERIENCE / QUALIFICATIONS

Must have at least 3 full lifecycle hands-on experience in preparing ADFdi, FBDI and HDL templates for migration into Oracle Cloud Financials
Working knowledge of Oracle Cloud Financial modules. Experience in working on Master and Transaction Data Migration from Legacy Applications into Oracle Cloud ERP (Financials)
Proficient with data wrangling, analytics, and transformation using tools such as Python, SQL, and Power Query
Experience in using business analyst methods such as flow charting, requirements capturing, stakeholder analysis, use cases, brainstorming, solution prototyping, and traceability
Experience in dealing directly with Finance end users and/or working on transformational projects that created substantial organizational level changes
Familiar with project management methodologies and frameworks
Familiar with Asian local markets and regulatory practices
CFA Level 1-3, or good understanding of asset management, is a plus


GENERAL CANDIDATE ATTRIBUTES

Inquisitive, analytical, and problem solver
Attentive to details and comfortable dealing with complex datasets, structured and unstructured
Customer-centric and strive to deliver value by effectively and proactively engaging stakeholders
Able to communicate complex ideas clearly and manage expectations with stakeholders. Has good negotiation skills
Able to prioritise and organise, take a flexible approach to workload, and work autonomously when required

","['Requirements Gathering', 'Oracle', 'Data Analysis', 'Change Management', 'ERP', 'Financials', 'Attentive', 'SQL', 'Data Migration', 'Python', 'Business Analyst', 'Integration Testing', 'Business Requirements']"
 , , , , , , , , , 
Clinical Research Coordinator_Haematology_Oncology (Data) (Contract),1E KENT RIDGE ROAD 119228,"Contract, Full Time",Executive,2 years exp,Healthcare / Pharmaceutical,Monthly,"$3,000to$6,000","The Challenges
• Collect data from clinical trials.
• Provide clinical trial support such as data entry and transcription.
• Ensure timely and accurate transcription of information on source documents, paper case report forms (CRFs), or electronic CRFs.
• Manage clinical trials through review, computerization, cleaning and auditing of clinical data and in compliance with standard operating procedures.
• Validate clinical trial data to ensure consistency, integrity and accuracy.
• Resolve queries on data inconsistencies
• Review case report forms for completeness and consistency.
• Work in collaboration with study team to ensure data validity.

The Requirements
· Degree in Nursing, Biomedical Science, Health Science or related field
· Good interpersonal and communication skills with patients and colleagues
· Good work attitude, organized, able to multi-task, work independently and perform well under pressure
· Computer proficiency is essential – MS Word, Powerpoint and Excel
Interested applicants are invited to email a detailed resume stating your current and expected salary to alliedhealth@nuhs.edu.sg
Please indicate in the subject title as: ""Applying for position of “Clinical Research Coordinator_Haematology_Oncology (Data) (Contract)”.
We regret that only shortlisted candidates will be notified.","['Able To Multitask', 'Clinical Research', 'work independently', 'Auditing', 'Inventory Control', 'Data Entry', 'Clinical Trials', 'Protocol', 'PowerPoint', 'MS Word', 'Compliance', 'Nursing', 'Life Sciences', 'Screening', 'Transcription', 'Technical Support']"
 , , , , , , , , , 
"Cyber Strategy Consultant, Data Protection",30A KALLANG PLACE 339213,Full Time,Executive,1 year exp,Information Technology,Monthly,"$3,000to$6,000","Responsibilities

Engage clients to identify requirements relating to cyber security solutions for Data Protection
Proposal, scope and size technical solutions for clients
Deploy competency’s related projects and provide consultation to clients with regard to the deployment as a Subject Matter Expert (SME)
Create technical documentation for the solution deployment
Empower clients through technical enablement
Provide post-sales support services for corrective and preventive maintenance when necessary

Requirements

Good Diploma or Bachelor’s Degree in Information Technology
At least 1 to 4 years of IT security experience
Experience in leveraging and expanding the capabilities of existing analytical tools and technologies; recommend new technologies as appropriate
Experience with web security, email security and Cloud Access Security Broker (CASB) and will be preferred
Positive working attitude
Good communication and written skills
Passionate in information security
Experience in programming and scripting is preferred
","['post-sales support', 'data protection', 'Information Security', 'Technical Documentation', 'Subject Matter Expert', 'technical solution', 'Cyber Security', 'Scripting', 'Web Security', 'solution deployment']"
"Cyber Security Consultant, Data Loss Protection",30A KALLANG PLACE 339213,Full Time,Executive,3 years exp,Information Technology,Monthly,"$3,000to$5,500","Responsibilities:

Carry out pre-sales engagement for projects relating to AI
Deploy AI related projects and provide consultation with regard to the deployment as a Subject Matter Expert (SME)
Create technical documentation for the AI deployment
Provide post-sales support services for corrective and preventive maintenance
Carry out technical enablement

Requirements:

Good Diploma or Bachelor’s Degree in Information Technology
Has advanced experience in Data Loss Protection
At least 3-5 years of IT security experience
Good communication and written skills
Positive working attitude
Passionate in information security
","['Information Security', 'Technical Documentation', 'Subject Matter Expert', 'pre-sales support', 'Cyber Security', 'Information Technology', 'Technical knowledge', 'Compliance', 'Team Player', 'Data Loss Prevention']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"Admin Executive / Assistant (Data Entry) - Up to $3,500","CPF TAMPINES BUILDING, 1 TAMPINES CENTRAL 5 529508",Permanent,Junior Executive,1 year exp,Admin / Secretarial,Monthly,"$2,500to$3,500","
Position: Admin Executive/Assistant
Location: Raffles Place
Working hours: Mon-Fri/Office hours
Salary (commensurate with experience): Up to $3,500 + AWS + Performance Bonus
Duration: Permanent
Industry: Insurance Broking firm

Main Responsibilities:

Cover daily administrative duties and data entry work.
Work with finance department to ensure that payment has been received from clients.
Monitor and review of policy claims.
Any other ad-hoc duties assigned.

Requirements:

At least Diploma in any discipline.
Proficient with Microsoft Excel/Word.
Full training and guidance is provided for inexperienced candidates.
Bilingual in English and Mandarin to liaise with Chinese clients who can converse in Mandarin only.

Email to: abby.pang(at)searchpersonnel.com.sg or call me at: 6398 5690 for more information.
Do visit www.facebook.com/search.personnel for more job listings.
***We do not charge our candidates any referral fee nor bind them with any contract.***
Abby Pang
Senior Consulting Manager (APAC)
Reg no.: R2093867
EA No: 13C6684","['Microsoft Office', 'Microsoft Excel', 'Listings', 'Interpersonal Skills', 'Invoicing', 'Administration', 'Data Entry', 'Office Administration', 'Administrative Support', 'Consulting', 'Team Player', 'Microsoft Word', 'Able To Work Independently']"
 , , , , , , , , , 
"Senior / Data Analyst, Mobile Analytics (12 months contract)",80 ROBINSON ROAD 068898,Contract,Senior Executive,5 years exp,"Entertainment, Information Technology",Monthly,"$5,000to$6,500","Who We Are:
2K develops and publishes interactive entertainment globally for console systems, handheld gaming devices and personal computers, including mobile devices. 2K is a leading publisher of today’s most popular gaming genres and most well-known for critically acclaimed game franchises like NBA 2K, WWE 2K, BioShock, Borderlands, Evolve, XCOM and the beloved Sid Meier’s Civilization.
What We Need:
2K has been a major console and PC game publisher for several console generations and is known for bringing amazing IP to the market. As our games get bigger and more complex, we are growing our analytics group. We are looking for a skilled and passionate Sr. Analyst to work in the Analytics team, who will be primarily focusing on 2K’s mobile games and be responsible with crunching data, translating that information into digestible reports, setting up dashboards, building predictive models, and giving actionable data and insights to our development team.
What You Will Do: Senior Data Analyst, Mobile Analytics
As a Senior/Data Analyst at 2K, you will be…

Working closely with development teams to provide insights to understand the impact of product decisions on game quality
Determining what data needs to be captured to serve development team’s needs and summarising the data in the most useful format
Analysing gameplay and economy telemetry data to understand how feature, content, and balance adjustments are impacting overall player experience, before and after the product launches
Analysing game and player data to understand player behaviour and enhance the quality of the player experience
Regularly performing ad hoc analyses for development, live ops, and performance marketing teams
Presenting findings derived from data analysis both in person and in presentation form for remote groups
Designing, testing and implementing scalable and repeatable model framework for user acquisition, engagement and monetization strategies around live ops
Defining and establishing business KPIs as well as creating and distributing regular performance reports and dashboards

Who We Think Will Be a Great Fit:
We’re looking for an analyst who is eager to mine data for insights as well as test hypotheses rigorously by using data-driven techniques. The ideal candidate must be able to identify the underlying story in the data and leverage their communication skills to develop a compelling narrative to their team as well as executives. Being a solution oriented problem solver as well as a self-starter with passion, creativity, and enthusiasm to drive the results for meaningful changes are also going to be very critical for this role.
Key to success in this role:

B.A. or B.S. in Mathematics, Statistics, Economics, Computer Science, Data Science, Engineering Sciences (or a similar quantitative discipline)
5+ years of experience in data mining & analytics with very large, complex, and multi-dimensional data sets
Experience with predictive modelling techniques and accomplished in use of statistical software packages (R or Python preferred)
Knowledge of one or more of the following: time series, experimental design, classification, clustering, and regression analysis
Expert in relational databases, and proficient with SQL
Advanced experience with Tableau or other similar visualization tools
Excellent communication skills, with a proven track record of working across all levels of the organization

Bonus points:

Master’s or PhD degree in quantitative field
Experience with machine learning and deep learning
Experience with big data technologies such as Spark, Hadoop, or Hive
Knowledge of free-to-play mobile game economics and/or performance marketing
Experience of initiating and leading interdisciplinary science and engineering research and projects
Passionate for mobile gaming and user growth
","['Tableau', 'Excellent Communication Skills', 'Entertainment', 'Hadoop', 'Mathematics', 'Translating', 'Mobile Games', 'Economics', 'Data Mining', 'Experimental Design', 'IP', 'Telemetry', 'Mobile Devices', 'Monetization', 'Data Science', 'Visualization']"
Service Lead - Data Center and Cloud,"CHROMOS, 10 BIOPOLIS ROAD 138670",Full Time,Professional,6 years exp,Information Technology,Monthly,"$8,500to$10,000","Main Purpose of Job

The individual will be a member of Global IT Team. Person will be responsible to understand business requirements in context of IT cloud infrastructure and translate them to Cloud solutions by working with internal stakeholders and external vendors to deliver “best solution” for the business needs.
Right candidate will help HSO organization to achieve cloud maturity.

Key Duties & Responsibilities
Strategic

Participate in development of cloud infrastructure (multi/hybrid cloud) strategy, ensuring alignment with global IT strategy.
Design and develop cloud infrastructure (multi/hybrid cloud) architecture patterns and documentation, to effectively explain architecture design concepts and solutions to various level of stakeholders.
Design and develop cloud platform-specific policies, security policies, standards, and procedures for cloud native platforms (PCF, Docker, Kubernetes, etc.) and Software as a Service solutions.
Identify and implement appropriate controls based on industry standards (e.g. CCM, ISO 27001).

Operational

Serve as the deep Subject Matter Expert (SME) in the development of cloud infrastructure. (multi/hybrid cloud) solutions using Landing Zone, DevSecOps, automated orchestration, and configuration management techniques.
Specialize in cloud infrastructure activities such as deployment, migration, maintenance, monitoring, and management. Recommend performance improvement based on demand and utilization.
Specialize in implementing secure and compliant enterprise servers, network infrastructure, boundary protection, and cloud architectures using Infrastructure-as-Code (IAC).
Respond to technical incidents/difficulties in a timely and competent manner.
Stay abreast of emerging security threats, vulnerabilities and controls to identify and minimize the impact on IT and Business.
Contribute in security assessments against industry frameworks and recommend holistic improvements considering all aspects of the organization.
Collaborate with the application, data, security and business teams to ensure excellent products and service delivery.
Constantly explore new solutions and technologies, integrate learning and recommendations into the development process.

Education

Bachelor's degree in information security, computer science, computer engineering, or IT equivalent
Cloud certification such as Azure Solutions Architect Expert is preferred

Experience

6 years or more years of experience in in Azure cloud solutions (IaaS/PaaS/SaaS) deployment, implementation and operations; international experience desired

Skills

Passion to work for a growing medical technology organization
Advance knowledge of cloud architectural principles and design
Expertise in Microsoft Azure Cloud products and solutions
Experience in cloud security architecture, security assessments, audit standards for Azure Cloud
Experience in deployment and management of Landing Zone and Data platform
Experience building and migrating applications in the Azure cloud
Experience in DevOps software development tools and methodologies
Strong understanding of data center networking
Self-motivated with a positive “can-do” attitude, creative with excellent presentation, communication, teamwork and interpersonal skills including strong persuasive techniques

By submitting your application, you agree that your personal data will be collected, disclosed, and retained by HOYA Group for assessing suitability for employment and verification purposes.

We regret to inform you that only shortlisted applicants will be notified. 

Thank you for your kind understanding.","['Information Security', 'Security Architecture', 'Microsoft Azure', 'Kubernetes', 'Assessing', 'Azure', 'Data Center', 'Architectural', 'ISO', 'ISO 27001', 'Configuration Management', 'Architecture Design', 'Docker', 'Orchestration', 'IT Strategy', 'Service Delivery']"
 , , , , , , , , , 
Events Data Analyst Early Professional Program - Singapore,"Capital Square, 23 Church Street 049481",Full Time,Fresh/entry level,1 year exp,Banking and Finance,Monthly,"$5,000to$8,000","Bloomberg runs on data, and data drives the market. Our Data team acquires and supplies this data to our clients. Teams work collaboratively to collect, analyze, process and publish the data which is the backbone of our iconic Bloomberg Terminal - the data ultimately feeding and moving the financial markets.
The Role:
As an Events Data Analyst you will apply your problem-solving skills to manage the financial data that feeds Bloomberg products. You will identify innovative workflow efficiencies and implement solutions to enhance our systems, products and processes. You will be instrumental in building and maintaining relationships with key players in the financial market.
Our Data Analysts possess a unique combination of business insight and technical aptitude, as well as strong communication skills and ability to build relationships with various stakeholders. They use these skills to extract, transform and load timely, accurate and comprehensive data accessible to our clients across various Bloomberg platforms, playing a key role in empowering our clients to make well informed business decisions. Providing exceptional support assisting our clients with their data queries is a key part of the role.
The Team:
The global Companies Data team provides market-leading data with industry insights across a wide array of datasets that cover company financial information including the description of business activities, industry classification, equity fundamentals, broker estimates, ESG, supply chain, corporate events, company management and more. We partner closely with the Product, Engineering, Sales and News areas to create derived data products to support the numerous use cases that our clients heavily rely on to drive their workflows.
We’ll trust you to:

Manage Event Feeds Data and identify opportunities to improve and drive clients’ data usage in APAC
Network with local institutions and users to increase presence in the corporate event conference space
Manage the ETL infrastructure and use business intelligence data to drive insights and impact
Acquire, extract and validate high-quality data using the variety of internal software
Provide timely and in-depth customer support for users of the Bloomberg Terminal and our associated Enterprise Products
Plan and lead self-initiated projects to optimize processes and/or improve the quality of the data set
Use statistics and data visualization skills to report on results of on-going operations and projects, as required
Build relationships with market players and form lasting partnerships with external and internal stakeholders (Investor’s relationships, News, Intelligence Team)
Contribute to continuous improvement by generating ideas to improve our data products and/or associated processes and building prototypes to validate and illustrate requirements
Partner with a wide variety of teams ranging from Engineering to Sales on product development
Monitor financial market developments to build industry knowledge and data analytical capabilities that generate premium content, including data-driven news stories

You’ll need to have:

1-2 years of work experience
Experience in stakeholder management, vendor management, or client facing role in the finance industry
A demonstrated interest in concepts and products of financial markets (example: course of degree or work/internship experience or extracurricular activities)
A demonstrated capability in Data Management, Data Cleaning & Processing, or Data Analysis
Effective project management skills and ability to prioritize tasks accordingly
Ability to communicate effectively and articulate thought process clearly
Eagerness to learn and collaborate with teams across regions and products
Effective research and analysis skills with attention to detail
An interest in using technology to perform operational data analysis
Business proficiency and fluency in English to manage respective clients and financial data

We’d love to see:

Experience in Event Feeds Data and understanding on how it can impact clients to drive usage in APAC
Experience in managing ETL infrastructure and ability to use business intelligence data to drive insights and impact
Proficiency in Python, SQL or R, demonstrated through school projects or work experience
Previous work experience with the Bloomberg Terminal or Bloomberg Market Concepts (BMC) certification

Does this sound like you?
This is an entry level role. Apply if you think we're a good match. Please note this is a two-stage application process, following the submission of your candidate details you will receive an email with directions to complete an online assessment. Your application will not be complete until you have submitted the assessment. 

In the meantime, feel free to have a look at this: https://www.bloomberg.com/careers/global-data/
Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law.
Bloomberg is a disability inclusive employer. Please let us know if you require any reasonable adjustments to be made for the recruitment process. If you would prefer to discuss this confidentially, please email apac_recruit@bloomberg.net.","['Data Cleaning', 'Data Analysis', 'Data Management', 'ETL', 'Data Processing', 'Financial Markets', 'Vendor Management', 'Bloomberg Terminal', 'Stakeholder Management', 'Data Visualization']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Solutions Architect (AI / ML / Data Mining),"HOR KEW BUSINESS CENTRE, 66 KALLANG PUDDING ROAD 349324",Full Time,Professional,8 years exp,Information Technology,Monthly,"$5,500to$9,500","About the job
Support DuraPower to fully recognize Digital value and help them substantially create more business value and most importantly contribute to shared vision of DuraPower.

Where you fit

DuraPower have been pioneering in electric cell manufacturing for over 12 years and seen the landscape develop from early adopters into the early majority. Today they are working together with other leaders in the industry to shape the future of e-mobility and stationary storage of lithium-ion battery. It has his presence across 21 markets across the globe headquartered in Singapore. This role is key to success of groups shared vison to build a robust Digital capability centered around new energy innovation and cater to decarbonized energy demand for the future.
The Digital leadership team is part of Innovation CoE, includes dedicated implementation team to act as the bridge between product R&D, business and external ecosystem

What’s the role?

As Solution Architect you will join our team in Singapore. This is an exciting role for you as you will experience diverse set of innovation in battery technology, Digital innovations and capability building while experiencing global market scenarios and trends in this sector. You will be responsible for the end-to-end full process of development/co development of solution architecture product and innovation roadmap and working closely with product manager and experts, involved in sourcing solution providers and integrating partnership with external stakeholders while leading the design to build product and capabilities.

Key Expectation:


To oversee the technology development of the end-to-end tools (portals – web and app, analytics utility, data visualization)
To help the leaders making right technology decisions for data engineering, data hosting and to identify right partners for development.

Key success measure for the role

Ability to build and drive simplicity in solutions to have effective interest and engagement of users. and working closely with partners, product owner and internal team.

Core Responsibilities are as follows:

Develop Product technology strategy jointly with the product manager.
Collaborate with Digital leadership team and cross functional team members in project execution.
Act as a trusted 'advisor' to the CTO and management team in your role as a guiding and helping portfolio projects be successful throughout the various stages of their growth.
Validate, structure, and support the implementation of appropriate technology opportunities that can accelerate the deployment of technologies, products, or services in DuraPower operations, in close collaboration with implementation (sometime external) team;
Cultivate a close working relationship with specific business stakeholders to ensure alignment of strategy, sharing of knowledge, and ongoing relevance to business groups.
Develop and leverage your internal and external network to source opportunities, validate technology relevance of projects.
Have an excellent nose for 'quality' and a proven ability to quickly down select the best technology for DuraPower from a large pool of opportunities.
Provide both challenge and support to others in the team (e.g. in our Digital Leadership Committee discussions), portfolio project representatives, and external parties;
Passion to contribute towards continuous team professionalization without losing sight of value delivery.
Highlighting Durapower as new energy and mobility leader within a low-carbon ecosystem with disruptive innovation in energy and transportation; and

What We Need from You

University degree in Data science Engineering with experience of 5-8 years experience; candidate with lesser candidates may be considered
Knowledge of systems development, including system development life cycle, project
management approaches and requirements, design and testing techniques
Proficiency in data modeling and design, including SQL development and database administration
Ability to implement common data management and reporting technologies, as well as the basics of columnar and NoSQL databases, data visualization, unstructured data, and predictive analytics.
Understanding of AI (ML/DL) technologies, like predictive modelling, optimisation, data mining, data visualization etc.
Knowledge of programming languages Python, C/C++, Java, and Perl and software engineering practices
Natural curiosity, creative and critical thinker with learner mindset.
Demonstrable technical expertise in, and passion for, technology and innovation. Professional experience in a technical role in the Energy, Mobility, is an upside.
Deep understanding of how technology or new business models unlock new opportunities.
Executive presence’ and the ability to represent Durapower in internal leadership and public forums.
Strong communication skills with the ability to build and maintain relationships within a complex, global corporation; and
A true “team player” with a collaborative attitude and an interest in developing talent.
","['Perl', 'Cell', 'Data Modeling', 'Technology Development', 'Architect', 'Software Engineering', 'Predictive Analytics', 'Data Engineering', 'Data Mining', 'SQL', 'Database Administration', 'Solution Architecture', 'Python', 'Java', 'Databases', 'Data Visualization']"
"Cyber Security Consultant, Data Protection",30A KALLANG PLACE 339213,Full Time,Executive,3 years exp,Information Technology,Monthly,"$5,000to$10,000","Responsibilities

Engage clients to identify requirements relating to cyber security solutions for Data Protection
Proposal, scope and size technical solutions for clients
Deploy competency’s related projects and provide consultation to clients with regard to the deployment as a Subject Matter Expert (SME)
Create technical documentation for the solution deployment
Empower clients through technical enablement
Provide post-sales support services for corrective and preventive maintenance when necessary

Requirements

Good Diploma or Bachelor’s Degree in Information Technology
At least 3 years of IT security experience
Experience in leveraging and expanding the capabilities of existing analytical tools and technologies; recommend new technologies as appropriate
Experience with web security, email security and Cloud Access Security Broker (CASB) and will be preferred
Positive working attitude
Good communication and written skills
Passionate in information security
Experience in programming and scripting is preferred
","['post-sales support', 'data protection', 'Information Security', 'Technical Documentation', 'Subject Matter Expert', 'technical solution', 'Cyber Security', 'Scripting', 'Web Security', 'solution deployment']"
Senior Cyber Security Consultant (Data Protection),30A KALLANG PLACE 339213,Full Time,Senior Executive,5 years exp,Information Technology,Monthly,"$4,500to$8,500","Responsibilities

Engage clients to identify requirements relating to cyber security solutions for Data Protection
Proposal, scope and size technical solutions for clients
Deploy competency’s related projects and provide consultation to clients with regard to the deployment as a Subject Matter Expert (SME)
Create technical documentation for the solution deployment
Empower clients through technical enablement
Provide post-sales support services for corrective and preventive maintenance when necessary

Requirements

Good Diploma or Bachelor’s Degree in Information Technology
At least 5 to 8 years of IT security experience
Experience in leveraging and expanding the capabilities of existing analytical tools and technologies; recommend new technologies as appropriate
Experience with web security, email security and Cloud Access Security Broker (CASB) and will be preferred
Positive working attitude
Good communication and written skills
Passionate in information security
Experience in programming and scripting is preferred
","['post-sales support', 'data protection', 'Information Security', 'Technical Documentation', 'Preventive Maintenance', 'Cyber Security', 'Information Technology', 'Web Security', 'Team Player', 'solution deployment']"
Lead Software Engineer (Big Data Stack Admin),"MARINA SQUARE, 6 RAFFLES BOULEVARD 039594",Full Time,Professional,10 years exp,Information Technology,Monthly,"$6,000to$12,000","Our client is a Asia’s leading insurance company, providing financial security

Job Purpose

We are seeking a highly motivated and talented Hadoop Admin or Big Data Stack Admin to work in next-generation data platform. Working alongside team of engineers and architects, you will be responsible for running and managing our big data stack in DEV/SIT/UAT/PROD and supporting a hybrid data platform. T

The Job / Responsibility

Responsible for implementation and ongoing administration of Platform infrastructure in a minimum of 15+ nodes environment.
Takes care of the day-to-day running of big data clusters (including but not limiting to Hadoop and MariaDB dbases)
Responsible for working closely with the database team, network team, BI team and application teams to make sure that all the big data applications are highly available (24x7) and performing as expected.
Responsible for capacity planning and estimating the requirements for lowering or increasing the capacity of the Hadoop/MariaDB cluster
Responsible for enabling different level of Hadoop/MariaDB security at ecosystem level.
Performance tuning of Hadoop clusters and Hadoop ecosystem.
Perform POCs of new capability in Hadoop/MariaDB Platform
Monitor and enhance Hadoop cluster jobs performance and capacity planning
Aligning with the systems engineering team to propose and deploy new hardware and software environments required for Hadoop and to expand existing environments.
Cluster maintenance as well as creation and removal of nodes using Ambari or others and CICD pipeline
Monitor (24x7) Hadoop/MariaDB cluster performance, connectivity and security
Manage and review Hadoop log files and enhance retention policy.
Handles performance tuning of Hadoop clusters and Hadoop MapReduce routines.
File system management and monitoring.
Diligently teaming with the infrastructure,network, database, application and business intelligence teams to guarantee high data quality and availability
Collaboration with application teams to install operating system and updates, patches, version upgrades when required.
Backup and recovery tasks
Good understanding of OS concepts, process management and resource scheduling.
Basics of networking, CPU, memory and storage.
Good hold of shell scripting
Takes accountability in considering business and regulatory compliance risks and takes appropriate steps to mitigate the risks.
Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company.
Highlights any potential concerns /risks and proactively shares best risk management practices.

Our Requirements

Candidate Must have a bachelor’s degree in Computer Science, Software Engineering, or a related field
10+ years in the software engineering profession, in which 5+ years of hands-on experience in Hadoop eco system.
Must have 3+ years’ experience owning multiple critical applications on big data platform with batch and real-time data pipelines.
5+ years’ experience as a Hadoop Admin and worked on more than one cluster with each cluster not limited to 15 Nodes
Must have experience on Hadoop Cluster setup from ground-up.
Must have strong experience with design, development and analytical skills in handling both structured and unstructured data.
Must have the ability to develop and maintainstrong collaborative relationships at all levels across IT and Business Stakeholders.
Must have the ability to prioritize multiple tasks and deal with urgent requests in a demanding environment.
Excellent written and oral communication skills. Adept and presenting complex topics, influencing and executing with timely / actionable follow-through
Hands on knowledge on Elastic search, Kibana dashboards and log management mechanism.
Good understanding of financial/insurance Data warehouse models.
Ability to provide innovative ideas and see through implementation in HDFS, Spark, Hive, Kafka, Scala, Python technologies.
Extensive experience working with data warehouses and big data platforms.
Experience in building strong relationships with senior leaders will be preferable.
Aptitude to acquire new skills as needed for the role
High level of integrity, takes accountability of work and good attitude over teamwork.
Takes initiative to improve current state of things and adaptable to embrace new changes.

Characteristic we look for …

A trendsetter. You thrive in an intellectually challenging environment with leading edge technologies.
A team player. We over ‘I’.
A learner. You have an insatiable thirst for knowledge and greater understanding.
A pragmatist. Your goal is to create useful products, not build technology for technology’s sake.
An empath. You understand what the customer needs and use that perspective to create the best user experience

Best Regards
Geetali Rastogi
EA License Number: 19C9859 | Registration Number: R1980793","['SciPy', 'Scala', 'White Box Testing', 'Academia', 'Big Data', 'Hardware', 'Pipelines', 'Software Engineering', 'Architects', 'Mastering', 'Visual Inspection', 'Networking', 'Python', 'Performance Tuning', 'Computer Vision Technology']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
"Tech Lead (Distributed Database), Data Platform",1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$10,000to$20,000","About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliates are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

What you will be doing:
You will be contributing directly to the database engine, including but not limited to storage, query execution, metadata management, resource management, and performance optimization. By joining this team, you can look forward to a great opportunity to solve hard problems and grow.
- Contribute to the database engine, by leading technical design, implementation, and verification
- Ensure code quality, extensibility, and sustainability within the module/project
- Being hands-on to solve hard problems as well as creating an opportunity for junior engineers to grow
- Support your team by creating a transparent, open, and creative culture

Qualifications:
- Bachelor Degree in Computer Science or related major
- At least 5 years of backend experience with at least 1 year of tech leadership experience
- Expert with Linux operating system principles, networking, and multi-threading
- Expert in software development skills in modern C++
- Expert in working on one or more of these technologies is a plus: ClickHouse, Apache Impala, Prestodb, Trino, Apache Doris, PostgreSQL, MySQL, Greenplum
- Contributor/Committer or PMC of the open-source community is a plus

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Scalability', 'PostgreSQL', 'ClickHouse', 'Database Systems', 'Database optimisation', 'Greenplum', 'network optimisation', 'MySQL', 'Impala', 'Database Administration', 'Process Optimisation', 'Open Source communities', 'Linux System', 'OLAP', 'Resource Management', 'Metadata', 'Metadata Management', 'Linux', 'C++']"
Postdoctoral Researcher – Data-driven Urban Modelling (C3282),1 CREATE WAY 138602,"Contract, Full Time",Professional,1 year exp,Sciences / Laboratory / R&D,Monthly,"$8,992to$10,345","Introduction
ETH Zurich is one of the leading universities of the world with a strong focus on science and engineering. In 2010 it established the Singapore-ETH Centre (SEC) in collaboration with the National Research Foundation (NRF) to do interdisciplinary research on pressing problems.
The centre currently runs several research programmes with the Future Cities Laboratory Global (FCL) as one of the programmes. It is home to a community of over 100 PhD, postdoctoral and Professorial researchers working on diverse themes related to sustainable cities and resilient infrastructure systems. In the course of their work, researchers actively collaborate with universities, research institutes, industry, and government agencies with the aim of offering practical solutions.
Project background
The Resource Efficient Urban Intensification (EFF) research group within FCL, SEC, aims to derive quantitative, predictive models of how the densification of cities impacts their social and economic functioning, as well as their resource efficiency. To that end, the research will make use of large-scale human activity data (e.g., aggregated mobile phone data) and other types of urban data.
FCL Global in Singapore is looking for an exceptional candidate to fill a postdoctoral fellow position for 2 years in the field of data-driven urban modelling.
Job Description

Analysis of ‘big’ urban data with respect to human activity patterns in cities.
Development of mathematical models for the densification of cities and its impact on the social and economic life, as well as on the urban resource efficiency.
Contribution to the design of the research project.
Collaboration with both academic and industrial partners of the project.
Co-authorship of scientific publications in leading peer-reviewed journals and/or top conferences.

Requirements
The ideal candidate should have:

PhD degree in Computer Science, Physics, Engineering, or equivalent
Strong track-record of publications
Experience in the field of urban analytics and/or human mobility
Practical skills in MATLAB, Python and/or R, as well as in the use of GIS tools
Strong communication skills in English, both oral and written

Information about the application process and contact for applicants
We look forward to receiving  your online application with the following documents:

Curriculum Vitae (CV) including educational history, full list of publications, awards, etc
Cover letter explaining your interests, goals, and how they would relate to and fit in with the EFF group’s research
Copy of your publication relevant to the project
Contact details of at least 2 references, mentioning for each of them the professional relationship you have with them

Applications via email or postal services will not be considered.
Work location: 1 Create Way, CREATE Tower, Singapore 138602 (NUS University Town)
Further information about The Singapore-ETH Centre can be found on our website: https://sec.ethz.ch/
The Singapore-ETH-Centre is an equal opportunity and family-friendly employer. All candidates will be evaluated on their merits and qualifications, without regards to gender, race, age or religion.","['Local Government', 'Machine Learning', 'Materials Science', 'Psychology', 'Physics', 'Formulation', 'Electrical', 'GIS', 'Research and Development', 'Good Communication Skills', 'Python', 'Statistics', 'Publications', 'Laboratory']"
2812 - Project Engineer [ Data Centre  /  Potong Pasir  /  Infrastructure  /  Construction ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,3 years exp,Engineering,Monthly,"$3,000to$4,500","Project Engineer

Working Days: 5 Days
Working Hours: 9am - 6pm
Salary: $3000 - $4500
Location: Potong Pasir [Office] // Island-wide [Site]

Requirements:

Diploma in Mechanical Engineering
With experience in data centre / infrastructure / construction engineering is a plus

Jobs Scope:

Develops project objectives by reviewing project proposals and plans; conferring with management
Determines project responsibilities by identifying project phases and elements; assigning personnel to phases and elements; reviewing offers from contractors
Determines project specifications by studying product design, customer requirements, and performance standards; completing technical studies; preparing works estimates
Confirms product performance by designing and conducting tests
Determines project schedule by studying project plan and specifications; calculating time requirements; sequencing project elements
Maintains project schedule by monitoring project progress; coordinating activities; resolving problems
Controls project plan by reviewing design, specifications, and plan and schedule changes; recommending actions
Controls project costs by approving expenditures; administering contractor contracts
Prepares project status reports by collecting, analysing, and summarizing information and trends; recommending actions
Maintains safe and clean working environment by enforcing procedures, rules, and regulations
Maintains product and company reputation by complying with regulations
Maintains and controlling of paperwork and submittals for approval requirements
Contributes to team effort by accomplishing related results as needed
Travel to project sites to witness start-up, integration, and training session
Assist in preparation of tender or pre-sales work whenever necessary
","['Submittals', 'Microsoft Office', 'Construction', 'Quality Control', 'Product Design', 'Drawing', 'Project Planning', 'Estimates', 'Procurement', 'Compliance', 'Project Management', 'AutoCAD', 'Team Player', 'Scheduling', 'Commissioning', 'Mechanical Engineering']"
 , , , , , , , , , 
 , , , , , , , , , 
Senior Platform and Data Engineer,30A KALLANG PLACE 339213,Full Time,Senior Executive,5 years exp,Information Technology,Monthly,"$7,000to$10,000","Responsibilities:

Familiarize with Ensign’s business domain and objectives to develop and deploy big data analytics applications that meet internal business requirements and the needs of partners and customers
Lead the design, development, testing, deployment of efficient and reliable big data processing workflows that follow secure SDLC practices
Design, develop, manage data warehouse architecture and relational databases
Provide monitoring, maintenance and support for system operations as part of M&S as required in commercial projects
Embrace the challenge of dealing with terabytes to petabytes of data on a daily basis
Manage different experimentation, development, staging, production environments to provide overall system functionality, health, scalability, resiliency, and security
Responsible for implementing and maintaining complex big data projects with a focus on collecting, parsing, managing, and analysing large sets of data to turn information into insights using multiple platforms
Deliver detailed documentation and ensure quality throughout project lifecycle

Requirements:

Bachelor’s degree in Computer Science/Information Systems/Computer Engineering or equivalent
Minimum 5 years of experience developing data engineering pipelines or machine learning operations using big data platforms (e.g. Hadoop, Apache Spark, MPP DBs)
Good in-depth knowledge of Hadoop ecosystem (e.g. HDFS, Impala, Kafka, Spark, NiFi, Elasticsearch), associated tools and cloud-based technologies (e.g. EMR, Redshift, S3)
Extensive experience in programming (PySpark, Scala) for data engineering
Understanding of modern software engineering tools such as Git, Bitbucket, Jenkins, Maven
Highly proficient at reading, profiling, parsing, transforming, cleansing and integrating data from various sources (structured, semi-structured and unstructured)
Have strong knowledge in secure SDLC and DevSecOps to design, develop, test, and deploy applications for customer projects
Knowledge in Agile and CI/CD is desirable
Comfort and experience working in Linux environment
Aptitude for automation and software profiling
Experience in Cyber Security / Telco industry will be an advantage
Proven ability to handle multiple customer projects concurrently
Detail-oriented, solution-focused and problem solver
","['Information Security', 'Machine Learning', 'PySpark', 'Big Data', 'DevOps', 'Pipelines', 'SDLC', 'Data Engineering', 'Data Analytics', 'Linux']"
 , , , , , , , , , 
Senior Platform and Data Engineer,30A KALLANG PLACE 339213,Full Time,Senior Executive,3 years exp,Information Technology,Monthly,"$5,000to$10,000","Duties and Responsibilities

Familiar with Ensign’s business domain and objectives to develop and deploy solutions that meet internal and customer requirements
Responsible for the design, build and administration of multi-node data lakes, and data warehouses and data marts
Responsible for health monitoring, solve cluster issues, patching and upgrades
Responsible for node administration, load balancing with add/remove/recovery of nodes
Ensure cluster stability, smooth upgrade releases and solving platform issues by investigating and applying solutions/patches
Deliver detailed documentation and ensure quality throughout project lifecycle

Requirements

Bachelor’s degree in Computer Science/Information Systems/Computer Engineering
Minimum 3 years of hands-on experience on cluster installation, deployment, upgrade, maintenance, troubleshooting various cluster issues and optimizing for better performance
Hands-on experience managing multi-node big data application platforms

​​ - HDFS, YARN, Spark, Hive, Presto, Apache Airflow

Hands-on experience managing multi-node messaging queue platforms

​ - Kafka, Rabbit MQ, Nifi

Hands-on experience managing multi-node containerization and orchestration platforms

​ - Docker, Docker Swarm, Kubernetes

Hands-on experience managing multi-node data warehousing platforms

​ - MongoDB, MySQL, PostgreSQL, ElasticSearch

Hands-on experience on setting up 3rd party applications

​ - GitLab, Arkime

Hands-on experience on setting up security features

- Kerberos, AD, LDAP, Keycloak

Strong awareness of data security, data governance and performance, with an ability to deliver these key non-functional requirements
","['Troubleshooting', 'LDAP', 'Kubernetes', 'PostgreSQL', 'Big Data', 'MySQL', 'Data Security', 'Data Governance', 'Spark', 'Data Warehousing']"
Big Data R&D Engineer - Game Direction,1 RAFFLES QUAY 048583,"Permanent, Full Time",Executive,5 years exp,Engineering,Monthly,"$10,000to$20,000","Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content.   

Why Join Us 
At ByteDance, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for millions of users across all of our products. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at ByteDance.  

Team Introduction 
The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the Bytedance Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics & dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you!  

As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.  

What you'll do: 
- Involved in the construction of offline and real-time data warehouses for our game business; 
-  Optimizing the data ETL process and solving technical issues related to massive data ETL - Involved in data governance work in complex data link dependencies and multi-dimensional data content ecology 
- Leveraging on our middle-platform architecture and product system to quickly implement data solutions for business.

Qualifications
- Bachelor or Masters degree in Computer Science or related technical field or equivalent practical experience 
- At least 3 years of experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.) 
- Experience with performing data analysis, data ingestion and data integration 
- Experience with schema design and data modeling 
- Experience with ETL (Extraction, Transformation & Loading) and architecting data systems 
- Experience in writing, analyzing and debugging SQL queries 
- Experience working with gaming business will be a plus 
- Deep understanding of various Big Data technologies 
- Passionate and self-motivated about technologies in the Big Data area 
- Solid communication and collaboration skills  

ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Data Analysis', 'Big Data', 'Data Modeling', 'Pipelines', 'ClickHouse', 'ETL', 'Data Integration', 'Data Engineering', 'SQL', 'Python', 'Writing', 'Pico', 'Java', 'Debugging']"
 , , , , , , , , , 
2812 - Personal Assistant [ Report  /  Secretarial  /  Admin  /  Document  /  Presentation  /  Data  /  Travel Arrangement ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Admin / Secretarial,Monthly,"$3,000to$4,000","Position title : Personal Assistant
Location: Woodlands
Working days : 8.30am to 5.30 Monday to Friday
Salary : SGD $ 3,000 – SGD $ 4,000 ; Bonus (at least 1 month)

Job Duties/Descriptions:
-Reporting to senior management and performing secretarial and administrative duties 
- Typing, formatting, and editing reports, documents and presentations.
- Entering data, maintaining databases, and keeping records
- Liaising with internal departments, answering calls, and making travel arrangement
- Managing internal and external correspondence on behalf of senior management
- Scheduling appointments, maintain an events calendar and sending reminders 
- Preparing facilities for scheduled events and arranging refreshments, if requried","['Microsoft PowerPoint', 'Microsoft Office', 'Interpersonal Skills', 'Arranging', 'Data Management', 'Office Management', 'Administration', 'Data Entry', 'Pressure', 'Communication Skills', 'Administrative Support', 'Scheduling', 'Databases']"
6606 - Project Engineer [ Mechanical  /  Engineering  /  Project Management  /  Data Centre  /  Infrastructure  /  Construction Engineering ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Executive,2 years exp,Engineering,Monthly,"$3,000to$4,500","Project Engineer

Working Days: 5 Days
Working Hours: 9am - 6pm
Salary: $3000 - $4500
Location: Lor Bakar Batu, Potong Pasir [Office] // Island-wide [Site]

Requirements:

Diploma in Mechanical Engineering
With experience in data centre / infrastructure / construction engineering is a plus

Jobs Scope:

Develops project objectives by reviewing project proposals and plans; conferring with management
Determines project responsibilities by identifying project phases and elements; assigning personnel to phases and elements; reviewing offers from contractors
Determines project specifications by studying product design, customer requirements, and performance standards; completing technical studies; preparing works estimates
Confirms product performance by designing and conducting tests
Determines project schedule by studying project plan and specifications; calculating time requirements; sequencing project elements
Maintains project schedule by monitoring project progress; coordinating activities; resolving problems
Controls project plan by reviewing design, specifications, and plan and schedule changes; recommending actions
Controls project costs by approving expenditures; administering contractor contracts
Prepares project status reports by collecting, analysing, and summarizing information and trends; recommending actions
Maintains safe and clean working environment by enforcing procedures, rules, and regulations
Maintains product and company reputation by complying with regulations
Maintains and controlling of paperwork and submittals for approval requirements
Contributes to team effort by accomplishing related results as needed
Travel to project sites to witness start-up, integration, and training session
Assist in preparation of tender or pre-sales work whenever necessary

If you are interested to apply, kindly WhatsApp me your updated resume in DOC file and allow our Consultant to match you with our Clients.
Whatsapp: +65 8204 7336
✉liki_wong@thesupremehr.com","['Submittals', 'Construction', 'Product Design', 'Active Directory', 'VMware', 'Scripting', 'Estimates', 'Windows Server', 'Windows', 'ITIL', 'Virtualization', 'Mechanical Engineering']"
281 - Regional Project Manager [ Data Center  /  Infrastructure  /  DCIM  /  BMS  /  Design  /  System  /  Building ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Manager,5 years exp,Engineering,Monthly,"$7,000to$10,000","Regional Project Manager
Working day / time: Monday to Friday | 9am to 6pm
Salary: $7k to $10k
Location: Ubi

Job Description:
The Regional Project Manager is responsible for leading and delivering data center
infrastructure management (DCIM) and building management system (BMS) projects across
multiple locations in the region. This includes overseeing the design, implementation, and
maintenance of systems and processes that support the day-to-day operations of the data
center and the building.

Responsibilities:
• Lead cross-functional project teams to ensure successful delivery of DCIM and BMS projects across multiple locations in the region
• Develop project schedules, budgets, and resource plans, and monitor progress to ensure that projects are delivered on time and within budget
• Coordinate with stakeholders across different locations to gather requirements and develop project plans that meet their needs
• Oversee the implementation and integration of DCIM and BMS technologies, including monitoring, power management, and asset management systems, HVAC, lighting, and security systems
• Develop and maintain project documentation, including project plans, status reports, and change requests
• Monitor project risks and issues, and develop mitigation plans to address any challenges that arise
• Ensure that all projects are delivered in accordance with IT policies, standards, and procedures
• Provide regular project updates to senior management, stakeholders, and project teams
• Stay up-to-date with the latest industry trends and best practices, and identify opportunities to improve the DCIM and BMS project management process across the region.

Requirements:
• Bachelor's degree in Computer Science, Engineering, Business Administration, or equivalent.
• At least 7 years of experience in project management, with a focus on data center infrastructure management (DCIM) and building management system (BMS) projects, and experience managing projects across multiple locations
• PMP, Prince2, or other project management certification preferred
• Strong knowledge of DCIM and BMS technologies, including monitoring, power management, asset management, HVAC, lighting, and security systems
• Experience with project management methodologies, such as Agile and Waterfall","['Budgets', 'Asset Management', 'Lighting', 'Data Center', 'PRINCE2', 'Agile', 'HVAC', 'Administration', 'Power Management', 'Project Management', 'PMP']"
 , , , , , , , , , 
6109-Regional Project Manager [ Ubi  /  Data Center  /  BMS ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Manager,5 years exp,"Engineering, General Management",Monthly,"$7,000to$10,000","• Singapore Based
• Attractive Salary Package
• Company Benefits & Incentives
• Interested applicants can also send your resume to ✉ supreme.parislow@gmail.com  and allow our Consultant to match you with our Clients.


Working day / time: Monday to Friday | 9am to 6pm
Salary: $7k to $10k
Location: Ubi

Responsibilities:

• Lead cross-functional project teams to ensure successful delivery of DCIM and BMS projects across multiple locations in the region
• Develop project schedules, budgets, and resource plans, and monitor progress to ensure that projects are delivered on time and within budget
• Coordinate with stakeholders across different locations to gather requirements and develop project plans that meet their needs
• Oversee the implementation and integration of DCIM and BMS technologies, including monitoring, power management, and asset management systems, HVAC, lighting, and security systems
• Develop and maintain project documentation, including project plans, status reports, and change requests
• Monitor project risks and issues, and develop mitigation plans to address any challenges that arise
• Ensure that all projects are delivered in accordance with IT policies, standards, and procedures

Interested applicant can send your resume to Paris Low at +65 90820524

The Supreme HR Advisory Pte Ltd
EA License No: 14C7279
EA Personnel : Low Pey Ning ( Paris Low )
EA Personnel Reg No : R22106109
","['Budgets', 'Asset Management', 'Leadership', 'Construction', 'Lighting', 'Interpersonal Skills', 'HVAC', 'Risk Management', 'Information Technology', 'Project Planning', 'Power Management', 'Project Management', 'Communication Skills', 'Team Player', 'Project Delivery', 'Software Development']"
Technical Project Manager (Data Engineering) - CL,"GUOCO TOWER, 1 WALLICH STREET 078881","Contract, Full Time",Middle Management,5 years exp,"Information Technology, Logistics / Supply Chain, Manufacturing",Monthly,"$7,000to$13,000","Responsibilities:

Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget and scope
Translate business requirements to technical specifications, provide high level solution design
Handle regular stakeholder communication and project updates


Requirements

5+ years of experience of managing engineering or data related projects
Work with the business users to understand business requirements and translate that to high level technical specifications
Manage and coordinate test plan, user sign off and go-live plan
Work on defining high level architecture and appreciate technical complexities required
Work with development team on effort assessment, and manage task assignments and deliverables
Strong communication skills to coordinate with project team, stakeholders and management
Comfortable working with both waterfall and agile methodologies
Working knowledge of SQL required


Nice to have
Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus.


Charles, Lau Ngie Hao License No. 02C3423 Personnel Registration No. R1656741

Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https://www.manpower.com.sg/privacy-policy","['MASSIVE', 'Operational Excellence', 'Scala', 'Data Modeling', 'Pipelines', 'Open Source Software', 'Hadoop', 'Agile Methodologies', 'ETL', 'Open Source', 'Data Engineering', 'SQL', 'Python', 'Data Science', 'Java', 'Business Requirements']"
 , , , , , , , , , 
 , , , , , , , , , 
Data Center UPS Sales Manager,1 RAFFLES QUAY 048583,"Permanent, Full Time",Manager,5 years exp,"Engineering, Sales / Retail",Monthly,"$6,000to$8,500","
Generate new business opportunities and proposes potential business deals
Works closely with local, regional, and global teams to close new business deals.
Establish, cultivate, and maintain key relationships with end customers, influencers, and contractors.
Establish budgetary forecasts and sales volume targets for the SEA DC market.
Identifies and support in qualification of strategic alliances to expand PS solution, products, and services; and business networking to leverage into additional markets.
Provide front line Data Center related marketing and technical support to distribution partners and dealers, as necessary.
Analyze sales and market data to provide relevant information to senior management for decision making.
Be the expert in Data Center power products and solutions, industry standards and overall on-site power system design and integration.
Ad hoc duties

Requirements:

Min Degree in Electrical/Mechanical Engineering
Min 6 – 8 years of relevant sales experience in Data Center Generators
Solid proven direct and channel sales track record.
Excellent communication and interpersonal skills

Interested & qualified applicants, please forward your latest CV in MS word format to fion@pnnacle.com.sg","['Troubleshooting', 'Unicorn', 'Hardware', 'Data Center', 'Interpersonal Skills', 'Asset Protection', 'Business Networking', 'Channel', 'Selling', 'Marketing', 'System Design', 'MS Word', 'Decision Making', 'Business Development', 'Corporate Security', 'Technical Support']"
2812 - Accounts Assistant [ AR  /  Trading  /  Coding  /  Data Entry  /  Billing  /  Oracle  /  Full Set ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,600to$3,000","Accounts Assistant
5 days, 9am- 5.45pm
Salary: $2600 - $3000
Address: Bugis

Responsibilities:
AR function for Trading entity:

Processing of AR bills, including verification, coding, data entry and filing;
Processing of verified AR Receipts into Oracle System daily;
Ensure timely and accurate billing of AR bills;
Performs inter-company reconciliations on a monthly basis;
Updates Discounts & Rebates Files upon issuances of Sales Credit Notes;
Liaises with all other departments to complete AR process, e.g. required receipt information and verifications, etc;
Assists in AR monthly closing process;
Assists in other ad-hoc AR related matter from time to time

Other investment holding entities:

Prepare full sets of accounts, including accounts payable and accounts receivable functions;
Prepare accounting schedules for audit;
Prepare financial and statistical statements and reports;
Analyse financial information to identify discrepancies;
Maintain confidentiality of all financial data;

Requirements:

Minimum Diploma in Finance / Accountancy / LCCI or equivalent
1 to 2 years relevant experience
Experience in Oracle will be advantageous
Proficient in Microsoft Office Excel and Word
Meticulous and able to handle data entries accurately and efficiently
Able to work independently with minimum supervision in fast-paced and high-volume environment with emphasis on accuracy and timeliness
Able to meet tight deadline for monthly closing
","['Sales', 'Accounts Payable', 'Microsoft Office', 'Oracle', 'Data Entry', 'Accounts Receivable', 'Accounting', 'Excel', 'Audit', 'Able To Work Independently']"
Assessment / Data Entry Operator,"WOODLANDS SPECTRUM, 2 WOODLANDS SECTOR 1 738068",Full Time,Non-executive,1 year exp,General Work,Monthly,"$2,000to$2,800","Laundry Assessment/Data Entry Admin

Roles & Responsibilities:
- Receive of garments/pickups from logistics/drivers
- Identify garments type/brand/color/etc and entry to computer system/app
- Assess of garments conditions and suitability for processing
- Sorting/packing of garments (when assigned)
- Housekeeping of workspace
- supervise team members on completion of tasks assigned

Requirements:
- Able to operate computer/mobile app (training of system will be provided)
- Able to read, write and communicate in English
- Able to use basic productivity software (example excel, or bookkeeping)
- Able to handle/carry min 5kg load
- Able to identify colours
- No experience required

Working Hours
- Day Shift (8am – 5pm)
- Night Shift (11pm – 7:30am)
- 5/5.5 days as per shift schedule (work timing may change to base on workload requirement)

Salary ($2000 - $2800)

We sincerely apologize that available positions for Singaporean/Permanent Residents only.

All interested applicants may apply, we may shortlist you for other roles or higher position (team lead) whenever possible.","['Always Punctual', 'Schedule', 'Housekeeping', 'Punctual', 'qualifications', 'book keeping', 'Data Entry', 'Team Player', 'Training', 'environment', 'On time']"
Data Science Advisor (MBA),South Changi Business Park Central 1 486036,Full Time,Non-executive,4 years exp,Information Technology,Monthly,"$7,000to$14,000","You will:
• Collaborate with internal and external teams to understand customer requirements
• Develop and apply a broad range of techniques and theories from statistics, machine learning, and business intelligence to deliver actionable business insights
• Develop and drive testing of algorithms efficacy for differing analytical use-cases
• Performs end-to-end steps involved in model development while establishing subject-matter expertise
• Work with the academic and business community to develop new techniques and to contribute to research in the area of large databases

Take the first step towards your dream career
Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

Essential Requirements
• Solid statistical skills
• Solid Advanced Excel, VBA, Python, SQL, Power BI Skills
• Good understanding of business environment and industry trends
• Good communication and problem-solving skills and being customer focused

Desirable Requirements
• Bachelor’s degree
• Ability to act as a coach to the team
• Strong product/technology/industry knowledge","['Statistical Programming', 'Machine Learning', 'Business Intelligence', 'Mathematics', 'Advanced Excel', 'VBA', 'Open Source', 'SQL', 'Python', 'Statistics', 'Data Science', 'Data Analytics', 'Power BI', 'Excel VBA', 'Databases']"
Sales & Marketing Coordinator [Telesales /  Data analysis /  5 days /  Geylang] (JQ),"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,"Admin / Secretarial, Customer Service",Monthly,"$2,200to$2,500","Salary : $2200-$2500 + Commission
Monday – Friday 9am - 6pm
Location: Geylang/Sims Drive

Job Scope:

Providing sales and administrative support involving efficient handling of sales and marketing plans by the management
Maintaining a healthy relationship with existing customers while opening new doors
Execution of e-commerce orders including processing and packing of orders
Processing daily orders obtained by the local outdoor sales team
Providing customer service via email, e-commerce platforms and phone calls, at times will also be required to do customer visitation
Assisting the Manager with the coordination of sales, stock management and order merchandise.
Managing customer sales and marketing materials
Assist the manager in sales proposal/budget and following ups
Recording new job file in the system which includes job and customer information
All other administrative duties may be required from time to time

Requirement

NAV system knowledge will be of advantage.
","['Sales', 'Telesales', 'Interpersonal Skills', 'Customer Information', 'Invoicing', 'Administration', 'Marketing', 'Data Entry', 'Administrative Support', 'Customer Service', 'Data']"
Enterprise Services - Data Technical Support Representative (Korean speaker) - Singapore,"CAPITAL SQUARE, 23 CHURCH STREET 049481",Full Time,Professional,2 years exp,Banking and Finance,Monthly,"$7,000to$14,000","We’re Bloomberg Enterprise Data - fast paced, innovative and expanding. We have worked hard and smart to become the successful business we are today. We partner closely with our clients, taking time to understand their unique businesses and individual data and technology needs. We provide a vast number of datasets that cover all asset classes, via multiple delivery technologies and flexible scheduling options. This means our clients get exactly the data they need, when they need it, in the format they prefer.
The role:
We’re looking for a passionate, motivated, service-orientated individual to come join our team. You’ll be trained to quickly and accurately identify problems, and then perform detailed & meaningful diagnostic & troubleshooting to identify the root cause. If needed, you’ll escalate the issue internally, all whilst ensuring our clients receive an exceptional, seamless support experience.
You are professional and personable, intelligent and analytical, and keen to join a diverse team that provides round-the-clock support to our Enterprise Data clients. You're a solution-provider, with a passion for providing platinum technical support. You are able to get results by working closely with team members and colleagues around the organization, but are also not afraid of making independent decisions when situation demands. You are an aspiring leader who operates with high impact and is keen to demonstrate your organizational and management skills.
We’ll trust you to:

Work closely with technical and market data contacts at client firms to help resolve & prevent issues that may impact their businesses
Handle escalations to internal Bloomberg groups such as Network Operations, Global Data, Data Feed teams, Implementation and Engineering
Take ownership of questions and technical issues reported by clients and provide direct support using telephone, ticket systems & email, and in person when feasible
Actively troubleshoot to recreate reported customer issues on internal, client simulated & test system environments OR by actually carrying out diagnostic work on the clients' own test/UAT systems
Identify opportunities to implement and drive adoption of self-service solutions to meet client needs
Identify team and personal workflow efficiencies through tooling and process improvement
Maintain the health and availability of our systems through alerting, monitoring, capacity management, instrumenting, and reporting
Partner with sales and account management to build and strengthen client relationships

You’ll need to have:

2+ years experience in a customer facing position involving the support of a technical product.
Excellent communication skills in both English and Korean, to liaise with Korea based clients
Prior working experience on or around market data or associated financial data platforms
An understanding of cloud architecture (AWS, Azure, GCP)
An analytical and problem solving mindset
A passion for customer service
Strong multitasking skills and the ability to maintain a professional demeanor when handling complex and time sensitive issues
Ability to derive requirements from stakeholders via email, meetings, and conference calls
Demonstrated continuous career growth within an organization

We’d love to see:

UNIX skills with ability to investigate technical issues or willingness to learn
Experience working with a scripting language or programming language (i.e Shell, Perl, Python, .NET, Java or C++)
A basic conceptual understanding of Web Services and REST API's
Experience with database querying languages such as SQL, NoSQL or similar
Exposure to architectural design in order to facilitate client adoption of Bloomberg's Enterprise Data products and services 
CFA or related financial services certifications

If this sounds like you:
Apply if you think we're a good match. We'll get in touch to let you know what the next steps are, but in the meantime feel free to have a look at this: https://www.bloomberg.com/professional/solution/content-and-data/
Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law. 

 Bloomberg is a disability inclusive employer. Please let us know if you require any reasonable adjustments to be made for the recruitment process. If you would prefer to discuss this confidentially, please email apac_recruit@bloomberg.net.","['Troubleshooting', 'Multitasking Skills', 'Scripting', 'Architectural Design', 'VMware vSphere', 'Windows OS', 'Windows Server', 'Python', 'Java', 'Disaster Recovery', 'Technical Support']"
 , , , , , , , , , 
 , , , , , , , , , 
9156 - Maintenance Planner [Data  /  Engineering  /  Building Services],"SHENTON HOUSE, 3 SHENTON WAY 068805",Full Time,Junior Executive,1 year exp,"Engineering, Manufacturing, Purchasing / Merchandising",Monthly,"$2,500to$3,500","Maintenance Planner

Working Hours: 5 Days [9am - 6pm]
Salary: $2500 - $3500
Location: Lor Bakar Batu, Singapore 348745 (Central)


Requirements:

Diploma / Degree in Engineering (Mechanical/Electrical Engineering)
1 - 2 years of relevant experience in Maintenance Planning and Scheduling

Jobs Scope:

Responsible for planning and scheduling of Turn Around Maintenance, Planned and unplanned shutdown works
Responsible for effective planning and scheduling of maintenance  activities achieving minimum equipment maintenance downtime, capturing  associated accurate and complete records and related documentation.
Ensures maintenance documentation such as work orders, calibration records is updated and complete at all times.
Supports start-up activities and handover of equipment and systems data from project to Operations team
Responsible for all Security Clearance and pass for engineering
To establish the pool of vendors that may support the projects, maintenance and turnaround activities
Carry out other ad-hoc duties assigned by the immediate supervisor or higher management


Interested applicants kindly click on the “Apply Now” button or whatsapp text / email your resume to allow our Consultant to match you with our Clients. No Charges will be incurred by Candidates for any service rendered (R2199156 14C7279)

supreme.cherlylim@gmail.com 
whatsapp text 9851 1096 ","['Security Clearance', 'Pharmaceutical Industry', 'Maintenance Management', 'Plant Maintenance', 'Preventive Maintenance', 'Microsoft Office', 'Aviation', 'Quality Control', 'Technical Assistance', 'Labels', 'Maintenance Planning and Scheduling', 'Electrical', 'Reliability', 'Planner', 'Procurement', 'SAP', 'Equipment Maintenance', 'Scheduling', 'Manufacturing', 'Calibration']"
6606 - Buyer [ Procurement  /  Purchasing  /  Cost Saving  /  Engineering  /  Construction  /  Data Centre  /  Infrastructure ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Senior Executive,3 years exp,Purchasing / Merchandising,Monthly,"$4,000to$5,000","(Data Centre / Engineering & Building Services Industry)
Buyer

Working Hours: 5 Days [9am - 6pm]
Salary: Up To $5,000 (Based on Experience & Last Drawn)
Location: Lor Bakar Batu (Potong Pasie)

Requirements:

Diploma / Degree holder in Supply Chain Management
1 - 2 years of relevant working experience / relevant industries

Jobs Scope:

Handles full set of purchasing process (Sourcing, RFQ, shipping and follow up on
deliveries)
Prepare Purchase Orders to suppliers ensure all deliveries are in time to meet site schedules
Ensures timely PO execution and address supplier’s capacity, materials issues that may affect supply
Works closely with vendors to schedule delivery and pick-up of equipment
Coordination with vendors on scheduling & expediting of deliveries or resolution of purchase discrepancies if any
Analyses and maintained an accurate cost per site (equipment and labour)
Supports all Engineering programs in identifying and qualifying Suppliers, auditing new Vendors using both
Technical and commercial knowledge to support company requirements
Maintain procurements database
Works closely with Finance to resolve invoice discrepancies and verified correct shipment/purchase orders on packing lists
Exercise good vendor management and monitor performance of suppliers to meet objectives in the area of quality, inventory control and actively engages suppliers
To perform any other duties that may be assigned by the immediate supervisor from time to time.

If you are interested to apply, kindly WhatsApp me your updated resume in DOC file and allow our Consultant to match you with our Clients.
Whatsapp: +65 8204 7336
✉liki_wong@thesupremehr.com","['Microsoft Excel', 'ERP', 'Supply Chain', 'Purchasing', 'Building Services', 'Auditing', 'Merchandising', 'Inventory Control', 'Procurement', 'Inventory Management', 'Vendor Management', 'SAP', 'Supply Chain Management', 'Excess', 'Scheduling', 'Pricing', 'Manufacturing', 'Sourcing', 'Shipping']"
 , , , , , , , , , 
 , , , , , , , , , 
Software Engineer in Test (PSET-CPD-Data Platform & Services)_22WD61243,"SYMBIOSIS, 3 FUSIONOPOLIS WAY 138633",Permanent,Executive,1 year exp,Information Technology,Monthly,"$3,866to$5,800","Position Overview
Autodesk Data Platform (ADP) provides centralized data and analytics platform for entire Autodesk’s products, services, and business needs. ADP Product Analytics team is looking for Software Development Engineer in Test to join a very talented and seasoned engineering team.
Responsibilities

Work with Scrum team to deliver high quality deliverables.
Test analysis, testcase design, test data preparation & test execution.
Implement, execute and maintain test automation scripts for the big data components and data aggregation workflows.
Integrate the test automation framework to CI/CD pipelines.
Actively create and enhance team’s automation tool sets and utilities.

Must-have qualifications

Bachelor's Degree in computer science or related field
Have good knowledge on test methodology and techniques
Able to design testcases, prepare test data and set up test environment, execute testcases independently
At least 1 year hands-on experience in writing automated tests
Proficient with one or more programming languages, like Java, Python
Familiar with SQL queries
Strong sense of responsibility, good sense of service and teamwork, strong ability to withstand pressure
Team player who is willing to help and collaborate with other team members
Strong communication skill (written and spoken)

Good to have qualifications

Experience on Big Data ecosystem
Experience on AWS cloud
CTFL certification
","['Autodesk Software', 'Test Automation Framework', 'Entertainment', 'Big Data', 'Pipelines', 'Test Analysis', 'Scrum', 'Architects', 'Test Automation', 'SQL', 'Python', 'Writing', 'Java', 'Test Execution', 'Software Development', 'C++']"
Tech Delivery Manager (Data Analytics) - 016,"KECK SENG TOWER, 133 CECIL STREET 069535","Contract, Full Time",Manager,5 years exp,Information Technology,Monthly,"$12,000to$15,000","Job Description:

The role will be responsible for the technical deliveries of project in the data analytics domain. This includes pre-project planning, analysis and design to development, implementation, testing and support. You will be expected to work on the Retail Data Program which aims to rollout new batch and real time campaign management capabilities within the Bank.
Other responsibilities include:
- Plan technical deliverables (including any system enhancements and upgrades) to meet project’s requirements within allocated budget and schedule.
- Plan & collaborate across different application teams to manage technical dependencies of the solution
- Plan, monitor and manage risks/issues related to technical delivery
- Provide status update related to technical delivery to Project Manager (PM)
- Partner with System Analysts and Business Solution Specialist to collate, understand and finalize functional and technical requirements
- Partner with Architects and Development Lead to ensure solution design complies with enterprise design principles, security and control standards
- Partner with Development Manager in managing application teams to build the enhancements
- Partner with Test Manager to ensure completion of System Integration Testing (SIT), User Acceptance Testing (UAT), performance / load testing and application security testing with quality results
- Manage technical implementation plan across application teams - coordinate technical implementation activities across application teams to ensure non-event production cutover and adequate post implementation support
- Escalate issues that impacts project schedule on timely basis and propose workarounds/resolutions","['UAT', 'Application Security', 'Data Analysis', 'Data Analytics Systems Design', 'Rollout', 'Architects', 'Data Analytics System Design', 'User Acceptance Testing', 'System Integration Testing', 'Data Analytics']"
Mechanical Engineer [ M&E  /  Data center  /  Design  /  Consultancy firm ] 3453,"NOVENA SQUARE, 238A THOMSON ROAD 307684",Permanent,Senior Executive,4 years exp,"Building and Construction, Engineering",Monthly,"$4,500to$6,000","Order Number: 2207-62534

Responsibilities:

Preparation of heat load/hydraulic calculations, water consumption requirement and system pressure loss calculation
Sizing of various mechanical equipment and components such as chillers, cooling towers, ventilation fans, pumps, storage tanks, pipework and ductwork
Preparation of design brief, schematics and layouts
Preparation of tender specifications and drawings
Support project team in the design and overseeing of installation of various M&E services in the company's building projects
Accountable for the correct, accurate, and reliable design and installation of the M&E systems
Design and consultancy work for multiple projects (Conceptualization, design & preparation of specifications/drawings, project scheduling, equipment procurement, inspection, QA and testing & commissioning to completion)
Liaise with clients, M&E Project Director/Managers, contractors
Any other ad hoc duties assigned

Requirements:

Diploma or Degree in electrical engineering or equivalent
3 - 5 years of relevant experience in M&E design and consultancy firm
Experience in data center design is a plus

We regret that only shortlisted candidates will be notified. However, rest assured that all applications will be updated to our resume bank for future opportunities

EA License no.: 07C5771
EA Personnel Reg. No.: R2093453
EA Personnel Name: Edmund Ting Chao Siong","['Microsoft Office', 'Water', 'Construction', 'Data Center', 'Procurement', 'Pressure', 'AutoCAD', 'Systems Design', 'Pumps', 'Scheduling', 'Electrical Engineering', 'Commissioning', 'Mechanical Engineering']"
2812 - Performance Marketing Executive [ SEO  /  SEM  /  Google Ads  /  Data ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Marketing / Public Relations,Monthly,"$2,500to$5,000","Performance Marketing Executive

Working Days: 5 Days [9am - 6pm]
Location: Bukit Batok 
Salary: Basic up to $2500 + bonus / lead [ Gross can hit $4k-$5k]

Requirements:

1 year experience in doing SEO / SEM

Jobs Scope:

Performance Marketing: To use all available conversion data to make informed decisions in optimizing PPC campaigns not limited to Google Ads & Facebook Ads. Ensuring to hit main KPIs such as Driver Leads, Customer Acquisition, Business Leads, Cost Per Lead, and Cost Per Acquisition, within the given budget
SEO: To be able to get the company’s website on 1st page of Google.
Data Driven:  To analyze and utilize existing data from various tools and platforms on hand to make informed decisions. Creating end-to-end marketing campaigns based on data research and analysis
Expert in Google Ads & Paid Social: Have hands-on execution experience in managing Google Ads, Facebook Ads, and other paid social platforms
Test & Learn Mentality:  To be open enough to try new channels & learn from them. A/B testing targeting, strategies and creatives.
Problem-solver: To be able to find creative online campaigns to move User and Driver Acquisition numbers.
User Empathy: To be able to think from a perspective of a user or a driver & build seamless user journeys.


Chew Xing Shan Reg No: R22107044
The Supreme HR Advisory Pte Ltd EA No: 14C7279","['SEM', 'Microsoft Office', 'Social Media', 'Marketing Strategy', 'Targeting', 'Marketing', 'Content Marketing', 'Customer Acquisition', 'Digital Marketing', 'Adobe Illustrator', 'Social Media Marketing', 'Ab Testing', 'Google Analytics', 'SEO', 'PPC', 'Adobe Photoshop']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
2812 - Account & Admin Assistant [ Partial Set  /  AR  /  AP  /  Bank Recon  /  Data Entry ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,200to$2,600","Account & Admin Assistant

Mon - Fri, 5 days | 8.30am - 6pm
Salary: $2200 - $2600
Location: Cecil street (Downtown)

Job Responsibilities:

Handle partial set account (Account receivable, Account payable, receipt, bank recon)
Manage administrative duties
Data Entry
Other Ad hoc duties as assigned

Requirements:

Min. Diploma in Account or relevant field
Min. 2 years of experience
Preferably short notice starter
","['Accounts Payable', 'Cecil', 'Microsoft Office', 'Financial Transactions', 'Accounting System', 'Data Entry', 'Accounts Receivable', 'Accounting', 'Microsoft Word', 'Able To Work Independently']"
 , , , , , , , , , 
 , , , , , , , , , 
2812 - Human Resource Executive [ Recruitment  /  Hiring  /  Data  /  Admin  /  Program ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Human Resources,Monthly,"$3,300to$4,000","Human Resource Executive
Basic: $3300 to $4000
5 Days Mon to Thurs: 9am to 7pm; Fri: 9am to 6pm
Location: Bendeemer

Requirements

Minimum 1 - 2 years’ experience in Human Resources and operational duties

Job scope

Assist in recruitment and scheduling interviews
Update employee movement (including hiring, transfers, promotions, terminations and resignations)
Take charge of employee onboarding and orientation process
Handle personal data changes with proper letter generation and documentation
Maintain and update workers' personal files and database
Assist in roll out and implementation of HR programs
Participate in HR continuous improvement initiatives
Support performance appraisal/ review administration process and HR support
Assist with ad-hoc duties as assigned
","['Human Resource Strategy', 'Human Resource Management System', 'Human Resource Systems Management', 'Human Resource Advisory', 'Human Resource Management', 'Administration', 'Human Resource Strategy Formulaiton', 'Human Resource Planning', 'Human Resource Digitalisation', 'Human Resource', 'Human Resource Strategy Formulation', 'Human Resources', 'Performance Appraisal', 'Scheduling']"
"Data Analyst, User Growth Tiktok",1 RAFFLES QUAY 048583,Full Time,Executive,3 years exp,Engineering,Monthly,"$6,000to$12,000","Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc.

You will:

Build and governing matrices for fast changing business in an analytical data-driven approach to identify business issues and opportunities;
Prototype analysis pipelines to provide insights, and provide quick responses to business inquiries and events;
Conduct routine and non-routine end-to-end analyses with large, complex data sets, and make recommendation on appropriate solutions.

Qualifications

Bachelor's degree in Statistics, Applied Mathematics, Computer Science or a related field;
Skilled in data manipulation with SQL, python or other programming-languages/tools;
Experienced in data analyzing, visualization and reporting;
Fast business understanding and collaborative in teamwork.


TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Big Data', 'Pipelines', 'Data Quality', 'Data Mining', 'SQL', 'Python', 'Statistics', 'Visualization', 'Data Analytics', 'Power BI', 'Applied Mathematics']"
 , , , , , , , , , 
"Senior Solution Architect, Data Platform",1 RAFFLES QUAY 048583,Full Time,Professional,5 years exp,Information Technology,Monthly,"$7,000to$14,000","About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
This role is a member of our Data Platform team focusing on Data products and solutions to enterprise services, leveraging TikTok's cutting-edge data infrastructure and data application. You will be helping enterprise customers to build their next generation data warehouse and data analytics, enabling them to do things that were not possible before.

Responsibilities
1. Drive Big Data solutions design across multiple data product roadmaps of Byteplus
2. Work with sales team, participate in pre-sales communication, convert customer business needs into big data technical solutions, and provide customers with business consulting and technical consulting services
3. Plan and implement GTM strategy together with commercial team
4. Provide technical support for customers and assist customers to complete project planning and product PoC testing.

Qualifications
1. Good understanding of big data technology and trends
2. Bachelor's degree or above, major in Computer Science, Statistics or Mathematics are preferred
3. Minimum 5 years of experience in big data pre-sales or enterprise solutions, demonstrable skills in relevant technical areas and products, behaviour analysis, AB testing etc.
4. Able to understand enterprise customers' needs, and a desire to drive solutions to their problems
5. Excellent communication and collaboration skills with ability to work in a cross-functional and global environment, good ability of managing highly effective projects
6. Accept international business travel.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['International Business', 'Big Data', 'Experimentation', 'Architect', 'Mathematics', 'Project Planning', 'Business Travel', 'Strategy', 'Adaptability', 'Software Design', 'Statistics', 'Consulting', 'Ab Testing', 'Data Analytics', 'Technical Support']"
Senior Solution Architect - Data Platform,1 RAFFLES QUAY 048583,Full Time,Professional,7 years exp,Information Technology,Monthly,"$13,000to$26,000","About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
This role is a member of our Data Platform team focusing on Data products and solutions to enterprise services, leveraging TikTok's cutting-edge data infrastructure and data application. You will be helping enterprise customers to build their next generation data warehouse and data analytics, enabling them to do things that were not possible before.

Responsibilities
1. Drive Big Data solutions design across multiple data product roadmaps of Byteplus
2. Work with sales team, participate in pre-sales communication, convert customer business needs into big data technical solutions, and provide customers with business consulting and technical consulting services
3. Plan and implement GTM strategy together with commercial team
4. Provide technical support for customers and assist customers to complete project planning and product PoC testing.

Qualifications
1. Good understanding of big data technology and trends
2. Bachelor's degree or above, major in Computer Science, Statistics or Mathematics are preferred
3. Minimum 7 years of experience in big data pre-sales or enterprise solutions, demonstrable skills in relevant technical areas and products, behaviour analysis, AB testing etc.
4. Able to understand enterprise customers' needs, and a desire to drive solutions to their problems
5. Excellent communication and collaboration skills with ability to work in a cross-functional and global environment, good ability of managing highly effective projects
6. Accept international business travel.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['International Business', 'Big Data', 'Experimentation', 'Architect', 'Mathematics', 'Project Planning', 'Business Travel', 'Strategy', 'Adaptability', 'Software Design', 'Statistics', 'Consulting', 'Ab Testing', 'Data Analytics', 'Technical Support']"
 , , , , , , , , , 
"Data Analyst, Human Rights Solutions",99 DUXTON ROAD 089543,"Permanent, Full Time",Executive,1 year exp,Consulting,Monthly,"$4,000to$6,000","LEVATE is seeking a Data Analyst with skills in data science and analytics to join our Advisory team in Hong Kong or Singapore and accelerate the development and growth of our human rights solutions and products.
Who we are
ELEVATE is the global market leader in ESG, sustainability, and supply-chain services. Our focus is on delivering ESG program effectiveness and impact to the world’s leading companies and their supply chains. We design, build, and manage data-driven, sustainability-linked programs that drive positive impact, with assessment, advisory, program management and analytics solutions. With 30+ offices globally (and still growing), we offer a unique opportunity to work on real issues that span the globe and positively impact people, communities, and the planet.
Job overview at a glance
We are looking for a highly motivated professional who is passionate about applying data science and analytics skills to supply chain and human rights problems. ELEVATE already operates some of the world’s most successful grievance mechanisms and helplines for supply-chain workers. They generate rich data that can be used to identify challenges and improve conditions for workers. You will be part of the Asia-Pacific Advisory team and will work with, and learn from, ELEVATE experts from teams across the globe.
Our human rights solutions are products/services that often require engagement with a variety of users and stakeholders, ranging from migrant workers to factory management to major global companies and civil society actors. They require an understanding of both human/user and tech needs. They cover numerous industries and geographies. Internal stakeholders may include software engineers, sales/marketing professionals, human rights consultants, and executive leaders. This role lies at the intersection of sustainability consulting and data analytics.
As we advance and scale our grievance mechanisms and help lines, we will need skills that can improve the data analytics side of them – from how data is collected, processed, and managed to how it is visualized, analyzed, and reported.
We are looking for entrepreneurial individuals who will be motivated by the opportunity to work in a rapidly growing and successful business at the cutting edge of sustainability, human rights, worker engagement, and data analytics and to partner with world-class leaders to take on some of the planet’s most pressing ESG challenges.
Who you are

A data analyst who wants to apply your skills for human impact
Passionate about sustainability and ESG issues, including business and human rights, social sustainability and supply-chain sustainability
Passionate about innovative analytic solutions and data insights
An entrepreneurial self-starter and continuous learner who is always innovating and 'getting things done'
A structured problem-solver, critical and creative thinker, and effective communicator
Motivated by working on complex challenges in a fast-paced, high-growth, dynamic work environment
A team player who thrives in multi-cultural teams and contributes to a positive, open atmosphere

Duties & Responsibilities

In partnership with the human rights solutions lead, manage the grievance mechanism/helpline offering operations and data reporting for clients globally
Lead data management, visualization and reporting
Support data management back-end CMS/CRM content and workflows and generate monthly data summary reports for ELEVATE’s grievance mechanisms;
Customize helpline system reporting, utilizing data analysis tools such as Tableau, PowerBI, Python, and JavaScript, in alignment with client requirements / strategy and ELEVATE’s approach
Engage internal stakeholders to maintain alignment and to execute on shared plans to define, develop, and scale solutions
Uphold standards of ELEVATE platforms and systems, including project management systems, business development systems, and other processes

Experience & Requirements

0-2+ years of relevant experience
Bachelor’s degree in data science, statistics, or related field; Master’s preferred
Demonstrated passion for human rights or social impact; direct experience or education preferred
Hard data analytics skills required, including familiarity with or ability to quickly master Zendesk, Tableau or other data visualization tools, JSON, and Python
Fluent in written and spoken English
Strong written and spoken communication and presentation skills
Strong collaboration and interpersonal skills
Ability to work virtually, one-on-one, and in a team
Ability to influence without formal authority
Capacity to work across different time zones and to hold meetings outside of regular local working hours

Equal Opportunity Employer
ELEVATE is committed to creating a diverse and inclusive workplace and is proud to be an Equal Opportunity Employer. All qualified applicants will be considered without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, genetics, disability, age, veteran status, or any other status protected by local law. Personal data provided by applicants will be treated as confidential information and will be used exclusively for employment purposes only.  Only short-listed candidates will be notified.  Applicants who are not invited for an interview may consider their applications filed for future reference.
To learn more about career opportunities at ELEVATE, please visit our Careers Page here: https://www.elevatelimited.com/careers/","['Tableau', 'JSON', 'Sustainability', 'Factory', 'Data Management', 'Human Rights', 'Program Management', 'PowerBI', 'Zendesk', 'Presentation Skills', 'Civil Society', 'Data Science', 'Visualization', 'Genetics', 'Data Visualization']"
2812 - Finance & Admin Assistant [ Invoice  /  Calling  /  Data Entry  /  Xero ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Fresh/entry level,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,200to$2,600","Finance & Admin Assistant
Working days : Mon - Friday 9am - 6pm
Location : Expo (Changi South)
Salary : SGD 2200 - SGD 2600

Job Responsibilities

Responsible for generating and sending all customer invoices.
Assist with collections including calling customers with overdue invoices.
Assist with day-to-day finance transactions and data entry into system
Attend and provide support in administrative duties for the Finance Team
Any ad-hoc duties as assigned

Job Requirements

Minimum GCE “ O “ Level /Diploma in Accountancy/ Higher Nitec in accountancy
At least 1 year of relevant work experience
Experience in using accounting software such as Xero is an advantage
Proficient in MS Office
","['Accounts Payable', 'Microsoft Office', 'Microsoft Excel', 'Tax', 'Payroll', 'Data Entry', 'Bank Reconciliation', 'MS Office', 'Accounts Receivable', 'SAP', 'Accounting', 'Xero', 'Team Player', 'Cash Flow']"
2812 - Finance & Admin Assistant [ Invoice  /  Calling  /  Data Entry  /  Xero ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Fresh/entry level,2 years exp,Accounting / Auditing / Taxation,Monthly,"$2,200to$2,600","Finance & Admin Assistant
Working days : Mon - Friday 9am - 6pm
Location : Expo (Changi South)
Salary : SGD 2200 - SGD 2600

Job Responsibilities

Responsible for generating and sending all customer invoices.
Assist with collections including calling customers with overdue invoices.
Assist with day-to-day finance transactions and data entry into system
Attend and provide support in administrative duties for the Finance Team
Any ad-hoc duties as assigned

Job Requirements

Minimum GCE “ O “ Level /Diploma in Accountancy/ Higher Nitec in accountancy
At least 1 year of relevant work experience
Experience in using accounting software such as Xero is an advantage
Proficient in MS Office
","['Accounts Payable', 'Microsoft Office', 'Microsoft Excel', 'Tax', 'Payroll', 'Data Entry', 'Bank Reconciliation', 'MS Office', 'Accounts Receivable', 'SAP', 'Accounting', 'Xero', 'Team Player', 'Cash Flow']"
 , , , , , , , , , 
Senior /  Associate Engineer (Radio Optimisation & Data Analytics),"STARHUB GREEN, 67 UBI AVENUE 1 408942","Permanent, Full Time",Executive,2 years exp,"Engineering, Telecommunications",Monthly,"$2,300to$3,300","Job Title: Senior/ Associate Engineer (Radio Optimisation & Data Analytics)
Job Description
Purpose:

Perform basic data mining and statistics analysis that contribute towards the high quality performance of our mobile networks.
Plan, optimize and monitor network performance based on user experiences

Responsibilities:

Perform data cleaning, analysis and visualization using appropriate software tools
Generate statistical reports and perform first tier analysis and troubleshooting.
Prepare and present the insights that facilitates decision making and management reporting
Improve data processing and data visualization capabilities
Participate in drive tests and validate network performance during software/ network upgrades, tests, and projects
Participate in projects that involve network growth, Integration of corporation networks, and new feature/ service trials and Implementations
Proactively evaluate network to minimize complaints and augment quality of service to consumers

Qualifications

Appropriate qualifications in Data Science/ Data Analytics/ Application development
Familiar with data visualization using Power BI and Excel
Familiar with programming languages eg Java, C#, Python, Visual Studio, MySQL
Possesses Class 3 driving license
Willing to perform work at night occasionally (during maintenance window period)
","['Preventive Maintenance', 'Troubleshooting', 'Equity Research', 'MySQL', 'Electrical', 'Telecommunication', 'Driving License', 'Trials', 'Python', 'Class 3 Driving License', 'Java', 'C#', 'Adaptable to Changes', 'Accessibility', 'Electronics', 'Visual Studio']"
 , , , , , , , , , 
 , , , , , , , , , 
 , , , , , , , , , 
Data Entry (Short-term /  Part-Time),"BURLINGTON SQUARE, 175A BENCOOLEN STREET 189650","Part Time, Full Time",Fresh/entry level,1 year exp,Admin / Secretarial,Monthly,"$1,400to$1,600","Location: Burlington Square 
Working hours: 9am - 6pm 
$8/hour 

Job description

Support day-to-day operation
Prepare Quotation and Sales Order
Timely invoice billing and follow up on outstanding invoices
Managing and processing claims and reimbursements from team members
To support any other general admin duties as and when required
To carry out all other reasonable tasks and responsibilities as assigned by the management

Job Requirement

Diploma in relevant field
Proficient in Microsoft Office (Excel and Word)
Working with positive attitude
Must keen to learn
Able to work in a team and independently as well.
","['Microsoft PowerPoint', 'Microsoft Office', 'Microsoft Excel', 'Strong Attention To Detail', 'Teaching', 'Social Media', 'Housekeeping', 'Selling', 'Cashiering', 'Communication Skills', 'Excel', 'Team Player', 'Customer Service', 'Facebook', 'Able To Work Independently']"
"Associate, Client Data Operations (Foreign Brokerage Firm) [ALT]","BANK OF CHINA BUILDING, 4 BATTERY ROAD 049908","Permanent, Full Time",Senior Executive,3 years exp,Banking and Finance,Monthly,"$5,000to$7,000","RESPONSIBILITIES:
· You will be responsible for the maintenance of all Client & Operational data, while ensuring high quality & integrity
· Work closely with both internal & external clients on all data-related matters
· Participate in any change or system enhancement projects leading to process excellence and digitalisation
· Provide support to other operational teams as & when required

REQUIREMENTS:
· At least 4 years of data management experience in a Bank or Financial Institution
· Familiar with the front-to-back office trade process flow
· Good understanding of the various financial products
· Good stakeholder management skills
· Strong communication & interpersonal skills

Please contact Alicia Tuang at 9150 6479 or AliciaT@charterhouse.com.sg for a confidential discussion

EA License no: 16S8066 | Reg no.: R1104694

Only successful candidates will be notified.","['Financial Services industry', 'Operations', 'Interpersonal Skills', 'Data Management', 'Data set', 'Stakeholder Management', 'Databases', 'Back Office', 'Financial Services', 'regulated financial services', 'Data']"
Book Keeping and Data Entry,"SIM LIM SQUARE, 1 ROCHOR CANAL ROAD 188504","Flexi-work, Full Time, Internship/Attachment, Part Time, Permanent",Junior Executive,1 year exp,"Accounting / Auditing / Taxation, Admin / Secretarial, Banking and Finance",Monthly,"$1,400to$2,500","Job brief
We are looking for a skilled Bookkeeper to maintain our financial records, including purchases, sales, receipts and payments.
Bookkeeper job duties include working closely with our Accounting team to create and analyze financial reports and ensure legal requirements compliance, process accounts payable and receivable and manage invoices and tax payments. Our ideal candidate holds a Finance degree (preferably followed by accounting CPE courses) and is familiar with accounting software packages, like FreshBooks, Kashoo and KashFlow.
Ultimately, the Bookkeeper’s responsibilities are to accurately record all day-to-day financial transactions of our company.
Responsibilities

Record day to day financial transactions and complete the posting process
Verify that transactions are recorded in the correct day book, suppliers ledger, customer ledger and general ledger
Bring the books to the trial balance stage
Perform partial checks of the posting process
Complete tax forms
Enter data, maintain records and create reports and financial statements
Process accounts receivable/payable and handle payroll in a timely manner

Requirements and skills

Proven bookkeeping experience
Solid understanding of basic bookkeeping and accounting payable/receivable principles
Proven ability to calculate, post and manage accounting figures and financial records
Data entry skills along with a knack for numbers
Hands-on experience with spreadsheets and proprietary software
Proficiency in English and in MS Office
Customer service orientation and negotiation skills
High degree of accuracy and attention to detail
","['Service Orientation', 'Accounts Payable', 'Tax', 'Books', 'Financial Transactions', 'Payroll', 'Data Entry', 'MS Office', 'General Ledger', 'Accounting', 'Attention to Detail', 'Financial Statements', 'Bookkeeping', 'Spreadsheets', 'Customer Service']"
Data Management Officer | Private bank | $3.6k,"THE OCTAGON, 105 CECIL STREET 069534","Contract, Permanent, Full Time",Non-executive,3 years exp,Banking and Finance,Monthly,"$3,000to$3,600","Responsibilities:

Maintain strong relationship with Front Office and provide support with queries and troubleshooting
Ensure accurate and timely execution of account opening, closure client and static modification service requests
Conduct name screening upon request from Compliance team
Ability to understand the business requirements for maintenance of external clients’ records
Participate in user acceptance testing when needed


Job Requirements:

Possess diploma/degree with min 3 years of related working experience
Proficient in Microsoft Excel (Pivot table, V Lookup) will be advantageous
Related working experience in static data maintenance (T24, CRM, EAM/EFA/Finder relationships)
Able to speak to people from all levels
Only Singaporeans


Working hours : Mon – Fri (9am – 6pm)
Working location : Pasir Panjang 
1 year contract (Rolling contract) + 1 month completion bonus

To submit your application, please click on the “Apply Button” or send your UPDATED CV in Microsoft Word format OR email to Michael.chee@Tangspac.com Your interest will be treated with strict confidentiality","['CRM', 'Wealth Management', 'Front Office', 'Excellent Communication Skills', 'Troubleshooting', 'Microsoft Excel', 'Temenos T24', 'Wealth', 'Private Banking', 'Transparency', 'Risk Management', 'Compliance', 'User Acceptance Testing', 'Microsoft Word', 'Diplomacy', 'Screening', 'Business Requirements']"
Research Engineer / Fellow (5G-Powered Intelligent Data-Driven Electric Vehicle) - ZW,10 DOVER DRIVE 138683,"Contract, Full Time",Non-executive,2 years exp,Information Technology,Monthly,"$3,600to$6,000","The Role
Your Responsibilities will include:

Collaborate with partners from both the academia and the industry to lead and/or conduct innovative research on, but not limited to 5G, AI, sustainability, etc.
Contribute to academic research in the relevant domains and publish high-tier journal papers and conference papers.
Participate in and manage the research project with Principal Investigator (PI) to ensure all project deliverables are met.
Coordinate procurement and liaison with vendors/suppliers.
Participate in computer science related laboratories and tutorials for undergraduate students.
Interview and supervise student assistants in the project.


Ideal Profile
Skills Required:

(Research Fellow) PhD in Computer Science or a related field
(Research Engineer) Bachelor/Master degree in Computer Science or a related field
Proven ability to conduct independent research with a relevant publication record
Outstanding data analytics, mathematical, and computer modelling skills
Excellent interpersonal communication and oral presentation skills
Self-driven and strong team spirit


What's on Offer?

Flexible working options
Opportunity to make a positive impact
Great work environment


About us
The Singapore Institute of Technology (SIT) is a public autonomous university and the third largest university by intake in Singapore. SIT’s mission is to innovate with industry, through an integrated applied learning and research approach, so as to contribute to the economy and society. Singapore is the small city with a big dream. We are home to the best talent and have the world’s highest per capital investment in science and technology.
We have an opening for Research Fellow or Research Engineer. The selected applicant is expected to lead and pursue high-quality research in applied artificial intelligence and sustainability that lead to publications in top-tier international conferences and journals, as well as real-world implementations. If interested, please send your resume including a cover letter, CV and a brief statement of your work undertaken in previous work.

Ref: A0NMMD44H7

Apply to this role by submitting your CV and completing you profile at https://sit01.snaphunt.com/job/A0NMMD44H7","['Sustainability', 'Academia', 'Artificial Intelligence', 'Team Spirit', 'Software Engineering', 'Procurement', 'Presentation Skills', 'Capital', 'Publications', 'Data Analytics']"
"1723-Mechanical Designer[Autodesk Vault with data management /   3D CAD drafting skill such as solid works or Autodesk Inventor, AutoCAD]","SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,1 year exp,"Building and Construction, Engineering, Precision Engineering",Monthly,"$1,800to$2,500","Role Responsibilities
• Prepare Engineering Drawings using Autodesk Inventor, AutoCAD
• Design and develop new products based on customer requirements
• Extract 2D drawings from 3D models and create productions drawings
• Prepare Engineering change note
• Prepare Engineering BOM using structures, assembly and sub assembly levels
• Attending site survey, site measurement, site meeting and necessary site discussion
• Able to liaise with the sales, customers, production and installation parties to implement the work
• Knowledge on sheet metal fabrication
• Sheet metal punching, bending, welding and assembly
• Creating Inventory master and validation
• Database management

Job Requirements:
• Minimum Nitec / Higher Nitec or Diploma in Mechanical Engineering or relevant engineering sectors
• Minimum 1 to 2 years with relevant experience
• Work experience in manufacturing line and has knowledge on Autodesk Vault with data management is an added advantage
• 3D CAD drafting skill such as solid works or Autodesk Inventor, AutoCAD","['Metal Fabrication', 'Inventory', 'Data Management', '3D', 'Fabrication', 'Welding', 'Autodesk Inventor', 'Sheet Metal', 'Autodesk Vault', 'AutoCAD', 'Assembly', 'Manufacturing', 'CAD', 'Mechanical Engineering']"
2812 - Global Market System Engineer [ Data Center  /  DC  /  Network  /  IT  /  OS  /  Software ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Senior Executive,5 years exp,Engineering,Monthly,"$3,000to$3,500","Global Market System Engineer
Working day / time:  Monday to Friday | 9am to 6pm
Salary: $3k to $3.5k
Location: Ubi

Job Description:
Supervises, directs, and leads T&C works. You are responsible for overall project engineering and system configuration of assigned projects. The opportunities are expected to be but not limited to the followings:
• Working for the large data center operators.
• Working with multiple global leading providers & vendors.
• Chance to be involved in multi-million-dollar project management.
• Involve in fastest growing DC market, collaborate with regional partners.
• Communicate with different level of managements.

What you will perform:
• Performs and lead in assigned project testing and commissioning to ensure the system, as designed and built meet the specific requirements, conduct of customer training and ensure customer acceptance on the system.
• Creates the high-level system architecture and design and selects major components for assigned project.
• Translating customer needs into specific, well-written requirements to which systems and subsystems (subelements, pieces, software and hardware, control items, etc.) can be architected and designed. 

Requirements duties include understanding all external interfaces and ensuring the functional architecture correctly capture the need.
• Directs and organises the preparation of engineering submittals
• Perform all engineering configuration, programming and setting up for all system equipment including server and controllers
• Assist in attending technical meetings with consultant and main con and owner.
• Testing of new products and solutions
• Overseas travel for project implementation may be requested
• Provide training and project deliverables such as documentation
• Deploy and implement Data Center Software.

Requirement:
• At least 5 years relevant working experience is preferred (e.g. Network Engineer)
• Degree in Engineering
• Experience in IT networking and data centre.
• Knowledge in OS (Windows, Linux), Database","['Submittals', 'Hardware', 'Data Center', 'Translating', 'Project Management', 'Networking', 'Windows', 'System Architecture', 'Project Engineering', 'Linux', 'Commissioning']"
"Data Steward Supervisor, OpenData (SG / MY)","MARINA BAY FINANCIAL CENTRE, 8 MARINA BOULEVARD 018981",Full Time,Senior Executive,1 year exp,"Education and Training, Information Technology, Others",Monthly,"$3,500to$6,500","Directly reporting to the OpenData Research Center Manager, we are looking for a Data Steward Supervisor who will be responsible for the direct supervision of data stewardship team members for the data offering in Singapore and Malaysia. 
You will also be responsible and retain all the responsibilities of a Data Steward, such as updating the attributes of records to improve core data, calling Group Practices, and updating provider affiliation information.
If you have a passion for data and quality – this is a great opportunity for you! Your role will be based in the Veeva Office in Singapore.

What You'll Do

Recruit, coach, motivate, appraise and retain team members
Deliver all necessary training to Data Stewards
Monitor, improve and give feedback on individual and team performance
Allocate work and resources to meet project deadlines
Design, document and optimise processes to ensure best-in-class delivery of data quality
Audit the data quality of Data Stewards
Ensure the team meets and exceeds productivity and quality standards
Run the daily operations in the Data Stewardship team
Report progress to direct line manager
Execute other duties and ad-hoc tasks related to data stewardship as assigned by the management

Requirements

BA/MA or equivalent degree
Ability to learn quickly and independently
Problem solving and efficient time management skills
Proficiency in Windows, Google apps, MS Office and other office software
People and result oriented
Strong interpersonal skills
Highly organized, attention to detail and focus on quality
Able to balance qualitative and quantitative performance of the team
Able to motivate and communicate clearly
Able to meet expectations and project deadlines
Obtain and refresh the most current version of various data elements using standard methods of research such as verification through internet and outgoing phone calls
Apply new verified data elements to core database records
Assure that new data elements are not duplications of existing core data elements for Healthcare providers (HCP’s) and Healthcare Organisations (HCO’s)
Proactive maintenance of existing data and handling customer requests
Removal of incorrect data elements from core databases

Nice-to-have

Experience working with MDM (master data management applications)
Local Health Care market understanding
Knowledge of medical terminology and data quality standards within the life sciences industry
Previous experience or interest in data, databases
","['Coaching', 'Store Operations', 'Data Sharing', 'Agile Project Management', 'Process Improvement', 'TIBCO', 'Interpersonal Skills', 'People and Performance Management', 'Medical Terminology', 'Problem Solving', 'Data Quality', 'Stewardship', 'Project Timeline', 'Team Leadership', 'Attention to Detail', 'Office Software', 'Life Sciences', 'Master Data Management', 'Databases', 'Ability To Learn']"
2812 - Maintenance Planner [ Data Centre  /  /  Engineering  /  /  Work orders  /  /  Project  /  /  Operation ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,2 years exp,Purchasing / Merchandising,Monthly,"$2,500to$3,500","Maintenance Planner

Working Hours: 5 Days [9am - 6pm]
Salary: $2500 - $3500
Location: Potong Pasir

Requirements:

Diploma / Degree in Engineering (Mechanical/Electrical Engineering)
1 - 2 years of relevant experience in Maintenance Planning and Scheduling

Jobs Scope:

Responsible for planning and scheduling of Turn Around Maintenance, Planned and unplanned shutdown works
Responsible for effective planning and scheduling of maintenance activities achieving minimum equipment maintenance downtime, capturing associated accurate and complete records and related documentation.
Ensures maintenance documentation such as work orders, calibration records is updated and complete at all times.
Supports start-up activities and handover of equipment and systems data from project to Operations team
Responsible for all Security Clearance and pass for engineering
To establish the pool of vendors that may support the projects, maintenance and turnaround activities
Carry out other ad-hoc duties assigned by the immediate supervisor or higher management
","['Security Clearance', 'Forecasting', 'Microsoft Excel', 'Interpersonal Skills', 'Production Planning', 'Supply Chain', 'Purchasing', 'Maintenance Planning and Scheduling', 'Planner', 'Procurement', 'Inventory Management', 'Equipment Maintenance', 'Demand Planning', 'Supply Chain Management', 'Scheduling', 'Manufacturing', 'Calibration']"
 , , , , , , , , , 
Data Analyst-User Growth Tiktok,1 RAFFLES QUAY 048583,Full Time,Professional,3 years exp,Engineering,Monthly,"$10,000to$20,000","Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc.

You will:

Build and governing matrices for fast changing business in an analytical data-driven approach to identify business issues and opportunities;
Prototype analysis pipelines to provide insights, and provide quick responses to business inquiries and events;
Conduct routine and non-routine end-to-end analyses with large, complex data sets, and make recommendation on appropriate solutions.


Qualifications

Bachelor's degree in Statistics, Applied Mathematics, Computer Science or a related field;
Skilled in data manipulation with SQL, python or other programming-languages/tools;
Experienced in data analyzing, visualization and reporting;
Fast business understanding and collaborative in teamwork.


TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.","['Data Analysis', 'Big Data', 'Pipelines', 'Data Quality', 'SQL', 'Attention to Detail', 'Python', 'Statistics', 'Data Science', 'Visualization', 'Data Analytics', 'Applied Mathematics']"
Research Engineer / Fellow (5G-Powered Intelligent Data-Driven Electric Vehicle) - ZW,10 DOVER DRIVE 138683,Contract,Junior Executive,2 years exp,Others,Monthly,"$3,600to$6,000","The Singapore Institute of Technology (SIT) is a public autonomous university and the third largest university by intake in Singapore. SIT’s mission is to innovate with industry, through an integrated applied learning and research approach, so as to contribute to the economy and society. Singapore is the small city with a big dream. We are home to the best talent and have the world’s highest per capital investment in science and technology.

We have an opening for Research Fellow or Research Engineer. The selected applicant is expected to lead and pursue high-quality research in applied artificial intelligence and sustainability that lead to publications in top-tier international conferences and journals, as well as real-world implementations. If interested, please send your resume including a cover letter, CV and a brief statement of your work undertaken in previous work.

Key Responsibilities:

Collaborate with partners from both the academia and the industry to lead and/or conduct innovative research on, but not limited to 5G, AI, sustainability, etc.
Contribute to academic research in the relevant domains and publish high-tier journal papers and conference papers.
Participate in and manage the research project with Principal Investigator (PI) to ensure all project deliverables are met.
Coordinate procurement and liaison with vendors/suppliers.
Participate in computer science related laboratories and tutorials for undergraduate students.
Interview and supervise student assistants in the project.

Job Requirements:

(Research Fellow) PhD in Computer Science or a related field
(Research Engineer) Bachelor/Master degree in Computer Science or a related field
Proven ability to conduct independent research with a relevant publication record
Outstanding data analytics, mathematical, and computer modelling skills
Excellent interpersonal communication and oral presentation skills in English
Self-driven and strong team spirit
Open to fixed-term contract (renewable upon review of satisfactory performance)
","['Sustainability', 'Academia', 'Artificial Intelligence', 'Team Spirit', 'Procurement', 'Artificial Intelligence Application', 'Presentation Skills', 'Capital', 'Publications', 'PhD thesis', 'Data Analytics', 'Technology']"
2812 - Performance Marketing Executive [ Accounting Firm  /  SEO  /  SEM  /  Performance  /  Data  /  Google Ads  /  Paid Capital ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,1 year exp,Marketing / Public Relations,Monthly,"$2,500to$5,000","Performance Marketing Executive

Working Days: 5 Days [9am - 6pm]
Location: Bukit Batok 
Salary: Basic up to $2500 + bonus / lead [ Gross can hit $4k-$5k]

Requirements:

1 year experience in doing SEO / SEM

Jobs Scope:

Performance Marketing: To use all available conversion data to make informed decisions in optimizing PPC campaigns not limited to Google Ads & Facebook Ads. Ensuring to hit main KPIs such as Driver Leads, Customer Acquisition, Business Leads, Cost Per Lead, and Cost Per Acquisition, within the given budget
SEO: To be able to get the company’s website on 1st page of Google.
Data Driven:  To analyze and utilize existing data from various tools and platforms on hand to make informed decisions. Creating end-to-end marketing campaigns based on data research and analysis
Expert in Google Ads & Paid Social: Have hands-on execution experience in managing Google Ads, Facebook Ads, and other paid social platforms
Test & Learn Mentality:  To be open enough to try new channels & learn from them. A/B testing targeting, strategies and creatives.
Problem-solver: To be able to find creative online campaigns to move User and Driver Acquisition numbers.
User Empathy: To be able to think from a perspective of a user or a driver & build seamless user journeys.
","['Market Research', 'SEM', 'Website Development', 'Social Media', 'Targeting', 'Project Planning', 'Marketing', 'Customer Acquisition', 'Adobe Illustrator', 'Ab Testing', 'SEO', 'PPC', 'Adobe Photoshop', 'Brand Awareness']"
2812 - Performance Marketing Executive [ Accounting Firm  /  SEO  /  SEM  /  Performance  /  Data  /  Google Ads  /  Paid Capital ],"SHENTON HOUSE, 3 SHENTON WAY 068805","Permanent, Full Time",Junior Executive,1 year exp,Marketing / Public Relations,Monthly,"$2,500to$5,000","Performance Marketing Executive

Working Days: 5 Days [9am - 6pm]
Location: Bukit Batok 
Salary: Basic up to $2500 + bonus / lead [ Gross can hit $4k-$5k]

Requirements:

1 year experience in doing SEO / SEM

Jobs Scope:

Performance Marketing: To use all available conversion data to make informed decisions in optimizing PPC campaigns not limited to Google Ads & Facebook Ads. Ensuring to hit main KPIs such as Driver Leads, Customer Acquisition, Business Leads, Cost Per Lead, and Cost Per Acquisition, within the given budget
SEO: To be able to get the company’s website on 1st page of Google.
Data Driven:  To analyze and utilize existing data from various tools and platforms on hand to make informed decisions. Creating end-to-end marketing campaigns based on data research and analysis
Expert in Google Ads & Paid Social: Have hands-on execution experience in managing Google Ads, Facebook Ads, and other paid social platforms
Test & Learn Mentality:  To be open enough to try new channels & learn from them. A/B testing targeting, strategies and creatives.
Problem-solver: To be able to find creative online campaigns to move User and Driver Acquisition numbers.
User Empathy: To be able to think from a perspective of a user or a driver & build seamless user journeys.
","['Market Research', 'SEM', 'Website Development', 'Social Media', 'Targeting', 'Project Planning', 'Marketing', 'Customer Acquisition', 'Adobe Illustrator', 'Ab Testing', 'SEO', 'PPC', 'Adobe Photoshop', 'Brand Awareness']"
 , , , , , , , , , 
Data Administrator  /  East  /  6k,"PLUS, 20 CECIL STREET 049705",Contract,Professional,5 years exp,Information Technology,Monthly,"$5,000to$6,000","Industry : IT
Location : East
Working Hours : 9am to 6pm
Salary Range : Up to S$6,000 Per month
Responsibilities:

Maintain high availability and reliability of databases
Perform database change request as submitted from Users and validating their request
Devise and perform database backup and recovery strategies
Perform database creation, patches, configuration, migration and version upgrades
Perform database replication, log shipping, mirroring for DR, reporting and operational
Perform troubleshooting and resolution of issues in the various database environment that our systems are deploy in
Interact with the internal users to understand requests/issues, establish clear expectations, and provide effective communication throughout the support process
Work with other members to manage the various databases to work out an acceptable solution
Performing analysis of request/support items to identify trends and/or areas for the implementation of automation efficiencies
Design and build automation solutions to reduce manual efforts and increase team efficiency
Providing visibility into metrics in the operations and support process
Problem Solving/Issue resolution
Manage multiple projects simultaneously and able to adapt to changing business needs
Be the subject matter expert for assigned specializations. Publish, improve and maintain technical documentation along with processes and procedures.
Work well with cross functional global and remote teams
Responsible to maximise database up-time and ensuring functional and performance SLAs
Worked in an operational support role with after hours on call responsibilities
Any other jobs assigned by your supervisors


Requirements:

Diploma in relevant discipline or field
At least 5 years of relevant working experience in database administration and support
Proficient understanding/experience preferred:
Experience in SQL Server 2008 R2, 2012, 2014, 2016, 2017
Experience in Oracle
Experience in MYSQL
Experience in AWS RDS, Azure Database, Azure Runbook
Experience in TSQL Scripting
Experience in troubleshooting, diagnose and recover from Database failure
Ability to manage daily support activities to ensure completion of operational requests within agreed Service Level Objectives
Ability to work in a collaborative, cross-team to ensure successful management of operational/support tasks
Ability to multi tasks and work under pressure environment
Ability to think and act with an “automation” with security and compliance mindset to problem-solving
Strong focus on customer satisfaction and experience
Strong written and oral communication skills


Job ID: QX66YW6R
Please submit your updated resume in Word format by using the Apply Now Button.
We regret that only shortlisted candidates will be notified

Email resume to reeve.lim@peopleprofilers.com
People Profilers Pte Ltd, 20 Cecil Street, #08-09, PLUS Building, Singapore 049705.
Tel: 6950 9740 / 9640 5305
http://www.peopleprofilers.com

EA License Number: 02C4944
Registration Number: R1330005
Posting Personnel: Reeve Lim Kok Kiong","['RDS', 'Cecil', 'Troubleshooting', 'Oracle', 'High Availability', 'MySQL', 'Scripting', 'Reliability', 'Replication', 'SQL', 'Database Administration', 'SQL Server', 'Databases']"