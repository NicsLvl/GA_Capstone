{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.10 from \"/usr/local/bin/python3\"\n  * The NumPy version is: \"1.21.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/nick/Github/would_you_like_some_fries_with_that/random.ipynb Cell 1\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nick/Github/would_you_like_some_fries_with_that/random.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nick/Github/would_you_like_some_fries_with_that/random.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nick/Github/would_you_like_some_fries_with_that/random.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nick/Github/would_you_like_some_fries_with_that/random.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshapely\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeometry\u001b[39;00m \u001b[39mimport\u001b[39;00m shape, Point\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/__init__.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m         _missing_dependencies\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_dependency\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_e\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m _missing_dependencies:\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to import required dependencies:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[39m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.10 from \"/usr/local/bin/python3\"\n  * The NumPy version is: \"1.21.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from shapely.geometry import shape, Point\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code = '730520'\n",
    "url = f\"https://developers.onemap.sg/commonapi/search?searchVal={postal_code}&returnGeom=Y&getAddrDetails=N&pageNum=1\"\n",
    "data = requests.get(url).json()    \n",
    "latitude = data['results'][0]['LATITUDE']\n",
    "longitude = data['results'][0]['LONGITUDE']\n",
    "# convert to float\n",
    "latitude = float(latitude)\n",
    "longitude = float(longitude)\n",
    "searchval = data['results'][0]['SEARCHVAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_list = [2,1,0.5,0.2]\n",
    "with open(\"pickles/bus_data.pkl\", \"rb\") as f:\n",
    "    bus_data = pickle.load(f)\n",
    "with open(\"pickles/location_df.pkl\", \"rb\") as f:\n",
    "    location_df = pickle.load(f)\n",
    "with open(\"pickles/subzone_names.pkl\", \"rb\") as f:\n",
    "    subzone_names = pickle.load(f)\n",
    "with open(\"pickles/polygons.pkl\", \"rb\") as f:\n",
    "    polygons = pickle.load(f)\n",
    "with open(\"pickles/polygons_coord.pkl\", \"rb\") as f:\n",
    "    polygons_coord = pickle.load(f)\n",
    "with open(\"pickles/RF.pkl\", \"rb\") as f:\n",
    "    RF = pickle.load(f)\n",
    "# with open(\"pickles/column_list.pkl\", \"rb\") as f:\n",
    "#     column_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which subzone the point is in\n",
    "point = Point(longitude, latitude)\n",
    "for j, polygon in enumerate(polygons_coord):\n",
    "    if polygon.contains(point):\n",
    "        sz = subzone_names[j]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_traffic_count(lat, long, stop_df, bus_data, distance_list):\n",
    "        \n",
    "        # create an empty numpy array\n",
    "        to_df_array = np.empty((0,384))\n",
    "\n",
    "        # create an empty 5082 x 4 numpy array\n",
    "        traffic_array = np.zeros((len(stop_df), len(distance_list)))\n",
    "        \n",
    "        for stop in range(len(stop_df)):\n",
    "            dist = geodesic((stop_df['latitude'][stop], stop_df['longitude'][stop]), \\\n",
    "                            (lat, long)).km\n",
    "            if dist<distance_list[0]:\n",
    "                traffic_array[stop,0] = 1\n",
    "                if dist<distance_list[1]:\n",
    "                    traffic_array[stop,1] = 1\n",
    "                    if dist<distance_list[2]:\n",
    "                        traffic_array[stop,2] = 1\n",
    "                        if dist<distance_list[3]:\n",
    "                            traffic_array[stop,3] = 1\n",
    "        \n",
    "        # multiply the 2 arrays to get a 96 x 4 array\n",
    "        mcd_array = np.dot(bus_data,traffic_array)\n",
    "\n",
    "        # convert mcd_array to a 1 x 384 array by unstacking the rows\n",
    "        mcd_array = mcd_array.reshape(1, -1)\n",
    "\n",
    "        # add it to the empty array\n",
    "        to_df_array = np.append(to_df_array, mcd_array, axis=0)\n",
    "        print(f'Number of McDonalds done: {len(to_df_array)}')\n",
    "        \n",
    "        return to_df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of McDonalds done: 1\n"
     ]
    }
   ],
   "source": [
    "# multiply the bus_data 96 x 5082 matrix by a 5082 x 4 (distance_list) matrix to get a 96 x 4 matrix for each Coordinates\n",
    "coord_list = single_traffic_count(latitude, longitude,location_df,bus_data,distance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_df = pd.read_csv('data/hdb_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the subzone data\n",
    "sz_pop_area_df = pd.read_csv('data/sz_pop_area.csv',index_col=0)\n",
    "# ignore index when importing the income data\n",
    "sz_income_df = pd.read_csv('data/sz_income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_density = sz_pop_area_df[sz_pop_area_df['subzone']==sz]['density'].values[0]\n",
    "sz_pop = sz_pop_area_df[sz_pop_area_df['subzone']==sz]['Hse'].values[0]\n",
    "sz_income = sz_income_df[sz_income_df['SZ']==sz]['sz_income'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_num_count(distance, latitude, longitude, hdb_df):\n",
    "        # input a value of \"1\" in the matrix if the distance between the bus stop and mcd is less than the distance specified\n",
    "        count=0\n",
    "        for hdb in range(len(hdb_df)):\n",
    "            dist = geodesic((hdb_df['latitude'][hdb], hdb_df['longitude'][hdb]), \\\n",
    "                            (latitude, longitude)).km\n",
    "            if dist < distance:\n",
    "                count+=1\n",
    "        \n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the run for distance 1km\n",
      "Successfully finished for distance 1km\n",
      "This is the run for distance 0.5km\n",
      "Successfully finished for distance 0.5km\n",
      "This is the run for distance 0.2km\n",
      "Successfully finished for distance 0.2km\n"
     ]
    }
   ],
   "source": [
    "hdb_data = []\n",
    "# Get the num_hdb feature data\n",
    "for i in distance_list[1:]:\n",
    "    print(f'This is the run for distance {i}km')\n",
    "    \n",
    "    # this function initiates the dataframe based on the length of mcd_df and then computes the number of X within the distance\n",
    "    # the columns of the item to be counted must be 'latitude' and 'longitude'\n",
    "\n",
    "    result = single_num_count(i,latitude, longitude,hdb_df)\n",
    "    hdb_data.append(result)\n",
    "    print(f'Successfully finished for distance {i}km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = coord_list[0][28]\n",
    "b = coord_list[0][378]\n",
    "c = coord_list[0][26]\n",
    "d = coord_list[0][194]\n",
    "e = coord_list[0][22]\n",
    "f = coord_list[0][286]\n",
    "g = coord_list[0][122]\n",
    "h = sz_income\n",
    "i = coord_list[0][142]\n",
    "j = coord_list[0][277]\n",
    "k = coord_list[0][281]\n",
    "l = sz_pop\n",
    "m = hdb_data[0]\n",
    "n = coord_list[0][100]\n",
    "o = coord_list[0][130]\n",
    "p = coord_list[0][285]\n",
    "q = coord_list[0][138]\n",
    "r = coord_list[0][108]\n",
    "s = coord_list[0][374]\n",
    "t = coord_list[0][118]\n",
    "u = coord_list[0][381]\n",
    "v = coord_list[0][289]\n",
    "w = coord_list[0][299]\n",
    "x = coord_list[0][382]\n",
    "y = coord_list[0][298]\n",
    "z = coord_list[0][292]\n",
    "aa = coord_list[0][42]\n",
    "ab = coord_list[0][282]\n",
    "ac = coord_list[0][24]\n",
    "ad = coord_list[0][274]\n",
    "ae = coord_list[0][193]\n",
    "af = sz_density\n",
    "ag = coord_list[0][5]\n",
    "ah = coord_list[0][293]\n",
    "ai = coord_list[0][4]\n",
    "aj = coord_list[0][302]\n",
    "ak = coord_list[0][196]\n",
    "al = hdb_data[2]\n",
    "am = coord_list[0][377]\n",
    "an = coord_list[0][129]\n",
    "ao = coord_list[0][278]\n",
    "ap = hdb_data[1]\n",
    "aq = coord_list[0][290]\n",
    "ar = coord_list[0][132]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined all the letters into an array for machine learning predicting \n",
    "test = np.array([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar])\n",
    "test = test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the location selected is FRAGRANT WOODS\n",
      "If a McDonalds were to be built here it would be priced Low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_result = RF.predict(test)[0]\n",
    "print(f'the location selected is {searchval}')\n",
    "print(f'If a McDonalds were to be built here it would be priced {top_result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
