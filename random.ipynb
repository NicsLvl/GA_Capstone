{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from shapely.geometry import shape, Point\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code = '730520'\n",
    "url = f\"https://developers.onemap.sg/commonapi/search?searchVal={postal_code}&returnGeom=Y&getAddrDetails=N&pageNum=1\"\n",
    "data = requests.get(url).json()    \n",
    "latitude = data['results'][0]['LATITUDE']\n",
    "longitude = data['results'][0]['LONGITUDE']\n",
    "# convert to float\n",
    "latitude = float(latitude)\n",
    "longitude = float(longitude)\n",
    "searchval = data['results'][0]['SEARCHVAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/vxq64h_j3ydccspj69p0_4_c0000gn/T/ipykernel_78022/2708155112.py:11: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
      "  polygons_coord = pickle.load(f)\n",
      "/Users/nick/anaconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nick/anaconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nick/anaconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator Pipeline from version 1.1.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nick/anaconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.1.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "distance_list = [2,1,0.5,0.2]\n",
    "with open(\"pickles/bus_data.pkl\", \"rb\") as f:\n",
    "    bus_data = pickle.load(f)\n",
    "with open(\"pickles/location_df.pkl\", \"rb\") as f:\n",
    "    location_df = pickle.load(f)\n",
    "with open(\"pickles/subzone_names.pkl\", \"rb\") as f:\n",
    "    subzone_names = pickle.load(f)\n",
    "with open(\"pickles/polygons.pkl\", \"rb\") as f:\n",
    "    polygons = pickle.load(f)\n",
    "with open(\"pickles/polygons_coord.pkl\", \"rb\") as f:\n",
    "    polygons_coord = pickle.load(f)\n",
    "with open(\"pickles/RF.pkl\", \"rb\") as f:\n",
    "    RF = pickle.load(f)\n",
    "# with open(\"pickles/column_list.pkl\", \"rb\") as f:\n",
    "#     column_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which subzone the point is in\n",
    "point = Point(longitude, latitude)\n",
    "for j, polygon in enumerate(polygons_coord):\n",
    "    if polygon.contains(point):\n",
    "        sz = subzone_names[j]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_traffic_count(lat, long, stop_df, bus_data, distance_list):\n",
    "        \n",
    "        # create an empty numpy array\n",
    "        to_df_array = np.empty((0,384))\n",
    "\n",
    "        # create an empty 5082 x 4 numpy array\n",
    "        traffic_array = np.zeros((len(stop_df), len(distance_list)))\n",
    "        \n",
    "        for stop in range(len(stop_df)):\n",
    "            dist = geodesic((stop_df['latitude'][stop], stop_df['longitude'][stop]), \\\n",
    "                            (lat, long)).km\n",
    "            if dist<distance_list[0]:\n",
    "                traffic_array[stop,0] = 1\n",
    "                if dist<distance_list[1]:\n",
    "                    traffic_array[stop,1] = 1\n",
    "                    if dist<distance_list[2]:\n",
    "                        traffic_array[stop,2] = 1\n",
    "                        if dist<distance_list[3]:\n",
    "                            traffic_array[stop,3] = 1\n",
    "        \n",
    "        # multiply the 2 arrays to get a 96 x 4 array\n",
    "        mcd_array = np.dot(bus_data,traffic_array)\n",
    "\n",
    "        # convert mcd_array to a 1 x 384 array by unstacking the rows\n",
    "        mcd_array = mcd_array.reshape(1, -1)\n",
    "\n",
    "        # add it to the empty array\n",
    "        to_df_array = np.append(to_df_array, mcd_array, axis=0)\n",
    "        print(f'Number of McDonalds done: {len(to_df_array)}')\n",
    "        \n",
    "        return to_df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of McDonalds done: 1\n"
     ]
    }
   ],
   "source": [
    "# multiply the bus_data 96 x 5082 matrix by a 5082 x 4 (distance_list) matrix to get a 96 x 4 matrix for each Coordinates\n",
    "coord_list = single_traffic_count(latitude, longitude,location_df,bus_data,distance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_df = pd.read_csv('data/hdb_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the subzone data\n",
    "sz_pop_area_df = pd.read_csv('data/sz_pop_area.csv',index_col=0)\n",
    "# ignore index when importing the income data\n",
    "sz_income_df = pd.read_csv('data/sz_income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_density = sz_pop_area_df[sz_pop_area_df['subzone']==sz]['density'].values[0]\n",
    "sz_pop = sz_pop_area_df[sz_pop_area_df['subzone']==sz]['Hse'].values[0]\n",
    "sz_income = sz_income_df[sz_income_df['SZ']==sz]['sz_income'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_num_count(distance, latitude, longitude, hdb_df):\n",
    "        # input a value of \"1\" in the matrix if the distance between the bus stop and mcd is less than the distance specified\n",
    "        count=0\n",
    "        for hdb in range(len(hdb_df)):\n",
    "            dist = geodesic((hdb_df['latitude'][hdb], hdb_df['longitude'][hdb]), \\\n",
    "                            (latitude, longitude)).km\n",
    "            if dist < distance:\n",
    "                count+=1\n",
    "        \n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the run for distance 1km\n",
      "Successfully finished for distance 1km\n",
      "This is the run for distance 0.5km\n",
      "Successfully finished for distance 0.5km\n",
      "This is the run for distance 0.2km\n",
      "Successfully finished for distance 0.2km\n"
     ]
    }
   ],
   "source": [
    "hdb_data = []\n",
    "# Get the num_hdb feature data\n",
    "for i in distance_list[1:]:\n",
    "    print(f'This is the run for distance {i}km')\n",
    "    \n",
    "    # this function initiates the dataframe based on the length of mcd_df and then computes the number of X within the distance\n",
    "    # the columns of the item to be counted must be 'latitude' and 'longitude'\n",
    "\n",
    "    result = single_num_count(i,latitude, longitude,hdb_df)\n",
    "    hdb_data.append(result)\n",
    "    print(f'Successfully finished for distance {i}km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = coord_list[0][28]\n",
    "b = coord_list[0][378]\n",
    "c = coord_list[0][26]\n",
    "d = coord_list[0][194]\n",
    "e = coord_list[0][22]\n",
    "f = coord_list[0][286]\n",
    "g = coord_list[0][122]\n",
    "h = sz_income\n",
    "i = coord_list[0][142]\n",
    "j = coord_list[0][277]\n",
    "k = coord_list[0][281]\n",
    "l = sz_pop\n",
    "m = hdb_data[0]\n",
    "n = coord_list[0][100]\n",
    "o = coord_list[0][130]\n",
    "p = coord_list[0][285]\n",
    "q = coord_list[0][138]\n",
    "r = coord_list[0][108]\n",
    "s = coord_list[0][374]\n",
    "t = coord_list[0][118]\n",
    "u = coord_list[0][381]\n",
    "v = coord_list[0][289]\n",
    "w = coord_list[0][299]\n",
    "x = coord_list[0][382]\n",
    "y = coord_list[0][298]\n",
    "z = coord_list[0][292]\n",
    "aa = coord_list[0][42]\n",
    "ab = coord_list[0][282]\n",
    "ac = coord_list[0][24]\n",
    "ad = coord_list[0][274]\n",
    "ae = coord_list[0][193]\n",
    "af = sz_density\n",
    "ag = coord_list[0][5]\n",
    "ah = coord_list[0][293]\n",
    "ai = coord_list[0][4]\n",
    "aj = coord_list[0][302]\n",
    "ak = coord_list[0][196]\n",
    "al = hdb_data[2]\n",
    "am = coord_list[0][377]\n",
    "an = coord_list[0][129]\n",
    "ao = coord_list[0][278]\n",
    "ap = hdb_data[1]\n",
    "aq = coord_list[0][290]\n",
    "ar = coord_list[0][132]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined all the letters into an array for machine learning predicting \n",
    "test = np.array([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar])\n",
    "test = test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the location selected is FRAGRANT WOODS\n",
      "If a McDonalds were to be built here it would be priced Low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_result = RF.predict(test)[0]\n",
    "print(f'the location selected is {searchval}')\n",
    "print(f'If a McDonalds were to be built here it would be priced {top_result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
